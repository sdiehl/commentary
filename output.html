<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
  <title></title>
  <style type="text/css">code{white-space: pre;}</style>
</head>
<body>
<div id="TOC">
<ul>
<li><a href="#ghc-source-code-abbreviations">GHC Source Code Abbreviations</a></li>
<li><a href="#aging-in-the-generational-gc">Aging in the generational GC</a></li>
<li><a href="#improving-llvm-alias-analysis">Improving LLVM Alias Analysis</a><ul>
<li><a href="#llvm-alias-analysis-infrastructure">LLVM Alias Analysis Infrastructure</a></li>
<li><a href="#maxs-work">Max's Work</a></li>
<li><a href="#tbaa">TBAA</a></li>
<li><a href="#stg-cmm-alias-properties">STG / Cmm Alias Properties</a></li>
<li><a href="#how-to-track-tbaa-information">How to Track TBAA information</a></li>
<li><a href="#llvm-type-system">LLVM type system</a></li>
<li><a href="#problems-optmisations-to-solve">Problems / Optmisations to Solve</a><ul>
<li><a href="#llvm-optimisations">LLVM Optimisations</a></li>
<li><a href="#safe-loads-speculative-load">Safe Loads (speculative load)</a></li>
<li><a href="#ghc-heap-check-case-merging">GHC Heap Check (case merging)</a></li>
</ul></li>
</ul></li>
<li><a href="#ghc-commentary-the-ghc-api">GHC Commentary: The GHC API</a><ul>
<li><a href="#targets">Targets</a></li>
<li><a href="#dependency-analysis">Dependency Analysis</a></li>
<li><a href="#the-modsummary-type">The !ModSummary type</a></li>
<li><a href="#loading-compiling-the-modules">Loading (compiling) the Modules</a></li>
</ul></li>
<li><a href="#ghc-commentary-asynchronous-exceptions">GHC Commentary: Asynchronous Exceptions</a></li>
<li><a href="#ghc-commentary-backends">GHC Commentary: Backends</a></li>
<li><a href="#types-in-the-back-end-aka-the-rep-swamp">Types in the back end (aka &quot;The `Rep` swamp&quot;)</a><ul>
<li><a href="#cmmtype">`CmmType`</a></li>
<li><a href="#the-machop-type">The `MachOp` type</a></li>
<li><a href="#foreign-calls-and-hints">Foreign calls and hints</a></li>
<li><a href="#native-code-generation-and-the-size-type">Native code generation and the `Size` type</a></li>
</ul></li>
<li><a href="#the-block-allocator">The Block Allocator</a><ul>
<li><a href="#structure-of-blocks">Structure of blocks</a></li>
</ul></li>
<li><a href="#ghc-commentary-garbage-collecting-cafs">GHC Commentary: Garbage Collecting CAFs</a><ul>
<li><a href="#static-reference-tables">Static Reference Tables</a></li>
<li><a href="#evacuating-static-objects">Evacuating Static Objects</a></li>
</ul></li>
<li><a href="#calling-convention">Calling Convention</a></li>
<li><a href="#return-convention">Return Convention</a><ul>
<li><a href="#historical-page">Historical page</a></li>
</ul></li>
<li><a href="#cleanup-after-the-new-codegen-is-enabled">Cleanup after the new codegen is enabled</a><ul>
<li><a href="#independent-tasks">Independent tasks</a></li>
<li><a href="#towards-removing-codegencg">Towards removing codeGen/Cg*</a></li>
<li><a href="#towards-removing-oldcmm">Towards removing `OldCmm`</a></li>
<li><a href="#later">Later</a></li>
</ul></li>
<li><a href="#cmm-implementing-exception-handling">Cmm: Implementing Exception Handling</a><ul>
<li><a href="#note-to-reader">Note To Reader</a></li>
</ul></li>
<li><a href="#table-of-contents">Table of Contents</a></li>
<li><a href="#the-cmm-language">The Cmm language</a><ul>
<li><a href="#additions-in-cmm">Additions in Cmm</a></li>
<li><a href="#compiling-cmm-with-ghc">Compiling Cmm with GHC</a></li>
<li><a href="#basic-cmm">Basic Cmm</a><ul>
<li><a href="#code-blocks-in-cmm">Code Blocks in Cmm</a></li>
<li><a href="#variables-registers-and-types">Variables, Registers and Types</a></li>
<li><a href="#literals-and-labels">Literals and Labels</a></li>
<li><a href="#sections-and-directives">Sections and Directives</a></li>
<li><a href="#expressions">Expressions</a></li>
<li><a href="#statements-and-calls">Statements and Calls</a></li>
<li><a href="#operators-and-primitive-operations">Operators and Primitive Operations</a></li>
</ul></li>
<li><a href="#cmm-design-observations-and-areas-for-potential-improvement">Cmm Design: Observations and Areas for Potential Improvement</a></li>
</ul></li>
<li><a href="#ghc-commentary-what-the-hell-is-a-.cmm-file">GHC Commentary: What the hell is a `.cmm` file?</a><ul>
<li><a href="#reading-references">Reading references</a></li>
<li><a href="#other-information">Other information</a></li>
</ul></li>
<li><a href="#code-generator">Code Generator</a><ul>
<li><a href="#a-brief-history-of-code-generator">A brief history of code generator</a></li>
<li><a href="#overview">Overview</a></li>
<li><a href="#first-stage-stg-to-cmm-conversion">First stage: STG to Cmm conversion</a></li>
<li><a href="#second-stage-the-cmm-pipeline">Second stage: the Cmm pipeline</a></li>
<li><a href="#dumping-and-debugging-cmm">Dumping and debugging Cmm</a></li>
<li><a href="#register-allocator-code">Register Allocator Code</a><ul>
<li><a href="#the-register-allocator">The register allocator</a></li>
<li><a href="#graph-coloring">Graph coloring</a></li>
<li><a href="#miscellanea">Miscellanea</a></li>
</ul></li>
</ul></li>
<li><a href="#the-ghc-commentary---coding-style-guidelines-for-the-compiler">The GHC Commentary - Coding Style Guidelines for the compiler</a><ul>
<li><a href="#general-style">General Style</a></li>
<li><a href="#comments">Comments</a><ul>
<li><a href="#comments-on-top-level-entities">Comments on top-level entities</a></li>
<li><a href="#comments-in-the-source-code">Comments in the source code</a></li>
<li><a href="#comments-and-examples">Comments and examples</a></li>
<li><a href="#longer-comments-or-architectural-commentary">Longer comments or architectural commentary</a></li>
<li><a href="#commit-messages">Commit messages</a></li>
</ul></li>
<li><a href="#warnings">Warnings</a></li>
<li><a href="#exports-and-imports">Exports and Imports</a><ul>
<li><a href="#exports">Exports</a></li>
<li><a href="#imports">Imports</a></li>
</ul></li>
<li><a href="#compiler-versions-and-language-extensions">Compiler versions and language extensions</a><ul>
<li><a href="#section"></a></li>
<li><a href="#literate-haskell">Literate Haskell</a></li>
<li><a href="#the-c-preprocessor-cpp">The C Preprocessor (CPP)</a></li>
<li><a href="#platform-tests">Platform tests</a></li>
</ul></li>
<li><a href="#tabs-vs-spaces">Tabs vs Spaces</a></li>
</ul></li>
<li><a href="#coercions-in-ghcs-core-language">Coercions in GHC's core language</a><ul>
<li><a href="#difficulties-with-the-current-approach">Difficulties with the current approach</a></li>
<li><a href="#main-proposal">Main proposal</a></li>
</ul></li>
<li><a href="#parsing-of-command-line-arguments">Parsing of command line arguments</a><ul>
<li><a href="#static-flags">Static flags</a></li>
<li><a href="#dynamic-flags">Dynamic flags</a></li>
</ul></li>
<li><a href="#the-ghc-commentary">The GHC Commentary</a><ul>
<li><a href="#editing-the-commentary">Editing the Commentary</a></li>
<li><a href="#contents">Contents</a></li>
<li><a href="#contributed-documentation">Contributed Documentation</a></li>
</ul></li>
<li><a href="#compiler-and-runtime-system-ways-in-ghc">Compiler and runtime system ways in GHC</a><ul>
<li><a href="#available-ways-in-a-standard-ghc">Available ways in a standard GHC</a><ul>
<li><a href="#ways-for-parallel-execution-on-clusters-and-multicores">Ways for parallel execution on clusters and multicores</a></li>
</ul></li>
<li><a href="#combining-ways">Combining ways</a></li>
</ul></li>
<li><a href="#internals">Internals</a></li>
<li><a href="#ghc-commentary-the-compiler">GHC Commentary: The Compiler</a><ul>
<li><a href="#overall-structure">Overall Structure</a></li>
<li><a href="#what-problems-do-we-need-to-solve">What problems do we need to solve?</a></li>
<li><a href="#current-mechanisms">Current mechanisms</a></li>
<li><a href="#new-concepts-for-backpack">New concepts for Backpack</a></li>
<li><a href="#features">Features</a></li>
<li><a href="#constraints">Constraints</a></li>
</ul></li>
<li><a href="#rts-configurations">RTS Configurations</a><ul>
<li><a href="#combinations">Combinations</a></li>
<li><a href="#other-configuration-options">Other configuration options</a></li>
</ul></li>
<li><a href="#contracts-for-haskell">Contracts for Haskell</a><ul>
<li><a href="#involved">Involved</a></li>
<li><a href="#overview-1">Overview</a></li>
<li><a href="#the-plan">The plan</a></li>
<li><a href="#current-status">Current status</a></li>
<li><a href="#questions">Questions</a></li>
<li><a href="#references">References</a></li>
</ul></li>
<li><a href="#the-ghc-commentary-coding-style-guidelines-for-rts-c-code">The GHC Commentary: Coding Style Guidelines for RTS C code</a><ul>
<li><a href="#comments-1">Comments</a></li>
<li><a href="#references-1">References</a></li>
<li><a href="#portability-issues">Portability issues</a><ul>
<li><a href="#which-c-standard">Which C Standard?</a></li>
<li><a href="#other-portability-conventions">Other portability conventions</a></li>
</ul></li>
<li><a href="#debuggingrobustness-tricks">Debugging/robustness tricks</a></li>
<li><a href="#syntactic-details">Syntactic details</a></li>
<li><a href="#inline-functions">Inline functions</a></li>
<li><a href="#source-control-issues">Source-control issues</a></li>
</ul></li>
<li><a href="#copying-gc">Copying GC</a></li>
<li><a href="#the-type">The  type</a><ul>
<li><a href="#case-expressions">Case expressions</a></li>
<li><a href="#shadowing">Shadowing</a></li>
<li><a href="#human-readable-core-generation">Human readable Core generation</a></li>
</ul></li>
<li><a href="#cps-conversion">CPS Conversion</a><ul>
<li><a href="#overview-2">Overview</a></li>
<li><a href="#design-aspects">Design Aspects</a></li>
<li><a href="#simple-design">Simple Design</a></li>
<li><a href="#to-be-worked-out">To be worked out</a></li>
<li><a href="#pipeline">Pipeline</a></li>
<li><a href="#todo">TODO</a></li>
<li><a href="#current-pipeline">Current Pipeline</a><ul>
<li><a href="#section-1"></a></li>
</ul></li>
<li><a href="#non-cps-changes">Non-CPS Changes</a></li>
<li><a href="#notes">Notes</a></li>
<li><a href="#loopholes">Loopholes</a><ul>
<li><a href="#gc-blocks">GC Blocks</a></li>
<li><a href="#update-frames">Update Frames</a></li>
<li><a href="#user-defined-continuations">User defined continuations</a></li>
<li><a href="#branches-to-continuations">Branches to continuations</a></li>
</ul></li>
<li><a href="#not-in-scope-of-current-work">Not in Scope of Current Work</a><ul>
<li><a href="#static-reference-table-handling-srt">Static Reference Table Handling (SRT)</a></li>
<li><a href="#cmm-optimization-assumed-by-cps">Cmm Optimization assumed by CPS</a></li>
</ul></li>
<li><a href="#notes-on-future-development">Notes on future development</a><ul>
<li><a href="#handling-gc">Handling GC</a></li>
</ul></li>
</ul></li>
<li><a href="#the-ghc-commentary-data-types-and-data-constructors">The GHC Commentary: Data types and data constructors</a><ul>
<li><a href="#data-types">Data types</a></li>
</ul></li>
<li><a href="#the-life-cycle-of-a-data-type">The life cycle of a data type</a><ul>
<li><a href="#the-constructor-wrapper-functions">The constructor wrapper functions</a></li>
<li><a href="#the-constructor-worker-functions">The constructor worker functions</a></li>
<li><a href="#external-core">External Core</a></li>
<li><a href="#unboxing-strict-fields">Unboxing strict fields</a></li>
<li><a href="#labels-and-info-tables">Labels and info tables</a></li>
</ul></li>
<li><a href="#demand-analyser-in-ghc">Demand analyser in GHC</a><ul>
<li><a href="#demand-signatures">Demand signatures</a><ul>
<li><a href="#demand-descriptions">Demand descriptions</a></li>
</ul></li>
<li><a href="#worker-wrapper-split">Worker-Wrapper split</a></li>
<li><a href="#relevant-compiler-parts">Relevant compiler parts</a></li>
</ul></li>
<li><a href="#support-for-deriving-and-instances">Support for deriving , , and  instances</a><ul>
<li><a href="#example">Example</a></li>
<li><a href="#algorithm-description">Algorithm description</a><ul>
<li><a href="#section-2"></a></li>
<li><a href="#section-3"></a></li>
<li><a href="#section-4"></a></li>
<li><a href="#covariant-and-contravariant-positions">Covariant and contravariant positions</a></li>
</ul></li>
<li><a href="#requirements-for-legal-instances">Requirements for legal instances</a><ul>
<li><a href="#relaxed-universality-check-for">Relaxed universality check for </a></li>
</ul></li>
<li><a href="#alternative-strategy-for-deriving-foldable-and-traversable">Alternative strategy for deriving `Foldable` and `Traversable`</a></li>
</ul></li>
<li><a href="#llvm-back-end-design">LLVM Back-end Design</a></li>
<li><a href="#implementation">Implementation</a><ul>
<li><a href="#framework">Framework</a></li>
<li><a href="#llvm-code-generation">LLVM Code Generation</a></li>
<li><a href="#register-pinning">Register Pinning</a></li>
<li><a href="#code-generation">Code Generation</a><ul>
<li><a href="#unregisterised-vs.-registerised">Unregisterised Vs. Registerised</a></li>
</ul></li>
<li><a href="#cmmdata">!CmmData</a><ul>
<li><a href="#st-pass-generation">1st Pass : Generation</a></li>
</ul></li>
<li><a href="#cmmstaticlit">!CmmStaticLit</a><ul>
<li><a href="#nd-pass-resolution">2nd Pass : Resolution</a></li>
</ul></li>
<li><a href="#cmmproc">!CmmProc</a></li>
</ul></li>
<li><a href="#desugaring-instance-declarations">Desugaring instance declarations</a><ul>
<li><a href="#basic-stuff">Basic stuff</a></li>
<li><a href="#dictionary-functions">Dictionary functions</a></li>
<li><a href="#the-inline-strategy">The INLINE strategy</a></li>
<li><a href="#the-out-of-line-a-strategy">The out-of-line (A) strategy</a></li>
<li><a href="#the-out-of-line-b-strategy">The out-of-line (B) strategy</a></li>
<li><a href="#user-inline-pragmas-and-out-of-line-a">User INLINE pragmas and out-of-line (A)</a></li>
<li><a href="#summary">Summary</a></li>
</ul></li>
<li><a href="#bugs-other-problems">Bugs &amp; Other Problems</a></li>
<li><a href="#compiling-more-than-one-module-at-once">Compiling more than one module at once</a><ul>
<li><a href="#the-overall-driver">The overall driver</a><ul>
<li><a href="#dependency-analysis-1">Dependency analysis</a></li>
<li><a href="#recompilation-checking-and-stability">Recompilation checking and stability</a></li>
<li><a href="#compilation">Compilation</a></li>
</ul></li>
</ul></li>
<li><a href="#eager-promotion">Eager Promotion</a></li>
<li><a href="#eager-version-bumping-strategy">Eager Version Bumping Strategy</a></li>
<li><a href="#data-types-for-haskell-entities-and">Data types for Haskell entities: , , , , and </a><ul>
<li><a href="#type-variables-and-term-variables">Type variables and term variables</a></li>
<li><a href="#and-implict-ids"> and implict Ids</a></li>
</ul></li>
<li><a href="#hc-files-and-the-evil-mangler">HC files and the Evil Mangler</a></li>
<li><a href="#strictness-analysis-examples">Strictness analysis: examples</a></li>
<li><a href="#system-fc-equality-constraints-and-coercions">System FC: equality constraints and coercions</a><ul>
<li><a href="#coercions-and-coercion-kinds">Coercions and Coercion Kinds</a></li>
<li><a href="#gadts">GADTs</a></li>
<li><a href="#representation-of-coercion-assumptions">Representation of coercion assumptions</a></li>
<li><a href="#newtypes-are-coerced-types">Newtypes are coerced types</a></li>
<li><a href="#roles">Roles</a></li>
<li><a href="#simplification">Simplification</a></li>
</ul></li>
<li><a href="#ghc-commentary-runtime-aspects-of-the-ffi">GHC Commentary: Runtime aspects of the FFI</a><ul>
<li><a href="#foreign-import-wrapper">Foreign Import &quot;wrapper&quot;</a></li>
</ul></li>
<li><a href="#function-calls">Function Calls</a><ul>
<li><a href="#generic-apply">Generic apply</a></li>
</ul></li>
<li><a href="#the-garbage-collector">The Garbage Collector</a><ul>
<li><a href="#gc-overview">GC overview</a></li>
<li><a href="#gc-data-structures">GC data structures</a><ul>
<li><a href="#generation">generation</a></li>
<li><a href="#nursery">nursery</a></li>
</ul></li>
</ul></li>
<li><a href="#i-know-kung-fu-learning-stg-by-example">I know kung fu: learning STG by example</a><ul>
<li><a href="#what-is-stg-exactly">What is STG, exactly?</a></li>
<li><a href="#an-overview-of-the-stg-machine">An overview of the STG machine</a><ul>
<li><a href="#components-of-the-machine">Components of the machine</a></li>
<li><a href="#important-concepts-in-the-machine">Important concepts in the machine</a></li>
<li><a href="#overview-of-execution-model-of-the-machine">Overview of execution model of the machine</a></li>
</ul></li>
<li><a href="#saturated-application-to-known-functions">Saturated application to known functions</a><ul>
<li><a href="#example-1-function-application-with-sufficient-stack-space">Example 1: function application with sufficient stack space</a></li>
<li><a href="#example-2-function-application-that-needs-to-grow-the-stack">Example 2: function application that needs to grow the stack</a></li>
</ul></li>
<li><a href="#example-3-unsaturated-applications-to-known-functions">Example 3: Unsaturated applications to known functions</a></li>
<li><a href="#example-4-applications-to-unknown-functions">Example 4: Applications to unknown functions</a><ul>
<li><a href="#dealing-with-generic-application">Dealing with generic application</a></li>
<li><a href="#making-the-call-to-the-generic-application-code">Making the call to the generic application code</a></li>
</ul></li>
<li><a href="#example-5-oversaturated-applications-to-known-functions">Example 5: oversaturated applications to known functions</a></li>
<li><a href="#example-6-allocation-of-thunks-and-data">Example 6: allocation of thunks and data</a><ul>
<li><a href="#checking-for-sufficient-heap-space">Checking for sufficient heap space</a></li>
<li><a href="#performing-the-actual-allocation">Performing the actual allocation</a></li>
<li><a href="#returning-an-allocated-value-to-the-caller">Returning an allocated value to the caller</a></li>
</ul></li>
<li><a href="#example-7-case-expressions">Example 7: `case` expressions</a><ul>
<li><a href="#forcing-the-scrutinee-of-the-case">Forcing the scrutinee of the `case`</a></li>
<li><a href="#dealing-with-the-forced-scrutinee">Dealing with the forced scrutinee</a></li>
</ul></li>
<li><a href="#example-8-thunks-and-thunk-update">Example 8: thunks and thunk update</a><ul>
<li><a href="#thunk-entry-point">Thunk entry point</a></li>
<li><a href="#continuation-of-the-thunk">Continuation of the thunk</a></li>
</ul></li>
<li><a href="#conclusion">Conclusion</a></li>
</ul></li>
<li><a href="#support-for-generic-programming">Support for generic programming</a><ul>
<li><a href="#status">Status</a></li>
<li><a href="#main-components">Main components</a></li>
<li><a href="#things-that-have-been-removed">Things that have been removed</a></li>
<li><a href="#what-already-works">What already works</a></li>
<li><a href="#testing">Testing</a></li>
</ul></li>
<li><a href="#kind-polymorphic-overhaul">Kind polymorphic overhaul</a><ul>
<li><a href="#generic-representation-universe">Generic representation universe</a></li>
<li><a href="#universe-interpretation">Universe interpretation</a><ul>
<li><a href="#names">Names</a></li>
</ul></li>
<li><a href="#metadata-representation">Metadata representation</a></li>
<li><a href="#conversion-between-user-datatypes-and-generic-representation">Conversion between user datatypes and generic representation</a></li>
<li><a href="#example-generic-function-fmap-kind--">Example generic function: `fmap` (kind `* -&gt; *`)</a></li>
<li><a href="#example-generic-function-show-kind-uses-metadata">Example generic function: `show` (kind `*`, uses metadata)</a></li>
<li><a href="#example-datatype-encoding-lists-derived-by-the-compiler">Example datatype encoding: lists (derived by the compiler)</a><ul>
<li><a href="#digression">Digression</a></li>
</ul></li>
<li><a href="#ghc-8.0-and-later">GHC 8.0 and later</a><ul>
<li><a href="#type-level-metadata-encoding">Type-level metadata encoding</a></li>
<li><a href="#strictness">Strictness</a></li>
</ul></li>
<li><a href="#source-tree-layout">Source Tree Layout</a></li>
<li><a href="#build-system-basics">Build System Basics</a></li>
<li><a href="#coding-style">Coding Style</a></li>
</ul></li>
<li><a href="#the-ghc-commentary-ghci">The GHC Commentary: GHCi</a><ul>
<li><a href="#debugging-the-interpreter">Debugging the interpreter</a></li>
<li><a href="#useful-stuff-to-know-about-the-interpreter">Useful stuff to know about the interpreter</a><ul>
<li><a href="#stack-management">Stack management</a></li>
<li><a href="#building-constructors">Building constructors</a></li>
<li><a href="#perspective">Perspective</a></li>
</ul></li>
<li><a href="#case-returns-between-interpreted-and-compiled-code">case returns between interpreted and compiled code</a><ul>
<li><a href="#returning-to-interpreted-code.">Returning to interpreted code.</a></li>
<li><a href="#returning-to-compiled-code.">Returning to compiled code.</a></li>
</ul></li>
<li><a href="#unboxed-tuples-a-right-royal-spanner-in-the-works">Unboxed tuples: a Right Royal Spanner In The Works</a></li>
</ul></li>
<li><a href="#porting-ghc-using-llvm-backend">Porting GHC using LLVM backend</a><ul>
<li><a href="#registerised-mode">Registerised Mode</a></li>
</ul></li>
<li><a href="#packages-in-ghc">Packages in GHC</a><ul>
<li><a href="#the-problem">The problem</a></li>
<li><a href="#assumptions">Assumptions</a></li>
<li><a href="#the-open-question">The open question</a></li>
<li><a href="#plan-a-ghcs-current-story">Plan A: GHC's current story</a></li>
<li><a href="#plan-b-package-mounting">Plan B: package mounting</a></li>
<li><a href="#plan-c-mention-the-package-in-the-import">Plan C: mention the package in the import</a></li>
</ul></li>
<li><a href="#problems">Problems</a><ul>
<li><a href="#breaking-re-installations">Breaking re-installations</a></li>
<li><a href="#type-errors-when-using-packages-together">Type errors when using packages together</a></li>
</ul></li>
<li><a href="#goals">Goals</a></li>
<li><a href="#implementation-plan">Implementation Plan</a><ul>
<li><a href="#persistent-package-store">Persistent package store</a></li>
<li><a href="#views">Views</a></li>
<li><a href="#consistent-developer-environment">Consistent developer environment</a></li>
<li><a href="#garbage-collection">Garbage collection</a></li>
<li><a href="#cabal-remove">cabal remove</a></li>
<li><a href="#cabal-upgrade">cabal upgrade</a></li>
<li><a href="#current-status-1">Current Status</a><ul>
<li><a href="#unique-install-location">Unique Install Location</a></li>
<li><a href="#ghc-pkg">ghc-pkg</a></li>
<li><a href="#adhoc-dependency-resolution">Adhoc dependency resolution</a></li>
<li><a href="#detect-whether-an-overwrite-happens-and-warn-about-it">Detect whether an overwrite happens and warn about it</a></li>
<li><a href="#communicate-the-installedpackageid-back-to-cabal-install">Communicate the `InstalledPackageId` back to cabal-install</a></li>
<li><a href="#garbage-collection-1">Garbage Collection</a></li>
<li><a href="#about-shadowing">About Shadowing</a></li>
<li><a href="#about-unique-identifier">About Unique Identifier</a></li>
</ul></li>
<li><a href="#original-plan">Original Plan</a></li>
<li><a href="#hashes-and-identifiers">Hashes and identifiers</a></li>
<li><a href="#install-location-of-installed-cabal-packages">Install location of installed Cabal packages</a><ul>
<li><a href="#hash">Hash</a></li>
<li><a href="#unique-number">Unique number</a></li>
</ul></li>
<li><a href="#ghc-pkg-1">`ghc-pkg`</a></li>
<li><a href="#simplistic-dependency-resolution">Simplistic dependency resolution</a></li>
<li><a href="#build-flavours">Build flavours</a><ul>
<li><a href="#the-cabal-hash">The Cabal hash</a></li>
<li><a href="#released-and-unreleased-packages">Released and Unreleased packages</a></li>
</ul></li>
<li><a href="#dependency-resolution-in-cabal-install">Dependency resolution in cabal-install</a></li>
<li><a href="#garbage-collection-2">Garbage Collection</a></li>
<li><a href="#currently-open-design-decisions">Currently open design decisions</a><ul>
<li><a href="#installedpackageid-and-install-path">`InstalledPackageId` and install path</a></li>
<li><a href="#handling-of-dirty-builds">Handling of dirty builds</a></li>
<li><a href="#build-flavours-1">Build flavours</a></li>
<li><a href="#installedpackageinfo-and-solver-algorithm">`InstalledPackageInfo` and solver algorithm</a></li>
<li><a href="#simplistic-dependency-resolution-1">Simplistic dependency resolution</a></li>
</ul></li>
<li><a href="#related-topics">Related topics</a><ul>
<li><a href="#separating-storage-and-selection-of-packages">Separating storage and selection of packages</a></li>
<li><a href="#first-class-environments">First class environments</a></li>
</ul></li>
<li><a href="#questions-to-remember">Questions to remember</a></li>
</ul></li>
<li><a href="#the-haskell-execution-model">The Haskell Execution Model</a></li>
<li><a href="#heap_alloced">HEAP_ALLOCED</a><ul>
<li><a href="#speeding-up-heap_alloced">Speeding up `HEAP_ALLOCED()`</a></li>
<li><a href="#eliminating-heap_alloced-completely">Eliminating `HEAP_ALLOCED` completely</a><ul>
<li><a href="#method-1-put-static-closures-in-an-aligned-section">Method 1: put static closures in an aligned section</a></li>
<li><a href="#method-2-copy-static-closures-into-a-special-area-at-startup">Method 2: copy static closures into a special area at startup</a></li>
</ul></li>
</ul></li>
<li><a href="#heap-and-stack-checks">Heap and Stack checks</a></li>
<li><a href="#ghc-commentary-the-layout-of-heap-objects">GHC Commentary: The Layout of Heap Objects</a><ul>
<li><a href="#terminology">Terminology</a></li>
<li><a href="#heap-objects">Heap Objects</a></li>
<li><a href="#info-tables">Info Tables</a><ul>
<li><a href="#section-5"></a></li>
</ul></li>
<li><a href="#types-of-payload-layout">Types of Payload Layout</a><ul>
<li><a href="#pointers-first-layout">Pointers-first layout</a></li>
<li><a href="#bitmap-layout">Bitmap layout</a></li>
</ul></li>
<li><a href="#dynamic-vs.-static-objects">Dynamic vs. Static objects</a><ul>
<li><a href="#dynamic-objects">Dynamic objects</a></li>
<li><a href="#static-objects">Static objects</a></li>
</ul></li>
<li><a href="#types-of-object">Types of object</a><ul>
<li><a href="#data-constructors">Data Constructors</a></li>
<li><a href="#function-closures">Function Closures</a></li>
<li><a href="#thunks">Thunks</a></li>
<li><a href="#selector-thunks">Selector thunks</a></li>
<li><a href="#partial-applications">Partial applications</a></li>
<li><a href="#generic-application">Generic application</a></li>
<li><a href="#stack-application">Stack application</a></li>
<li><a href="#indirections">Indirections</a></li>
<li><a href="#byte-code-objects">Byte-code objects</a></li>
<li><a href="#black-holes">Black holes</a></li>
<li><a href="#arrays">Arrays</a></li>
<li><a href="#mvars">MVars</a></li>
<li><a href="#weak-pointers">Weak pointers</a></li>
<li><a href="#stable-names">Stable Names</a></li>
<li><a href="#thread-state-objects">Thread State Objects</a></li>
<li><a href="#stm-objects">STM objects</a></li>
<li><a href="#forwarding-pointers">Forwarding Pointers</a></li>
</ul></li>
<li><a href="#how-to-add-new-heap-objects">How to add new heap objects</a></li>
<li><a href="#change-history">Change History</a></li>
<li><a href="#speculation-and-commentary">Speculation and Commentary</a></li>
<li><a href="#record-of-performance-improvements-made-to-the-hoopl-library-starting-january-2012">Record of performance improvements made to the Hoopl library starting January 2012</a></li>
</ul></li>
<li><a href="#haskell-program-coverage">Haskell Program Coverage</a><ul>
<li><a href="#binary-tick-boxes">Binary Tick Boxes</a></li>
<li><a href="#machine-generated-haskell">Machine Generated Haskell</a></li>
</ul></li>
<li><a href="#compiling-one-module-hscmain">Compiling one module: !HscMain</a></li>
<li><a href="#the-diagram">The Diagram</a></li>
<li><a href="#picture-of-the-main-compiler-pipeline">Picture of the main compiler pipeline</a></li>
<li><a href="#the-types">The  types</a><ul>
<li><a href="#decorating-hssyn-with-type-information">Decorating `HsSyn` with type information</a></li>
<li><a href="#source-locations">Source Locations</a></li>
</ul></li>
<li><a href="#interface-files">Interface files</a><ul>
<li><a href="#when-is-an-interface-file-loaded">When is an interface file loaded?</a></li>
</ul></li>
<li><a href="#immix-garbage-collector">Immix Garbage Collector</a></li>
<li><a href="#the-patches">The patches</a><ul>
<li><a href="#the-main-patch">The main patch</a></li>
<li><a href="#line-before-inscreasing-block-size">Line before inscreasing block size</a></li>
<li><a href="#allocate-in-lines-in-minor-gcs">Allocate in lines in minor GCs</a></li>
<li><a href="#remove-partial-list">Remove partial list</a></li>
</ul></li>
<li><a href="#to-do">To do</a></li>
<li><a href="#ghc-source-tree-roadmap-includes">GHC Source Tree Roadmap: includes/</a><ul>
<li><a href="#external-apis">External APIs</a></li>
<li><a href="#derived-constants">Derived Constants</a></li>
<li><a href="#used-when-compiling-via-c">Used when compiling via C</a></li>
<li><a href="#the-rts-external-apis">The RTS external APIs</a></li>
<li><a href="#included-into-c---.cmm-code">Included into C-- (`.cmm`) code</a></li>
</ul></li>
<li><a href="#installing-using-the-llvm-back-end">Installing &amp; Using the LLVM Back-end</a><ul>
<li><a href="#installing">Installing</a></li>
<li><a href="#llvm-support">LLVM Support</a></li>
<li><a href="#using">Using</a></li>
<li><a href="#supported-platforms-correctness">Supported Platforms &amp; Correctness</a></li>
<li><a href="#shared-libraries">Shared Libraries</a></li>
<li><a href="#performance">Performance</a></li>
</ul></li>
<li><a href="#ghc-commentary-librariesinteger">GHC Commentary: Libraries/Integer</a><ul>
<li><a href="#selecting-an-integer-implementation">Selecting an Integer implementation</a></li>
<li><a href="#the-integer-interface">The Integer interface</a></li>
<li><a href="#how-integer-is-handled-inside-ghc">How Integer is handled inside GHC</a></li>
</ul></li>
<li><a href="#an-integrated-code-generator-for-ghc">An Integrated Code Generator for GHC</a><ul>
<li><a href="#design-elements">Design elements</a></li>
<li><a href="#design-philosophy">Design philosophy</a></li>
<li><a href="#proposed-compilation-pipeline">Proposed compilation pipeline</a><ul>
<li><a href="#convert-from-stg-to-control-flow-graph">Convert from STG to control flow graph</a></li>
<li><a href="#instruction-selection">Instruction selection</a></li>
<li><a href="#optimisation">Optimisation</a></li>
<li><a href="#proc-point-analysis">Proc-point analysis</a></li>
<li><a href="#register-allocation">Register allocation</a></li>
<li><a href="#stack-layout">Stack layout</a></li>
<li><a href="#tidy-up">Tidy up</a></li>
</ul></li>
<li><a href="#machine-dependence">Machine-dependence</a></li>
</ul></li>
<li><a href="#ghc-commentary-the-byte-code-interpreter-and-dynamic-linker">GHC Commentary: The byte-code interpreter and dynamic linker</a><ul>
<li><a href="#linker">Linker</a></li>
<li><a href="#bytecode-interpreter">Bytecode Interpreter</a></li>
</ul></li>
<li><a href="#the-io-manager">The I/O Manager</a></li>
<li><a href="#key-data-types">Key data types</a></li>
<li><a href="#kinds">Kinds</a><ul>
<li><a href="#representing-kinds">Representing kinds</a></li>
<li><a href="#kind-subtyping">Kind subtyping</a></li>
</ul></li>
<li><a href="#linearity">Linearity</a></li>
<li><a href="#ticky">Ticky</a><ul>
<li><a href="#declarations-for-ticky-counters">Declarations for ticky counters</a></li>
</ul></li>
<li><a href="#strictness-and-let-floating">Strictness and let-floating</a></li>
<li><a href="#coercions">Coercions</a></li>
<li><a href="#warn-arity">WARN: arity /</a></li>
<li><a href="#explaining-demand-transformers">Explaining demand transformers</a></li>
<li><a href="#nofib-stuff">Nofib stuff</a></li>
<li><a href="#ghc-commentary-libraries">GHC Commentary: Libraries</a></li>
<li><a href="#building-packages-that-ghc-doesnt-depend-on">Building packages that GHC doesn't depend on</a></li>
<li><a href="#classifying-boot-packages">Classifying boot packages</a><ul>
<li><a href="#required-or-optional">Required or optional</a></li>
<li><a href="#coupling-to-ghc">Coupling to GHC</a></li>
<li><a href="#zero-boot-packages">Zero-boot packages</a></li>
<li><a href="#installation">Installation</a></li>
</ul></li>
<li><a href="#boot-packages-dependencies">Boot packages dependencies</a><ul>
<li><a href="#warning-pattern-matching-in-ghc-prim-integer-simple-and-integer-gmp">WARNING: Pattern matching in `ghc-prim`, `integer-simple`, and `integer-gmp`</a></li>
</ul></li>
<li><a href="#repositories">Repositories</a></li>
<li><a href="#the-llvm-backend">The LLVM backend</a></li>
<li><a href="#loopification">Loopification</a></li>
<li><a href="#llvm-mangler">LLVM Mangler</a><ul>
<li><a href="#tables_next_to_code-tntc">TABLES_NEXT_TO_CODE (TNTC)</a></li>
<li><a href="#stack-alignment">Stack Alignment</a></li>
<li><a href="#simd-avx">SIMD / AVX</a></li>
</ul></li>
<li><a href="#migrating-old-commentary">Migrating Old Commentary</a><ul>
<li><a href="#before-the-show-begins">Before the Show Begins</a></li>
<li><a href="#genesis">Genesis</a></li>
<li><a href="#the-beast-dissected">The Beast Dissected</a></li>
<li><a href="#rts-libraries">RTS &amp; Libraries</a></li>
<li><a href="#extensions-or-making-a-complicated-system-more-complicated">Extensions, or Making a Complicated System More Complicated</a></li>
</ul></li>
<li><a href="#the-marvellous-module-structure-of-ghc">The Marvellous Module Structure of GHC</a><ul>
<li><a href="#compilation-order-is-as-follows">Compilation order is as follows:</a></li>
<li><a href="#typechecker-stuff">Typechecker stuff</a></li>
<li><a href="#hssyn-stuff">!HsSyn stuff</a></li>
<li><a href="#library-stuff-base-package">Library stuff: base package</a></li>
<li><a href="#high-level-dependency-graph">High-level Dependency Graph</a></li>
</ul></li>
<li><a href="#module-types">Module Types</a><ul>
<li><a href="#module">Module</a></li>
<li><a href="#modiface">!ModIface</a></li>
<li><a href="#moddetails">!ModDetails</a><ul>
<li><a href="#modguts">!ModGuts</a></li>
</ul></li>
<li><a href="#modsummary">!ModSummary</a></li>
<li><a href="#homemodinfo">!HomeModInfo</a></li>
<li><a href="#homepackagetable">!HomePackageTable</a></li>
<li><a href="#externalpackagestate">!ExternalPackageState</a></li>
</ul></li>
<li><a href="#multi-instance-packages">Multi-instance packages</a><ul>
<li><a href="#todo-list">!ToDo list</a></li>
<li><a href="#next-step-dealing-with-ways">Next step: dealing with ways</a></li>
</ul></li>
<li><a href="#the-type-1">The  type</a><ul>
<li><a href="#the-of-a-name">The  of a Name</a></li>
<li><a href="#entities-and">Entities and </a></li>
</ul></li>
<li><a href="#native-code-generator-ncg">Native Code Generator (NCG)</a><ul>
<li><a href="#files-parts">Files, Parts</a></li>
<li><a href="#overview-3">Overview</a><ul>
<li><a href="#spilling">Spilling</a></li>
<li><a href="#dealing-with-common-cases-fast">Dealing with common cases fast</a></li>
</ul></li>
<li><a href="#complications-observations-and-possible-improvements">Complications, observations, and possible improvements</a><ul>
<li><a href="#real-vs-virtual-registers-in-the-instruction-selectors">Real vs virtual registers in the instruction selectors</a></li>
</ul></li>
<li><a href="#selecting-insns-for-64-bit-valuesloadsstores-on-32-bit-platforms">Selecting insns for 64-bit values/loads/stores on 32-bit platforms</a></li>
<li><a href="#shortcomings-and-inefficiencies-in-the-register-allocator">Shortcomings and inefficiencies in the register allocator</a><ul>
<li><a href="#redundant-reconstruction-of-the-control-flow-graph">Redundant reconstruction of the control flow graph</a></li>
<li><a href="#really-ridiculous-method-for-doing-spilling">Really ridiculous method for doing spilling</a></li>
<li><a href="#redundant-move-support-for-revised-instruction-selector-suggestion">Redundant-move support for revised instruction selector suggestion</a></li>
</ul></li>
<li><a href="#x86-arcana-that-you-should-know-about">x86 arcana that you should know about</a></li>
<li><a href="#generating-code-for-ccalls">Generating code for ccalls</a></li>
<li><a href="#duplicate-implementation-for-many-stg-macros">Duplicate implementation for many STG macros</a></li>
<li><a href="#how-to-debug-the-ncg-without-losing-your-sanityhaircool">How to debug the NCG without losing your sanity/hair/cool</a></li>
<li><a href="#historical-page-1">Historical page</a></li>
</ul></li>
<li><a href="#overview-of-modules-in-the-new-code-generator">Overview of modules in the new code generator</a><ul>
<li><a href="#the-new-cmm-data-type">The new Cmm data type</a></li>
<li><a href="#module-structure-of-the-new-code-generator">Module structure of the new code generator</a><ul>
<li><a href="#basic-datatypes-and-infrastructure">Basic datatypes and infrastructure</a></li>
<li><a href="#analyses-and-transformations">Analyses and transformations</a></li>
<li><a href="#linking-the-pipeline">Linking the pipeline</a></li>
<li><a href="#dead-code">Dead code</a></li>
</ul></li>
<li><a href="#historical-page-2">Historical page</a></li>
</ul></li>
<li><a href="#design-of-the-new-code-generator">Design of the new code generator</a><ul>
<li><a href="#overview-4">Overview</a></li>
<li><a href="#the-cmm-pipeline">The Cmm pipeline</a><ul>
<li><a href="#branches-to-continuations-and-the-adams-optimisation">Branches to continuations and the &quot;Adams optimisation&quot;</a></li>
</ul></li>
<li><a href="#runtime-system">Runtime system</a></li>
</ul></li>
<li><a href="#note-historical-page">NOTE: Historical page</a></li>
<li><a href="#stupidity-in-the-new-code-generator">Stupidity in the New Code Generator</a><ul>
<li><a href="#cantankerous-comparisons">Cantankerous Comparisons</a></li>
<li><a href="#dead-stackheap-checks">Dead stack/heap checks</a></li>
<li><a href="#instruction-reordering">Instruction reordering</a></li>
<li><a href="#stack-space-overuse">Stack space overuse</a></li>
<li><a href="#double-temp-use-means-no-inlinining">Double temp-use means no inlinining?</a></li>
<li><a href="#stupid-spills">Stupid spills</a></li>
<li><a href="#noppy-proc-points">Noppy proc-points</a></li>
<li><a href="#lots-of-temporary-variables">Lots of temporary variables</a></li>
<li><a href="#double-proc-points">Double proc points</a></li>
<li><a href="#rewriting-stacks">Rewriting stacks</a></li>
<li><a href="#spilling-hpsp">Spilling Hp/Sp</a></li>
<li><a href="#up-and-down">Up and Down</a></li>
<li><a href="#sp-is-generally-stupid">Sp is generally stupid</a></li>
<li><a href="#heap-and-r1-aliasing">Heap and R1 aliasing</a></li>
<li><a href="#historical-page-3">Historical page</a></li>
</ul></li>
<li><a href="#ghcs-glorious-new-code-generator">GHC's glorious new code generator</a><ul>
<li><a href="#workflow-for-the-new-code-generator-and-hoopl">Workflow for the new code generator and Hoopl</a></li>
<li><a href="#status-report-april-2011">Status report April 2011</a></li>
</ul></li>
<li><a href="#old-code-generator-prior-to-ghc-7.8">Old Code Generator (prior to GHC 7.8)</a><ul>
<li><a href="#storage-manager-representations">Storage manager representations</a></li>
<li><a href="#generated-cmm-naming-convention">Generated Cmm Naming Convention</a></li>
<li><a href="#modules">Modules</a><ul>
<li><a href="#section-6"></a></li>
<li><a href="#section-7"></a></li>
<li><a href="#section-8"></a></li>
<li><a href="#section-9"></a></li>
<li><a href="#section-10"></a></li>
<li><a href="#memory-and-register-management">Memory and Register Management</a></li>
<li><a href="#function-calls-and-parameter-passing">Function Calls and Parameter Passing</a></li>
<li><a href="#misc-utilities">Misc utilities</a></li>
<li><a href="#special-runtime-support">Special runtime support</a></li>
</ul></li>
</ul></li>
<li><a href="#ordering-the-core-to-core-optimisation-passes">Ordering the Core-to-Core optimisation passes</a><ul>
<li><a href="#this-ordering-obeys-all-the-constraints-except-5">This ordering obeys all the constraints except (5)</a></li>
<li><a href="#constraints-1">Constraints</a><ul>
<li><a href="#float-in-before-strictness">1. float-in before strictness</a></li>
<li><a href="#dont-simplify-between-float-in-and-strictness">2. Don't simplify between float-in and strictness</a></li>
<li><a href="#want-full-laziness-before-foldrbuild">3. Want full-laziness before foldr/build</a></li>
<li><a href="#want-strictness-after-foldrbuild">4. Want strictness after foldr/build</a></li>
<li><a href="#want-full-laziness-after-strictness">5. Want full laziness after strictness</a></li>
<li><a href="#want-float-in-after-foldrbuild">6. Want float-in after foldr/build</a></li>
<li><a href="#want-simplify-after-float-inwards">7. Want simplify after float-inwards</a></li>
<li><a href="#if-full-laziness-is-ever-done-after-strictness">8. If full laziness is ever done after strictness</a></li>
<li><a href="#ignore-inline-pragmas-flag-for-final-simplification">9. Ignore-inline-pragmas flag for final simplification</a></li>
<li><a href="#run-float-inwards-once-more-after-strictness-simplify">10. Run Float Inwards once more after strictness-simplify</a></li>
</ul></li>
</ul></li>
<li><a href="#overall-organisation-of-ghc">Overall organisation of GHC</a></li>
<li><a href="#ghc-source-code">GHC source code</a></li>
<li><a href="#updates">Updates</a><ul>
<li><a href="#unique">Unique</a></li>
<li><a href="#redesign-2014">Redesign (2014)</a></li>
</ul></li>
<li><a href="#the-data-type-and-its-friends">The data type  and its friends</a><ul>
<li><a href="#views-of-types">Views of types</a></li>
<li><a href="#the-representation-of">The representation of </a></li>
<li><a href="#overloaded-types">Overloaded types</a></li>
<li><a href="#classifying-types">Classifying types</a></li>
</ul></li>
<li><a href="#package-compatibility">Package Compatibility</a><ul>
<li><a href="#dont-reorganise-packages">1. Don't reorganise packages</a></li>
<li><a href="#provide-older-versions-of-base-with-a-new-ghc-release">2. Provide older version(s) of base with a new GHC release</a></li>
<li><a href="#allow-packages-to-re-export-modules">4. Allow packages to re-export modules</a></li>
<li><a href="#provide-backwards-compatible-versions-of-base">4.1 Provide backwards-compatible versions of base</a></li>
<li><a href="#rename-base-and-provide-a-compatibility-wrapper">4.2 Rename base, and provide a compatibility wrapper</a></li>
<li><a href="#dont-rename-base">4.3 Don't rename base</a></li>
<li><a href="#do-some-kind-of-providesrequires-interface-in-cabal">5. Do some kind of provides/requires interface in Cabal</a><ul>
<li><a href="#make-api-specifications-more-symmetric">5.1 Make API specifications more symmetric</a></li>
<li><a href="#make-api-specifications-explicit">5.2 Make API specifications explicit</a></li>
<li><a href="#make-api-specifications-more-specific">5.3 Make API specifications more specific</a></li>
</ul></li>
<li><a href="#distributions-at-the-hackage-level">6. Distributions at the Hackage level</a></li>
<li><a href="#allow-package-overlaps">7. Allow package overlaps</a></li>
<li><a href="#the-problem-of-lax-version-dependencies">The problem of lax version dependencies</a></li>
</ul></li>
<li><a href="#note-about-this-page">Note about this page</a></li>
<li><a href="#explicit-package-imports">Explicit package imports</a><ul>
<li><a href="#is-the-from-compulsory">Is the 'from <package>' compulsory?</a></li>
<li><a href="#package-versions">Package versions</a></li>
<li><a href="#importing-from-the-home-package">Importing from the home package</a></li>
<li><a href="#the-as-p-alias">The 'as P' alias</a></li>
<li><a href="#qualified-names">Qualified names</a></li>
<li><a href="#exporting-modules-from-other-packages">Exporting modules from other packages</a></li>
<li><a href="#syntax">Syntax</a><ul>
<li><a href="#syntax-formalised-and-summarised">Syntax formalised and summarised</a></li>
<li><a href="#proposal-for-package-mounting">Proposal for Package Mounting</a></li>
<li><a href="#evaluation">Evaluation</a></li>
<li><a href="#note-on-package-grafting">Note on Package Grafting</a></li>
</ul></li>
<li><a href="#alternative-proposal-for-packages-with-explicit-namespaces">Alternative Proposal for Packages (with explicit namespaces)</a></li>
<li><a href="#a-different-but-related-problem">A different, but related, problem</a></li>
<li><a href="#proposal">Proposal</a><ul>
<li><a href="#naming-a-namespace">Naming a namespace</a></li>
<li><a href="#what-namespaces-are-available-by-default">What namespaces are available by default?</a></li>
<li><a href="#namespace-resolution">Namespace resolution</a></li>
<li><a href="#syntax-1">Syntax</a></li>
<li><a href="#exports-1">Exports</a></li>
<li><a href="#implicit-imports">Implicit imports</a></li>
<li><a href="#exposed-vs-hidden-packages">Exposed vs Hidden packages</a></li>
<li><a href="#what-if-you-wanted-to-import-a.b.c-from-p1-and-a.b.c-from-p2-into-the-same-module">What if you wanted to import A.B.C from P1 and A.B.C from P2 into the <em>same</em> module?</a></li>
</ul></li>
</ul></li>
<li><a href="#package-reorg">Package Reorg</a><ul>
<li><a href="#goals-1">Goals</a></li>
<li><a href="#proposal-1">Proposal</a><ul>
<li><a href="#what-is-in-the-core-packages">What is in the Core Packages?</a></li>
<li><a href="#requirements-to-libraries-to-be-included-in-core-set">Requirements to libraries to be included in core set</a></li>
<li><a href="#the-base-package">The base package</a></li>
<li><a href="#other-packages">Other packages</a></li>
</ul></li>
<li><a href="#testing-1">Testing</a></li>
<li><a href="#implementation-specific-notes">Implementation-specific notes</a><ul>
<li><a href="#notes-about-ghc">Notes about GHC</a></li>
<li><a href="#notes-about-hugs">Notes about Hugs</a></li>
</ul></li>
</ul></li>
<li><a href="#commentary-the-package-system">Commentary: The Package System</a><ul>
<li><a href="#architecture">Architecture</a></li>
<li><a href="#identifying-packages">Identifying Packages</a></li>
<li><a href="#design-constraints">Design constraints</a></li>
<li><a href="#the-plan-1">The Plan</a><ul>
<li><a href="#detecting-abi-incompatibility">Detecting ABI incompatibility</a></li>
<li><a href="#allowing-abi-compatibilty">Allowing ABI compatibilty</a></li>
</ul></li>
</ul></li>
<li><a href="#the-parser">The Parser</a><ul>
<li><a href="#principles">Principles</a></li>
<li><a href="#avoiding-right-recursion">Avoiding right-recursion</a></li>
<li><a href="#indentation">Indentation</a></li>
<li><a href="#syntax-extensions">Syntax extensions</a></li>
</ul></li>
<li><a href="#pinned-objects">Pinned Objects</a></li>
<li><a href="#overview-5">Overview</a></li>
<li><a href="#the-driver-pipeline">The driver pipeline</a></li>
<li><a href="#the-compiler-pipeline">The compiler pipeline</a></li>
<li><a href="#video">Video</a></li>
<li><a href="#platforms">Platforms</a><ul>
<li><a href="#limitations">Limitations</a></li>
<li><a href="#macros">Macros</a></li>
</ul></li>
<li><a href="#pointer-tagging-1">Pointer Tagging</a><ul>
<li><a href="#meaning-of-the-tag-bits">Meaning of the tag bits</a></li>
<li><a href="#optimisations-enabled-by-tag-bits">Optimisations enabled by tag bits</a></li>
<li><a href="#garbage-collection-with-tagged-pointers">Garbage collection with tagged pointers</a></li>
<li><a href="#invariants">Invariants</a></li>
<li><a href="#compacting-gc">Compacting GC</a></li>
<li><a href="#dealing-with-tags-in-the-code">Dealing with tags in the code</a></li>
</ul></li>
<li><a href="#position-independent-code-and-dynamic-linking">Position-Independent Code and Dynamic Linking</a><ul>
<li><a href="#how-to-access-symbols">How to access symbols</a></li>
<li><a href="#clabel.labeldynamic">CLabel.labelDynamic</a></li>
<li><a href="#info-tables-1">Info Tables</a></li>
<li><a href="#imported-labels-in-srts-windows">Imported labels in SRTs (Windows)</a></li>
<li><a href="#pic-and-dynamic-linking-support-in-the-ncg">PIC and dynamic linking support in the NCG</a></li>
<li><a href="#how-things-are-done-on-different-platforms">How things are done on different platforms</a><ul>
<li><a href="#position-dependent-code">Position dependent code</a></li>
<li><a href="#position-independent-code">Position independent code</a></li>
</ul></li>
<li><a href="#linking-on-elf">Linking on ELF</a></li>
<li><a href="#mangling-dynamic-library-names">Mangling dynamic library names</a></li>
</ul></li>
<li><a href="#ghc-commentary-the-c-code-generator">GHC Commentary: The C code generator</a><ul>
<li><a href="#header-files">Header files</a></li>
<li><a href="#prototypes">Prototypes</a></li>
</ul></li>
<li><a href="#primitive-operations-primops">Primitive Operations (!PrimOps)</a><ul>
<li><a href="#the-primops.txt.pp-file">The primops.txt.pp file</a></li>
<li><a href="#implementation-of-primops">Implementation of !PrimOps</a><ul>
<li><a href="#inline-primops">Inline !PrimOps</a></li>
<li><a href="#out-of-line-primops">Out-of-line !PrimOps</a></li>
<li><a href="#foreign-out-of-line-primops-and-foreign-import-prim">Foreign out-of-line !PrimOps and `foreign import prim`</a></li>
</ul></li>
<li><a href="#adding-a-new-primop">Adding a new !PrimOp</a></li>
</ul></li>
<li><a href="#profiling">Profiling</a><ul>
<li><a href="#cost-centre-profiling">Cost-centre profiling</a></li>
<li><a href="#ticky-ticky-profiling">Ticky-ticky profiling</a></li>
</ul></li>
<li><a href="#and">, , and </a><ul>
<li><a href="#the-module-and-modulename-types">The `Module` and `ModuleName` types</a></li>
<li><a href="#the-type-2">The  type</a></li>
</ul></li>
<li><a href="#recompilation-avoidance">Recompilation Avoidance</a><ul>
<li><a href="#what-is-recompilation-avoidance">What is recompilation avoidance?</a></li>
<li><a href="#example-2">Example</a></li>
<li><a href="#why-do-we-need-recompilation-avoidance">Why do we need recompilation avoidance?</a><ul>
<li><a href="#ghci-and---make">GHCi and `--make`</a></li>
<li><a href="#make">`make`</a></li>
</ul></li>
<li><a href="#how-does-it-work">How does it work?</a><ul>
<li><a href="#deciding-whether-to-recompile">Deciding whether to recompile</a></li>
<li><a href="#example-3">Example</a></li>
<li><a href="#how-does-fingerprinting-work">How does fingerprinting work?</a></li>
<li><a href="#mutually-recursive-groups-of-entities">Mutually recursive groups of entities</a></li>
<li><a href="#fixities">Fixities</a></li>
<li><a href="#instances">Instances</a></li>
<li><a href="#orphans">Orphans</a></li>
<li><a href="#rules">Rules</a></li>
<li><a href="#on-ordering">On ordering</a></li>
<li><a href="#packages">Packages</a></li>
<li><a href="#package-version-changes">Package version changes</a></li>
</ul></li>
<li><a href="#interface-stability">Interface stability</a></li>
</ul></li>
<li><a href="#the-register-allocator-1">The Register Allocator</a><ul>
<li><a href="#overview-6">Overview</a></li>
<li><a href="#code-map">Code map</a></li>
<li><a href="#references-2">References</a></li>
<li><a href="#register-pressure-in-haskell-code">Register pressure in Haskell code</a></li>
<li><a href="#hackingdebugging">Hacking/Debugging</a></li>
<li><a href="#runtime-performance">Runtime performance</a></li>
<li><a href="#possible-improvements">Possible Improvements</a></li>
</ul></li>
<li><a href="#haskell-excecution-registers">Haskell Excecution: Registers</a></li>
<li><a href="#relevant-ghc-parts-for-demand-analysis-results">Relevant GHC parts for Demand Analysis results</a></li>
<li><a href="#remembered-sets">Remembered Sets</a><ul>
<li><a href="#remembered-set-maintenance-during-mutation">Remembered set maintenance during mutation</a><ul>
<li><a href="#thunk-updates">Thunk Updates</a></li>
<li><a href="#mutable-objects-mut_var-mvar">Mutable objects: MUT_VAR, MVAR</a></li>
<li><a href="#arrays-mut_arr_ptrs">Arrays: MUT_ARR_PTRS</a></li>
<li><a href="#threads-tso">Threads: TSO</a></li>
</ul></li>
<li><a href="#remembered-set-maintenance-during-gc">Remembered set maintenance during GC</a></li>
</ul></li>
<li><a href="#the-renamer">The renamer</a><ul>
<li><a href="#the-global-renamer-environment">The global renamer environment, </a></li>
<li><a href="#unused-imports">Unused imports</a></li>
<li><a href="#name-space-management">Name Space Management</a></li>
<li><a href="#rebindable-syntax">Rebindable syntax</a></li>
</ul></li>
<li><a href="#replacing-the-native-code-generator">Replacing the Native Code Generator</a></li>
<li><a href="#resource-limits">Resource Limits</a><ul>
<li><a href="#code-generation-changes">Code generation changes</a><ul>
<li><a href="#dynamic-closure-allocation">Dynamic closure allocation</a></li>
<li><a href="#caf-allocation">CAF Allocation</a></li>
<li><a href="#thunk-code">Thunk code</a></li>
<li><a href="#foreign-calls">Foreign calls</a></li>
</ul></li>
<li><a href="#case-split">Case split</a></li>
<li><a href="#front-end-changes">Front-end changes</a></li>
</ul></li>
<li><a href="#garbage-collection-roots">Garbage Collection Roots</a></li>
<li><a href="#ghc-source-tree-roadmap-rts">GHC Source Tree Roadmap: rts/</a><ul>
<li><a href="#subdirectories-of-rts">Subdirectories of rts/</a></li>
<li><a href="#haskell-execution">Haskell Execution</a></li>
<li><a href="#the-wikicommentaryrtsstorage-storage-manager">The [wiki:Commentary/Rts/Storage Storage Manager]</a></li>
<li><a href="#data-structures">Data Structures</a></li>
<li><a href="#the-wikicommentaryrtsscheduler-scheduler">The [wiki:Commentary/Rts/Scheduler Scheduler]</a></li>
<li><a href="#c-files-the-wikicommentaryrtsffi-ffi">C files: the [wiki:Commentary/Rts/FFI FFI]</a></li>
<li><a href="#the-wikicommentaryrtsinterpreter-byte-code-interpreter">The [wiki:Commentary/Rts/Interpreter Byte-code Interpreter]</a></li>
<li><a href="#wikicommentaryprofiling-profiling">[wiki:Commentary/Profiling Profiling]</a></li>
<li><a href="#rts-debugging">RTS Debugging</a></li>
<li><a href="#the-front-panel">The Front Panel</a></li>
<li><a href="#other">Other</a></li>
<li><a href="#old-stuff">OLD stuff</a></li>
</ul></li>
<li><a href="#sanity-checking">Sanity Checking</a></li>
<li><a href="#the-scheduler">The Scheduler</a><ul>
<li><a href="#os-threads">OS Threads</a></li>
<li><a href="#haskell-threads">Haskell threads</a></li>
</ul></li>
<li><a href="#seq-magic">Seq magic</a><ul>
<li><a href="#the-baseline-position">The baseline position</a><ul>
<li><a href="#problem-1-trac-1031">Problem 1 (Trac #1031)</a></li>
<li><a href="#problem-2-trac-2273">Problem 2 (Trac #2273)</a></li>
<li><a href="#problem-3-trac-5262">Problem 3 (Trac #5262)</a></li>
<li><a href="#problem-4-seq-in-the-io-monad">Problem 4: seq in the IO monad</a></li>
<li><a href="#problem-5-the-need-for-special-rules">Problem 5: the need for special rules</a></li>
</ul></li>
</ul></li>
<li><a href="#a-better-way">A better way</a></li>
<li><a href="#the-ghc-commentary-signals">The GHC Commentary: Signals</a><ul>
<li><a href="#signal-handling-in-the-rts">Signal handling in the RTS</a><ul>
<li><a href="#the-timer-signal">The timer signal</a></li>
</ul></li>
<li><a href="#the-interrupt-signal">The interrupt signal</a></li>
<li><a href="#signal-handling-in-haskell-code">Signal handling in Haskell code</a></li>
<li><a href="#rts-alarm-signals-and-foreign-libraries">RTS Alarm Signals and Foreign Libraries</a></li>
</ul></li>
<li><a href="#slop">Slop</a><ul>
<li><a href="#why-do-we-want-to-avoid-slop">Why do we want to avoid slop?</a></li>
<li><a href="#how-does-slop-arise">How does slop arise?</a></li>
<li><a href="#what-do-we-do-about-it">What do we do about it?</a></li>
</ul></li>
<li><a href="#layout-of-important-files-and-directories">Layout of important files and directories</a><ul>
<li><a href="#files-in-top">Files in `$(TOP)`</a></li>
<li><a href="#libraries">`libraries/`</a></li>
<li><a href="#compiler-docs-ghc">`compiler/`, `docs/`, `ghc/`</a></li>
<li><a href="#rts">`rts/`</a></li>
<li><a href="#includes">`includes/`</a></li>
<li><a href="#utils-libffi">`utils/`, `libffi/`</a></li>
<li><a href="#driver">`driver/`</a></li>
<li><a href="#ghc-tarballs-windows-only">`ghc-tarballs/` (Windows only)</a></li>
<li><a href="#testsuite-nofib">`testsuite/`, `nofib/`</a></li>
<li><a href="#mk-rules">`mk/`, `rules/`</a></li>
<li><a href="#distrib">`distrib/`</a></li>
<li><a href="#stuff-that-appears-only-in-a-build-tree">Stuff that appears only in a build tree</a><ul>
<li><a href="#inplace">`inplace/`</a></li>
<li><a href="#dist">`.../dist*/`</a></li>
</ul></li>
<li><a href="#stack-layout-1">Stack Layout</a><ul>
<li><a href="#representing-stack-slots">Representing Stack Slots</a></li>
<li><a href="#laying-out-the-stack">Laying out the stack</a></li>
<li><a href="#a-greedy-algorithm">A greedy algorithm</a></li>
</ul></li>
</ul></li>
<li><a href="#layout-of-the-stack">Layout of the stack</a><ul>
<li><a href="#info-tables-for-stack-frames">Info tables for stack frames</a></li>
<li><a href="#layout-of-the-payload">Layout of the payload</a></li>
<li><a href="#kinds-of-stack-frame">Kinds of Stack Frame</a></li>
</ul></li>
<li><a href="#the-stg-syntax-data-types">The STG syntax data types</a></li>
<li><a href="#ghc-commentary-software-transactional-memory-stm">GHC Commentary: Software Transactional Memory (STM)</a></li>
<li><a href="#background">Background</a><ul>
<li><a href="#definitions">Definitions</a><ul>
<li><a href="#useful-rts-terms">Useful RTS terms</a></li>
<li><a href="#transactional-memory-terms">Transactional Memory terms</a></li>
</ul></li>
</ul></li>
<li><a href="#overview-of-features">Overview of Features</a><ul>
<li><a href="#reading-and-writing">Reading and Writing</a></li>
<li><a href="#blocking">Blocking</a></li>
<li><a href="#choice">Choice</a></li>
<li><a href="#data-invariants">Data Invariants</a></li>
<li><a href="#exceptions">Exceptions</a></li>
</ul></li>
<li><a href="#overview-of-the-implementation">Overview of the Implementation</a><ul>
<li><a href="#transactions-that-read-and-write.">Transactions that Read and Write.</a><ul>
<li><a href="#transactional-record">Transactional Record</a></li>
<li><a href="#starting">Starting</a></li>
<li><a href="#reading">Reading</a></li>
<li><a href="#writing">Writing</a></li>
<li><a href="#validation">Validation</a></li>
<li><a href="#committing">Committing</a></li>
<li><a href="#aborting">Aborting</a></li>
<li><a href="#exceptions-1">Exceptions</a></li>
</ul></li>
<li><a href="#blocking-with">Blocking with </a></li>
<li><a href="#choice-with">Choice with </a></li>
<li><a href="#invariants-1">Invariants</a><ul>
<li><a href="#details">Details</a></li>
<li><a href="#changes-from-choice">Changes from Choice</a></li>
</ul></li>
<li><a href="#other-details">Other Details</a><ul>
<li><a href="#detecting-long-running-transactions">Detecting Long Running Transactions</a></li>
<li><a href="#transaction-state">Transaction State</a></li>
<li><a href="#gc-and-aba">GC and ABA</a></li>
<li><a href="#management-of-s">Management of s</a></li>
<li><a href="#tokens-and-version-numbers.">Tokens and Version Numbers.</a></li>
<li><a href="#implementation-invariants">Implementation Invariants</a></li>
<li><a href="#fine-grain-locking">Fine Grain Locking</a></li>
</ul></li>
<li><a href="#bibliography">Bibliography</a></li>
</ul></li>
<li><a href="#ghc-commentary-storage">GHC Commentary: Storage</a></li>
<li><a href="#general-overview">General overview</a></li>
<li><a href="#important-note">IMPORTANT NOTE</a></li>
<li><a href="#the-demand-analyzer">The demand analyzer</a><ul>
<li><a href="#important-datatypes">Important datatypes</a></li>
</ul></li>
<li><a href="#symbol-names">Symbol Names</a><ul>
<li><a href="#tuples">Tuples</a></li>
<li><a href="#unboxed-tuples">Unboxed Tuples</a></li>
<li><a href="#alphanumeric-characters">Alphanumeric Characters</a></li>
<li><a href="#constructor-characters">Constructor Characters</a></li>
<li><a href="#variable-characters">Variable Characters</a></li>
<li><a href="#other-1">Other</a></li>
<li><a href="#examples">Examples</a></li>
</ul></li>
<li><a href="#the-monad-for-renaming-typechecking-desugaring">The monad for renaming, typechecking, desugaring</a></li>
<li><a href="#kirstens-sketchy-notes-on-getting-ticky-to-work">Kirsten's sketchy notes on getting ticky to work</a></li>
<li><a href="#the-ghc-commentary-checking-types">The GHC Commentary: Checking Types</a><ul>
<li><a href="#the-overall-flow-of-things">The Overall Flow of Things</a><ul>
<li><a href="#entry-points-into-the-type-checker">Entry Points Into the Type Checker</a></li>
<li><a href="#renaming-and-type-checking-a-module">Renaming and Type Checking a Module</a></li>
</ul></li>
<li><a href="#type-checking-a-declaration-group">Type Checking a Declaration Group</a></li>
<li><a href="#type-checking-type-and-class-declarations">Type checking Type and Class Declarations</a></li>
<li><a href="#more-details">More Details</a><ul>
<li><a href="#types-variables-and-zonking">Types Variables and Zonking</a></li>
<li><a href="#type-representation">Type Representation</a></li>
<li><a href="#type-checking-environment">Type Checking Environment</a></li>
<li><a href="#expressions-1">Expressions</a></li>
<li><a href="#handling-of-dictionaries-and-method-instances">Handling of Dictionaries and Method Instances</a></li>
</ul></li>
<li><a href="#connection-with-ghcs-constraint-solver">Connection with GHC's Constraint Solver</a></li>
<li><a href="#generating-evidence">Generating Evidence</a></li>
<li><a href="#the-solver">The Solver</a><ul>
<li><a href="#given-constraints">Given Constraints</a></li>
<li><a href="#derived-constraints">Derived Constraints</a></li>
<li><a href="#wanted-constraints">Wanted Constraints</a></li>
</ul></li>
</ul></li>
<li><a href="#the-data-type-and-its-friends-1">The data type  and its friends</a><ul>
<li><a href="#views-of-types-1">Views of types</a></li>
<li><a href="#the-representation-of-1">The representation of </a></li>
<li><a href="#overloaded-types-1">Overloaded types</a></li>
<li><a href="#classifying-types-1">Classifying types</a></li>
<li><a href="#unique-1">Unique</a></li>
<li><a href="#current-design">Current design</a><ul>
<li><a href="#known-key-things">Known-key things</a></li>
<li><a href="#interface-files-1">Interface files</a></li>
</ul></li>
<li><a href="#redesign-2014-1">Redesign (2014)</a></li>
</ul></li>
<li><a href="#unpacking-primitive-fields">Unpacking primitive fields</a><ul>
<li><a href="#goals-and-non-goals">Goals and non-goals</a></li>
<li><a href="#detailed-design">Detailed design</a></li>
<li><a href="#benchmarks">Benchmarks</a></li>
</ul></li>
<li><a href="#unused-imports-1">Unused imports</a><ul>
<li><a href="#the-current-story">The current story</a></li>
<li><a href="#examples-1">Examples</a></li>
<li><a href="#specfication">Specfication</a></li>
<li><a href="#implementation-1">Implementation</a></li>
<li><a href="#algorithm">Algorithm</a></li>
</ul></li>
<li><a href="#updates-1">Updates</a></li>
<li><a href="#the-user-manual">The user manual</a></li>
<li><a href="#ghc-boot-library-version-history">GHC Boot Library Version History</a></li>
<li><a href="#ghc-commentary-weak-pointers-and-finalizers">GHC Commentary: Weak Pointers and Finalizers</a></li>
<li><a href="#work-in-progress-on-the-llvm-backend">Work in Progress on the LLVM Backend</a><ul>
<li><a href="#llvm-ir-representation">LLVM IR Representation</a></li>
<li><a href="#tables_next_to_code-1">TABLES_NEXT_TO_CODE</a></li>
<li><a href="#llvm-alias-analysis-pass">LLVM Alias Analysis Pass</a></li>
<li><a href="#optimise-llvm-for-the-type-of-code-ghc-produces">Optimise LLVM for the type of Code GHC produces</a></li>
<li><a href="#update-the-back-end-to-use-the-new-cmm-data-types-new-code-generator">Update the Back-end to use the new Cmm data types / New Code Generator</a></li>
<li><a href="#llvms-link-time-optimisations">LLVM's Link Time Optimisations</a></li>
<li><a href="#llvm-cross-compiler-port">LLVM Cross Compiler / Port</a></li>
<li><a href="#get-rid-of-proc-point-splitting">Get rid of Proc Point Splitting</a></li>
<li><a href="#dont-pass-around-dead-stg-registers">Don't Pass Around Dead STG Registers</a></li>
</ul></li>
<li><a href="#wired-in-and-known-key-things">Wired-in and known-key things</a><ul>
<li><a href="#wired-in-things">Wired-in things</a></li>
<li><a href="#known-key-things-1">Known-key things</a></li>
<li><a href="#initialisation">Initialisation</a></li>
<li><a href="#orig-rdrname-things">`Orig` `RdrName` things</a></li>
</ul></li>
<li><a href="#ghc-commentary-the-word">GHC Commentary: The Word</a></li>
</ul>
</div>
<h1 id="ghc-source-code-abbreviations">GHC Source Code Abbreviations</h1>
<p>Certain abbreviations are used pervasively throughout the GHC source code. This page gives a partial list of them and their expansion:</p>
<ul>
<li><strong>ANF</strong>: A-normal form</li>
</ul>
<ul>
<li><strong>CAF</strong>: Constant Applicative Form</li>
</ul>
<ul>
<li><strong>Class</strong>: Type Class</li>
</ul>
<ul>
<li><strong>Cmm</strong>: The final IR used in GHC, based on the C-- language</li>
</ul>
<ul>
<li><strong>Core</strong>: GHC core language. Based on System FC (variant of System F). Represents a type-checked and desugared program in some (out of several) intermediate compilation step</li>
</ul>
<ul>
<li><strong>CoreFV</strong>: Free variables in core</li>
</ul>
<ul>
<li><strong>!CoreLint</strong>: Type and sanity-checking of core. (Lint: Jargon for a program analysis that looks for bug-suspicious code.)</li>
</ul>
<ul>
<li><strong>!CoreSubst</strong>: Substitution in core</li>
</ul>
<ul>
<li><strong>!CoreSyn</strong>: Core abstract syntax</li>
</ul>
<ul>
<li><strong>!DataCon</strong>: Data constructor</li>
</ul>
<ul>
<li><strong>Ds</strong>: Desugarer</li>
</ul>
<ul>
<li><strong>Gbl</strong>: Global</li>
</ul>
<ul>
<li><strong>Hs</strong>: Haskell Syntax (generally as opposed to Core, for example, Expr vs !HsExpr)</li>
</ul>
<ul>
<li><strong>Hsc</strong>: Haskell compiler. Means it Deals with compiling a single module and no more.</li>
</ul>
<ul>
<li><strong>!HsSyn</strong>: Haskell abstract syntax</li>
</ul>
<ul>
<li><strong>Id</strong>: Synonym for Var, but indicating a term variable</li>
</ul>
<ul>
<li><strong>Iface</strong>: Interface, as in Haskell interface (.hi) files</li>
</ul>
<ul>
<li><strong>!IfaceSyn</strong>: Interface abstract syntax</li>
</ul>
<ul>
<li><strong>LHs</strong>: Located Haskell something</li>
</ul>
<ul>
<li><strong>Loc</strong>: Location, as in !SrcLoc</li>
</ul>
<ul>
<li><strong>Located</strong>: Something annotated with a !SrcSpan</li>
</ul>
<ul>
<li><strong>Lcl</strong>: Local</li>
</ul>
<ul>
<li><strong>nativeGen</strong>: Native code generator (generates assembly from Cmm)</li>
</ul>
<ul>
<li><strong>Occ</strong>: Occurrence</li>
</ul>
<p><code>*However,inthecontextof</code><a href="http://hackage.haskell.org/trac/ghc/wiki/Commentary/Compiler/RdrNameType#TheOccNametype"><code>OccName</code></a><code>,&quot;occurrence&quot;actuallymeans&quot;classified(i.e.asatypename,valuename,etc)butnotqualifiedandnotyetresolved&quot;</code></p>
<ul>
<li><strong>PId</strong>: Package ID</li>
</ul>
<ul>
<li><strong>!PprCore</strong>: Pretty-printing core</li>
</ul>
<ul>
<li><strong>Rdr</strong>: Parser (or reader)</li>
</ul>
<ul>
<li><strong>Rn</strong>: Rename or Renamer</li>
</ul>
<ul>
<li><strong>Rts</strong>: Run Time System</li>
</ul>
<ul>
<li><strong>!SimplCore</strong>: Simplify core (the so-called simplifier belongs to this, as does the strictness analyser)</li>
</ul>
<ul>
<li><strong>!SrcLoc</strong>: Source location (filename, line number, character position)</li>
</ul>
<ul>
<li><strong>!SrcSpan</strong>: Source location span (filename, start line number and character position, end line number and character position)</li>
</ul>
<ul>
<li><strong>STG</strong>: [Commentary/Compiler/StgSynType Spineless Tagless G-machine]</li>
</ul>
<ul>
<li><strong>Tc</strong>: !TypeCheck{ing,er}</li>
</ul>
<ul>
<li><strong>TSO</strong>: <a href="https://ghc.haskell.org/trac/ghc/wiki/Commentary/Rts/Storage/HeapObjects#ThreadStateObjects">Thread State Object</a></li>
</ul>
<ul>
<li><strong>!TyCon</strong>: Type constructor</li>
</ul>
<ul>
<li><strong>!TyThing</strong>: Something that is type-checkable</li>
</ul>
<ul>
<li><strong>Ty</strong>: Type</li>
</ul>
<ul>
<li><strong>!TyVar</strong>: Synonym for Var, but indicating a type variable</li>
</ul>
<ul>
<li><strong>Var</strong>: A variable with some information about its type (or kind)</li>
</ul>
<h1 id="aging-in-the-generational-gc">Aging in the generational GC</h1>
<p>Aging is an important technique in generational GC: the idea is that objects that have only recently been allocated have not had sufficient chance to die, and so promoting them immediately to the next generation may lead to retention of unnecessary data. The problem is amplified if the prematurely promoted objects are thunks that are subsequently updated, leading to retention of an arbitrary amount of live data until the next collection of the old generation, which may be a long time coming.</p>
<p>The idea is that instead of promoting live objects directly from generation 0 into generation 1, they stay in generation 0 for a &quot;while&quot;, and if they live long enough, they get promoted. The simplest way is to segment the objects in generation 0 by the number of collections they have survived, up to a maximum. GHC 6.12 used to do this: each generation had a tunable number of <em>steps</em>. Objects were initially promoted to step 0, copied through each subsequent step on following GC cycles, and then eventually promoted to the next generation.</p>
<p>Measurement we made showed that the optimal number of steps was somewhere between 1 and 3 (2 was almost always better than either 1 or 3). In priniciple it is possible to have a fractional number of steps, although GHC 6.12 only supported integral numbers.</p>
<p>In GHC 6.13 and later, we made the following change: each block now points to the generation to which objects in that block will be copied in the next GC (the `dest` field of `bdescr`). This lets us decide on a block-by-block basis which objects to promote and which to retain in a generation, and lets us implement fractional numbers of steps. At the same time, we dropped the notion of explicit steps, so each generation just has a single list of blocks. This means that we can no longer do aging of more than 2 GC cycles, but since the measurements showed that this was unlikely to be beneficial, and the new structure is much simpler, we felt it was worthwhile.</p>
<p>Blocks in the nursery have a `dest` field pointing to generation 0, and blocks of live objects in generation 0 have a `dest` field pointing to generation 1. This gives us the same effect as 2 steps did in the GHC 6.12, except that intermediate generations (e.g. gen 1 in a 3-gen setup) now only have one step rather than 2. We could implement aging in the intermediate generations too if that turns out to be beneficial (more than 2 generations is rarely better than 2, according to our measurements).</p>
<h1 id="improving-llvm-alias-analysis">Improving LLVM Alias Analysis</h1>
<p>This page tracks the information and progress relevant to improving the alias analysis pass for the LLVM backend of GHC.</p>
<p>This correspond to bug #5567.</p>
<h2 id="llvm-alias-analysis-infrastructure">LLVM Alias Analysis Infrastructure</h2>
<p>Some links to the various documentation on LLVM's AA support:</p>
<p><code>*</code><a href="http://llvm.org/docs/AliasAnalysis.html"><code>LLVM</code> <code>Alias</code> <code>Analysis</code> <code>Infrastructure</code></a><br />
<code>*</code><a href="http://llvm.org/docs/Passes.html"><code>LLVM's</code> <code>Analysis</code> <code>and</code> <code>Transform</code> <code>Passes</code></a><br />
<code>*</code><a href="http://llvm.org/docs/GetElementPtr.html"><code>The</code> <code>Often</code> <code>Misunderstood</code> <code>GEP</code> <code>Instruction</code></a><br />
<code>*</code><a href="http://llvm.org/docs/LangRef.html"><code>LLVM</code> <code>Language</code> <code>Reference</code></a><br />
<code>*</code><a href="http://groups.google.com/group/llvm-dev/browse_thread/thread/2a5944692508bcc2/363c96bb1c6a506d?show_docid=363c96bb1c6a506d&amp;pli=1"><code>LLVM</code> <code>Dev</code> <code>List:</code> <code>Comparison</code> <code>of</code> <code>Alias</code> <code>Analysis</code> <code>in</code> <code>LLVM</code></a></p>
<h2 id="maxs-work">Max's Work</h2>
<p>Max had a crack at writing a custom alias analysis pass for LLVM, relevant links are:</p>
<p><code>*</code><a href="http://lists.cs.uiuc.edu/pipermail/llvmdev/2011-September/043603.html"><code>Email</code> <code>to</code> <code>LLVM</code> <code>dev</code></a><br />
<code>*</code><a href="http://blog.omega-prime.co.uk/?p=135"><code>Blog</code> <code>post</code> <code>about</code> <code>results</code></a><br />
<code>*</code><a href="https://github.com/bgamari/ghc-llvm-analyses"><code>A</code> <code>port</code> <code>to</code> <code>LLVM</code> <code>3.6</code></a></p>
<h2 id="tbaa">TBAA</h2>
<p>LLVM as of version 2.9 includes Type Based Alias Analysis. This mean using metadata you can specify a type hierarchy (with alias properties between types) and annotate your code with these types to improve the alias information. This should allow us to improve the alias analysis without any changes to LLVM itself like Max made.</p>
<p><code>*</code><a href="http://llvm.org/docs/LangRef.html#tbaa"><code>LLVM</code> <code>TBBA</code> <code>Doc</code></a></p>
<h2 id="stg-cmm-alias-properties">STG / Cmm Alias Properties</h2>
<p><strong>Question</strong> (David Terei): What alias properties does the codegen obey? Sp and Hp never alias? R<n> registers never alias? ....</p>
<p><strong>Answer</strong> (Simon Marlow): Sp[] and Hp[] never alias, R[] never aliases with Sp[], and that's about it.</p>
<p></p>
<p><em>' Simon</em>': As long as it propagates properly, such that every F(Sp) is a stack pointer, where F() is any expression context except a dereference. That is, we better be sure that</p>
<p></p>
<p>is &quot;stack&quot;, not &quot;heap&quot;.</p>
<h2 id="how-to-track-tbaa-information">How to Track TBAA information</h2>
<p>Really to be sound and support Cmm in full we would need to track and propagate TBAA information. It's Types after all! At the moment we don't. We simply rely on the fact that the Cmm code generated for loads and stores is nearly always in the form of:</p>
<p></p>
<p>That is to say, it has the values it depends on for the pointer derivation in-lined in the load or store expression. It is very rarely of the form:</p>
<p></p>
<p>And when it is, 'it is' (unconfirmed) always deriving a &quot;heap&quot; pointer, &quot;stack&quot; pointers are always of the in-line variety. This assumption if true allows us to look at just a store or load in isolation to properly Type it.</p>
<p>There are two ways to type this 'properly'.</p>
<p>1. Do data flow analysis. This is the only proper way to do it but also annoying. 2. Do block local analysis. Instead of doing full blow data flow analysis, just track the type of pointers stored to CmmLocal regs at the block level. This is safe but just may miss some opportunities when a CmmLocal's value is assigned in another block... My hunch is this is quite rare so this method should be fairly effective (and easier to implement and quicker to run that 1.)</p>
<h2 id="llvm-type-system">LLVM type system</h2>
<p>The above aliasing information can be encoded as follows:</p>
<p></p>
<p>The fact that `R[]` never aliases with `Sp[]` is never used as the one way relation isn't expressible in LLVM.</p>
<p>Stores/loads needs to be annotated with `!tbaa` and one of the above four types e.g.</p>
<p></p>
<h2 id="problems-optmisations-to-solve">Problems / Optmisations to Solve</h2>
<h3 id="llvm-optimisations">LLVM Optimisations</h3>
<p>Roman reported that running 'opt -std-compile-opts' gives much better code than running 'opt -O3'.</p>
<p><strong>Following is from Roman Leschinskiy</strong></p>
<p>'-O2 -std-compile-opts' does the trick but it's obviously overkill because it essentially executes the whole optimisation pipeline twice. The crucial passes seem to be loop rotation and loop invariant code motion. These are already executed twice by -O2 but it seems that they don't have enough information then and that something interesting happens in later passes which allows them to work much better the third time.</p>
<h3 id="safe-loads-speculative-load">Safe Loads (speculative load)</h3>
<p>We want to allow LLVM to speculatively hoist loads out of conditional blocks. Relevant LLVM source code is here:</p>
<p><code>*</code><a href="http://llvm.org/docs/doxygen/html/SimplifyCFG_8cpp_source.html"><code>SimplifyCFG</code> <code>Source</code> <code>Code</code></a><br />
<code>*</code><a href="http://llvm.org/docs/doxygen/html/namespacellvm.html#a4899ff634bf732c16dd22ecfdafdea7d"><code>llvm::isSafeToSpeculativelyExecute</code></a><br />
<code>*</code><a href="http://lists.cs.uiuc.edu/pipermail/llvmdev/2012-January/046958.html"><code>LLVM</code> <code>Mailing</code> <code>List</code> <code>Discussion</code> <code>about</code> <code>'Safe</code> <code>loads'</code></a></p>
<p><strong>Following is from Roman Leshchinskiy</strong></p>
<p>I've poked around a bit and things are rather complicated. So far I've identified two problems. Here is a small example function:</p>
<p></p>
<p>This is the interesting C-- bit:</p>
<p></p>
<p>Look at what indexDoubleArray# compiles to: F64[I32[Sp + 12] + ((R1 &lt;&lt; 3) + 8)]. We would very much like LLVM to hoist the I32[Sp+12] bit (i.e., loading the pointer to the ByteArray data) out of the loop because that might allow all sorts of wonderful optimisation such as promoting it to a register. But alas, this doesn't happen, LLVM leaves the load in the loop. Why? Because it assumes that the load might fail (for instance, if Sp is NULL) and so can't move it past conditionals. We know, of course, that this particular load can't fail and so can be executed speculatively but there doesn't seem to be a way of communicating this to LLVM.</p>
<p>As a quick experiment, I hacked LLVM to accept &quot;safe&quot; annotations on loads and then manually annotated the LLVM assembly generated by GHC and that helped quite a bit. I suppose that's the way to go - we'll have to get this into LLVM in some form and then the backend will have to generate those annotations for loads which can't fail. I assume they are loads through the stack pointer and perhaps the heap pointer unless we're loading newly allocated memory (those loads can't be moved past heap checks). In any case, the stack pointer is the most important thing. I can also imagine annotating pointers (such as Sp) rather than instructions but that doesn't seem to be the LLVM way and it's also less flexible.</p>
<h3 id="ghc-heap-check-case-merging">GHC Heap Check (case merging)</h3>
<p>See bug #1498</p>
<p><strong>Following is from Roman Leshchinskiy</strong></p>
<p>I investigated heap check a bit more and it seems to me that it's largely GHC's fault. LLVM does do loop unswitching which correctly pulls out loop-invariant heap checks but that happens fairly late in its pipeline and heap checks interfere with optimisations before that.</p>
<p>However, we really shouldn't be generating those heap checks in the first place. Here is a small example loop:</p>
<p></p>
<p>This is the C-- that GHC generates:</p>
<p></p>
<p>Note how in each loop iteration, we add 12 to Hp, then do the heap check and then subtract 12 from Hp again. I really don't think we should be generating that and then relying on LLVM to optimise it away.</p>
<p>This happens because GHC commons up heap checks for case alternatives and does just one check before evaluating the case. The relevant comment from CgCase.lhs is this:</p>
<p>A more interesting situation is this:</p>
<p></p>
<p>where !x! indicates a possible heap-check point. The heap checks in the alternatives <strong>can</strong> be omitted, in which case the topmost heapcheck will take their worst case into account.</p>
<p>This certainly makes sense if A allocates. But with vector-based code at least, a lot of the time neither A nor C will allocate <strong>and</strong> C will tail-call A again so by pushing the heap check into !A!, we are now doing it <strong>in</strong> the loop rather than at the end.</p>
<p>It seems to me that we should only do this if A actually allocates and leave the heap checks in the alternatives if it doesn't (perhaps we could also use a common heap check if <strong>all</strong> alternatives allocate). I tried to hack this and see what happens but found the code in CgCase and friends largely incomprehensible. What would I have to change to implement this (perhaps controlled by a command line flag) and is it a good idea at all?</p>
<h1 id="ghc-commentary-the-ghc-api">GHC Commentary: The GHC API</h1>
<p>This section of the commentary describes everything between [wiki:Commentary/Compiler/HscMain HscMain] and the front-end; that is, the parts of GHC that coordinate the compilation of multiple modules.</p>
<p>The GHC API is rather stateful; the state of an interaction with GHC is stored in an abstract value of type . The only fundamental reason for this choice is that the  models the state of the RTS's linker, which must be single-threaded.</p>
<p>Although the GHC API apparently supports multiple clients, because each can be interacting with a different , in fact it only supports one client that is actually executing code, because the [wiki:Commentary/Rts/Interpreter#Linker RTS linker] has a single global symbol table.</p>
<p>This part of the commentary is not a tutorial on <em>using</em> the GHC API: for that, see <a href="http://haskell.org/haskellwiki/GHC/As_a_library">Using GHC as a Library</a>. Here we are going to talk about the implementation.</p>
<p>A typical interaction with the GHC API goes something like the following:</p>
<p><code>*Youprobablywanttowrapthewholeprogramin</code><code>togeterrormessages</code><br />
<code>*Createanewsession:</code><br />
<code>*Settheflags:</code><code>,</code><code>.</code><br />
<code>*Addsome</code><em><code>targets</code></em><code>:</code><code>,</code><code>,</code><br />
<code>*Perform</code><a href="ref(Dependency_Analysis)" title="wikilink"><code>ref(Dependency</code> <code>Analysis)</code></a><code>:</code><br />
<code>*Load(compile)thesourcefiles:</code></p>
<p>Warning: Initializing GHC is tricky! Here is a template that seems to initialize GHC and a session. Derived from ghc's Main.main function.</p>
<p></p>
<p>You must pass the path to  as an argument to .</p>
<p>The  field of  tells the compiler what kind of output to generate from compilation. There is unfortunately some overlap between this and the  passed to ; we hope to clean this up in the future, but for now it's probably a good idea to make sure that these two settings are consisent. That is, if , then , if  then .</p>
<h2 id="targets">Targets</h2>
<p>The targets specify the source files or modules at the top of the dependency tree. For a Haskell program there is often just a single target , but for a library the targets would consist of every visible module in the library.</p>
<p>The  type is defined in <a href="GhcFile(compiler/main/HscTypes.lhs)" class="uri" title="wikilink">GhcFile(compiler/main/HscTypes.lhs)</a>. Note that a  includes not just the file or module name, but also optionally the complete source text of the module as a : this is to support an interactive development environment where the source file is being edited, and the in-memory copy of the source file is to be used in preference to the version on disk.</p>
<h2 id="dependency-analysis">Dependency Analysis</h2>
<p>The dependency analysis phase determines all the Haskell source files that are to be compiled or loaded in the current session, by traversing the transitive dependencies of the targets. This process is called the <em>downsweep</em> because we are traversing the dependency tree downwards from the targets. (The <em>upsweep</em>, where we compile all these files happens in the opposite direction of course).</p>
<p>The  function takes the targets and returns a list of  consisting of all the modules to be compiled/loaded.</p>
<h2 id="the-modsummary-type">The !ModSummary type</h2>
<p>A  (defined in <a href="GhcFile(compiler/main/HscTypes.lhs)" class="uri" title="wikilink">GhcFile(compiler/main/HscTypes.lhs)</a>) contains various information about a module:</p>
<p><code>*Its</code><code>,whichincludesthepackagethatitbelongsto</code><br />
<code>*Its</code><code>,whichliststhepathnamesofallthefilesassociatedwiththemodule</code><br />
<code>*Themodulesthatitimports</code><br />
<code>*Thetimeitwaslastmodified</code><br />
<code>*...someotherthings</code></p>
<p>We collect  information for all the modules we are interested in during the <em>downsweep</em>, below. Extracting the information about the module name and the imports from a source file is the job of <a href="GhcFile(compiler/main/HeaderInfo.hs)" class="uri" title="wikilink">GhcFile(compiler/main/HeaderInfo.hs)</a> which partially parses the source file.</p>
<p>Converting a given module name into a  is done by  in <a href="GhcFile(compiler/main/GHC.hs)" class="uri" title="wikilink">GhcFile(compiler/main/GHC.hs)</a>. Similarly, if we have a filename rather than a module name, we generate a  using .</p>
<h2 id="loading-compiling-the-modules">Loading (compiling) the Modules</h2>
<p>When the dependency analysis is complete, we can load these modules by calling . The same interface is used regardless of whether we are loading modules into GHCi with the  command, or compiling a program with : we always end up calling .</p>
<p>The process in principle is fairly simple:</p>
<p><code>*Visiteachmoduleinthedependencytreefromthebottomup,invoking[wiki:Commentary/Compiler/HscMainHscMain]</code><br />
<code>tocompileit(the</code><em><code>upsweep</code></em><code>).</code><br />
<code>*Finally,linkallthecodetogether.InGHCithisinvolvesloadingalltheobjectcodeintomemoryandlinkingit</code><br />
<code>withthe[wiki:Commentary/Rts/Interpreter#LinkerRTSlinker],andthenlinkingallthebyte-codetogether.In</code><br />
<code></code><code>modethisinvolvesinvokingtheexternallinkertolinktheobjectcodeintoabinary.</code></p>
<p>The process is made more tricky in practice for two reasons:</p>
<p><code>*Wemightnotneedtocompilecertainmodules,ifnoneoftheirdependencieshavechanged.GHC's</code><br />
<code>[wiki:Commentary/Compiler/RecompilationAvoidancerecompilationchecker]determineswhetheramodulereallyneeds</code><br />
<code>tobecompiledornot.</code><br />
<code>*InGHCi,wemightjustbereloadingtheprogramaftermakingsomechanges,sowedon'tevenwanttore-link</code><br />
<code>modulesforwhichnodependencieshavechanged.</code></p>
<h1 id="ghc-commentary-asynchronous-exceptions">GHC Commentary: Asynchronous Exceptions</h1>
<h1 id="ghc-commentary-backends">GHC Commentary: Backends</h1>
<p>After [wiki:Commentary/Compiler/CmmType Cmm] has been generated, we have a choice of targets to compile to:</p>
<p><code>*[wiki:Commentary/Compiler/Backends/PprCTheCcodegenerator]</code><br />
<code>*[wiki:Commentary/Compiler/Backends/NCGThenativecodegenerator]</code><br />
<code>*[wiki:Commentary/Compiler/Backends/LLVMTheLLVMcodegenerator]</code><br />
<code>*[wiki:Commentary/Compiler/Backends/GHCiTheGHCicodegenerator]</code></p>
<p>These backends are completely interchangeable. Our preferred route is the native code generator. The C code generator is used for portable, non-optimised, or unregisterised compilation (Note that the LLVM backend also supports building GHC in unregisterised mode as well as registerised mode so it is usually the preferred route for porting GHC).</p>
<h1 id="types-in-the-back-end-aka-the-rep-swamp">Types in the back end (aka &quot;The `Rep` swamp&quot;)</h1>
<p>I have completed a major representation change, affecting both old and new code generators, of the various `Rep` types. It's pervasive in that it touches a lot of files; and in the native code-gen very many lines are changed. The new situation is much cleaner.</p>
<p>Here are the highlights of the new design.</p>
<h2 id="cmmtype">`CmmType`</h2>
<p>There is a new type `CmmType`, defined in module `CmmExpr`, which is just what it sounds like: it's the type of a `CmmExpr` or a `CmmReg`.</p>
<p><code>*A`CmmType`is</code><em><code>abstract</code></em><code>:itsrepresentationisprivateto`CmmExpr`.Thatmakesiteasytochangerepresentation.</code><br />
<code>*A`CmmType`isactuallyjustapairofa`Width`andacategory(`CmmCat`).</code><br />
<code>*The`Width`typeisexportedandwidelyusedinpattern-matching,butitdoeswhatitsaysonthetin:widthonly.</code><br />
<code>*Incontrast,the`CmmCat`typeisentirelyprivateto`CmmExpr`.Itisjustanenumerationthatallowsustodistinguish:floats,gcpointers,andother.</code></p>
<p>Other important points are these:</p>
<p><code>*Each`LocalReg`hasa`CmmType`attached;thisreplacesthepreviousunsavourycombinationof`MachRep`and`CmmKind`.Indeed,bothofthelatteraregoneentirely.</code></p>
<p><code>*Noticethata`CmmType`accuratelyknowsaboutgc-pointer-hood.Ultimatelywewillabandonstatic-reference-tablegenerationinSTGsyntax,andinsteadgenerateSRTsfromtheCmmcode.We'llneedtoupdatetheRTS`.cmm`filestodeclarepointer-hood.</code></p>
<p><code>*Thetype`TyCon.PrimRep`remains;itenumeratestherepresentationsthataHaskellvaluecantake.Differencesfrom`CmmType`:</code><br />
<code>*`PrimRep`contains`VoidRep`,but`CmmType`hasnozero-widthform.</code><br />
<code>*`CmmType`includessub-wordwidthvalues(e.g.8-bit)which`PrimRep`doesnot.</code><br />
<code>Thefunction`primRepCmmType`convertsanon-void`PrimRep`toa`CmmType`.</code></p>
<p><code>*`CmmLint`iscomplainsifyouassignagc-ptrtoanon-gc-ptrandviceversa.Ittreats&quot;gc-ptr+constant&quot;asagc-ptr.</code></p>
<p><code></code><em><code>NB:</code> <code>you'd</code> <code>better</code> <code>not</code> <code>make</code> <code>an</code> <code>interior</code> <code>pointer</code> <code>live</code> <code>across</code> <code>a</code> <code>call</code></em><code>,elsewe'llsaveitonthestackandtreatitasaGCroot.It'snotclearhowtoguaranteethisdoesn'thappenastheresultofsomeoptimisation.</code></p>
<p><strong>Parsing `.cmm` RTS files.</strong> The global register `P0` is a gc-pointer version of `R0`. They both map to the same physical register, though!</p>
<h2 id="the-machop-type">The `MachOp` type</h2>
<p>The `MachOp` type enumerates (in machine-independent form) the available machine instructions. The principle they embody is that <em>everything except the width is embodied in the opcode</em>. In particular, we have</p>
<p><code>*`MO_S_Lt`,`MO_U_Lt`,and`MO_F_Lt`forcomparison(signed,unsigned,andfloat).</code><br />
<code>*`MO_SS_Conv`,`MO_SF_Conv`etc,forconversion(`SS`issigned-to-signed,`SF`issigned-to-float,etc).</code></p>
<p>These constructor all take `Width` arguments.</p>
<p>The `MachOp` data type is defined in `CmmExpr`, not in a separate `MachOp` module.</p>
<h2 id="foreign-calls-and-hints">Foreign calls and hints</h2>
<p>In the new Cmm representation (`ZipCfgCmmRep`), but not the old one, arguments and results to all calls, including foreign ones, are ordinary `CmmExpr` or `CmmReg` respectively. The extra information we need for foreign calls (is this signed? is this an address?) are kept in the calling convention. Specifically:</p>
<p><code>*`MidUnsafeCall`callsa`MidCallTarget`</code><br />
<code>*`MidCallTarget`iseithera`CallishMachOp`ora`ForeignTarget`</code><br />
<code>*Inthelattercasewesupplya`CmmExpr`(thefunctiontocall)anda`ForeignConvention`</code><br />
<code>*A`ForeignConvention`containstheCcallingconvention(stdcall,ccalletc),andalistof`ForiegnHints`forargumentsandforresults.(Wemightwanttorenamethistype.)</code></p>
<p>This simple change was horribly pervasive. The old Cmm rep (and Michael Adams's stuff) still has arguments and results being (argument,hint) pairs, as before.</p>
<h2 id="native-code-generation-and-the-size-type">Native code generation and the `Size` type</h2>
<p>The native code generator has an instruction data type for each architecture. Many of the instructions in these data types used to have a `MachRep` argument, but now have a `Size` argument instead. In fact, so far as the native code generators are concerned, these `Size` types (which can be machine-specific) are simply a plug-in replacement for `MachRep`, with one big difference: <strong>`Size` is completely local to the native code generator</strong> and hence can be changed at will without affecting the rest of the compiler.</p>
<p>`Size` is badly named, but I inherited the name from the previous code.</p>
<p>I rather think that many instructions should have a `Width` parameter, not a `Size` parameter. But I didn't feel confident to change this. Generally speaking the NCG is a huge swamp and needs re-factoring. I'm working on getting Backtraces in GHC. Progress can be seen here: <a href="https://github.com/abacathoo/ghc" class="uri">https://github.com/abacathoo/ghc</a></p>
<h1 id="the-block-allocator">The Block Allocator</h1>
<p>Source: <a href="GhcFile(includes/rts/storage/Block.h)" class="uri" title="wikilink">GhcFile(includes/rts/storage/Block.h)</a>, <a href="GhcFile(rts/sm/BlockAlloc.h)" class="uri" title="wikilink">GhcFile(rts/sm/BlockAlloc.h)</a>, <a href="GhcFile(rts/sm/BlockAlloc.c)" class="uri" title="wikilink">GhcFile(rts/sm/BlockAlloc.c)</a>, <a href="GhcFile(includes/rts/storage/MBlock.h)" class="uri" title="wikilink">GhcFile(includes/rts/storage/MBlock.h)</a>, <a href="GhcFile(rts/sm/MBlock.c)" class="uri" title="wikilink">GhcFile(rts/sm/MBlock.c)</a>.</p>
<p>The block allocator is where the storage manager derives much of its flexibilty. Rather than keep our heap in a single contiguous region of memory, or one contiguous region per generation, we manage linked lists of memory blocks. Managing contiguous regions is difficult, especially when you want to change the size of some of the areas. A block-structured storage arrangement has several advantages:</p>
<p><code>*resizingareasofmemoryiseasy:justchainmoreblocksontothelist.</code></p>
<p><code>*managinglargeobjectswithoutcopyingiseasy:allocateeachoneacompleteblock,andusetheblocklinkageto</code><br />
<code>chainthemtogether.</code></p>
<p><code>*freememorycanberecycledfaster,becauseablockisablock.</code></p>
<p>The concept relies on the property that most data objects are significantly smaller than a block, and only rarely do we need to allocate objects that approach or exceed the size of a block.</p>
<h2 id="structure-of-blocks">Structure of blocks</h2>
<p>We want to allocate memory in units of a small block (around 4k, say). Furthermore, we want each block to have an associated small structure called a <em>block descriptor</em>, which contains information about the block: its link field, which generation it belongs to, and so on. This is similar to the well-known &quot;BiBOP&quot; (Big Bag of Pages) technique, where objects with similar tags are collected together on a page so as to avoid needing to store an individual tag with each object.</p>
<p>We want a function `Bdescr(p)`, that, given an arbitrary pointer into a block, returns the address of the block descriptor that corresponds to the block containing that pointer.</p>
<p>There are two options:</p>
<p><code>*Puttheblockdescriptoratthestartoftheblock.`Bdescr(p)=p&amp;~BLOCK_SIZE`.Thisoptionhasproblemsif</code><br />
<code>weneedtoallocateacontiguousregionlargerthanasingleblock(GHCdoesthisoccasionallywhenallocating</code><br />
<code>alargenumberofobjectsinonego).</code></p>
<p><code>*Allocatememoryinlargerunits(a</code><em><code>megablock</code></em><code>),dividethemegablockintoblocks,andputalltheblock</code><br />
<code>descriptorsatthebeginning.Themegablockisaligned,sothattheaddressoftheblockdescriptorfor</code><br />
<code>ablockisasimplefunctionofitsaddress.The'Bdescr'functionismorecomplicatedthanthefirst</code><br />
<code>method,butitiseasiertoallocatecontiguousregions(unlessthecontiguousregionislargerthan</code><br />
<code>amegablock...).</code></p>
<p>We adopt the second approach. The following diagram shows a megablock:</p>
<p><a href="Image(sm-block.png)" class="uri" title="wikilink">Image(sm-block.png)</a></p>
<p>We currently have megablocks of 1Mb in size (m = 20) with blocks of 4k in size (k = 12), and these sizes are easy to change (<a href="GhcFile(includes/rts/Constants.h)" class="uri" title="wikilink">GhcFile(includes/rts/Constants.h)</a>).</p>
<p>Block descriptors are currently 32 or 64 bytes depending on the word size (d = 5 or 6). The block descriptor itself is the structure `bdescr` defined in <a href="GhcFile(includes/rts/storage/Block.h)" class="uri" title="wikilink">GhcFile(includes/rts/storage/Block.h)</a>, and that file also defines the `Bdescr()` macro.</p>
<p>The block allocator has a the following structure:</p>
<p><code>*Atthebottom,talkingtotheOS,isthemegablockallocator(</code><a href="GhcFile(rts/sm/MBlock.c)" title="wikilink"><code>GhcFile(rts/sm/MBlock.c)</code></a><code>,</code><a href="GhcFile(includes/rts/storage/MBlock.h)" title="wikilink"><code>GhcFile(includes/rts/storage/MBlock.h)</code></a><code>).</code><br />
<code>Itisresponsiblefordeliveringmegablocks,correctlyaligned,totheupperlayers.Itisalsoresponsiblefor</code><br />
<code>implementing[wiki:Commentary/HeapAllocedHEAP_ALLOCED()]:thepredicatethattestswhetherapointerpointstodynamicallyallocatedmemory</code><br />
<code>ornot.Thisisimplementedasasimplebitmaplookupona32-bitmachine,andsomethingmorecomplexon</code><br />
<code>64-bitaddressedmachines.See</code><a href="GhcFile(includes/rts/storage/MBlock.h)" title="wikilink"><code>GhcFile(includes/rts/storage/MBlock.h)</code></a><code>fordetails.</code><br />
<code></code><a href="br" title="wikilink"><code>br</code></a><a href="br" title="wikilink"><code>br</code></a><br />
<code>Currently,megablocksareneverfreedbacktotheOS,exceptattheendoftheprogram.Thisisapotential</code><br />
<code>improvementthatcouldbemade.</code></p>
<p><code>*Sittingontopofthemegablockallocatoristheblocklayer(</code><a href="GhcFile(includes/rts/storage/Block.h)" title="wikilink"><code>GhcFile(includes/rts/storage/Block.h)</code></a><code>,</code><a href="GhcFile(rts/sm/BlockAlloc.c)" title="wikilink"><code>GhcFile(rts/sm/BlockAlloc.c)</code></a><code>).</code><br />
<code>Thislayerisresponsibleforproviding:</code></p>
<p></p>
<p><code>Thesefunctionsallocateanddeallocateablock</code><em><code>group</code></em><code>:acontiguoussequenceofblocks(thedegenerate,andcommon,case</code><br />
<code>isasingleblock).Theblockallocatorisresponsibleforkeepingtrackoffreeblocks.Currentlyitdoesthisby</code><br />
<code>maintaininganordered(byaddress)listoffreeblocks,withcontiguousblockscoallesced.Howeverthisiscertanly</code><br />
<code>notoptimal,andhasbeenshowntobeabottleneckincertaincases-improvingthisallocationschemewouldbegood.</code></p>
<h1 id="ghc-commentary-garbage-collecting-cafs">GHC Commentary: Garbage Collecting CAFs</h1>
<p>Files: <a href="GhcFile(rts/sm/GC.c)" class="uri" title="wikilink">GhcFile(rts/sm/GC.c)</a>, function scavange_srt in <a href="GhcFile(rts/sm/Scav.h)" class="uri" title="wikilink">GhcFile(rts/sm/Scav.h)</a></p>
<p>Constant Applicative Forms, or CAFs for short, are top-level values defined in a program. Essentially, they are objects that are not allocated dynamically at run-time but, instead, are part of the static data of the program. Sometimes, a CAF may refer to many values in the heap. To avoid memory leaks in such situations, we need to know when a CAF is never going to be used again, and so we can deallocate the values that it refers to.</p>
<p>See Note [CAF management] in <a href="GhcFile(rts/sm/Storage.c)" class="uri" title="wikilink">GhcFile(rts/sm/Storage.c)</a> for more information.</p>
<h2 id="static-reference-tables">Static Reference Tables</h2>
<p>File: <a href="GhcFile(includes/rts/storage/InfoTables.h)" class="uri" title="wikilink">GhcFile(includes/rts/storage/InfoTables.h)</a></p>
<p>The info table of various closures may contain information about what static objects are referenced by the closure. This information is stored in two parts:</p>
<p><code>1.astaticreferencetable(SRT),whichisanarrayofreferencestostaticobjects</code><br />
<code>2.abitmaskwhichspecifieswhichoftheobjectsareactuallyusedbytheclosure.</code></p>
<p>There are two different ways to access this information depending on the size of the SRT:</p>
<p><code>*&quot;small&quot;:if</code><code>isasmallbitmap,notall1s,thenGET_FUN?_SRTcontainstheSRT.</code><br />
<code>*&quot;large&quot;:if</code><code>isall1s,thenGET_FUN?_SRTcontainsalargebitmap,andtheactualSRT.</code></p>
<h2 id="evacuating-static-objects">Evacuating Static Objects</h2>
<p>Files: <a href="GhcFile(rts/sm/GCThread.h)" class="uri" title="wikilink">GhcFile(rts/sm/GCThread.h)</a>, <a href="GhcFile(rts/sm/Evac.c)" class="uri" title="wikilink">GhcFile(rts/sm/Evac.c)</a>, <a href="GhcFile(rts/sm/GC.c)" class="uri" title="wikilink">GhcFile(rts/sm/GC.c)</a></p>
<p>While scavenging objects, we also process (aka &quot;evacuate&quot;) any static objects that need to be kept alive. When a GC thread discovers a live static object, it places it on its  list. Later, this list is used to scavange the static objects, potentially finding more live objects. Note that this process might find more static objects, and thus further extend the  list.</p>
<p>When a static object is scavenged, it is removed from  and placed on another list, called . Later, we use this list to &quot;clean up&quot; the liveness markers from these static objects, so that we can repeat the process on the next garbage collection. Note that we can't &quot;clean up&quot; the liveness markers as we go along because we use them to notice cycles among the static objects.</p>
<h1 id="calling-convention">Calling Convention</h1>
<p>Entry conventions are very conventional: the first N argumements in registers and the rest on the stack.</p>
<h1 id="return-convention">Return Convention</h1>
<p>All returns are now <em>direct</em>; that is, a return is made by jumping to the code associated with the [wiki:Commentary/Rts/Storage/HeapObjects#InfoTables info table] of the topmost [wiki:Commentary/Rts/Storage/Stack stack frame].</p>
<p>GHC used to have a more complex return convention called vectored returns in which some stack frames pointed to vectors of return addresses; this was dropped in GHC 6.8 after measurements that showed it was not (any longer) worthwhile.</p>
<h2 id="historical-page">Historical page</h2>
<p>This page is a bunch of notes on the new code generator. It is outdated and is here only for historical reasons.It should probably be removed. See [wiki:Commentary/Compiler/CodeGen Code Generator] page for a description of current code generator.</p>
<h1 id="cleanup-after-the-new-codegen-is-enabled">Cleanup after the new codegen is enabled</h1>
<p>The new codegen was enabled by default in 832077ca5393d298324cb6b0a2cb501e27209768. Now that the switch has been made, we can remove all the cruft associated with the old code generator. There are dependencies between some of the components, so we have to do things in the right order. Here is a list of the cleanup tasks, and notes about dependencies:</p>
<h2 id="independent-tasks">Independent tasks</h2>
<p><code>*Use`BlockId`or`Label`consistently,currentlyweuseamixtureofthetwo.Maybegetridofthe`BlockId`module.</code></p>
<p><code>*Removelive-varandCAFlistsfrom`StgSyn`,andthencleanup`CoreToStg`</code></p>
<p><code>*DONE:RemovetheSRTpassin`simplStg/SRT.lhs`</code></p>
<p><code>*DONE:removeRET_DYNfromtheRTS</code></p>
<p><code>*DONE:remove`-fnew-codegen`,related`HscMain`bitsandthe`CodeGen`module.</code></p>
<p><code>*DONE:remove`CmmOpt.cmmMiniInline`,itisnotusedanymore</code></p>
<p><code>*Fixthelayering:`cmm`modulesshouldnotdependon`codeGen/StgCmm*`</code></p>
<h2 id="towards-removing-codegencg">Towards removing codeGen/Cg*</h2>
<p><code>*DONE:`CmmParse`shouldproducenew`Cmm`.</code><br />
<code>*Wewillprobablywanttwokindsof`.cmm`file,onethatistobefedthrough`CmmLayoutStack`andonethatisn't.</code><br />
<code>*primopswillbefedthrough`CmmLayoutStack`,andwillusethenativecallingconvention,withthecodegeneratorinsertingthecopyin/copyoutforus.</code></p>
<p><code>*DONE:Removeallthe`Cg*`modules</code></p>
<h2 id="towards-removing-oldcmm">Towards removing `OldCmm`</h2>
<p><code>*INPROGRESS(SimonM):ChangetheNCGovertoconsumenew`Cmm`.WepossiblyalsowantthegeneratednativecodetousetheHooplBlockrepresentation,althoughthatwillmeanchangingbranchinstructionstohavebothtrueandfalsetargets,ratherthantrueandfallthroughaswehavenow.</code></p>
<p><code>*Remove`cmm/CmmCvt`(thiswillsavesomecompile-timetoo)</code></p>
<p><code>*Remove`cmm/OldCmm*`,`cmm/PprOldCmm`etc.</code></p>
<h2 id="later">Later</h2>
<p><code>*DothenewSRTstory(!ToDo:writeawikipageaboutthis)</code></p>
<h1 id="cmm-implementing-exception-handling">Cmm: Implementing Exception Handling</h1>
<p>The IEEE 754 specification for floating point numbers defines exceptions for certain floating point operations, including:</p>
<p><code>*rangeviolation(overflow,underflow);</code><br />
<code>*roundingerrors(inexact);</code><br />
<code>*invalidoperation(invalidoperand,suchascomparisonwitha`NaN`value,thesquarerootofanegativenumberordivisionofzerobyzero);and,</code><br />
<code>*zerodivide(aspecialcaseofaninvalidoperation).</code></p>
<p>Many architectures support floating point exceptions by including a special register as an addition to other exception handling registers. The IBM PPC includes the `FPSCR` (&quot;Floating Point Status Control Register&quot;); the Intel x86 processors use the `MXCSR` register. When the PPC performs a floating point operation it checks for possible errors and sets the `FPSCR`. Some processors allow a flag in the Foating-Point Unit (FPU) status and control register to be set that will disable some exceptions or the entire FPU exception handling facility. Some processors disable the FPU after an exception has occurred while others, notably Intel's x86 and x87 processors, continue to perform FPU operations. Depending on whether quiet !NaNs (QNaNs) or signaling !NaNs (SNaNs) are used by the software, an FPU exception may signal an interrupt for the software to pass to its own exception handler.</p>
<p>Some higher level languages provide facilities to handle these exceptions, including Ada, Fortran (F90 and later), C++ and C (C99, fenv.h, float.h on certain compilers); others may handle such exceptions without exposing a low-level interface. There are three reasons to handle FPU exceptions, and these reasons apply similarly to other exceptions:</p>
<p><code>*thefacilitiesprovidegreatercontrol;</code><br />
<code>*thefacilitiesareefficient--moreefficientthanahigher-levelsoftwaresolution;and,</code><br />
<code>*FPUexceptionsmaybeunavoidable,especiallyifseveralFPUoperationsareseriallyperformedatthemachinelevelsothehigherlevelsoftwarehasnoopportunitytochecktheresultsinbetweenoperations.</code></p>
<h4 id="an-integral-exception-example">An Integral Exception Example</h4>
<p>There has been at least one problem in GHC that would benefit from exception handling--in some cases, for `Integral`s. See bug ticket #1042. The bug occurs in `show`ing the number, in [GhcFile(libraries/base/GHC/Show.lhs) GHC.Show], `showSignedInt`, before conversion from base_2 to base_10, where a negative `Int` (always `Int32`) is negated in order to process it as a positive value when converting it to a string, base_10, causing an overflow error on some architectures. (Bear in mind that it would show up here in the example for #1042 because the function would be evaluated in GHCi here; the negation is the problem and the exception shows up in the <em>next</em> instruction on that operand, here `DIV`.)</p>
<p>The exception example in #1042 does not occur on PowerPC machines, which dutifully print the two's complement of : `0`. (`-2147483648` is the minimum bound for signed Ints, so negating it should properly become, bitwise, a positive `2147483647` (all but bit 31 set); once negated again when divided by `-1` this would be `0`; `-0` is converted to `0`.) On some architectures such as Intel 64 and IA-32, negating the minimum bound does not wrap around to `0` but overflows, which is reported as a floating point &quot;overflow&quot; (`#O`) exception: the `NEG` instruction modifies the `OF` flag (bit 11) in the `EFLAGS` register--curiously enough, the `DIV` and `IDIV` instructions have <em>undefined</em> effects on the `OF` flag.</p>
<p>The workaround was to avoid negating `minBound` `Int`s; note that no Intel instructions allow one to modify the `OF` flag directly. Alternative solutions might be to</p>
<p><code>1.maskthe&quot;exception&quot;byclearingtheinterruptflag,`IF`,usingthe`CLI`instruction;or,</code><br />
<code>1.conditionallyunsettheflagbyusingthe`PUSHF`instructiononthe`EFLAGS`registertopushitslowerword(bits15-0,includingtheoffendingbit11(`OF`))ontothestack,resetthe`OF`bit,thenpushthatbackontothestackandpopitintoEFLAGSwith`POPF`.Dependingonvariableregisterused,theassembleroutputwouldlooksimilarto:</code></p>
<p></p>
<h4 id="a-floating-point-exception-example">A Floating Point Exception Example</h4>
<p>There was a long message thread on the Haskell-prime mailing list, &quot;realToFrac Issues,&quot; beginning with <a href="http://www.haskell.org/pipermail/haskell-prime/2006-February/000791.html">John Meacham's message</a> and ending with <a href="http://www.haskell.org/pipermail/haskell-prime/2006-March/000840.html">Simon Marlow's message</a>. The following code for converting a Float to a Double will <em>fail</em> to produce a floating point exception or NaN on x86 machines (recall that 0.0/0.0 is NaN <em>and</em> a definite FPU exception):</p>
<p>[in GHCi-6.6 on PowerPC, OS X]: </p>
<p>This bug is not due to the lack of FPU exceptions in Cmm but bears mention as the internal conversion performed in 'realToFrac' on 'Float's would benefit from FPU exceptions: with Haskell-support for FPU exceptions this realToFrac would be able to issue an exception for NaN, Infinity or rounding errors when converting a Float to a Double and vice versa. There is a related problem with rounding errors in the functions 'encodeFloat', 'decodeFloat', 'encodeDouble' and 'decodeDouble', see [wiki:ReplacingGMPNotes/TheCurrentGMPImplementation].</p>
<p>On 5 May 2008, Isaac Dupree asked</p>
<p><code>Istheredocumentation(e.g.ontheGHCCommentarysomewhereIcan't</code><br />
<code>find)anexplanationofwhatC--&quot;kinds&quot;areorhowthey'reuseful/used?</code></p>
<p>Probably not. GHC Cmm is a sort of pidgin version of C-- 2.0, and true C-- kinds are explained in the <a href="http://www.cminusminus.org/code.html">C-- specification, section 5.1</a>.</p>
<p><code>WhenIwasportabilizingthatcodeareaawhileagoIhadignorantly</code><br />
<code>changedsomeoftheusesof&quot;kind&quot;to&quot;hint&quot;forconsistency(bothnames</code><br />
<code>hadbeenbeingusedforthesamethingviatype-synonym.)andbecauseI</code><br />
<code>couldguesshowthecodemakesenseifitwas,informally,ahintabout</code><br />
<code>whattodo.</code></p>
<p>Hint was the word used originally, and several people (including reviewers) objected to it on the grounds that the 'hints' are actually mandatory to get the compiler to do what you want (e.g., pass arguments in floating-point registers). So we changed the name to 'kind'.</p>
<p>If you like dense, indigestible academic papers full of formalism, there's <a href="http://www.cs.tufts.edu/~nr/pubs/staged-abstract.html">one I'm quite proud of</a>. It explains in detail how kinds are useful for specifying and implementing procedure calling conventions, which is the use to which they are put within GHC.</p>
<p>Norman Ramsey</p>
<h3 id="note-to-reader">Note To Reader</h3>
<p>This page was written with more detail than usual since you may need to know how to work with Cmm as a programming language. Cmm is the basis for the future of GHC, Native Code Generation, and if you are interested in hacking Cmm at least this page might help reduce your learning curve. As a finer detail, if you read the [wiki:Commentary/Compiler/HscMain Compiler pipeline] wiki page or glanced at the diagram there you may have noticed that whether you are working backward from an `intermediate C` (Haskell-C &quot;HC&quot;, `.hc`) file or an Assembler file you get to Cmm before you get to the STG language, the Simplifier or anything else. In other words, for really low-level debugging you may have an easier time if you know what Cmm is about. Cmm also has opportunities for implementing small and easy hacks, such as little optimisations and implementing new Cmm Primitive Operations.</p>
<p>A portion of the [wiki:Commentary/Rts RTS] is written in Cmm: <a href="GhcFile(rts/Apply.cmm)" class="uri" title="wikilink">GhcFile(rts/Apply.cmm)</a>, <a href="GhcFile(rts/Exception.cmm)" class="uri" title="wikilink">GhcFile(rts/Exception.cmm)</a>, <a href="GhcFile(rts/HeapStackCheck.cmm)" class="uri" title="wikilink">GhcFile(rts/HeapStackCheck.cmm)</a>, <a href="GhcFile(rts/PrimOps.cmm)" class="uri" title="wikilink">GhcFile(rts/PrimOps.cmm)</a>, <a href="GhcFile(rts/StgMiscClosures.cmm)" class="uri" title="wikilink">GhcFile(rts/StgMiscClosures.cmm)</a>, <a href="GhcFile(rts/StgStartup.cmm)" class="uri" title="wikilink">GhcFile(rts/StgStartup.cmm)</a> and <a href="GhcFile(StgStdThunks.cmm)" class="uri" title="wikilink">GhcFile(StgStdThunks.cmm)</a>. (For notes related to `PrimOps.cmm` see the [wiki:Commentary/PrimOps PrimOps] page; for much of the rest, see the [wiki:Commentary/Rts/HaskellExecution HaskellExecution] page.) Cmm is optimised before GHC outputs either HC or Assembler. The C compiler (from HC, pretty printed by <a href="GhcFile(compiler/cmm/PprC.hs)" class="uri" title="wikilink">GhcFile(compiler/cmm/PprC.hs)</a>) and the [wiki:Commentary/Compiler/Backends/NCG Native Code Generator] (NCG) [wiki:Commentary/Compiler/Backends Backends] are closely tied to data representations and transformations performed in Cmm. In GHC, Cmm roughly performs a function similar to the intermediate <a href="http://gcc.gnu.org/onlinedocs/gccint/RTL.html">Register Transfer Language (RTL)</a> in GCC.</p>
<h1 id="table-of-contents">Table of Contents</h1>
<p><code>1.[wiki:Commentary/Compiler/CmmType#AdditionsinCmmAdditionsinCmm]</code><br />
<code>1.[wiki:Commentary/Compiler/CmmType#CompilingCmmwithGHCCompilingCmmwithGHC]</code><br />
<code>1.[wiki:Commentary/Compiler/CmmType#BasicCmmBasicCmm]</code><br />
<code>1.[wiki:Commentary/Compiler/CmmType#CodeBlocksinCmmCodeBlocksinCmm]</code><br />
<code>*[wiki:Commentary/Compiler/CmmType#BasicBlocksandProceduresBasicBlocksandProcedures]</code><br />
<code>1.[wiki:Commentary/Compiler/CmmType#VariablesRegistersandTypesVariables,RegistersandTypes]</code><br />
<code>1.[wiki:Commentary/Compiler/CmmType#LocalRegistersLocalRegisters]</code><br />
<code>1.[wiki:Commentary/Compiler/CmmType#GlobalRegistersandHintsGlobalRegistersandHints]</code><br />
<code>1.[wiki:Commentary/Compiler/CmmType#DeclarationandInitialisationDeclarationandInitialisation]</code><br />
<code>1.[wiki:Commentary/Compiler/CmmType#MemoryAccessMemoryAccess]</code><br />
<code>1.[wiki:Commentary/Compiler/CmmType#LiteralsandLabelsLiteralsandLabels]</code><br />
<code>*[wiki:Commentary/Compiler/CmmType#LabelsLabels]</code><br />
<code>1.[wiki:Commentary/Compiler/CmmType#SectionsandDirectivesSectionsandDirectives]</code><br />
<code>*[wiki:Commentary/Compiler/CmmType#TargetDirectiveTargetDirective]</code><br />
<code>1.[wiki:Commentary/Compiler/CmmType#ExpressionsExpressions]</code><br />
<code>*[wiki:Commentary/Compiler/CmmType#QuasioperatorSyntaxQuasi-operatorSyntax]</code><br />
<code>1.[wiki:Commentary/Compiler/CmmType#StatementsandCallsStatementsandCalls]</code><br />
<code>*[wiki:Commentary/Compiler/CmmType#CmmCallsCmmCalls]</code><br />
<code>1.[wiki:Commentary/Compiler/CmmType#OperatorsandPrimitiveOperationsOperatorsandPrimitiveOperations]</code><br />
<code>1.[wiki:Commentary/Compiler/CmmType#OperatorsOperators]</code><br />
<code>1.[wiki:Commentary/Compiler/CmmType#PrimitiveOperationsPrimitiveOperations]</code><br />
<code>1.[wiki:Commentary/Compiler/CmmType#CmmDesign:ObservationsandAreasforPotentialImprovementCmmDesign:ObservationsandAreasforPotentialImprovement]</code></p>
<h1 id="the-cmm-language">The Cmm language</h1>
<p>`Cmm` is the GHC implementation of the `C--` language; it is also the extension of Cmm source code files: `.cmm` (see [wiki:Commentary/Rts/Cmm What the hell is a .cmm file?]). The GHC [wiki:Commentary/Compiler/CodeGen Code Generator] (`CodeGen`) compiles the STG program into `C--` code, represented by the `Cmm` data type. This data type follows the <a href="http://www.cminusminus.org/">definition of `C--`</a> pretty closely but there are some remarkable differences. For a discussion of the Cmm implementation noting most of those differences, see the [wiki:Commentary/Compiler/CmmType#BasicCmm Basic Cmm] section, below.</p>
<p><code>*</code><a href="GhcFile(compiler/cmm/Cmm.hs)" title="wikilink"><code>GhcFile(compiler/cmm/Cmm.hs)</code></a><code>:themaindatatypedefinition.</code><br />
<code>*</code><a href="GhcFile(compiler/cmm/MachOp.hs)" title="wikilink"><code>GhcFile(compiler/cmm/MachOp.hs)</code></a><code>:datatypesdefiningthemachineoperations(e.g.floatingpointdivide)providedby`Cmm`.</code><br />
<code>*</code><a href="GhcFile(compiler/cmm/CLabel.hs)" title="wikilink"><code>GhcFile(compiler/cmm/CLabel.hs)</code></a><code>:datatypefortop-level`Cmm`labels.</code></p>
<p><code>*</code><a href="GhcFile(compiler/cmm/PprCmm.hs)" title="wikilink"><code>GhcFile(compiler/cmm/PprCmm.hs)</code></a><code>:pretty-printerfor`Cmm`.</code><br />
<code>*</code><a href="GhcFile(compiler/cmm/CmmUtils.hs)" title="wikilink"><code>GhcFile(compiler/cmm/CmmUtils.hs)</code></a><code>:operationsover`Cmm`</code></p>
<p><code>*</code><a href="GhcFile(compiler/cmm/CmmLint.hs)" title="wikilink"><code>GhcFile(compiler/cmm/CmmLint.hs)</code></a><code>:aconsistencychecker.</code><br />
<code>*</code><a href="GhcFile(compiler/cmm/CmmOpt.hs)" title="wikilink"><code>GhcFile(compiler/cmm/CmmOpt.hs)</code></a><code>:anoptimiserfor`Cmm`.</code></p>
<p><code>*</code><a href="GhcFile(compiler/cmm/CmmParse.y)" title="wikilink"><code>GhcFile(compiler/cmm/CmmParse.y)</code></a><code>,</code><a href="GhcFile(compiler/cmm/CmmLex.x)" title="wikilink"><code>GhcFile(compiler/cmm/CmmLex.x)</code></a><code>:parserandlexerfor[wiki:Commentary/Rts/Cmm.cmmfiles].</code></p>
<p><code>*</code><a href="GhcFile(compiler/cmm/PprC.hs)" title="wikilink"><code>GhcFile(compiler/cmm/PprC.hs)</code></a><code>:pretty-print`Cmm`inCsyntax,whencompilingviaC.</code></p>
<h2 id="additions-in-cmm">Additions in Cmm</h2>
<p>Although both Cmm and C-- allow foreign calls, the `.cmm` syntax includes the </p>
<p>The [R2] part is the (set of) register(s) that you need to save over the call.</p>
<p>Other additions to C-- are noted throughout the [wiki:Commentary/Compiler/CmmType#BasicCmm Basic Cmm] section, below.</p>
<h2 id="compiling-cmm-with-ghc">Compiling Cmm with GHC</h2>
<p>GHC is able to compile `.cmm` files with a minimum of user-effort. To compile `.cmm` files, simply invoke the main GHC driver but remember to:</p>
<p><code>*addtheoption`-dcmm-lint`ifyouhavehandwrittenCmmcode;</code><br />
<code>*addappropriateincludes,especially</code><a href="GhcFile(includes/Cmm.h)" title="wikilink"><code>GhcFile(includes/Cmm.h)</code></a><code>ifyouareusingCmmmacrosorGHCdefinesforcertaintypes,suchas`W_`for`bits32`or`bits64`(dependingonthemachinewordsize)--`Cmm.h`isinthe`/includes`directoryofeveryGHCdistribution,i.e.,`usr/local/lib/ghc-6.6/includes`;and,</code><br />
<code>*ifyoudoincludeGHCheaderfiles,remembertopassthecodethroughtheCpreprocessorbyaddingthe`-cpp`option.</code></p>
<p>For additional fun, you may pass GHC the `-keep-s-file` option to keep the temporary assembler file in your compile directory. For example:  This will only work with very basic Cmm files. If you noticed that GHC currently provides no `-keep-cmm-file` option and `-keep-tmp-files` does not save a `.cmm` file and you are thinking about redirecting output from `-ddump-cmm`, beware. The output from `-ddump-cmm` contains equal-lines and dash-lines separating Cmm Blocks and Basic Blocks; these are unparseable. The parser also cannot handle `const` sections. For example, the parser will fail on the first `0` or alphabetic token after `const`:  Although GHC's Cmm pretty printer outputs C-- standard parenthetical list of arguments after procedure names, i.e., `()`, the Cmm parser will fail at the `(` token. For example:  The Cmm procedure names in <a href="GhcFile(rts/PrimOps.cmm)" class="uri" title="wikilink">GhcFile(rts/PrimOps.cmm)</a> are not followed by a (possibly empty) parenthetical list of arguments; all their arguments are Global (STG) Registers, anyway, see [wiki:Commentary/Compiler/CmmType#VariablesRegistersandTypes Variables, Registers and Types], below. Don't be confused by the procedure definitions in other handwritten `.cmm` files in the RTS, such as <a href="GhcFile(rts/Apply.cmm)" class="uri" title="wikilink">GhcFile(rts/Apply.cmm)</a>: all-uppercase procedure invocations are special reserved tokens in <a href="GhcFile(compiler/cmm/CmmLex.x)" class="uri" title="wikilink">GhcFile(compiler/cmm/CmmLex.x)</a> and <a href="GhcFile(compiler/cmm/CmmParse.y)" class="uri" title="wikilink">GhcFile(compiler/cmm/CmmParse.y)</a>. For example, `INFO_TABLE` is parsed as one of the tokens in the Alex `info` predicate: </p>
<p>GHC's Cmm parser also cannot parse nested code blocks. For example:  The C-- specification example in section 4.6.2, &quot;Procedures as section contents&quot; also will not parse in Cmm:  Note that if `p (bits32 i) { ... }` were written as a Cmm-parseable procedure, as `p { ... }`, the parse error would occur at the closing curly bracket for the `section &quot;data&quot; { ... p { ... } }`&lt;- here.</p>
<h2 id="basic-cmm">Basic Cmm</h2>
<p>FIXME: The links in this section are dead. But the files can be found here: <a href="http://www.cs.tufts.edu/~nr/c--/index.html">1</a>. Relevant discussion about the documentations of C--: <a href="https://mail.haskell.org/pipermail/ghc-devs/2014-September/006301.html">2</a></p>
<p>Cmm is a high level assembler with a syntax style similar to C. This section describes Cmm by working up from assembler--the C-- papers and specification work down from C. At the least, you should know what a &quot;high level&quot; assembler is, see <a href="http://webster.cs.ucr.edu/AsmTools/HLA/HLADoc/HLARef/HLARef3.html#1035157">&quot;What is a High Level Assembler?&quot;</a>. Cmm is different than other high level assembler languages in that it was designed to be a semi-portable intermediate language for compilers; most other high level assemblers are designed to make the tedium of assembly language more convenient and intelligible to humans. If you are completely new to C--, I highly recommend these papers listed on the <a href="http://cminusminus.org/papers.html">C-- Papers</a> page:</p>
<p><code>*</code><a href="http://cminusminus.org/abstracts/ppdp.html"><code>C--:</code> <code>A</code> <code>Portable</code> <code>Assembly</code> <code>Language</code> <code>that</code> <code>Supports</code> <code>Garbage</code> <code>Collection</code> <code>(1999)</code></a><code>(PaperpagewithAbstract)</code><br />
<code>*</code><a href="http://cminusminus.org/abstracts/pal-ifl.html"><code>C--:</code> <code>A</code> <code>Portable</code> <code>Assembly</code> <code>Language</code> <code>(1997)</code></a><code>(PaperpagewithAbstract)</code><br />
<code>*</code><a href="http://cminusminus.org/abstracts/c--pldi-00.html"><code>A</code> <code>Single</code> <code>Intermediate</code> <code>Language</code> <code>That</code> <code>Supports</code> <code>Multiple</code> <code>Implementations</code> <code>of</code> <code>Exceptions</code> <code>(2000)</code></a><code>(PaperpagewithAbstract)</code><br />
<code>*</code><a href="http://cminusminus.org/extern/man2.pdf"><code>The</code> <code>C--</code> <code>Language</code> <code>Specification</code> <code>Version</code> <code>2.0</code> <code>(CVS</code> <code>Revision</code> <code>1.128,</code> <code>23</code> <code>February</code> <code>2005)</code></a><code>(PDF)</code></p>
<p>Cmm is not a stand alone C-- compiler; it is an implementation of C-- embedded in the GHC compiler. One difference between Cmm and a C-- compiler like <a href="http://cminusminus.org/code.html">Quick C--</a> is this: Cmm uses the C preprocessor (cpp). Cpp lets Cmm <em>integrate</em> with C code, especially the C header defines in <a href="GhcFile(includes)" class="uri" title="wikilink">GhcFile(includes)</a>, and among many other consequences it makes the C-- `import` and `export` statements irrelevant; in fact, according to <a href="GhcFile(compiler/cmm/CmmParse.y)" class="uri" title="wikilink">GhcFile(compiler/cmm/CmmParse.y)</a> they are ignored. The most significant action taken by the Cmm modules in the Compiler is to optimise Cmm, through <a href="GhcFile(compiler/cmm/CmmOpt.hs)" class="uri" title="wikilink">GhcFile(compiler/cmm/CmmOpt.hs)</a>. The Cmm Optimiser generally runs a few simplification passes over primitive Cmm operations, inlines simple Cmm expressions that do not contain global registers (these would be left to one of the [wiki:Commentary/Compiler/Backends Backends], which currently cannot handle inlines with global registers) and performs a simple loop optimisation.</p>
<h3 id="code-blocks-in-cmm">Code Blocks in Cmm</h3>
<p>The Haskell representation of Cmm separates contiguous code into:</p>
<p><code>*</code><em><code>modules</code></em><code>(compilationunits;a`.cmm`file);and</code><br />
<code>*</code><em><code>basic</code> <code>blocks</code></em></p>
<p>Cmm modules contain static data elements (see [wiki:Commentary/Compiler/CmmType#LiteralsandLabels Literals and Labels]) and [wiki:Commentary/Compiler/CmmType#BasicBlocks:Procedures Basic Blocks], collected together in `Cmm`, a type synonym for `GenCmm`, defined in <a href="GhcFile(compiler/cmm/Cmm.hs)" class="uri" title="wikilink">GhcFile(compiler/cmm/Cmm.hs)</a>:  `CmmStmt` is described in [wiki:Commentary/Compiler/CmmType#StatementsandCalls Statements and Calls];<a href="BR" class="uri" title="wikilink">BR</a> `Section` is described in [wiki:Commentary/Compiler/CmmType#SectionsandDirectives Sections and Directives];<a href="BR" class="uri" title="wikilink">BR</a> the static data in `[d]` is [`CmmStatic`] from the type synonym `Cmm`;<a href="BR" class="uri" title="wikilink">BR</a> `CmmStatic` is described in [wiki:Commentary/Compiler/CmmType#LiteralsandLabels Literals and Labels].</p>
<h4 id="basic-blocks-and-procedures">Basic Blocks and Procedures</h4>
<p>Cmm procedures are represented by the first constructor in `GenCmmTop d i`:  For a description of Cmm labels and the `CLabel` data type, see the subsection [wiki:Commentary/Compiler/CmmType#LiteralsandLabels Literals and Labels], below.</p>
<p>Cmm Basic Blocks are labeled blocks of Cmm code ending in an explicit jump. Sections (see [wiki:Commentary/Compiler/CmmType#SectionsandDirectives Sections and Directives]) have no jumps--in Cmm, Sections cannot contain nested Procedures (see, e.g., [wiki:Commentary/Compiler/CmmType#CompilingCmmwithGHC Compiling Cmm with GHC]). Basic Blocks encapsulate parts of Procedures. The data type `GenBasicBlock` and the type synonym `CmmBasicBlock` encapsulate Basic Blocks; they are defined in <a href="GhcFile(compiler/cmm/Cmm.hs)" class="uri" title="wikilink">GhcFile(compiler/cmm/Cmm.hs)</a>:  The `BlockId` data type simply carries a `Unique` with each Basic Block. For descriptions of `Unique`, see</p>
<p><code>*the[wiki:Commentary/Compiler/RenamerRenamer]page;</code><br />
<code>*the[wiki:Commentary/Compiler/WiredIn#KnownkeythingsKnownKeyThings]sectionofthe[wiki:Commentary/Compiler/WiredInWired-inandKnownKeyThings]page;and,</code><br />
<code>*the[wiki:Commentary/Compiler/EntityTypes#TypevariablesandtermvariablesTypevariablesandtermvariables]sectionofthe[wiki:Commentary/Compiler/EntityTypesEntityTypes]page.</code></p>
<h3 id="variables-registers-and-types">Variables, Registers and Types</h3>
<p>Like other high level assembly languages, all variables in C-- are machine registers, separated into different types according to bit length (8, 16, 32, 64, 80, 128) and register type (integral or floating point). The C-- standard specifies little more type information about a register than its bit length: there are no distinguishing types for signed or unsigned integrals, or for &quot;pointers&quot; (registers holding a memory address). A C-- standard compiler supports additional information on the type of a register value through compiler <em>hints</em>. In a foreign call, a `&quot;signed&quot; bits8` would be sign-extended and may be passed as a 32-bit value. Cmm diverges from the C-- specification on this point somewhat (see below). C-- and Cmm do not represent special registers, such as a Condition Register (`CR`) or floating point unit (FPU) status and control register (`FPSCR` on the PowerPC, `MXCSR` on Intel x86 processors), as these are a matter for the [wiki:Commentary/Compiler/Backends Backends].</p>
<p>C-- and Cmm hide the actual number of registers available on a particular machine by assuming an &quot;infinite&quot; supply of registers. A backend, such as the NCG or C compiler on GHC, will later optimise the number of registers used and assign the Cmm variables to actual machine registers; the NCG temporarily stores any overflow in a small memory stack called the <em>spill stack</em>, while the C compiler relies on C's own runtime system. Haskell handles Cmm registers with three data types: `LocalReg`, `GlobalReg` and `CmmReg`. `LocalReg`s and `GlobalRegs` are collected together in a single `Cmm` data type: </p>
<h4 id="local-registers">Local Registers</h4>
<p>Local Registers exist within the scope of a Procedure:  For a list of references with information on `Unique`, see the [wiki:Commentary/Compiler/CmmType#BasicBlocksandProcedures Basic Blocks and Procedures] section, above.</p>
<p>A `MachRep`, the type of a machine register, is defined in <a href="GhcFile(compiler/cmm/MachOp.hs)" class="uri" title="wikilink">GhcFile(compiler/cmm/MachOp.hs)</a>:  There is currently no register for floating point vectors, such as `F128`. The types of Cmm variables are defined in the Happy parser file <a href="GhcFile(compiler/cmm/CmmParse.y)" class="uri" title="wikilink">GhcFile(compiler/cmm/CmmParse.y)</a> and the Alex lexer file <a href="GhcFile(compiler/cmm/CmmLex.x)" class="uri" title="wikilink">GhcFile(compiler/cmm/CmmLex.x)</a>. (Happy and Alex will compile these into `CmmParse.hs` and `CmmLex.hs`, respectively.) Cmm recognises the following `C--` types as parseable tokens, listed next to their corresponding s in <a href="GhcFile(includes/Cmm.h)" class="uri" title="wikilink">GhcFile(includes/Cmm.h)</a> and their STG types: || <strong>Cmm Token</strong> || <strong>Cmm.h #define</strong> || <strong>STG type</strong> || || `bits8` || `I8` || `StgChar` or `StgWord8` || || `bits16` || `I16` || `StgWord16` || || `bits32` || `I32`, `CInt`, `CLong` || `StgWord32`; `StgWord` (depending on architecture) || || `bits64` || `I64`, `CInt`, `CLong`, `L_` || `StgWord64`; `StgWord` (depending on architecture) || || `float32` || `F_` || `StgFloat` || || `float64` || `D_` || `StgDouble` ||</p>
<p><a href="GhcFile(includes/Cmm.h)" class="uri" title="wikilink">GhcFile(includes/Cmm.h)</a> also defines `L_` for `bits64`, so `F_`, `D_` and `L_` correspond to the `GlobalReg` data type constructors `FloatReg`, `DoubleReg` and `LongReg`. Note that although GHC may generate other register types supported by the `MachRep` data type, such as `I128`, they are not parseable tokens. That is, they are internal to GHC. The special defines `CInt` and `CLong` are used for compatibility with C on the target architecture, typically for making `foreign &quot;C&quot;` calls.</p>
<p><strong>Note</strong>: Even Cmm types that are not explicit variables (Cmm literals and results of Cmm expressions) have implicit `MachRep`s, in the same way as you would use temporary registers to hold labelled constants or intermediate values in assembler functions. See:</p>
<p><code>*[wiki:Commentary/Compiler/CmmType#LiteralsandLabelsLiteralsandLabels]forinformationrelatedtotheCmmliterals`CmmInt`and`CmmFloat`;and,</code><br />
<code>*[wiki:Commentary/Compiler/CmmType#ExpressionsExpressions],regardingthe`cmmExprRep`functiondefinedin</code><a href="GhcFile(compiler/cmm/Cmm.hs)" title="wikilink"><code>GhcFile(compiler/cmm/Cmm.hs)</code></a><code>.</code></p>
<h4 id="global-registers-and-hints">Global Registers and Hints</h4>
<p>These are universal both to a Cmm module and to the whole compiled program. Variables are global if they are declared at the top-level of a compilation unit (outside any procedure). Global Variables are marked as external symbols with the `.globl` assembler directive. In Cmm, global registers are used for special STG registers and specific registers for passing arguments and returning values. The Haskell representation of Global Variables (Registers) is the `GlobalReg` data type, defined in <a href="GhcFile(compiler/cmm/Cmm.hs)" class="uri" title="wikilink">GhcFile(compiler/cmm/Cmm.hs)</a>:  For a description of the `Hp` and `Sp` <em>virtual registers</em>, see [wiki:Commentary/Rts/HaskellExecution The Haskell Execution Model] page. General `GlobalReg`s are clearly visible in Cmm code according to the following syntax defined in <a href="GhcFile(compiler/cmm/CmmLex.x)" class="uri" title="wikilink">GhcFile(compiler/cmm/CmmLex.x)</a>: || <strong>`GlobalReg` Constructor</strong> || <strong>Syntax</strong> || <strong>Examples</strong> || || `VanillaReg Int` || `R ++ Int` || `R1`, `R10` || || `FloatReg Int` || `F ++ Int` || `F1`, `F10` || || `DoubleReg Int` || `D ++ Int` || `D1`, `D10` || || `LongReg Int` || `L ++ Int` || `L1`, `L10` || General `GlobalRegs` numbers are decimal integers, see the `parseInteger` function in <a href="GhcFile(compiler/utils/StringBuffer.lhs)" class="uri" title="wikilink">GhcFile(compiler/utils/StringBuffer.lhs)</a>. The remainder of the `GlobalReg` constructors, from `Sp` to `BaseReg` are lexical tokens exactly like their name in the data type; `PicBaseReg` does not have a lexical token since it is used only inside the NCG. See [wiki:Commentary/PositionIndependentCode Position Independent Code and Dynamic Linking] for an in-depth description of PIC implementations in the NCG.</p>
<p>`GlobalRegs` are a very special case in Cmm, partly because they must conform to the STG register convention and the target C calling convention. That the Cmm parser recognises `R1` and `F3` as `GlobalRegs` is only the first step. The main files to look at for more information on this delicate topic are:</p>
<p><code>*</code><a href="GhcFile(compiler/codeGen/CgCallConv.hs)" title="wikilink"><code>GhcFile(compiler/codeGen/CgCallConv.hs)</code></a><code>(thesectionon&quot;Registerassignment&quot;)</code><br />
<code>*</code><a href="GhcFile(includes/stg/Regs.h)" title="wikilink"><code>GhcFile(includes/stg/Regs.h)</code></a><code>(definingSTGregisters)</code><br />
<code>*</code><a href="GhcFile(includes/stg/MachRegs.h)" title="wikilink"><code>GhcFile(includes/stg/MachRegs.h)</code></a><code>(target-specificmappingofmachineregistersfor</code><em><code>registerised</code></em><code>buildsofGHC)</code><br />
<code>*</code><a href="GhcFile(rts/PrimOps.cmm)" title="wikilink"><code>GhcFile(rts/PrimOps.cmm)</code></a><code>(examplesof`GlobalReg`registerusageforout-of-lineprimops)</code></p>
<p>All arguments to out-of-line !PrimOps in <a href="GhcFile(rts/PrimOps.cmm)" class="uri" title="wikilink">GhcFile(rts/PrimOps.cmm)</a> are STG registers.</p>
<p>Cmm recognises all C-- syntax with regard to <em>hints</em>. For example:  Hints are represented in Haskell as `MachHint`s, defined near `MachRep` in <a href="GhcFile(compiler/cmm/MachOp.hs)" class="uri" title="wikilink">GhcFile(compiler/cmm/MachOp.hs)</a>: </p>
<p>Although the C-- specification does not allow the C-- type system to statically distinguish between floats, signed ints, unsigned ints or pointers, Cmm does. Cmm `MachRep`s carry the float or int kind of a variable, either within a local block or in a global register. `GlobalReg` includes separate constructors for `Vanilla`, `Float`, `Double` and `Long`. Cmm still does not distinguish between signed ints, unsigned ints and pointers (addresses) at the register level, as these are given <em>hint</em> pseudo-types or their real type is determined as they run through primitive operations. `MachHint`s still follow the C-- specification and carry kind information as an aide to the backend optimisers.</p>
<p>Global Registers in Cmm currently have a problem with inlining: because neither <a href="GhcFile(compiler/cmm/PprC.hs)" class="uri" title="wikilink">GhcFile(compiler/cmm/PprC.hs)</a> nor the NCG are able to keep Global Registers from clashing with C argument passing registers, Cmm expressions that contain Global Registers cannot be inlined into an argument position of a foreign call. For more thorough notes on inlining, see the comments in <a href="GhcFile(compiler/cmm/CmmOpt.hs)" class="uri" title="wikilink">GhcFile(compiler/cmm/CmmOpt.hs)</a>.</p>
<h4 id="declaration-and-initialisation">Declaration and Initialisation</h4>
<p>Cmm variables hold the same values registers do in assembly languages but may be declared in a similar way to variables in C. As in C--, they may actually be declared anywhere in the scope for which they are visible (a block or file)--for Cmm, this is done by the `loopDecls` function in <a href="GhcFile(compiler/cmm/CmmParse.y)" class="uri" title="wikilink">GhcFile(compiler/cmm/CmmParse.y)</a>. In <a href="GhcFile(compiler/rts/PrimOps.cmm)" class="uri" title="wikilink">GhcFile(compiler/rts/PrimOps.cmm)</a>, you will see Cmm variable declarations like this one:  Remember that Cmm code is run through the C preprocessor. `W_` will be transformed into `bits32`, `bits64` or whatever is the `bits`<em>size</em> of the machine word, as defined in <a href="GhcFile(includes/Cmm.h)" class="uri" title="wikilink">GhcFile(includes/Cmm.h)</a>. In Haskell code, you may use the <a href="GhcFile(compiler/cmm/MachOp.hs)" class="uri" title="wikilink">GhcFile(compiler/cmm/MachOp.hs)</a> functions `wordRep` and `halfWordRep` to dynamically determine the machine word size. For a description of word sizes in GHC, see the [wiki:Commentary/Rts/Word Word] page.</p>
<p>The variables `w`, `code` and `val` should be real registers. With the above declaration the variables are uninitialised. Initialisation requires an assignment <em>statement</em>. Cmm does not recognise C-- &quot;`{` <em>literal</em>, ... `}`&quot; initialisation syntax, such as `bits32{10}` or `bits32[3] {1, 2, 3}`. Cmm does recognise initialisation with a literal:  The typical method seems to be to declare variables and then initialise them just before their first use. (Remember that you may declare a variable anywhere in a procedure and use it in an expression before it is initialised but you must initialise it before using it anywhere else--statements, for example.)</p>
<h4 id="memory-access">Memory Access</h4>
<p>If the value in `w` were the address of a memory location, you would obtain the value at that location similar to Intel assembler syntax. In Cmm, you would write:  compare the above statement to indirect addressing in Intel assembler: </p>
<p>The code between the brackets (`w` in `[w]`, above) is an <em>expression</em>. See the [wiki:Commentary/Compiler/CmmType#Expressions Expressions] section. For now, consider the similarity between the Cmm-version of indexed memory addressing syntax, here:  and the corresponding Intel assembler indexed memory addressing syntax, here:  You will generally not see this type of syntax in either handwritten or GHC-produced Cmm code, although it is allowed; it simply shows up in macros. C-- also allows the `*` (multiplication) operator in addressing expressions, for an approximation of <em>scaled</em> addressing (`[base * (2^n)]`); for example, `n` (the &quot;scale&quot;) must be `0`, `1`, `2` or `4`. C-- itself would not enforce alignment or limits on the scale. Cmm, however, could not process it: since the NCG currently outputs GNU Assembler syntax, the Cmm or NCG optimisers would have to reduce `n` in (`* n`) to an absolute address or relative offset, or to an expression using only `+` or `-`. This is not currently the case and would be difficult to implement where one of the operands to the `*` is a relative address not visible in the code block. <a href="GhcFile(includes/Cmm.h)" class="uri" title="wikilink">GhcFile(includes/Cmm.h)</a> defines macros to perform the calculation with a constant. For example:  is used in:  The function `cmmMachOpFold` in <a href="GhcFile(compiler/cmm/CmmOpt.hs)" class="uri" title="wikilink">GhcFile(compiler/cmm/CmmOpt.hs)</a> will reduce the resulting expression `Sp + (n * SIZEOF_W)` to `Sp + N`, where `N` is a constant. A very large number of macros for accessing STG struct fields and the like are produced by <a href="GhcFile(includes/mkDerivedConstants.c)" class="uri" title="wikilink">GhcFile(includes/mkDerivedConstants.c)</a> and output into the file `includes/DerivedConstants.h` when GHC is compiled.</p>
<p>Of course, all this also holds true for the reverse (when an assignment is made to a memory address):  or, for an example of a macro from `DerivedConstants.h`:  this will be transformed to: </p>
<h3 id="literals-and-labels">Literals and Labels</h3>
<p>Cmm literals are exactly like C-- literals, including the Haskell-style type syntax, for example: `0x00000001::bits32`. Cmm literals may be used for initialisation by assignment or in expressions. The `CmmLit` and `CmmStatic` data types, defined in <a href="GhcFile(compiler/cmm/Cmm.hs)" class="uri" title="wikilink">GhcFile(compiler/cmm/Cmm.hs)</a> together represent Cmm literals, static information and Cmm labels:  Note how the `CmmLit` constructor `CmmInt Integer MachRep` contains sign information in the `Integer`, the representation of the literal itself: this conforms to the C-- specification, where integral literals contain sign information. For an example of a function using `CmmInt` sign information, see `cmmMachOpFold` in <a href="GhcFile(compiler/cmm/CmmOpt.hs)" class="uri" title="wikilink">GhcFile(compiler/cmm/CmmOpt.hs)</a>, where sign-operations are performed on the `Integer`.</p>
<p>The `MachRep` of a literal, such as `CmmInt Integer MachRep` or `CmmFloat Rational MachRep` may not always require the size defined by `MachRep`. The NCG optimiser, <a href="GhcFile(compiler/nativeGen/MachCodeGen.hs)" class="uri" title="wikilink">GhcFile(compiler/nativeGen/MachCodeGen.hs)</a>, will test a literal such as `1::bits32` (in Haskell, `CmmInt (1::Integer) I32`) for whether it would fit into the bit-size of Assembler instruction literals on that particular architecture with a function defined in <a href="GhcFile(compiler/nativeGen/MachRegs.lhs)" class="uri" title="wikilink">GhcFile(compiler/nativeGen/MachRegs.lhs)</a>, such as `fits16Bits` on the PPC. If the Integer literal fits, the function `makeImmediate` will truncate it to the specified size if possible and store it in a NCG data type, `Imm`, specifically `Maybe Imm`. (These are also defined in <a href="GhcFile(compiler/nativeGen/MachRegs.lhs)" class="uri" title="wikilink">GhcFile(compiler/nativeGen/MachRegs.lhs)</a>.)</p>
<p>The Haskell representation of Cmm separates unchangeable Cmm values into a separate data type, `CmmStatic`, defined in <a href="GhcFile(compiler/cmm/Cmm.hs)" class="uri" title="wikilink">GhcFile(compiler/cmm/Cmm.hs)</a>:  Note the `CmmAlign` constructor: this maps to the assembler directive `.align N` to set alignment for a data item (hopefully one you remembered to label). This is the same as the `align` directive noted in Section 4.5 of the <a href="http://cminusminus.org/extern/man2.pdf">C-- specification (PDF)</a>. In the current implementation of Cmm the `align` directive seems superfluous because <a href="GhcFile(compiler/nativeGen/PprMach.hs)" class="uri" title="wikilink">GhcFile(compiler/nativeGen/PprMach.hs)</a> translates `Section`s to assembler with alignment directives corresponding to the target architecture (see [wiki:Commentary/Compiler/CmmType#SectionsandDirectives Sections and Directives], below).</p>
<h4 id="labels">Labels</h4>
<p>Remember that C--/Cmm names consist of a string where the first character is:</p>
<p><code>*ASCIIalphabetic(uppercaseorlowercase);</code><br />
<code>*anunderscore:`_`;</code><br />
<code>*aperiod:`.`;</code><br />
<code>*adollarsign:`$`;or,</code><br />
<code>*acommercialat:`@`.</code></p>
<p>Cmm labels conform to the C-- specification. C--/Cmm uses labels to refer to memory locations in code--if you use a data directive but do not give it a label, you will have no means of referring to the memory! For `GlobalReg`s (transformed to assembler `.globl`), labels serve as both symbols and labels (in the assembler meaning of the terms). The Haskell representation of Cmm Labels is contained in the `CmmLit` data type, see [wiki:Commentary/Compiler/CmmType#Literals Literals] section, above. Note how Cmm Labels are `CLabel`s with address information. The `Clabel` data type, defined in <a href="GhcFile(compiler/cmm/CLabel.hs)" class="uri" title="wikilink">GhcFile(compiler/cmm/CLabel.hs)</a>, is used throughout the Compiler for symbol information in binary files. Here it is: </p>
<h3 id="sections-and-directives">Sections and Directives</h3>
<p>The Haskell representation of Cmm Section directives, in <a href="GhcFile(compiler/cmm/Cmm.hs)" class="uri" title="wikilink">GhcFile(compiler/cmm/Cmm.hs)</a> as the first part of the &quot;Static Data&quot; section, is:  Cmm supports the following directives, corresponding to the assembler directives pretty-printed by the `pprSectionHeader` function in <a href="GhcFile(compiler/nativeGen/PprMach.hs)" class="uri" title="wikilink">GhcFile(compiler/nativeGen/PprMach.hs)</a>: || <strong>`Section` Constructor</strong> || <strong>Cmm section directive</strong> || <strong>Assembler Directive</strong> || || `Text` || `&quot;text&quot;` || `.text` || || `Data` || `&quot;data&quot;` || `.data` || || `ReadOnlyData` || `&quot;rodata&quot;` || `.rodata`<a href="BR" class="uri" title="wikilink">BR</a>(generally; varies by arch,OS) || || `RelocatableReadOnlyData` || no parse (GHC internal), output: `&quot;relreadonly&quot;` || `.const_data`<a href="BR" class="uri" title="wikilink">BR</a>`.section .rodata`<a href="BR" class="uri" title="wikilink">BR</a>(generally; varies by arch,OS) || || `UninitialisedData` || `&quot;bss&quot;`, output: `&quot;uninitialised&quot;` || `.bss` || || `ReadOnlyData16` || no parse (GHC internal), output: none || `.const`<a href="BR" class="uri" title="wikilink">BR</a>`.section .rodata`<a href="BR" class="uri" title="wikilink">BR</a>(generally; on x86_64:<a href="BR" class="uri" title="wikilink">BR</a>`.section .rodata.cst16`) || You probably already noticed I omitted the alignment directives (for clarity). For example, `pprSectionHeader` would pretty-print `ReadOnlyData` as  on an i386 with the Darwin OS. If you are really on the ball you might have noticed that the `PprMach.hs` output of &quot;`.section .data`&quot; and the like is really playing it safe since on most OS's, using GNU Assembler, the `.data` directive is equivalent to `.section __DATA .data`, or simply `.section .data`. Note that `OtherSection String` is not a catch-all for the Cmm parser. If you wrote:  The Cmm parser (through GHC) would panic, complaining, &quot;`PprMach.pprSectionHeader: unknown section`.&quot;</p>
<p>While the C-- specification allows a bare `data` keyword directive, Cmm does not: </p>
<p>Cmm does not recognise the C-- &quot;`stack`&quot; declaration for allocating memory on the system stack.</p>
<p>GHC-produced Cmm code is replete with `data` sections, each of which is stored in `.data` section of the binary code. This contributes significantly to the large binary size for GHC-compiled code.</p>
<p><code>====TargetDirective====</code></p>
<p>The C-- specification defines a special `target` directive, in section 4.7. The `target` directive is essentially a code block defining the properties of the target architecture:  This is essentially a custom-coded version of the GNU Assembler (`as`) `.machine` directive, which is essentially the same as passing the `-arch [cpu_type]` option to `as`.</p>
<p>Cmm does not support the `target` directive. This is partly due GHC generally lacking cross-compiler capabilities. Should GHC move toward adding cross-compilation capabilities, the `target` might not be a bad thing to add. Target architecture parameters are currently handled through the [wiki:Attic/Building/BuildSystem Build System], which partly sets such architectural parameters through <a href="GhcFile(includes/mkDerivedConstants.c)" class="uri" title="wikilink">GhcFile(includes/mkDerivedConstants.c)</a> and <a href="GhcFile(includes/ghcconfig.h)" class="uri" title="wikilink">GhcFile(includes/ghcconfig.h)</a>.</p>
<h3 id="expressions">Expressions</h3>
<p>Expressions in Cmm follow the C-- specification. They have:</p>
<p><code>*noside-effects;and,</code><br />
<code>*oneresult:</code><br />
<code>*a</code><em><code>k</code></em><code>-bitvalue</code><a href="BR" title="wikilink"><code>BR</code></a><code>--theseexpressionsmaptothe`MachOp`datatype,definedin</code><a href="GhcFile(compiler/cmm/MachOp.hs)" title="wikilink"><code>GhcFile(compiler/cmm/MachOp.hs)</code></a><code>,see[wiki:Commentary/Compiler/CmmType#OperatorsandPrimitiveOperationsOperatorsandPrimitiveOperations],the</code><em><code>k</code></em><code>-bitvaluemaybe:</code><br />
<code>*aCmmliteral(`CmmLit`);or,</code><br />
<code>*aCmmvariable(`CmmReg`,see[wiki:Commentary/Compiler/CmmType#VariablesRegistersandTypesVariables,RegistersandTypes]);</code><a href="BR" title="wikilink"><code>BRor</code></a><code>,</code><br />
<code>*abooleancondition.</code></p>
<p>Cmm expressions may include</p>
<p><code>*aliteraloraname(`CmmLit`containsboth,see[wiki:Commentary/Compiler/CmmType#LiteralsandLabelsLiteralsandLabels],above);</code><br />
<code>*amemoryreference(`CmmLoad`and`CmmReg`,see[wiki:Commentary/Compiler/CmmType#MemoryAccessMemoryAccess],above);</code><br />
<code>*anoperator(a`MachOp`,in`CmmMachOp`,below);or,</code><br />
<code>*anotherexpression(a`[CmmExpr]`,in`CmmMachOp`,below).</code></p>
<p>These are all included as constructors in the `CmmExpr` data type, defined in <a href="GhcFile(compiler/cmm/Cmm.hs)" class="uri" title="wikilink">GhcFile(compiler/cmm/Cmm.hs)</a>:  Note that `CmmRegOff reg i` is only shorthand for a specific `CmmMachOp` application:  The function `cmmRegRep` is described below. Note: the original comment following `CmmExpr` in <a href="GhcFile(compiler/cmm/Cmm.hs)" class="uri" title="wikilink">GhcFile(compiler/cmm/Cmm.hs)</a> is erroneous (cf., `mangleIndexTree` in <a href="GhcFile(compiler/nativeGen/MachCodeGen.hs)" class="uri" title="wikilink">GhcFile(compiler/nativeGen/MachCodeGen.hs)</a>) but makes the same point described here. The offset, `(CmmLit (CmmInt i rep))`, is a literal (`CmmLit`), not a name (`CLabel`). A `CmmExpr` for an offset must be reducible to a `CmmInt` <em>in Haskell</em>; in other words, offsets in Cmm expressions may not be external symbols whose addresses are not resolvable in the current context.</p>
<p>Boolean comparisons are not boolean conditions. Boolean comparisons involve relational operators, such as `&gt;`, `&lt;` and `==`, and map to `MachOp`s that are converted to comparison followed by branch instructions. For example, `&lt;` would map to `MO_S_Lt` for signed operands, <a href="GhcFile(compiler/nativeGen/MachCodeGen.hs)" class="uri" title="wikilink">GhcFile(compiler/nativeGen/MachCodeGen.hs)</a> would transform `MO_S_Lt` into the `LTT` constructor of the `Cond` union data type defined in <a href="GhcFile(compiler/nativeGen/MachInstrs.hs)" class="uri" title="wikilink">GhcFile(compiler/nativeGen/MachInstrs.hs)</a> and <a href="GhcFile(compiler/nativeGen/PprMach.hs)" class="uri" title="wikilink">GhcFile(compiler/nativeGen/PprMach.hs)</a> would transform `LTT` to the distinguishing comparison type for an assembler comparison instruction. You already know that the result of a comparison instruction is actually a change in the state of the Condition Register (CR), so Cmm boolean expressions do have a kind of side-effect but that is to be expected. In fact, it is necessary since at the least a conditional expression becomes two assembler instructions, in PPC Assembler:  This condition mapping does have an unfortunate consequence: conditional expressions do not fold into single instructions. In Cmm, as in C--, expressions with relational operators may evaluate to an integral (`0`, nonzero) instead of evaluating to a boolean type. For certain cases, such as an arithmetic operation immediately followed by a comparison, extended mnemonics such as `addi.` might eliminate the comparison instruction. See [wiki:Commentary/Compiler/CmmType#CmmDesignObservationsandAreasforPotentialImprovement Cmm Design: Observations and Areas for Potential Improvement] for more discussion and potential solutions to this situation.</p>
<p>Boolean conditions include: `&amp;&amp;`, `||`, `!` and parenthetical combinations of boolean conditions. The `if expr { }` and `if expr { } else { }` statements contain boolean conditions. The C-- type produced by conditional expressions is `bool`, in Cmm, type `BoolExpr` in <a href="GhcFile(compiler/cmm/CmmParse.y)" class="uri" title="wikilink">GhcFile(compiler/cmm/CmmParse.y)</a>:  The type `BoolExpr` maps to the `CmmCondBranch` or `CmmBranch` constructors of type `CmmStmt`, defined in <a href="GhcFile(compiler/cmm/Cmm.hs)" class="uri" title="wikilink">GhcFile(compiler/cmm/Cmm.hs)</a>, see [wiki:Commentary/Compiler/CmmType#StatementsandCalls Statements and Calls].</p>
<p>The `CmmExpr` constructor `CmmMachOp MachOp [CmmExpr]` is the core of every operator-based expression; the key here is `MachOp`, which in turn depends on the type of `MachRep` for each operand. See [wiki:Commentary/Compiler/CmmType#FundamentalandPrimitiveOperators Fundamental and PrimitiveOperators]. In order to process `CmmExpr`s, the data type comes with a deconstructor function to obtain the relevant `MachRep`s, defined in <a href="GhcFile(compiler/cmm/Cmm.hs)" class="uri" title="wikilink">GhcFile(compiler/cmm/Cmm.hs)</a>:  The deconstructors `cmmLitRep` and `cmmRegRep` (with its supporting deconstructor `localRegRep`) are also defined in <a href="GhcFile(compiler/cmm/Cmm.hs)" class="uri" title="wikilink">GhcFile(compiler/cmm/Cmm.hs)</a>.</p>
<p>In PPC Assembler you might add two 32-bit integrals by:  while in Cmm you might write:  Remember that the assignment operator, `=`, is a statement since it has the &quot;side effect&quot; of modifying the value in `res`. The `+` expression in the above statement, for a 32-bit architecture, would be represented in Haskell as:  The `expr` production rule in the Cmm Parser <a href="GhcFile(compiler/cmm/CmmParse.y)" class="uri" title="wikilink">GhcFile(compiler/cmm/CmmParse.y)</a> maps tokens to &quot;values&quot;, such as `+` to an addition operation, `MO_Add`. The `mkMachOp` function in the Parser determines the `MachOp` type in `CmmMachOp MachOp [CmmExpr]` from the token value and the `MachRep` type of the `head` variable. Notice that the simple `+` operator did not contain sign information, only the `MachRep`. For `expr`, signed and other `MachOps`, see the `machOps` function in <a href="GhcFile(compiler/cmm/CmmParse.y)" class="uri" title="wikilink">GhcFile(compiler/cmm/CmmParse.y)</a>. Here is a table of operators and the corresponding `MachOp`s recognised by Cmm (listed in order of precedence): || <strong>Operator</strong> || <strong>`MachOp`</strong> || || `/` || `MO_U_Quot` || || `*` || `MO_Mul` || || `%` || `MO_U_Rem` || || `-` || `MO_Sub` || || `+` || `MO_Add` || || `&gt;&gt;` || `MO_U_Shr` || || `&lt;&lt;` || `MO_Shl` || || `&amp;` || `MO_And` || || `^` || `MO_Xor` || || `|` || `MO_Or` || || `&gt;=` || `MO_U_Ge` || || `&gt;` || `MO_U_Gt` || || `&lt;=` || `MO_U_Le` || || `&lt;` || `MO_U_Lt` || || `!=` || `MO_Ne` || || `==` || `MO_Eq` || || `~` || `MO_Not` || || `-` || `MO_S_Neg` ||</p>
<h4 id="quasi-operator-syntax">Quasi-operator Syntax</h4>
<p>If you read to the end of `expr` in <a href="GhcFile(compiler/cmm/CmmParse.y)" class="uri" title="wikilink">GhcFile(compiler/cmm/CmmParse.y)</a>, in the next production rule, `expr0`, you will notice that Cmm expressions also recognise a set of name (not symbol) based operators that would probably be better understood as <em>quasi-operators</em>. The syntax for these quasi-operators is in some cases similar to syntax for Cmm statements and generally conform to the C-- specification, sections 3.3.2 (`expr`) and 7.4.1 (syntax of primitive operators), <em>except that</em> 3. <em>and, by the equivalence of the two,</em> 1. <em>may return</em> <strong>multiple</strong> '' arguments''. In Cmm, quasi-operators may have side effects. The syntax for quasi-operators may be:</p>
<p><code>1.`expr0`</code><code>`expr0`</code><a href="BR" title="wikilink"><code>BR</code></a><code>(justlikeinfix-functionsinHaskell);</code><br />
<code>1.`type[expression]`</code><a href="BR" title="wikilink"><code>BR</code></a><code>(thememoryaccessquasi-expressiondescribedin[wiki:Commentary/Compiler/CmmType#MemoryAccessMemoryAccess];theHaskellrepresentationofthissyntaxis`CmmLoadCmmExprMachRep`);</code><br />
<code>1.`%name(exprs0)`</code><a href="BR" title="wikilink"><code>BR</code></a><code>(standardprefixform,similartoC--</code><em><code>statement</code></em><code>syntaxforproceduresbutwiththedistinguishingprefix`%`;inCmmthisis</code><em><code>also</code> <code>used</code> <code>as</code> <code>statement</code> <code>syntax</code> <code>for</code> <code>calls,</code> <code>which</code> <code>are</code> <code>really</code> <code>built-in</code> <code>procedures</code></em><code>,see[wiki:Commentary/Compiler/CmmType#CmmCallsCmmCalls])</code></p>
<p>A `expr0` may be a literal (`CmmLit`) integral, floating point, string or a `CmmReg` (the production rule `reg`: a `name` for a local register (`LocalReg`) or a `GlobalReg`).</p>
<p>Note that the `name` in `expr0` syntax types 1. and 3. must be a known <em>primitive</em> (primitive operation), see [wiki:Commentary/Compiler/CmmType#OperatorsandPrimitiveOperations Operators and Primitive Operations]. The first and third syntax types are interchangeable:  The primitive operations allowed by Cmm are listed in the `machOps` production rule, in <a href="GhcFile(compiler/cmm/CmmParse.y)" class="uri" title="wikilink">GhcFile(compiler/cmm/CmmParse.y)</a>, and largely correspond to `MachOp` data type constructors, in <a href="GhcFile(compiler/cmm/MachOp.hs)" class="uri" title="wikilink">GhcFile(compiler/cmm/MachOp.hs)</a>, with a few additions. The primitive operations distinguish between signed, unsigned and floating point types.</p>
<p>Cmm adds some expression macros that map to Haskell Cmm functions. They are listed under `exprMacros` in <a href="GhcFile(compiler/cmm/CmmParse.y)" class="uri" title="wikilink">GhcFile(compiler/cmm/CmmParse.y)</a> and include:</p>
<p><code>*`ENTRY_CODE`</code><br />
<code>*`INFO_PTR`</code><br />
<code>*`STD_INFO`</code><br />
<code>*`FUN_INFO`</code><br />
<code>*`GET_ENTRY`</code><br />
<code>*`GET_STD_INFO`</code><br />
<code>*`GET_FUN_INFO`</code><br />
<code>*`INFO_TYPE`</code><br />
<code>*`INFO_PTRS`</code><br />
<code>*`INFO_NPTRS`</code><br />
<code>*`RET_VEC`</code></p>
<h3 id="statements-and-calls">Statements and Calls</h3>
<p>Cmm Statements generally conform to the C-- specification, with a few exceptions noted below. Cmm Statements implement:</p>
<p><code>*no-op;theemptystatement:`;`</code><br />
<code>*C--(C99/C++style)comments:`//...\n`and`/*...*/`</code><br />
<code>*theassignmentoperator:`=`</code><br />
<code>*storeoperation(assignmenttoamemorylocation):`type[expr]=`</code><br />
<code>*controlflowwithinprocedures(`goto`)andbetweenprocedures(`jump`,returns)(note:returnsare</code><em><code>only</code></em><code>Cmmmacros)</code><br />
<code>*foreigncalls(`foreign&quot;C&quot;...`)andcallstoCmmPrimitiveOperations(`%`)</code><br />
<code>*procedurecallsandtailcalls</code><br />
<code>*conditionalstatement(`if...{...}else{...}`)</code><br />
<code>*tabledconditional(`switch`)</code></p>
<p>Cmm does not implement the C-- specification for Spans (sec. 6.1) or Continuations (sec. 6.7).<a href="BR" class="uri" title="wikilink">BR</a> Although Cmm supports primitive operations that may have side effects (see [wiki:Commentary/Compiler/CmmType#PrimitiveOperations Primitive Operations], below), it does not parse the syntax `%%` form mentioned in section 6.3 of the C-- specification. Use the `%name(arg1,arg2)` expression-syntax instead. <a href="BR" class="uri" title="wikilink">BR</a> Cmm does not implement the `return` statement (C-- spec, sec. 6.8.2) but provides a set of macros that return a list of tuples of a `CgRep` and a `CmmExpr`: `[(CgRep,CmmExpr)]`. For a description of `CgRep`, see comments in <a href="GhcFile(compiler/codeGen/SMRep.lhs)" class="uri" title="wikilink">GhcFile(compiler/codeGen/SMRep.lhs)</a>. The return macros are defined at the end of the production rule `stmtMacros` in <a href="GhcFile(compiler/cmm/CmmParse.y)" class="uri" title="wikilink">GhcFile(compiler/cmm/CmmParse.y)</a>:</p>
<p><code>*`RET_P`</code><br />
<code>*`RET_N`</code><br />
<code>*`RET_PP`</code><br />
<code>*`RET_NN`</code><br />
<code>*`RET_NP`</code><br />
<code>*`RET_PPP`</code><br />
<code>*`RET_NNP`</code><br />
<code>*`RET_NNNP`</code><br />
<code>*`RET_NPNP`</code></p>
<p>In the above macros, `P` stands for `PtrArg` and `N` stands for `NonPtrArg`; both are `CgRep` constructors. These return macros provide greater control for the [wiki:Commentary/Compiler/CodeGen CodeGen] and integrate with the RTS but limit the number and type of return arguments in Cmm: you may only return according to these macros! The returns are processed by the `emitRetUT` function in <a href="GhcFile(compiler/cmm/CmmParse.y)" class="uri" title="wikilink">GhcFile(compiler/cmm/CmmParse.y)</a>, which in turn calls several functions from <a href="GhcFile(compiler/codeGen/CgMonad.lhs)" class="uri" title="wikilink">GhcFile(compiler/codeGen/CgMonad.lhs)</a>, notably `emitStmts`, which is the core Code Generator function for emitting `CmmStmt` data.</p>
<p>The Haskell representation of Cmm Statements is the data type `CmmStmt`, defined in <a href="GhcFile(compiler/cmm/Cmm.hs)" class="uri" title="wikilink">GhcFile(compiler/cmm/Cmm.hs)</a>:  Note how the constructor `CmmJump` contains `[LocalReg]`: this is the Cmm implementation of the C-- `jump` statement for calling another procedure where the parameters are the arguments passed to the other procedure. None of the parameters contain the address--in assembler, a label--of the caller, to return control to the caller. The `CmmCall` constructor also lacks a parameter to store the caller's address. Cmm implements C-- jump nesting and matching returns by <em>tail calls</em>, as described in section 6.8 of the C-- specification. Tail calls are managed through the [wiki:Commentary/Compiler/CodeGen CodeGen], see <a href="GhcFile(compiler/codeGen/CgTailCall.lhs)" class="uri" title="wikilink">GhcFile(compiler/codeGen/CgTailCall.lhs)</a>. You may have already noticed that the call target of the `CmmJump` is a `CmmExpr`: this is the Cmm implementation of computed procedure addresses, for example:  The computed procedure address, in this case `(bits32[x+4])`, should always be the first instruction of a `Cmm` procedure. You cannot obtain the address of a code block <em>within</em> a procedure and `jump` to it, as an alternative way of computing a <em>continuation</em>.</p>
<p>`CmmBranch BlockId` represents an unconditional branch to another [wiki:Commentary/Compiler/CmmType#BasicBlocksandProcedures Basic Block] in the same procedure. There are two unconditional branches in Cmm/C--:</p>
<p><code>1.`goto`statement;and</code><br />
<code>1.abranchfromthe`else`portionofan`if-then-else`statement.</code></p>
<p>`CmmCondBranch CmmExpr BlockId` represents a conditional branch to another [wiki:Commentary/Compiler/CmmType#BasicBlocksandProcedures Basic Block] in the same procedure. This is the `if expr` statement where `expr` is a `CmmExpr`, used in both the unary `if` and `if-then-else` statements. `CmmCondBranch` maps to more complex Assembler instruction sets or HC code (<a href="GhcFile(compiler/cmm/PprC.hs)" class="uri" title="wikilink">GhcFile(compiler/cmm/PprC.hs)</a>). For assembler, labels are created for each new Basic Block. During parsing, conditional statements map to the `BoolExpr` data type which guides the encoding of assembler instruction sets.</p>
<p>`CmmSwitch` represents the `switch` statement. It is parsed and created as with the `doSwitch` function in <a href="GhcFile(compiler/cmm/CmmParse.y)" class="uri" title="wikilink">GhcFile(compiler/cmm/CmmParse.y)</a> or created from `case` expressions with the `emitSwitch` and `mk_switch` functions in <a href="GhcFile(compiler/codeGen/CgUtils.hs)" class="uri" title="wikilink">GhcFile(compiler/codeGen/CgUtils.hs)</a>. In the NCG, a `CmmSwitch` is generated as a jump table using the `genSwitch` function in <a href="GhcFile(compiler/nativeGen/MachCodeGen.hs)" class="uri" title="wikilink">GhcFile(compiler/nativeGen/MachCodeGen.hs)</a>. There is currently no implementation of any optimisations, such as a cascade of comparisons for switches with a wide deviation in values or binary search for very wide value ranges--for output to HC, earlier versions of GCC could not handle large if-trees, anyway.</p>
<h4 id="cmm-calls">Cmm Calls</h4>
<p>Cmm calls include both calls to foreign functions and calls to Cmm quasi-operators using expression syntax (see [wiki:Commentary/Compiler/CmmType#QuasioperatorSyntax Quasi-operator Syntax]). Although Cmm does not implement any of the control flow statements of C-- specification (section 6.8.1), foreign calls from Cmm are one of the most complex components of the system due to various differences between the Cmm and C calling conventions.</p>
<p>The data type, `CmmCallTarget` is defined in <a href="GhcFile(compiler/cmm/Cmm.hs)" class="uri" title="wikilink">GhcFile(compiler/cmm/Cmm.hs)</a> as:  `CCallConv` is defined in <a href="GhcFile(compiler/prelude/ForeignCall.lhs)" class="uri" title="wikilink">GhcFile(compiler/prelude/ForeignCall.lhs)</a>; for information on register assignments, see comments in <a href="GhcFile(compiler/codeGen/CgCallConv.hs)" class="uri" title="wikilink">GhcFile(compiler/codeGen/CgCallConv.hs)</a>.</p>
<p>`CallishMachOp` is defined in <a href="GhcFile(compiler/cmm/MachOp.hs)" class="uri" title="wikilink">GhcFile(compiler/cmm/MachOp.hs)</a>; see, also, below [wiki:Commentary/Compiler/CmmType#PrimitiveOperations Primitive Operations]. `CallishMachOp`s are generally used for floating point computations (without implementing any floating point exceptions). Here is an example of using a `CallishMachOp` (not yet implemented): </p>
<h3 id="operators-and-primitive-operations">Operators and Primitive Operations</h3>
<p>Cmm generally conforms to the C-- specification for operators and &quot;primitive operations&quot;. The C-- specification, in section 7.4, refers to both of these as &quot;primitive operations&quot; but there are really two different types:</p>
<p><code>*</code><em><code>operators</code></em><code>,asIrefertothem,are:</code><br />
<code>*parseabletokens,suchas`+`,`-`,`*`or`/`;</code><br />
<code>*generallymaptoasinglemachineinstructionorpartofamachineinstruction;</code><br />
<code>*havenosideeffects;and,</code><br />
<code>*arerepresentedinHaskellusingthe`MachOp`datatype;</code><br />
<code>*</code><em><code>primitive</code> <code>operations</code></em><code>(Cmm</code><em><code>quasi-operators</code></em><code>)arespecial,usuallyinlined,procedures,representedinHaskellusingthe`CallishMachOp`datatype;primitiveoperationsmayhavesideeffects.</code></p>
<p>The `MachOp` and `CallishMachOp` data types are defined in <a href="GhcFile(compiler/cmm/MachOp.hs)" class="uri" title="wikilink">GhcFile(compiler/cmm/MachOp.hs)</a>.</p>
<p>Both Cmm Operators and Primitive Operations are handled in Haskell as [wiki:Commentary/PrimOps#InlinePrimOps Inline PrimOps], though what I am calling Cmm <em>primitive operations</em> may be implemented as out-of-line foreign calls.</p>
<h4 id="operators">Operators</h4>
<p> Each `MachOp` generally corresponds to a machine instruction but may have its value precomputed in the Cmm, NCG or HC optimisers.</p>
<h4 id="primitive-operations">Primitive Operations</h4>
<p>Primitive Operations generally involve more than one machine instruction and may not always be inlined.</p>
<p> For an example, the floating point sine function, `sinFloat#` in <a href="GhcFile(compiler/prelude/primops.txt.pp)" class="uri" title="wikilink">GhcFile(compiler/prelude/primops.txt.pp)</a> is piped through the `callishOp` function in <a href="GhcFile(compiler/codeGen/CgPrimOp.hs)" class="uri" title="wikilink">GhcFile(compiler/codeGen/CgPrimOp.hs)</a> to become `Just MO_F32_Sin`. The `CallishMachOp` constructor `MO_F32_Sin` is piped through a platform specific function such as <a href="GhcFile(compiler/nativeGen/X86/CodeGen.hs)" class="uri" title="wikilink">GhcFile(compiler/nativeGen/X86/CodeGen.hs)</a> on X86, where the function `genCCall` will call `outOfLineFloatOp` to issue a call to a C function such as `sin`.</p>
<h2 id="cmm-design-observations-and-areas-for-potential-improvement">Cmm Design: Observations and Areas for Potential Improvement</h2>
<p>&quot;If the application of a primitive operator causes a system exception, such as division by zero, this is an unchecked run-time error. (A future version of this specification may provide a way for a program to recover from such an exception.)&quot; C-- spec, Section 7.4. Cmm may be able to implement a partial solution to this problem, following the paper: <a href="http://cminusminus.org/abstracts/c--pldi-00.html">A Single Intermediate Language That Supports Multiple Implementations of Exceptions (2000)</a>. (TODO: write notes to wiki and test fix.)</p>
<p>The IEEE 754 specification for floating point numbers defines exceptions for certain floating point operations, including:</p>
<p><code>*rangeviolation(overflow,underflow);</code><br />
<code>*roundingerrors(inexact);</code><br />
<code>*invalidoperation(invalidoperand,suchascomparisonwitha`NaN`value,thesquarerootofanegativenumberordivisionofzerobyzero);and,</code><br />
<code>*zerodivide(aspecialcaseofaninvalidoperation).</code></p>
<p>Many architectures support floating point exceptions by including a special register as an addition to other exception handling registers. The IBM PPC includes the `FPSCR` (&quot;Floating Point Status Control Register&quot;); the Intel x86 processors use the `MXCSR` register. When the PPC performs a floating point operation it checks for possible errors and sets the `FPSCR`. Some processors allow a flag in the Foating-Point Unit (FPU) status and control register to be set that will disable some exceptions or the entire FPU exception handling facility. Some processors disable the FPU after an exception has occurred while others, notably Intel's x86 and x87 processors, continue to perform FPU operations. Depending on whether quiet !NaNs (QNaNs) or signaling !NaNs (SNaNs) are used by the software, an FPU exception may signal an interrupt for the software to pass to its own exception handler.</p>
<p>Some higher level languages provide facilities to handle these exceptions, including Ada, Fortran (F90 and later), C++ and C (C99, fenv.h, float.h on certain compilers); others may handle such exceptions without exposing a low-level interface. There are three reasons to handle FPU exceptions, and these reasons apply similarly to other exceptions:</p>
<p><code>*thefacilitiesprovidegreatercontrol;</code><br />
<code>*thefacilitiesareefficient--moreefficientthanahigher-levelsoftwaresolution;and,</code><br />
<code>*FPUexceptionsmaybeunavoidable,especiallyifseveralFPUoperationsareseriallyperformedatthemachinelevelsothehigherlevelsoftwarehasnoopportunitytochecktheresultsinbetweenoperations.</code></p>
<p>A potential solution to the problem of implementing Cmm exceptions, especially for floating point operations, is at [wiki:Commentary/CmmExceptions Cmm: Implementing Exception Handling].</p>
<p>The C-- Language Specification mentions over 75 primitive operators. The Specification lists separate operators for integral and floating point (signed) arithmetic (including carry, borrow and overflow checking), logical comparisons and conversions (from one size float to another, from float to integral and vice versa, etc.). C-- also includes special operators for floating point number values, such as `NaN`, `mzero`<em>k</em> and `pzero`<em>k</em>, and rounding modes; integral kinds also include bitwise operators, unsigned variants, and bit extraction for width changing and sign or zero-extension. A C-- implementation may conveniently map each of these operators to a machine instruction, or to a simulated operation on architectures that do not support a single instruction. There seem to be two main problems with the current GHC-implementation of Cmm:</p>
<p><code>1.notenoughoperators</code><br />
<code>1.noimplementationofvector(SIMD)registers(thoughthereisa`I128``MachRep`)</code></p>
<p>If a particular architecture supports it, assembler includes instructions such as mnemonics with the `.` (&quot;dot&quot;) suffix (`add., fsub.`), which set the Condition Register (CR) thereby saving you at least one instruction. (Extended mnemonics can save you even more.) Extended mnemonics with side effects may be implemented as new `CallishMachOps`, see [wiki:Commentary/Compiler/CmmType#PrimitiveOperations Primitive Operations] and [wiki:Commentary/Compiler/CmmType#CmmCalls Cmm Calls]. Assembler also supports machine exceptions, especially exceptions for floating-point operations, invalid storage access or misalignment (effective address alignment). The current implementation of Cmm cannot model such exceptions through flow control because no flow control is implemented, see [wiki:Commentary/Compiler/CmmType#CmmCalls Cmm Calls].</p>
<p>Hiding the kinds of registers on a machine eliminates the ability to handle floating point exceptions at the Cmm level and to explicitly vectorize (use SIMD extensions). The argument for exposing vector types may be a special case since such low-level operations are exposed at the C-level, as new types of variables or &quot;intrinsics,&quot; that are C-language extensions provided by special header files and compiler support (`vector unsigned int` or `__m128i`, `vector float` or `__m128`) and operations (`vec_add()`, `+` (with at least one vector operand), `_mm_add_epi32()`).</p>
<h1 id="ghc-commentary-what-the-hell-is-a-.cmm-file">GHC Commentary: What the hell is a `.cmm` file?</h1>
<p>A `.cmm` file is rather like C--. The syntax is almost C-- (a few constructs are missing), and it is augmented with some macros that are expanded by GHC's code generator (eg. `INFO_TABLE()`). A `.cmm` file is compiled by GHC itself: the syntax is parsed by <a href="GhcFile(compiler/cmm/CmmParse.y)" class="uri" title="wikilink">GhcFile(compiler/cmm/CmmParse.y)</a> and <a href="GhcFile(compiler/cmm/CmmLex.x)" class="uri" title="wikilink">GhcFile(compiler/cmm/CmmLex.x)</a> into the [wiki:Commentary/Compiler/CmmType Cmm] data type, where it is then passed through one of the [wiki:Commentary/Compiler/Backends back-ends].</p>
<p>We use the C preprocessor on `.cmm` files, making extensive use of macros to make writing this low-level code a bit less tedious and error-prone. Most of our C-- macros are in <a href="GhcFile(includes/Cmm.h)" class="uri" title="wikilink">GhcFile(includes/Cmm.h)</a>. One useful fact about the macros is `P_` is an alias for `gcptr`, and you should not use it for non-garbage-collected pointers.</p>
<h2 id="reading-references">Reading references</h2>
<p>Reading material for learning Cmm is somewhat scattered, so I (Arash) have created a list of useful links. Since the Cmm language is changing as GHC changes, I have prioritized resources that are not too old. (<em>Feel free to add/remove/modify this list! :)</em>)</p>
<p><code>*AnoverviewofCmmisgivenin</code><a href="https://davidterei.com/downloads/papers/terei:2009:honours_thesis.pdf"><code>David</code> <code>Terei's</code> <code>bachelor</code> <code>thesis</code></a><code>(chapter2.4.3).</code><br />
<code>*Thecommentsinthebeginningof</code><a href="GhcFile(compiler/cmm/CmmParse.y)" title="wikilink"><code>GhcFile(compiler/cmm/CmmParse.y)</code></a><code>issuper-usefulandkeptuptodate.Therestofthefilecontainsthe</code><em><code>grammar</code></em><code>ofthelanguage.Afraidofgrammars?EdwardYangwrotethisfantastic</code><a href="http://blog.ezyang.com/2013/07/no-grammar-no-problem/"><code>blog</code> <code>post</code></a><code>onhowtounderstandtheconstructsofCmmbyusingthegrammar.</code><br />
<code>*CmmhasapreprocessorliketheoneinCandmanyofthemacrosaredefinedin</code><a href="GhcFile(includes/Cmm.h)" title="wikilink"><code>GhcFile(includes/Cmm.h)</code></a><code>.</code><br />
<code>*In2012,SimonMarlowextendedtheCmmlanguagebyaddinganewhigh-levelsyntaxwhichcanbeusedwhenyoudon'tneedlow-levelaccess(likeregisters).The</code><a href="https://github.com/ghc/ghc/commit/a7c0387d20c1c9994d1100b14fbb8fb4e28a259e"><code>commit</code></a><code>explainsthedetails.</code><br />
<code>*Cmmisalsodescribed[wiki:Commentary/Compiler/CmmTypeonthiswiki],butitiswrittenbeforethenewsyntaxwasintroduced.</code><br />
<code>*Stackframetypesarecreatedusing`INFO_TABLE_RET`,thesyntaxcanbeconfusingsincethereareboth</code><em><code>arguments</code></em><code>and</code><em><code>fields</code></em><code>,I(Arash)havenotseenanythinglikeitinotherprogramminglanguages.Itriedtoexplainitinmy</code><a href="http://arashrouhani.com/papers/master-thesis.pdf"><code>master</code> <code>thesis</code></a><code>(sections4.2and4.2.1).</code></p>
<h2 id="other-information">Other information</h2>
<p>It can take time to learn Cmm. One unintuitive thing to watch out for is that there are no function calls in low-level cmm code. The new syntax from 2012 allows function calls but you should know that they are kind of magical.</p>
<p>We say that <strong>Cmm</strong> is GHC's implementation of <strong>C--</strong>. This naming scheme is not done consistently everywhere, unfortunately. If you are interested in C-- (which have diverged from Cmm), you can check out the <a href="http://www.cminusminus.org/">website</a> and the <a href="http://www.cs.tufts.edu/~nr/c--/extern/man2.pdf">specification</a>.</p>
<h1 id="code-generator">Code Generator</h1>
<p>This page describes code generator (&quot;codegen&quot;) in GHC. It is meant to reflect current state of the implementation. If you notice any inaccuracies please update the page (if you know how) or complain on ghc-devs.</p>
<h2 id="a-brief-history-of-code-generator">A brief history of code generator</h2>
<p>You might occasionally hear about &quot;old&quot; and &quot;new&quot; code generator. GHC 7.6 and earlier used the old code generator. New code generator was being developed since 2007 and it was [changeset:832077ca5393d298324cb6b0a2cb501e27209768/ghc enabled by default on 31 August 2012] after the release of GHC 7.6.1. The first stable GHC to use the new code generator is 7.8.1 released in early 2014. The commentary on the old code generator can be found [wiki:Commentary/Compiler/OldCodeGen here]. Notes from the development process of the new code generator are located in a couple of pages on the wiki - to find them go to [wiki:TitleIndex Index] and look for pages starting with &quot;!NewCodeGen&quot;.</p>
<p>There are some plans for the future development of code generator. One plan is to expand the capability of the pipeline so that it does native code generation too so that existing backends can be discarded - see [wiki:Commentary/Compiler/IntegratedCodeGen IntegratedCodeGen] for discussion of the design. It is hard to say if this will ever happen as currently there is no work being done on that subject and in the meanwhile there was an alternative proposal to [wiki:Commentary/Compiler/Backends/LLVM/ReplacingNCG replace native code generator with LLVM].</p>
<h2 id="overview">Overview</h2>
<p>The goal of the code generator is to convert program from [wiki:Commentary/Compiler/GeneratedCode STG] representation to [wiki:Commentary/Compiler/CmmType Cmm] representation. STG is a functional language with explicit stack. Cmm is a low-level imperative language - something between C and assembly - that is suitable for machine code generation. Note that terminology might be a bit confusing here: the term &quot;code generator&quot; can refer both to STG-&gt;Cmm pass and the whole STG-&gt;Cmm-&gt;assembly pass. The Cmm-&gt;assembly conversion is performed by one the backends, eg. NCG (Native Code Generator or LLVM.</p>
<p>The top-most entry point to the codegen is located in <a href="GhcFile(compiler/main/HscMain.hs)" class="uri" title="wikilink">GhcFile(compiler/main/HscMain.hs)</a> in the `tryNewCodegen` function. Code generation is done in two stages:</p>
<p><code>1.ConvertSTGtoCmmwithimplicitstack,andnativeCmmcalls.Thiswholestagelivesin</code><a href="GhcFile(compiler/codeGen)" title="wikilink"><code>GhcFile(compiler/codeGen)</code></a><code>directorywiththeentrypointbeing`codeGen`functionin</code><a href="GhcFile(compiler/codeGen/StgCmm.hs)" title="wikilink"><code>GhcFile(compiler/codeGen/StgCmm.hs)</code></a><code>module.</code><br />
<code>2.OptimisetheCmm,andCPS-convertittohaveanexplicitstack,andnonativecalls.Thislivesin</code><a href="GhcFile(compiler/cmm)" title="wikilink"><code>GhcFile(compiler/cmm)</code></a><code>directorywiththe`cmmPipeline`functionfrom</code><a href="GhcFile(compiler/cmm/CmmPipeline.hs)" title="wikilink"><code>GhcFile(compiler/cmm/CmmPipeline.hs)</code></a><code>modulebeingtheentrypoint.</code></p>
<p>The CPS-converted Cmm is fed to one of the backends. This is done by `codeOutput` function (<a href="GhcFile(compiler/main/CodeOutput.lhs)" class="uri" title="wikilink">GhcFile(compiler/main/CodeOutput.lhs)</a> called from `hscGenHardCode` after returning from `tryNewCodegen`.</p>
<h2 id="first-stage-stg-to-cmm-conversion">First stage: STG to Cmm conversion</h2>
<p><code>*</code><strong><code>Code</code> <code>generator</code></strong><code>convertsSTGto`CmmGraph`.Implementedin`StgCmm*`modules(indirectory`codeGen`).</code><br />
<code>*`Cmm.CmmGraph`isprettymuchaHooplgraphof`CmmNode.CmmNode`nodes.Controltransferinstructionsarealwaysthelastnodeofabasicblock.</code><br />
<code>*Parameterpassingismadeexplicit;thecallingconventiondependsonthetargetarchitecture.Thekeyfunctionis`CmmCallConv.assignArgumentsPos`.</code><br />
<code>*ParametersarepassedinvirtualregistersR1,R2etc.[Thesemap1-1torealregisters.]</code><br />
<code>*Overflowparametersarepassedonthestackusingexplicitmemorystores,tolocationsdescribedabstractlyusingthe[wiki:Commentary/Compiler/StackAreas</code><em><code>Stack</code> <code>Area</code></em><code>abstraction].</code><br />
<code>*Makingthecallingconventionexplicitincludesanexplicitstoreinstructionofthereturnaddress,whichisstoredexplicitlyonthestackinthesamewayasoverflowparameters.Thisisdone(obscurely)in`StgCmmMonad.mkCall`.</code></p>
<h2 id="second-stage-the-cmm-pipeline">Second stage: the Cmm pipeline</h2>
<p>The core of the Cmm pipeline is implemented by the `cpsTop` function in <a href="GhcFile(compiler/cmm/CmmPipeline.hs)" class="uri" title="wikilink">GhcFile(compiler/cmm/CmmPipeline.hs)</a> module. Below is a high-level overview of the pipeline. See source code comments in respective modules for a more in-depth explanation of each pass.</p>
<p><code>*</code><strong><code>Control</code> <code>Flow</code> <code>Optimisations</code></strong><code>,implementedin`CmmContFlowOpt`,simplifiesthecontrolflowgraphby:</code><br />
<code>*Eliminatingblocksthathaveonlyonepredecessorbyconcatenatingthemwiththatpredecessor</code><br />
<code>*Shortcutingtargetsofbranchesandcalls(seeNote[Whatisshortcutting])</code><br />
<code></code><br />
<code>Ifablockbecomesunreachablebecauseofshortcuttingitiseliminatedfromthegraph.However,</code><strong><code>it</code> <code>is</code> <code>theoretically</code> <code>possible</code> <code>that</code> <code>this</code> <code>pass</code> <code>will</code> <code>produce</code> <code>unreachable</code> <code>blocks</code></strong><code>.Thereasonisthelabelrenamingpassperformedafterblockconcatenationhasbeencompleted.</code></p>
<p><code>Thispassmightbeoptionallycalledforthesecondtimeattheendofthepipeline.</code></p>
<p><code>*</code><strong><code>Common</code> <code>Block</code> <code>Elimination</code></strong><code>,implementedin`CmmCommonBlockElim`,eliminatesblocksthatareidentical(exceptforthelabelontheirfirstnode).Sincethispasstraversesblocksindepth-firstorderanyunreachableblocksintroducedbyControlFlowOptimisationsareeliminated.</code><strong><code>This</code> <code>pass</code> <code>is</code> <code>optional.</code></strong></p>
<p><code>*</code><strong><code>Determine</code> <code>proc-points</code></strong><code>,implementedin`CmmProcPoint`.Theideabehindthe&quot;proc-pointsplitting&quot;isthatwefirstdetermineproc-points,ie.blocksinthegraphthatcanbeturnedintoentrypointsofprocedures,andthensplitalargerfunctionintomanysmallerones,eachhavingaproc-pointasitsentrypoint.ThisisrequiredfortheLLVMbackend.Theproc-pointsplittingitselfisdonelaterinthepipeline,buthereweonlydeterminethesetofproc-points.Wefirstcall`callProcPoints`,whichassumesthatentrypointtoaCmmgraphandeverycontinuationofacallisaprocpoint.Ifwearesplittingproc-pointsweupdatethelistofproc-pointsbycalling`minimalProcPointSet`,whichaddsallblocksreachablefrommorethanoneblockinthegraph.Thesetofproc-pointsisrequiredbythestacklayoutpass.</code></p>
<p><code>*</code><strong><code>Figure</code> <code>out</code> <code>the</code> <code>stack</code> <code>layout</code></strong><code>,implementedin`CmmStackLayout`.Thejobofthispassisto:</code><br />
<code>*replacereferencestoabstractstackAreaswithfixedoffsetsfromSp.</code><br />
<code>*replacethe!CmmHighStackMarkconstantusedinthestackcheckwith</code><br />
<code>themaximumstackusageoftheproc.</code><br />
<code>*saveanyvariablesthatareliveacrossacall,andreloadthemas</code><br />
<code>necessary.</code><br />
<strong><code>Important</code></strong><code>:Itmayhappenthatstacklayoutwillinvalidatethecomputedsetofproc-pointsbymakingaproc-pointunreachable.Thisunreachableblockiseliminatedbyoneofsubsequentpassesthatperformsdepth-firsttraversalofagraph:sinkingpass(ifoptimisationsareenabled),proc-pointanalysis(ifoptimisationsaredisabledandwe'redoingproc-pointsplitting)orattheveryendofthepipeline(ifoptimisationsaredisabledandwe'renotdoingproc-pointsplitting).Thismeansthatstartingfromthispointinthepipelinewehaveinconsistentdataandsubsequentstepsmustbepreparedforit.</code><br />
<br />
<code>*</code><strong><code>Sinking</code> <code>assignments</code></strong><code>,implementedin`CmmSink`,performstheseoptimizations:</code><br />
<code>*movesassignmentsclosertotheiruses,toreduceregisterpressure</code><br />
<code>*pushesassignmentsintoasinglebranchofaconditionalifpossible</code><br />
<code>*inlinesassignmentstoregistersthatarementionedonlyonce</code><br />
<code>*discardsdeadassignments</code><br />
<strong><code>This</code> <code>pass</code> <code>is</code> <code>optional.</code></strong><code>Itcurrentlydoesnoteliminatedeadcodeinloops(#8327)andhassomeotherminordeficiencies(eg.#8336).</code></p>
<p><code>*</code><strong><code>CAF</code> <code>analysis</code></strong><code>,implementedin`CmmBuildInfoTables`.ComputedCAFinformationisreturnedfrom`cmmPipeline`andusedtocreateStaticReferenceTables(SRT).See[wiki:Commentary/Rts/Storage/GC/CAFshere]forsomemoredetailonCAFsandSRTs.ThispassisimplementedusingHoopl(seebelow).</code></p>
<p><code>*</code><strong><code>Proc-point</code> <code>analysis</code> <code>and</code> <code>splitting</code></strong><code>(onlywhensplittingproc-points),implementedby`procPointAnalysis`in`CmmProcPoint`,takesalistofproc-pointsandforeachblockanddeterminesfromwhichproc-pointtheblockisreachable.ThisisimplementedusingHoopl.</code><br />
<code>Thenthecallto`splitAtProcPoints`splitstheCmmgraphintomultipleCmmgraphs(eachrepresentsasinglefunction)andbuildinfotablestoeachofthem.</code><br />
<code>Whendoingthiswemustbepreparedforthefactthataproc-pointdoesnotactuallyexistinthegraphsinceitwasremovedbystacklayoutpass(see#8205).</code></p>
<p><code>*</code><strong><code>Attach</code> <code>continuations'</code> <code>info</code> <code>tables</code></strong><code>(onlywhenNOTsplittingproc-points),implementedby`attachContInfoTables`in`CmmProcPoint`attachesinfotablesforthecontinuationsofcallsinthegraph.</code><em><code>[PLEASE</code> <code>WRITE</code> <code>MORE</code> <code>IF</code> <code>YOU</code> <code>KNOW</code> <code>WHY</code> <code>THIS</code> <code>IS</code> <code>!DONE]</code></em></p>
<p><code>*</code><strong><code>Update</code> <code>info</code> <code>tables</code> <code>to</code> <code>include</code> <code>stack</code> <code>liveness</code></strong><code>,implementedby`setInfoTableStackMap`in`CmmLayoutStack`.PopulatesinfotablesofeachCmmfunctionwithstackusageinformation.Usesstackmapscreatedbythestacklayoutpass.</code></p>
<p><code>*</code><strong><code>Control</code> <code>Flow</code> <code>Optimisations</code></strong><code>,sameasthebeginningofthepipeline,butthispassrunsonlywith`-O1`and`-O2`.Sincethispassmightproduceunreachableblocksitisfollowedbyacallto`removeUnreachableBlocksProc`(alsoin`CmmContFlowOpt.hs`)</code></p>
<h2 id="dumping-and-debugging-cmm">Dumping and debugging Cmm</h2>
<p>You can dump the generated Cmm code using `-ddump-cmm` flag. This is helpful for debugging Cmm problems. Cmm dump is divided into several sections:</p>
<p></p>
<p>&quot;Cmm produced by new codegen&quot; is emited in `HscMain` module after converting STG to Cmm. This Cmm has not been processed in any way by the Cmm pipeline. If you see that something is incorrect in that dump it means that the problem is located in the STG-&gt;Cmm pass. The last section, &quot;Output Cmm&quot;, is also dumped in `HscMain` but this is done after the Cmm has been processed by the whole Cmm pipeline. All other sections are dumped by the Cmm pipeline. You can dump only selected passes with more specific flags. For example, if you know (or suspect) that the sinking pass is performing some incorrect transformations you can make the dump shorter by adding `-ddump-cmm-sp -ddump-cmm-sink` flags. This will produce only the &quot;Layout Stack&quot; dump (just before sinking pass) and &quot;Sink assignments&quot; dump (just after the sinking pass) allowing you to focus on the changes introduced by the sinking pass.</p>
<h2 id="register-allocator-code">Register Allocator Code</h2>
<p>The register allocator code is split into two main sections, the register allocator proper and a generic graph coloring library. The graph coloring library is also used by the Stg-&gt;Cmm converter.</p>
<h3 id="the-register-allocator">The register allocator</h3>
<p><code>*</code><a href="GhcFile(compiler/nativeGen/RegLiveness.hs)" title="wikilink"><code>GhcFile(compiler/nativeGen/RegLiveness.hs)</code></a><code></code><a href="BR" title="wikilink"><code>BR</code></a><br />
<code>Defines</code><code>and</code><code>whichcarrynativemachineinstructionsannotatedwithregisterlivenessinformation.Italsoprovidesfunctionstoannotatenativecode(</code><code>)withthislivenessinformation,andtoslurpoutsetsofregisterconflictsforfeedingintothecoloringallocator.</code></p>
<p><code>*</code><a href="GhcFile(compiler/nativeGen/RegAllocColor.hs)" title="wikilink"><code>GhcFile(compiler/nativeGen/RegAllocColor.hs)</code></a><code></code><a href="BR" title="wikilink"><code>BR</code></a><br />
<code>Defines</code><code>,themaindriverfunctionforthegraphcoloringallocator.Thedriveraccepts</code><code>swhichusevirtualregs,andproduces</code><code>whichuserealmachineregs.Thismodulealsoprovidesfunctionstohelpbuildanddeepseqtheregisterconflictgraph.</code></p>
<p><code>*</code><a href="GhcFile(compiler/nativeGen/RegAllocLinear.hs)" title="wikilink"><code>GhcFile(compiler/nativeGen/RegAllocLinear.hs)</code></a><code></code><a href="BR" title="wikilink"><code>BR</code></a><br />
<code>Definesthelinearscanallocator.Itsinterfaceisidenticaltothecoloringallocator.</code></p>
<p><code>*</code><a href="GhcFile(compiler/nativeGen/RegAllocInfo.hs)" title="wikilink"><code>GhcFile(compiler/nativeGen/RegAllocInfo.hs)</code></a><code></code><a href="BR" title="wikilink"><code>BR</code></a><br />
<code>Definestheregisterinformationfunction,</code><code>,whichtakesasetofrealandvirtualregistersandreturnstheactualregistersusedbyaparticular</code><code>;registerallocationisinAT&amp;Tsyntaxorder(source,destination),inaninternalfunction,</code><code>;definesthe</code><code>datatype</code><a href="BR" title="wikilink"><code>BR</code></a><a href="BR" title="wikilink"><code>BR</code></a></p>
<p><code>*</code><a href="GhcFile(compiler/nativeGen/RegSpillCost.hs)" title="wikilink"><code>GhcFile(compiler/nativeGen/RegSpillCost.hs)</code></a><code></code><a href="BR" title="wikilink"><code>BR</code></a><br />
<code>Defines</code><code>whichisresponsibleforselectingavirtualregtospilltothestackwhennotenoughrealregsareavailable.</code></p>
<p><code>*</code><a href="GhcFile(compiler/nativeGen/RegSpill.hs)" title="wikilink"><code>GhcFile(compiler/nativeGen/RegSpill.hs)</code></a><code></code><a href="BR" title="wikilink"><code>BR</code></a><br />
<code>Defines</code><code>whichtakes</code><code>sandinsertsspill/reloadinstructionsvirtualregsthatwouldn'tfitinrealregs.</code><code>'sstrategyistosimplyinsertsspill/reloadsforeveryuse/defofaparticularvirtualreg.Thisinefficientcodeiscleanedupbythespillcleanerafterallocation.</code><br />
<br />
<code>*</code><a href="GhcFile(compiler/nativeGen/RegSpillClean.hs)" title="wikilink"><code>GhcFile(compiler/nativeGen/RegSpillClean.hs)</code></a><code></code><a href="BR" title="wikilink"><code>BR</code></a><br />
<code>Thespillcleanerisrunafterrealregshavebeenallocated.Iterasesspill/reloadinstructionsinsertedby</code><code>thatweren'tstrictlynessesary.</code></p>
<p><code>*</code><a href="GhcFile(compiler/nativeGen/RegAllocStats.hs)" title="wikilink"><code>GhcFile(compiler/nativeGen/RegAllocStats.hs)</code></a><code></code><a href="BR" title="wikilink"><code>BR</code></a><br />
<code>Definesdatatypesandprettyprintersusedforcollectingstatisticsanddebugginginfofromthecoloringallocator.</code></p>
<h3 id="graph-coloring">Graph coloring</h3>
<p><code>*</code><a href="GhcFile(compiler/utils/GraphBase.hs)" title="wikilink"><code>GhcFile(compiler/utils/GraphBase.hs)</code></a><code></code><a href="BR" title="wikilink"><code>BR</code></a><br />
<code>Definesthebasic</code><code>,</code><code>and</code><code>typesusedbythecoloringalgorithm.</code></p>
<p><code>*</code><a href="GhcFile(compiler/utils/GraphColor.hs)" title="wikilink"><code>GhcFile(compiler/utils/GraphColor.hs)</code></a><code></code><a href="BR" title="wikilink"><code>BR</code></a><br />
<code>Definesthefunction</code><code>whichisresponsibleforassigningcolors(realregs)tonodes(virtualregs)intheregisterconflictgraph.</code></p>
<p><code>*</code><a href="GhcFile(compiler/utils/GraphOps.hs)" title="wikilink"><code>GhcFile(compiler/utils/GraphOps.hs)</code></a><code></code><a href="BR" title="wikilink"><code>BR</code></a><br />
<code>Definesfunctionstoperformbasicoperationsonthegraphssuchasadding,deleting,andcoalescingnodes.</code></p>
<p><code>*</code><a href="GhcFile(compiler/utils/GraphPps.hs)" title="wikilink"><code>GhcFile(compiler/utils/GraphPps.hs)</code></a><code></code><a href="BR" title="wikilink"><code>BR</code></a><br />
<code>Definesfunctionsforprettyprintgraphsinhumanreadable-ishandgraphvizformat.</code></p>
<h3 id="miscellanea">Miscellanea</h3>
<p><code>*</code><a href="GhcFile(compiler/nativeGen/RegCoalesce.hs)" title="wikilink"><code>GhcFile(compiler/nativeGen/RegCoalesce.hs)</code></a><code></code><a href="BR" title="wikilink"><code>BR</code></a><br />
<code>Definesafunction</code><code>thatdoesaggressivecoalescingdirectlyon</code><code>,withoutusingthegraph.Thisisn'tusedatthemomentbuthasbeenleftinincasewewanttorejigtheallocatorwhenthenewCPSconvertercomesonline.</code></p>
<p><code>*</code><a href="GhcFile(compiler/nativeGen/RegArchBase.hs)" title="wikilink"><code>GhcFile(compiler/nativeGen/RegArchBase.hs)</code></a><code></code><a href="BR" title="wikilink"><code>BR</code></a><br />
<code>Definesutilsforcalculatingwhetheraregisterintheconflictgraphistriviallycolorable,inagenericwaywhichhandlesaliasingbetweenregisterclasses.ThismoduleisnotuseddirectlybyGHC.</code></p>
<p><code>*</code><a href="GhcFile(compiler/nativeGen/RegArchX86.hs)" title="wikilink"><code>GhcFile(compiler/nativeGen/RegArchX86.hs)</code></a><code></code><a href="BR" title="wikilink"><code>BR</code></a><br />
<code>Containsadescriptionofthealiasingconstraintsbetweentheregistersetsonx86.ThismoduleisnotuseddirectlybyGHC.</code></p>
<p><a href="PageOutline" class="uri" title="wikilink">PageOutline</a></p>
<h1 id="the-ghc-commentary---coding-style-guidelines-for-the-compiler">The GHC Commentary - Coding Style Guidelines for the compiler</h1>
<p>This is a rough description of some of the coding practices and style that we use for Haskell code inside . For run-time system code see the [wiki:Commentary/Rts/Conventions Coding Style Guidelines for RTS C code]. Also see the wiki page on [wiki:WorkingConventions Working Conventions] for issues related to version control, workflow, testing, bug tracking and other miscellany.</p>
<h2 id="general-style">General Style</h2>
<p>The general rule is to stick to the same coding style as is already used in the file you're editing. If you must make stylistic changes, commit them separately from functional changes, so that someone looking back through the change logs can easily distinguish them.</p>
<p>It's much better to write code that is transparent than to write code that is short.</p>
<p>Often it's better to write out the code longhand than to reuse a generic abstraction (not always, of course). Sometimes it's better to duplicate some similar code than to try to construct an elaborate generalisation with only two instances. Remember: other people have to be able to quickly understand what you've done, and overuse of abstractions just serves to obscure the <em>really</em> tricky stuff, and there's no shortage of that in GHC.</p>
<h2 id="comments">Comments</h2>
<p>There are two kinds of comments in source code, comments that describe the interface (i.e. how is this supposed to be used) and comments that describe the implementation (e.g. subtle gotchas).</p>
<h3 id="comments-on-top-level-entities">Comments on top-level entities</h3>
<p>Every top-level entity should have a Haddock comment that describes what it does and, if needed, why it's there. Example:</p>
<p></p>
<p>We use Haddock so that the comment is included in the generated HTML documentation.</p>
<p>There's a bit of a broken window effect going on, but please try to follow this rule for new functions you add.</p>
<h3 id="comments-in-the-source-code">Comments in the source code</h3>
<p>Commenting is good but</p>
<p><code>*longcomments</code><em><code>interleaved</code> <code>with</code> <code>the</code> <code>code</code></em><code>canmakethecodeitselfincrediblyhardtoread,and</code><br />
<code>*longcomments</code><em><code>detached</code> <code>from</code> <code>the</code> <code>code</code></em><code>areeasytomisswhenyouareeditingthecodeitself,andsoonbecomeoutofdateorevenmisleading.</code></p>
<p>We have adopted a style that seems to help. Here's an example:  Notice that</p>
<p><code>*</code><strong><code>Interleaved</code> <code>with</code> <code>the</code> <code>code</code></strong><code>isashortlink`Note[Floatcoercions]`.Youcan'tmissitwhenyouareeditingthecode,butyoucanstillseethecodeitself.</code><br />
<code>*</code><strong><code>Detached</code> <code>from</code> <code>the</code> <code>code</code></strong><code>isthelinkedcomment,startingwiththesamestring`Note[Floatcoercions]`.Itcanbelong,andoftenincludesexamples.</code></p>
<p>The standard format &quot;`Note [Float coercions]`&quot; serves like an URL, to point to an out-of-line comment. Usually the target is in the same module, but not always. Sometimes we say </p>
<p>Please use this technique. It's robust, and survives successive changes to the same lines of code. When you are changing code, it draws attention to non-obvious things you might want to bear in mind. When you encounter the note itself you can search for the string to find the code that implements the thoughts contained in the comment.</p>
<h3 id="comments-and-examples">Comments and examples</h3>
<p>When writing a comment to explain a subtle point, consider including an example code snippet that illustrates the point. For example, the above `Note [Float coercions]` continues thus:  These kind of code snippets are extremely helpful to illustrate the point in a concrete way. Other ways of making the comment concrete are:</p>
<p><code>*CiteaparticularTracticketthatthisbitofcodedealswith</code><br />
<code>*Citeatestcaseinthetestsuitethatillustratesit</code></p>
<h3 id="longer-comments-or-architectural-commentary">Longer comments or architectural commentary</h3>
<p>Comments with a broad scope, describing the architecture or workings of more than one module, belong here in the commentary rather than in the code. Put the URL for the relevant commentary page in a comment in the code itself, and also put URLs for all relevant commentary pages in a comment at the top of each module.</p>
<h3 id="commit-messages">Commit messages</h3>
<p>Please do not use commit messages to describe how something works, or give examples, <em>even if the patch is devoted to a single change</em>. The information is harder to find in a commit message, and (much worse) there is no explicit indication in the code that there is carefully-written information available about that particular line of code. Instead, you can refer to the Note from the commit message.</p>
<p>Commit messages can nevertheless contain substantial information, but it is usually of a global nature. E.g. &quot;This patch modifies 20 files to implement a new form of inlining pragma&quot;. They are also a useful place to say which ticket is fixed by the commit, summarise the changes embodied in the commit etc.</p>
<p>In short, commit messages describe <em>changes</em>, whereas comment explain the code <em>as it now is</em>.</p>
<h2 id="warnings">Warnings</h2>
<p>We are aiming to make the GHC code warning-free, for all warnings turned on by  The build automatically sets these flags for all source files (see `mk/warnings.mk`).</p>
<p>The [wiki:TestingPatches validate script], which is used to test the build before commiting, additionally sets the `-Werror` flag, so that the code <strong>must</strong> be warning-free to pass validation. The `-Werror` flag is not set during normal builds, so warnings will be printed but won't halt the build.</p>
<p>Currently we are some way from our goal, so some modules have a  pragma; you are encouraged to remove this pragma and fix any warnings when working on a module.</p>
<h2 id="exports-and-imports">Exports and Imports</h2>
<h3 id="exports">Exports</h3>
<p> We usually (99% of the time) include an export list. The only exceptions are perhaps where the export list would list absolutely everything in the module, and even then sometimes we do it anyway.</p>
<p>It's helpful to give type signatures inside comments in the export list, but hard to keep them consistent, so we don't always do that.</p>
<h3 id="imports">Imports</h3>
<p>List imports in the following order:</p>
<p><code>*Localtothissubsystem(ordirectory)first</code><br />
<code>*Compilerimports,generallyorderedfromspecifictogeneric(ie.modulesfromutils/andbasicTypes/usuallycomelast)</code><br />
<code>*Libraryimports</code><br />
<code>*StandardHaskell98importslast</code></p>
<p></p>
<p>Import library modules from the [wiki:Commentary/Libraries boot packages] only (boot packages are those packages in the file [source:packages] that have a '-' in the &quot;tag&quot; column). Use `#defines `in `HsVersions.h` when the modules names differ between versions of GHC. For code inside `#ifdef GHCI`, don't worry about GHC versioning issues, because this code is only ever compiled by the this very version of GHC.</p>
<p><strong>Do not use explicit import lists</strong>, except to resolve name clashes. There are several reasons for this:</p>
<p><code>*Theyslowdowndevelopment:almosteverychangeisaccompaniedbyanimportlistchange.</code></p>
<p><code>*Theycausespuriousconflictsbetweendevelopers.</code></p>
<p><code>*Theyleadtouselesswarningsaboutunusedimports,andtimewastedtryingto</code><br />
<code>keeptheimportdeclarations&quot;minimal&quot;.</code></p>
<p><code>*GHC'swarningsareusefulfordetectingunnecessaryimports:see`-fwarn-unused-imports`.</code></p>
<p><code>*TAGSisagoodwaytofindoutwhereanidentifierisdefined(use`maketags`in`ghc/compiler`,</code><br />
<code>andhit`M-.`inemacs).</code></p>
<p>If the module can be compiled multiple ways (eg. GHCI vs. non-GHCI), make sure the imports are properly `#ifdefed` too, so as to avoid spurious unused import warnings.</p>
<h2 id="compiler-versions-and-language-extensions">Compiler versions and language extensions</h2>
<p>GHC must be compilable and validate by the previous two major GHC releases, and itself. It isn't necessary for it to be compilable by every intermediate development version.</p>
<p>To maintain compatibility, use [wiki:Commentary/CodingStyle#HsVersions.h HsVersions.h] (see below) where possible, and try to avoid using #ifdef in the source itself.</p>
<h3 id="section"></h3>
<p> is a CPP header file containing a number of macros that help smooth out the differences between compiler versions. It defines, for example, macros for library module names which have moved between versions. Take a look <a href="GhcFile(compiler/HsVersions.h)" class="uri" title="wikilink">GhcFile(compiler/HsVersions.h)</a>. </p>
<h3 id="literate-haskell">Literate Haskell</h3>
<p>In GHC we use a mixture of literate () and non-literate () source. I (Simon M.) prefer to use non-literate style, because I think the } clutter up the source too much, and I like to use Haddock-style comments (we haven't tried processing the whole of GHC with Haddock yet, though).</p>
<h3 id="the-c-preprocessor-cpp">The C Preprocessor (CPP)</h3>
<p>Whenever possible we try to avoid using CPP, as it can hide code from the compiler (which means changes that work on one platform can break the build on another) and code using CPP can be harder to understand.</p>
<p>The following CPP symbols are used throughout the compiler:</p>
<p><strong><code>DEBUG</code></strong><code>::</code><br />
<code>Usedtoenablesextrachecksanddebuggingoutputinthecompiler.TheASSERTmacro(see</code><code>)providesassertionswhichdisappearwhenDEBUGisnotdefined.</code></p>
<p><code>However,wheneverpossible,itisbettertouse`debugIsOn`fromthe`Util`module,whichisdefinedtobe`True`when`DEBUG`isdefinedand`False`otherwise.TheidealwaytoprovidedebuggingoutputistouseaHaskellexpression&quot;`whendebugIsOn$...`&quot;toarrangethatthecompilerwillbesilentwhen`DEBUG`isoff(unlessofcoursesomethinggoeswrongortheverbositylevelisnonzero).Whenoption`-O`isused,GHCwilleasilysweepawaytheunreachablecode.</code></p>
<p><code>Asalastresort,debuggingcodecanbeplacedinside`#ifdefDEBUG`,butsincethisstrategyguaranteesthatonlyafractionofthecodeisseenbethecompileronanyonecompilation,itistobeavoidedwhenpossible.</code></p>
<p><code>Regardingperformance,agoodruleofthumbisthat`DEBUG`shouldn'taddmorethanabout10-20%tothecompilationtime.Thisisthecaseatthemoment.Ifitgetstooexpensive,wewon'tuseit.Formoreexpensiveruntimechecks,consideraddingaflag-seeforexample`-dcore-lint`.</code></p>
<p><strong>Trap, pitfall for using the ASSERT macro</strong>:</p>
<p>The ASSERT macro uses CPP, and if you are unwise enough to try to write assertions using primed variables (), one possible outcome is that CPP silently fails to expand the ASSERT, and you get this very baffling error message:  Now you can Google for this error message :-)</p>
<p><strong><code>GHCI</code></strong><code>::</code><br />
<code>EnablesGHCisupport,includingthebytecodegeneratorandinteractiveuserinterface.Thisisn'tthedefault,becausethecompilerneedstobebootstrappedwithitselfinorderforGHCitoworkproperly.Thereasonisthatthebyte-codecompilerandlinkerarequitecloselytiedtotheruntimesystem,soitisessentialthatGHCiislinkedwiththemostup-to-dateRTS.AnotherreasonisthattherepresentationofcertaindatatypesmustbeconsistentbetweenGHCianditslibraries,andifthesewereinconsistentthendisastercouldfollow.</code></p>
<h3 id="platform-tests">Platform tests</h3>
<p>Please refer to [wiki:Commentary/PlatformNaming Platforms and Conventions] wiki page for an overview of how to handle target specific code in GHC.</p>
<h2 id="tabs-vs-spaces">Tabs vs Spaces</h2>
<p>GHCs source code is indented with a mixture of tabs and spaces, and is standardised on a tabstop of 8.</p>
<p>Most of the Haskell source code in GHC is free of tabs. We'd like to move away from tabs in the long term, and so a git hook on darcs.haskell.org will reject series of commits that add tabs to a file that is currently tab-free. (Note that there are no restrictions on adding tabs to a file already containing them.)</p>
<p>In order to avoid angering this git hook, you should set your editor to indent using spaces rather than tabs:</p>
<p><code>*InEmacs,add`(setq-defaultindent-tabs-modenil)`toyour`.emacs`file(</code><a href="http://cscs.umich.edu/~rlr/Misc/emacs_tabs.htm"><code>more</code> <code>discussion</code></a><code>)</code><br />
<code>*InSublimeText,savethefollowingtofilesat`Packages/User/Haskell.sublime-settings`and`Packages/User/LiterateHaskell.sublime-settings`:</code></p>
<p></p>
<p><code>*In!TextMate,inthetabspop-upmenuatthebottomofthewindow,select&quot;SoftTabs&quot;,asshowinthefollowingscreenshotwherethebluerectangleis:</code></p>
<p><code></code><a href="Image(TextMate-tabs-menu.png)" title="wikilink"><code>Image(TextMate-tabs-menu.png)</code></a><code></code></p>
<p><code>Alternatively,opentheBundleEditorandaddanewPreferencecalledIndentationtothebundleeditor.Giveitthefollowingcontents:</code></p>
<p></p>
<h1 id="coercions-in-ghcs-core-language">Coercions in GHC's core language</h1>
<p>Ever since coercions were introduced into GHC's Core language I have treated</p>
<p><code>*Coercionsliketypes</code><br />
<code>*Coercionvariablesliketypevariables</code></p>
<p>In particular, casts, coercion applications, and coercion abstractoins are all erased before we generate code.</p>
<p>I now think that this is the wrong approach. This note describes why.</p>
<h2 id="difficulties-with-the-current-approach">Difficulties with the current approach</h2>
<p>Ther are two problems with the current approach</p>
<p><code>*Equalityevidencevariables(&quot;typevariables&quot;)aretreateddifferentlytodictionaryevidencevariables(&quot;termvaraibles&quot;).Thisleadstolotsoftiresomenon-uniformities.</code><br />
<code>*Inanabstraction`/\a\x:a.e`thetypevariable`a`canappearinthetypeofaterm-variablebinder`x`.Incontrast`x`can'tappearinthetypeofanotherbinder.Coercionbindersbehaveexactlyliketermbindersinthisway,andquiteunliketypebinders.</code><br />
<code>*Moreseriously,wedon'thaveadecentwaytohandlesuperclassequalities.</code></p>
<p>The last problem is the one that triggered this note, and needs a bit more explanation. Consider  The dictionary for C looks like this:  Now imagine typechecking a function like this  The Core program we generate looks something like this:  The `nd` binding extracts the `Num` superclass dictionary from the `C` dictionary; the case expression is called a <em>superclass selector</em>.</p>
<p>Now suppose that we needed to use the equality superclass rather than the `Num` superclass:  The obvious translation would look like this:  But Core doesn't (currently) have a let-binding form that binds a coercion variable, and whose right-hand side is a term (in this example, a case expression) rather than a literal coercion! So the current plan is to generate this instead:  This non-uniformity of equality and dictionary evidence is extremely awkward in the desugarer. Moreover, it means that we can't abstract the superclass selector; we'd really like to have:  And it interacts poorly with the class-op rules that GHC uses to simplify dictinary selectors. Imagine the call  ...unfinished...</p>
<h2 id="main-proposal">Main proposal</h2>
<p>Recall our basic types  Note that</p>
<p><code>*`Var`canbeatypevariable,coercionvariable,ortermvariable.Youcantellwhichwithadynamictest(e.g.`isId::Var-&gt;Bool`).</code></p>
<p><code>*`Lam`isusedfortypeabstractions,coercionabstractions,andvalueabstractions.The`Var`cantellyouwhich.</code></p>
<p><code>*Typeapplications(inaterm)looklike`(Appf(Typet))`.The`(Typet)`partmustliterallyappearthere,withnointerveningjunk.Thisisnotstaticallyenforced,butitturnsouttobemuchmoreconvenientthanhavingaconstructor`TyAppCoreExprType`.</code></p>
<p>OK now the new proposal is to <em>treat equality evidence just like any other sort of evidence</em>.</p>
<p><code>*Acoercionvariableistreatedliketerm-levelidentifier,notatype-levelidentifier.(Moreonwhatthatmeansbelow.)</code></p>
<p><code>*Acoercionisan`CoreExpr`,ofform`Coerciong`,whosetypeis`(s~t)`,ofform`PredTy(EqPredst)`.</code></p>
<p><code>*Unliketypeapplications,coercionapplicationsarenotrequiredtohavea`(Coerciong)`astheargument.Forexample,supposewehave</code></p>
<p></p>
<p><code>Thentheterm`(fx(id(x~Int)c))`wouldbefine.Noticethatthecoercionargumentisanappplicationoftheidentityfunction.(Yesit'sabitcontrived.)In`CoreExpr`formitwouldlooklike:</code></p>
<p></p>
<p><code>*Similarlyalet-bindingcanbindacoercion</code></p>
<p></p>
<p><code>*Coercionapplicationiscall-byvalue.Dittolet-bindings.Youmusthavetheevidencebeforecallingthefunction.</code><br />
<br />
<code>*Soitdoesn'tmakesensetohaverecursivecoercionbindings.</code></p>
<p><code>*Ifwesee`Let(NonRecc(Coerciong))e`wecansubstitute`(Coerciong)`foranyterm-leveloccurrencesof`c`intheterm`e`,and`g`for`c`inanyoccurrencesof`c`incoercionsinside`e`.(Thisseemsabitmessy.)</code></p>
<h1 id="parsing-of-command-line-arguments">Parsing of command line arguments</h1>
<p>GHC's many flavours of command line flags make the code interpreting them rather involved. The following provides a brief overview of the processing of these options. Since the addition of the interactive front-end to GHC, there are two kinds of flags: static and dynamic. Static flags can only be set once on the command line. They remain the same throughout the whole GHC session (so for example you cannot change them within GHCi using `:set` or with `OPTIONS_GHC` pragma in the source code). Dynamic flags are the opposite: they can be changed in GHCi sessions using `:set` command or `OPTIONS_GHC` pragma in the source code. There are few static flags and it is likely that in the future there will be even less. Thus, you won't see many static flag references in the source code, but you will see a lot of functions that use dynamic flags.</p>
<p>Command line flags are described by Flag data type defined in <a href="GhcFile(compiler/main/CmdLineParser.hs)" class="uri" title="wikilink">GhcFile(compiler/main/CmdLineParser.hs)</a>:</p>
<p></p>
<p>This file contains functions that actually parse the command line parameters.</p>
<h2 id="static-flags">Static flags</h2>
<p>Static flags are managed by functions in <a href="GhcFile(compiler/main/StaticFlags.hs)" class="uri" title="wikilink">GhcFile(compiler/main/StaticFlags.hs)</a>.</p>
<p>Function `parseStaticFlags ::` is an entry point for parsing static flags. It is called by the `main :: IO ()` function of GHC in <a href="GhcFile(ghc/Main.hs)" class="uri" title="wikilink">GhcFile(ghc/Main.hs)</a>. Two global IORefs are used to parse static flags: `v_opt_C_ready` and `v_opt_C`. These are defined using `GLOBAL_VAR` macro from <a href="GhcFile(compiler/HsVersions.h)" class="uri" title="wikilink">GhcFile(compiler/HsVersions.h)</a>. First IORef is a flag that checks whether the static flags are parsed at the right time. Initialized to `False`, it is set to `True` after the parsing is done. `v_opt_C` is a `[String]` used to store parsed flags (see `addOpt` and `removeOpt` functions).</p>
<p>In <a href="GhcFile(compiler/main/StaticFlags.hs)" class="uri" title="wikilink">GhcFile(compiler/main/StaticFlags.hs)</a>, `flagsStatic :: [Flag IO]` defines a list of static flags and what actions should be taken when these flags are encountered (see `Flag` data type above). It also contains some helper functions to check whether particular flags have been set. Functions `staticFlags :: [String]` and `packed_staticFlags :: [FastString]` return a list of parsed command line static flags, provided that parsing has been done (checking the value of `v_opt_C_ready`).</p>
<h2 id="dynamic-flags">Dynamic flags</h2>
<p>They are managed by functions in <a href="GhcFile(compiler/main/DynFlags.hs)" class="uri" title="wikilink">GhcFile(compiler/main/DynFlags.hs)</a> file. Looking from the top you will find data types used to described enabled dynamic flags: `DumpFlag`, `GeneralFlag`, `WarningFlag`, `Language`, `SafeHaskellMode`, `ExtensionFlag` and finally `DynFlags`. Function `defaultDynFlags :: Settings -&gt; DynFlags` initializes some of the flags to default values. Available dynamic flags and their respective actions are defined by `dynamic_flags :: [Flag (CmdLineP DynFlags)]`. Also, `fWarningFlags :: [FlagSpec WarningFlag]`, `fFlags :: [FlagSpec GeneralFlag]`, `xFlags :: [FlagSpec ExtensionFlag]` and a few more smaller functions define even more flags needed for example for language extensions, warnings and other things. These flags are descibred by the data type `FlagSpec f`:</p>
<p> Flags described by `FlagSpec` can be reversed, e.g. flags that start with `-f` prefix are reversed by using `-fno-` prefix instead.</p>
<h1 id="the-ghc-commentary">The GHC Commentary</h1>
<p>This tree of wiki pages is a &quot;commentary&quot; on the GHC source code. It contains all the explanatory material that doesn't belong in comments in the source code itself, because the material is wide-ranging, usually covers multiple source files, and is more architectural in nature. The commentary can also be considered a design document for GHC.</p>
<p>For the beginners there is [wiki:Newcomers a short getting started guide].</p>
<p>For the dedicated, there are [wiki:AboutVideos videos of Simon and Simon giving an overview of GHC], at the 2006 [wiki:Hackathon GHC Hackathon].</p>
<p>Also check out the [wiki:ReadingList GHC Reading List], which gives lots of background reading that will help you understand the actual implementation. Here's <a href="http://www.stephendiehl.com/posts/essential_compilers.html">another reading list</a> from Stephen Diehl.</p>
<h2 id="editing-the-commentary">Editing the Commentary</h2>
<p>Please feel free to add material to the rest of the wiki: don't worry too much about accuracy (in due course someone will edit your contribution). When unsure though please indicate this and its best to ask on the GHC mailing list so you can correct the commentary. Please give some thought to where in the commentary your contribution belongs. GHC has an older commentary (non wiki based) that read like a single coherent narrative, made sure to define terms before using them, and introduced concepts in the order which made them easiest to understand. Please do try to preserve those properties in this wiki commentary. If you're unsure or in a hurry, consider creating a wiki page outside the commentary and linking to it from the commentary (or the &quot;contributed documentation&quot; section below).</p>
<p>Try to link to source files as much as possible by using this macro: . Also try to add appropriate links to other parts of the commentary.</p>
<h2 id="contents">Contents</h2>
<p><code>*[wiki:Commentary/GettingStartedGettingStarted]</code><br />
<code>*[wiki:Commentary/SourceTreeSourceTreeRoadmap]</code><br />
<code>*[wiki:Commentary/ModuleStructureModuleStructure]</code><br />
<code>*[wiki:Commentary/CodingStyleCodingStyle]</code><br />
<code>*[wiki:Commentary/AbbreviationsAbbreviationsinGHC]</code><br />
<code>*[wiki:Commentary/PlatformNamingPlatformsandtheirNamingConvention]</code></p>
<p><code>*[wiki:Commentary/CompilerTheCompiler]</code></p>
<p><code>*[wiki:Commentary/LibrariesTheLibrariesonwhichGHCdepends]</code><br />
<code>*[wiki:Commentary/Libraries/IntegerTheIntegerlibraries(`integer-gmp`and`integer-simple`)]</code></p>
<p><code>*[wiki:Commentary/RtsTheRuntimeSystem(RTS)]</code><br />
<code>*[wiki:Commentary/Rts/ConventionsRTSCodingConventions]</code><br />
<code>*[wiki:Commentary/Rts/HaskellExecutionTheHaskellExecutionModel]</code><br />
<code>*[wiki:Commentary/Rts/StorageThememorylayoutofheapandstackobjects]</code><br />
<br />
<code>*Cross-cuttingconcerns:topicswhichspanboththecompilerandtheruntimesystem</code><br />
<code>*[wiki:Commentary/ProfilingProfiling]</code><br />
<code>*[wiki:Commentary/Compiler/WiredInWired-inandknown-keythings]</code><br />
<code>*[wiki:Commentary/PrimOpsPrimitiveOperations(PrimOps)]</code><br />
<code>*[wiki:Commentary/PackagesThePackageSystem]</code><br />
<br />
<code>*[wiki:Commentary/UserManualTheUserManual](formattingguidelinesetc)</code></p>
<h2 id="contributed-documentation">Contributed Documentation</h2>
<p>The above commentary covers the source code of GHC. For material that doesn't concern this topic (such as proposals, work-in-progress and status reports) or that don't fit into the existing structure, you will find them below. Feel free to add new material here but please categorise it correctly.</p>
<p><code>*GeneralNotesontheGHCcompiler</code><br />
<code>*EdwardYang'sblogpostabout</code><a href="http://blog.ezyang.com/2011/04/tracing-the-compilation-of-hello-factorial/"><code>the</code> <code>entire</code> <code>complilation</code> <code>pipeline</code> <code>for</code> <code>`factorial`</code></a><br />
<code>*[wiki:AddingNewPrimitiveOperationsNewPrimOps]:HowtoaddnewprimitiveoperationstoGHCHaskell.</code><br />
<code>*[wiki:ReplacingGMPNotesReplacingGMP]:NotesfromanefforttoreplaceGMPwithanotherBignumlibrary.</code><br />
<code>*[wiki:ExternalCoreExternalCore]:DescribestheprocessofbringingExternalCoreuptospeed.Oncefinished,thiswillsimplydescribewhatExternalCoreis,andhowitworks.</code><br />
<code>*</code><a href="http://sourceforge.net/apps/mediawiki/developers/index.php?title=ScrapYourBoilerplate"><code>The</code> <code>Scrap</code> <code>your</code> <code>boilerplate</code> <code>homepage</code></a><code>.</code><br />
<code>*[wiki:Commentary/Compiler/OptOrderingOptimisationOrdering]Describetheorderingandinteractionofoptimisationpasses(Old).</code><br />
<code>*</code><a href="https://github.com/takenobu-hs/haskell-ghc-illustrated"><code>GHC</code> <code>Illustrated</code></a><code>(followthePDFlink),averyinsightfultutorialonGHC'sinternals.</code><br />
<code>*</code><a href="https://ocharles.org.uk/blog/pages/2014-12-01-24-days-of-ghc-extensions.html"><code>Ollie</code> <code>Charles's</code> <code>24</code> <code>days</code> <code>of</code> <code>GHC</code> <code>Extensions</code></a><code>,and</code><a href="http://augustss.blogspot.com/2014/12/a-commentary-on-24-days-of-ghc.html"><code>Lennart</code> <code>Augstsson's</code> <code>commentary</code></a><br />
<code>*</code><a href="https://ocharles.org.uk/blog/posts/2014-12-01-24-days-of-ghc-extensions.html"><code>Welcome</code></a><br />
<code>*</code><a href="https://ocharles.org.uk/blog/guest-posts/2014-12-23-static-pointers.html"><code>Static</code> <code>Pointers</code></a><br />
<code>*</code><a href="https://ocharles.org.uk/blog/guest-posts/2014-12-22-template-haskell.html"><code>Template</code> <code>Haskell</code></a><br />
<code>*</code><a href="https://ocharles.org.uk/blog/guest-posts/2014-12-21-arrows.html"><code>Arrows</code></a><br />
<code>*</code><a href="https://ocharles.org.uk/blog/guest-posts/2014-12-20-scoped-type-variables.html"><code>Scoped</code> <code>Type</code> <code>Variables</code></a><br />
<code>*</code><a href="https://ocharles.org.uk/blog/guest-posts/2014-12-19-existential-quantification.html"><code>Existential</code> <code>Quantification</code></a><br />
<code>*</code><a href="https://ocharles.org.uk/blog/guest-posts/2014-12-18-rank-n-types.html"><code>Rank</code> <code>N</code> <code>Types</code></a><br />
<code>*</code><a href="https://ocharles.org.uk/blog/posts/2014-12-17-overloaded-strings.html"><code>Overloaded</code> <code>Strings</code></a><br />
<code>*</code><a href="https://ocharles.org.uk/blog/posts/2014-12-16-derive-generic.html"><code>DeriveGeneric</code></a><br />
<code>*</code><a href="https://ocharles.org.uk/blog/guest-posts/2014-12-15-deriving.html"><code>Deriving</code></a><br />
<code>*</code><a href="https://ocharles.org.uk/blog/posts/2014-12-14-functional-dependencies.html"><code>Functional</code> <code>Dependencies</code></a><br />
<code>*</code><a href="https://ocharles.org.uk/blog/posts/2014-12-13-multi-param-type-classes.html"><code>Multi-parameter</code> <code>Type</code> <code>Classes</code></a><br />
<code>*</code><a href="https://ocharles.org.uk/blog/posts/2014-12-12-type-families.html"><code>Type</code> <code>Families</code></a><br />
<code>*</code><a href="https://ocharles.org.uk/blog/posts/2014-12-11-implicit-params.html"><code>Implicit</code> <code>Parameters</code></a><br />
<code>*</code><a href="https://ocharles.org.uk/blog/posts/2014-12-10-nullary-type-classes.html"><code>Nullary</code> <code>Type</code> <code>Classes</code></a><br />
<code>*</code><a href="https://ocharles.org.uk/blog/posts/2014-12-09-recursive-do.html"><code>Recursive</code> <code>Do</code></a><br />
<code>*</code><a href="https://ocharles.org.uk/blog/posts/2014-12-08-type-operators.html"><code>Type</code> <code>Operators</code></a><br />
<code>*</code><a href="https://ocharles.org.uk/blog/guest-posts/2014-12-07-list-comprehensions.html"><code>List</code> <code>Comprehensions</code></a><br />
<code>*</code><a href="https://ocharles.org.uk/blog/guest-posts/2014-12-06-rebindable-syntax.html"><code>Rebindable</code> <code>Syntax</code></a><br />
<code>*</code><a href="https://ocharles.org.uk/blog/posts/2014-12-05-bang-patterns.html"><code>Bang</code> <code>Patterns</code></a><br />
<code>*</code><a href="https://ocharles.org.uk/blog/posts/2014-12-04-record-wildcards.html"><code>Record</code> <code>Wildcards</code></a><br />
<code>*</code><a href="https://ocharles.org.uk/blog/posts/2014-12-03-pattern-synonyms.html"><code>Pattern</code> <code>Synonyms</code></a><br />
<code>*</code><a href="https://ocharles.org.uk/blog/posts/2014-12-02-view-patterns.html"><code>View</code> <code>Patterns</code></a><br />
<code>*</code><a href="https://ocharles.org.uk/blog/posts/2014-12-24-conclusion.html"><code>Thanks</code></a><br />
<code>*[wiki:Commentary/Rts/CompilerWays]:Compiler</code><em><code>ways</code></em><code>inGHC,what,how,andwhere</code></p>
<p><code>*NotesonimplementedGHCfeatures:</code><br />
<code>*</code><a href="https://www.fpcomplete.com/tutorial-preview/4431/z0KpB0ai2R"><code>Evaluation</code> <code>order</code> <code>and</code> <code>state</code> <code>tokens</code></a><code>:noteswrittenbyMichaelSnoyberginresponseto#9390.</code><br />
<code>*[wiki:FoldrBuildNotesNotesonfusion](egfoldr/build)</code><br />
<code>*[wiki:OverloadedListsOverloadedlistsyntax]allowsyoutouselistnotationforthingsotherthanlists.</code><br />
<code>*[wiki:GhcKindsKindpolymorphismanddatatypepromotion]</code><br />
<code>*[wiki:KindFactAkindforclassconstraints.ImplementedasConstraintKinds]</code><br />
<code>*[wiki:Commentary/Compiler/Backends/LLVMLLVMbackend]</code><br />
<code>*[wiki:Commentary/Compiler/GenericDerivingSupportforgenericprogramming]</code><br />
<code>*[wiki:TemplateHaskellNotesaboutTemplateHaskell]</code><br />
<code>*[wiki:RewriteRulesRewriteRules]:NotesabouttheimplementationofRULEsinGHC</code><br />
<code>*[wiki:MonadComprehensionsMonadComprehensions]:Translationrulesandsomeimplementationdetails</code><br />
<code>*[wiki:HaddockCommentsHaddock]:SomenotesabouthowtheHaddockcommentsupportisimplemented.</code><br />
<code>*[wiki:IntermediateTypesIntermediateTypes]:NotesaboutthetypesystemofGHC'snewintermediatelanguage(intheHEADsinceICFP'06)</code><br />
<code>*[wiki:TypeFunctionsTypefamilies/typefunctions]:Notesconcerningtheimplementationoftypefamilies,associatedtypes,andequalityconstraintsaswellastheextensionofthetypecheckerwithacontraintsolverforequalityconstraints.</code><br />
<code>*[wiki:Commentary/Compiler/SeqMagicMagictodowith`seq`andfriends]</code><br />
<code>*[wiki:NewPluginsCompilerplug-ins]</code><br />
<code>*[wiki:MemcpyOptimizationsmemcpy/memmove/memsetoptimizations]</code><br />
<code>*[wiki:BackEndNotesBackendIdeas]:Someideasandnotesaboutthebackend.</code><br />
<code>*[wiki:Commentary/Compiler/NewCodeGenNotesaboutthenewcodegenerator]</code><br />
<code>*[wiki:Commentary/Compiler/HooplPerformanceArecordofimprovementsmadetotheperformanceoftheHoopllibraryfordataflowoptimisation]</code><br />
<code>*[wiki:DataParallelDPH]:NotesabouttheimplementationofDataParallelHaskell</code><br />
<code>*[wiki:SafeHaskellSafeHaskell]:ThedesignoftheGHCSafeHaskellextension</code><br />
<code>*[wiki:SQLLikeComprehensionsSQL-LikeComprehensions]:NotesonSPJs&quot;ComprehensiveComprehensions&quot;(!TransformComprehensions)</code><br />
<code>*[wiki:DeferErrorsToRuntimeDeferringcompilationtypeerrorstoruntime(`-fdefer-type-errors`)]</code><br />
<code>*[wiki:Commentary/Compiler/DemandDemandanalyser]Notesonthemeanings,worker-wrappersplittingofdemandsignaturesandrelevantcomponentsofthecompiler</code><br />
<code>*[wiki:NewAxiomsClosedtypefamilies]</code><br />
<code>*[wiki:OneShot]Themagic`oneShot`function.</code><br />
<code>*[wiki:Commentary/Compiler/DeriveFunctorDerivingFunctor,Foldable,andTraversable]</code></p>
<p><code>*Notesonproposedorinprogress(butoutoftree)GHCcompilerfeatures:</code><br />
<code>*[wiki:LanguageStrictMakingHaskellstrict]</code><br />
<code>*[wiki:PatternMatchCheckImprovingpattern-matchoverlapandexhaustivenesschecks]</code><br />
<code>*[wiki:GhcAstAnnotationsSource-locationsonHsSyn]</code><br />
<code>*[wiki:CabalDependencyHowGHCinter-operateswithCabal]and[wiki:Backpack]</code><br />
<code>*[wiki:StaticValues]andticket#7015</code><br />
<code>*[wiki:PartialTypeSignaturesPartialtypesignatures]anditsticket#9478</code><br />
<code>*[wiki:LateLamLiftLatelambda-lifting],anditsticket#9476</code><br />
<code>*[wiki:RolesRolesinHaskell]</code><br />
<code>*[wiki:DependentHaskellDependenttypesinHaskell]</code><br />
<code>*[wiki:NestedCPRNestedCPRanalysis]</code><br />
<code>*[wiki:TemplateHaskell/AnnotationsGivingTemplateHaskellfullaccesstoannotations]</code><br />
<code>*[wiki:FunDepsCheckingconsistencyoffunctionaldependencies]</code><br />
<code>*[wiki:Commentary/GSoCMultipleInstancesAllowingmultipleinstancesofthesamepackagetobeinstalled],eachinstancehavingdifferentdependencies</code><br />
<code>*[wiki:Commentary/ContractsContractsinHaskell]</code><br />
<code>*[wiki:HolesAgda-styleholesinterms]whichsupportswritingpartialprograms.</code><br />
<code>*[wiki:RecordsRecords]</code><br />
<code>*</code><a href="http://haskell.org/haskellwiki/GHC/CouldAndHPCHaskell"><code>Cloud</code> <code>Haskell</code></a><br />
<code>*[wiki:PackageLanguageAmodularpackagelanguageforHaskell]ScottKilpatrickandDerekDreyeraredesigninganew</code></p>
<h1 id="compiler-and-runtime-system-ways-in-ghc">Compiler and runtime system ways in GHC</h1>
<p>GHC can compile programs in different <em>ways</em>. For instance, a program might be compiled with profiling enabled (`-prof`), or for multithreaded execution (`-threaded`), or maybe making some debugging tools available (`-debug`, see Debugging/RuntimeSystem for a description).</p>
<p>There are two types of GHC ways, RTS-only ways and full ways.</p>
<ul>
<li><strong>Runtime system (RTS) ways</strong> affect the way that the runtime system is built. As an example, `-threaded` is a runtime system way. When you compile a program with `-threaded`, it will be linked to a (precompiled) version of the RTS with multithreading enabled.</li>
</ul>
<p>Obviously, the compiler's RTS must have been built for this way (the threaded RTS is activated by default BTW). In customised builds, an RTS way can be added in the build configuration `mk/build.mk` (see <a href="GhcFile(mk/build.mk.sample)" class="uri" title="wikilink">GhcFile(mk/build.mk.sample)</a>), by adding its <em>short name</em> to the variable `GhcRTSWays`.</p>
<ul>
<li><strong>Full ways</strong></li>
</ul>
<p>Full compiler ways are ways which affect both the generated code and the runtime system that runs it.</p>
<p>The profiling way `-prof` is such a way. The machine code of a program compiled for profiling differs from a normal version's code by all code that gathers the profiling information, and the runtime system has additional functionality to access and report this information. Therefore, all libraries used in a profiling-enabled program need to also have profiling enabled, i.e. a separate library version for profiling needs to be installed to compile the program with `prof`. (If the library was installed without this profiling version, the program cannot be linked).</p>
<p>In customised builds, a full way is added in the build configuration `mk/build.mk` by adding its tag to the variable `GhcLibWays`.</p>
<h2 id="available-ways-in-a-standard-ghc">Available ways in a standard GHC</h2>
<p>Ways are identified internally by a way name, and enabled by specific compilation flags. In addition, there are short names (tags) for the available ways, mainly used by the build system.</p>
<p>Here is a table of available ways in a standard GHC, as of May 2015.</p>
<p>||=Way flag =||= Way name =||= Tag =||= Type =||= Description =|| ||= - =|| - || `v` || Full || (vanilla way) default || ||=`-threaded` =|| WayThreaded || `thr` || RTS || multithreaded runtime system || ||=`-debug` =|| WayDebug || `debug` || RTS || debugging, enables trace messages and extra checks || ||=`-prof` =|| WayProf || `p` || Full || profiling, enables cost centre stacks and profiling reports || ||=`-eventlog` =|| WayEventLog || `l` || RTS || Event logging (for ghc-events, threadscope, and EdenTV) || ||=`-dyn` =|| WayDyn || `dyn` || Full || Dynamic linking ||</p>
<p>The standard (<em>vanilla</em>) way of GHC has a name (<em>vanilla</em>), but it could (probably?) even be switched off in a custom build if desired. Obviously, the libraries would still need to be built in the vanilla way for all RTS-only ways, so one would need `GhcLibWays=v` when building any other RTS-only way.</p>
<p>The code (see below) contains another way, for Glasgow parallel Haskell, which is currently unmaintained (`WayPar`).</p>
<h3 id="ways-for-parallel-execution-on-clusters-and-multicores">Ways for parallel execution on clusters and multicores</h3>
<p>The parallel Haskell runtime system for Eden (available from <a href="http://github.com/jberthold/ghc" class="uri">http://github.com/jberthold/ghc</a>) defines several RTS-only ways for Eden. All these ways execute the RTS in multiple instances with distributed heaps, they differ in the communication substrate (and consequently in the platform).</p>
<p>||=Way flag =||= Way name =||= Tag =||= Type =||= communication (OS) =|| ||=`-parpvm` =|| WayParPvm ||`pp`|| RTS || PVM (Linux) || ||=`-parmpi` =|| WayParMPI ||`pm`|| RTS || MPI (Linux) || ||=`-parcp` =|| WayParCp ||`pc`|| RTS || OS-native shared memory (Windows/Linux) || ||=`-parms` =|| WayParMSlot ||`ms`|| RTS || Windows mail slots (Windows) ||</p>
<h2 id="combining-ways">Combining ways</h2>
<p>The alert reader might have noticed that combinations like &quot;threaded with dynamic linking&quot; or &quot;profiled with eventlog&quot; are not covered in the table. Some ways can be used together (most prominently, debugging can be used together with any other way), others are mutually excluding each other (like profiling with eventlog).</p>
<p>The allowed combinations are defined inside the compiler, in <a href="GhcFile(compiler/main/DynFlags.hs)" class="uri" title="wikilink">GhcFile(compiler/main/DynFlags.hs)</a>. Which brings us to discussing some of the internals.</p>
<h1 id="internals">Internals</h1>
<p>Ways are defined in <a href="GhcFile(compiler/main/DynFlags.hs)" class="uri" title="wikilink">GhcFile(compiler/main/DynFlags.hs)</a> as a Haskell data structure `Way`.</p>
<p>Function `dynamic_flags` defines the actual flag strings for the ghc invocation (like `-prof`, `-threaded`), which activate the respective `Way`.</p>
<p>The short name tags for ways are defined in `wayTag`. The tags are used in the suffixes of *.o and *.a files for RTS and libraries, for instance `*.p_o` for profiling, `*.l_o` for eventlog.</p>
<p>A number of other functions in there customise behaviour depending on the ways. Note `wayOptc` which sets some options for the C compiler, like `-DTRACING` for the `-eventlog` way.</p>
<p>However, this is not the full truth. For instance, there is no `-DDEBUG` for the debug way here, but the RTS is full of `#ifdef DEBUG`.</p>
<p>In <a href="GhcFile(mk/ways.mk)" class="uri" title="wikilink">GhcFile(mk/ways.mk)</a>, we find all the short names and all combinations enumerated, and some more options are defined here (`WAY_*_HC_OPTS`). These definitions are for the driver script, and pass on the right (long-name) options to the Haskell compiler to activate what is inside DynFlags (like -prof for WAY_p_HC_OPTS). Here we find ```WAY_debug_HC_OPTS= -static -optc-DDEBUG -ticky -DTICKY_TICKY``` so we can learn that ticky profiling is activated by compiling with `debug`.</p>
<p>(TODO be more precise on where the options from ways.mk are used.)</p>
<h1 id="ghc-commentary-the-compiler">GHC Commentary: The Compiler</h1>
<p>The compiler itself is written entirely in Haskell, and lives in the many sub-directories of the <a href="GhcFile(compiler)" class="uri" title="wikilink">GhcFile(compiler)</a> directory.</p>
<p><code>*[wiki:ModuleDependenciesCompilerModuleDependencies](dealswiththearcanemutualrecursionsamongGHC'smanydatatypes)</code><br />
<code>*[wiki:Commentary/CodingStyleCodingguidelines]</code></p>
<p><code>*[wiki:Commentary/Compiler/CommandLineArgsCommandlinearguments]</code><br />
<code>*[wiki:Commentary/PipelineThecompilationpipeline]</code></p>
<p><code>*</code><strong><code>Compiling</code> <code>one</code> <code>module:</code> <code>!HscMain</code></strong><br />
<code>*[wiki:Commentary/Compiler/HscMainOverview]givesthebigpicture.</code><br />
<code>*Somedetailsofthe[wiki:Commentary/Compiler/Parserparser]</code><br />
<code>*Somedetailsofthe[wiki:Commentary/Compiler/Renamerrenamer]</code><br />
<code>*Somedetailsofthe[wiki:Commentary/Compiler/TypeCheckertypechecker]</code><br />
<code>*Somedetailsofthe[wiki:Commentary/Compiler/Core2CorePipelinesimplifier]</code><br />
<code>*Somedetailsofthe[wiki:Commentary/Compiler/CodeGencodegenerator]convertsSTGtoCmm</code><br />
<code>*[wiki:Commentary/Compiler/BackendsBackends]convertCmmtonativecode:</code><br />
<code>*[wiki:Commentary/Compiler/Backends/PprCCcodegenerator]</code><br />
<code>*[wiki:Commentary/Compiler/Backends/NCGNativecodegenerator]</code><br />
<code>*[wiki:Commentary/Compiler/Backends/LLVMLLVMbackend]</code><br />
<code>*[wiki:Commentary/Compiler/Backends/GHCiGHCibackend]</code><br />
<code>*Aguidetothe[wiki:Commentary/Compiler/GeneratedCodegeneratedassemblycode]</code></p>
<p><code>*[wiki:Commentary/Compiler/KeyDataTypesKeydatatypes]</code><br />
<code>*[wiki:Commentary/Compiler/HsSynTypeThesourcelanguage:HsSyn]</code><br />
<code>*[wiki:Commentary/Compiler/RdrNameTypeRdrNames,Modules,andOccNames]</code><br />
<code>*[wiki:Commentary/Compiler/ModuleTypesModIface,ModDetails,ModGuts]</code><br />
<code>*[wiki:Commentary/Compiler/NameTypeNames]</code><br />
<code>*[wiki:Commentary/Compiler/EntityTypesEntities]:variables,typeconstructors,dataconstructors,andclasses.</code><br />
<code>*Types:</code><br />
<code>*[wiki:Commentary/Compiler/TypeTypeTypes]</code><br />
<code>*[wiki:Commentary/Compiler/KindsKinds]</code><br />
<code>*[wiki:Commentary/Compiler/FCEqualitytypesandcoercions]</code><br />
<code>*[wiki:Commentary/Compiler/CoreSynTypeThecorelanguage]</code><br />
<code>*[wiki:Commentary/Compiler/StgSynTypeTheSTGlanguage]</code><br />
<code>*[wiki:Commentary/Compiler/CmmTypeTheCmmlanguage]</code><br />
<code>*[wiki:Commentary/Compiler/BackEndTypesBackendtypes]</code><br />
<br />
<code>*[wiki:Commentary/Compiler/DriverCompilingmorethanonemoduleatonce]</code><br />
<code>*[wiki:Commentary/Compiler/DataTypesHowdatatypedeclarationsarecompiled]</code><br />
<code>*[wiki:Commentary/Compiler/APITheGHCAPI]</code><br />
<code>*[wiki:Commentary/Compiler/SymbolNamesSymbolnamesandtheZ-encoding]</code><br />
<code>*[wiki:TemplateHaskell/ConversionsTemplateHaskell]</code><br />
<code>*[wiki:Commentary/Compiler/WiredInWired-inandknown-keythings]</code><br />
<code>*[wiki:Commentary/Compiler/PackagesPackages]</code><br />
<code>*[wiki:Commentary/Compiler/RecompilationAvoidanceRecompilationAvoidance]</code></p>
<p>Case studies:</p>
<p><code>*[wiki:Commentary/Compiler/CaseStudies/BoolImplementationofwired-inBooldatatype]</code></p>
<h2 id="overall-structure">Overall Structure</h2>
<p>Here is a block diagram of its top-level structure:</p>
<p><a href="Image(ghc-top.png)" class="uri" title="wikilink">Image(ghc-top.png)</a></p>
<p>The part called [wiki:Commentary/Compiler/HscMain HscMain] deals with compiling a single module. On top of this is built the <strong>compilation manager</strong> (in blue) that manages the compilation of multiple modules. It exports an interface called the <strong>GHC API</strong>. On top of this API are four small front ends:</p>
<p><code>*GHCi,theinteractiveenvironment,isimplementedin</code><a href="GhcFile(ghc/InteractiveUI.hs)" title="wikilink"><code>GhcFile(ghc/InteractiveUI.hs)</code></a><code>and</code><a href="GhcFile(compiler/main/InteractiveEval.hs)" title="wikilink"><code>GhcFile(compiler/main/InteractiveEval.hs)</code></a><code>.ItsitssquarelyontopoftheGHCAPI.</code><br />
<br />
<code>*</code><code>isalmostatrivialclientoftheGHCAPI,andisimplementedin</code><a href="GhcFile(compiler/main/GhcMake.hs)" title="wikilink"><code>GhcFile(compiler/main/GhcMake.hs)</code></a><code>.</code></p>
<p><code>*</code><code>,theMakefiledependencygenerator,isalsoaclientoftheGHCAPIandisimplementedin</code><a href="GhcFile(compiler/main/DriverMkDepend.hs)" title="wikilink"><code>GhcFile(compiler/main/DriverMkDepend.hs)</code></a><code>.</code></p>
<p><code>*The&quot;one-shot&quot;mode,whereGHCcompileseachfileonthecommandlineseparately(eg.</code><code>).ThismodebypassestheGHCAPI,andisimplemented</code><br />
<code>directlyontopof[wiki:Commentary/Compiler/HscMainHscMain],sinceitcompilesonlyonefileatatime.Infact,thisisallthat</code><br />
<code>GHCconsistedofpriortoversion5.00whenGHCiand`--make`wereintroduced.</code></p>
<p>GHC is packaged as a single binary in which all of these front-ends are present, selected by the command-line flags indicated above. There is a single command-line interface implemented in <a href="GhcFile(ghc/Main.hs)" class="uri" title="wikilink">GhcFile(ghc/Main.hs)</a>.</p>
<p>In addition, GHC is compiled, without its front ends, as a <em>library</em> which can be imported by any Haskell program; see [wiki:Commentary/Compiler/API the GHC API]. Package keys, installed package IDs, ABI hashes, package names and versions, Nix-style hashes, ... there's so many different identifiers, what do they all mean? I think the biggest source of confusion (for myself included) is keeping straight not only what these terms mean, but also what people want them to mean in the future, and what we //actually// care about. So I want to help clarify this a bit, by clearly separating the //problem you are trying to solve// from //how you are solving the problem//.</p>
<p>The content here overlaps with wiki:Commentary/Packages but is looking at the latest iteration of the multi-instances and Backpack work.</p>
<p>See also `Note [The identifier lexicon]` in `compiler/basicTypes/Module.hs`.</p>
<p>Some relevant tickets: #10622</p>
<h2 id="what-problems-do-we-need-to-solve">What problems do we need to solve?</h2>
<p>When we come up with identification schemes for packages, we are trying to solve a few problems:</p>
<p><code>[SYMBOL]::</code><br />
<code>Whatsymbolnamesshouldweputinthebinary?(e.g.,the&quot;foozm0zi1&quot;in&quot;foozm0zi1_A_DZCF_closure&quot;)</code><br />
<code>-Itmustbeuniqueenoughthatforalllibrarieswewould</code><br />
<code>liketobeabletolinktogether,thereshouldnotbe</code><br />
<code>conflicts.</code><br />
<code>-HOWEVER,itmustbestableenoughthatifwemakeaminor</code><br />
<code>sourcecodechange,wedon'thavetogratuitouslyrecompile</code><br />
<code>everydependency.</code></p>
<p><code>[ABI]::</code><br />
<code>WhencanIswapoutonecompiledpackagewithanotherWITHOUTrecompiling,i.e.whatistheABIofthepackage?EqualABIsimpliesequalsymbols,thoughnotviceversa.ABIisusuallycomputedaftercompilationiscomplete.</code><br />
<code>-ABIcanserveascorrectnesscondition:ifwelinkagainstaspecificABI,wecanbesurethatanythingwithanequivalentABIwon'tcauseourpackagetosegfault.</code><br />
<code>-ABIcanalsoserveasanindirection:welinkedagainstanABI,anythingthatiscompatiblecanbehotswappedinwithoutcompilation.Inpractice,thiscapabilityisrarelyusedbyusersbecauseit'squitehardtocompileapackagemultipletimeswiththesameABI,because(1)compilationisnondeterministic,and(2)evenifnotypeschange,achangeinimplementationcancauseadifferentexportedunfolding,whichisABIrelevant.</code></p>
<p><code>[SOURCE]::</code><br />
<code>Whatistheunitofdistribution?Inotherwords,whenamaintaineruploadsansdisttoHackage,howdoyouidentifythatsourcetarball?</code><br />
<code>-OnHackage,apackagenameplusversionuniquelyidentifiesan</code><br />
<code>sdist.Thisisenforcedbycommunitystandards;inalocal</code><br />
<code>developmentenvironment,thismaynotholdsincedevswilledit</code><br />
<code>codewithoutupdatingtheversionnumber.Callthis[WEAKSOURCE].</code><br />
<code>-Alternately,acryptographichashofthesourcecodeuniquely</code><br />
<code>identifiesthestreamofbytes.Thisisenforcedbymath.Callthis[STRONGSOURCE].</code></p>
<p><code>[LIBRARY]::</code><br />
<code>Whenyoubuildalibrary,yougetan`libfoo.so`file.WhatidentifiesanOSlevellibrary?</code></p>
<p><code>[NIX]::</code><br />
<code>WhatisthefullsetofsourcewhichIcanusetoreproduceablybuildabuildproduct?</code><br />
<code>-Intoday'sCabal,youcouldapproximatethisbytaking[WEAKSOURCE]ofapackage,aswellasallofitstransitivedependencies.Callthis[WEAKNIX].</code><br />
<code>-TheNixapproachistoensuredeterministicbuildsbytakingthehashofthesource[STRONGSOURCE]andalsorecursivelyincludingthe[NIX]ofeachdirectdependency.Callthis[STRONGNIX].</code><br />
<code>-Notethat[ABI]doesNOTimply[NIX];apackagemightbebinarycompatiblebutdosomethingdifferent,andinaNixmodeltheyshouldberecordeddifferently.</code></p>
<p><code>[TYPES]::</code><br />
<code>Whenaretwotypesthesame?Iftherearefromdifferingpackages,theyareobviouslydifferent;iftheyarefromthesamepackage,theymightstillbedifferentifthedependenciesweredifferentineachcase.</code><br />
<code>-Typesshowupinerrormessage,sothisisaUSERVISIBLE</code><br />
<code>notion.Manypeoplehave(cogently)arguedthatthisshould</code><br />
<code>beASSIMPLEaspossible,becausethere'snothingworse</code><br />
<code>thanbeingtoldthatData.ByteString.ByteStringisnot</code><br />
<code>equaltoData.ByteString.ByteString(becausetheywerefrom</code><br />
<code>differentpackages.)</code></p>
<h2 id="current-mechanisms">Current mechanisms</h2>
<p>Today, we have a lot of different MECHANISMS for identifying these:</p>
<p><code>PackageName::</code><br />
<code>Somethinglike&quot;lens&quot;</code></p>
<p><code>PackageVersion::</code><br />
<code>Somethinglike&quot;0.1.2&quot;</code></p>
<p><code>(Source)PackageID::</code><br />
<code>Packagenameplusversion.WithHackagetoday,thisidentifiesaunitofdistribution:givenapackageIDyoucandownloadasourcetarball[SOURCE]ofapackage(butnotbuildit).Pre-GHC7.10,thepackageIDwasusedforlibraryidentification,symbolsandtype-checking([LIBRARY],[SYMBOL]and[TYPES]),butthisisnolongerthecase.</code></p>
<p><code>InstalledPackageID::</code><br />
<code>Packagename,packageversion,andtheoutputofghc--abi-hash.Thisiscurrentlyusedtouniquelyidentifyabuiltpackage,althoughtechnicallyitonlyidentifies[ABI].</code></p>
<p><code>PackageKey(newin7.10)::</code><br />
<code>Hashofpackagename,packageversion,thepackagekeysofall</code><br />
<code>textualdependenciesthepackageincluded,andinBackpack</code><br />
<code>amappingfromholenametomodulebypackagekey.</code><br />
<code>InGHC7.10thisisusedforlibraryidentification,symbolsandtype-checking([LIBRARY],[SYMBOL]and[TYPES]).Becauseitincludespackagekeysoftextualdependencies,italsodistinguishesbetweendifferentdependencyresolutions,ala[WEAKNIX].</code></p>
<h2 id="new-concepts-for-backpack">New concepts for Backpack</h2>
<p>First, we have to take the concept of an InstalledPackageId and make it more precise, having it identity components rather than packages.</p>
<p><code>ComponentID::</code><br />
<code>Thepackagename,thepackageversion,thenameofthecomponent(blankinthecaseofthedefaultlibrarycomponent),andthehashofsourcecodesdisttarball,selectedCabalflags(notthecommandlineflags),GHCflags,hashesofdirectdependenciesofthecomponent(the`build-depends`ofthelibraryintheCabalfile).</code></p>
<p>Then in Backpack we have these concepts:</p>
<p><code>Indefinite/definiteunit::</code><br />
<code>Anindefiniteunitisasingleunitwhichhasn'tbeeninstantiated;adefiniteunitisonethathasaninstantiationofitsholes.Unitswithoutholesarebothdefiniteandindefinite(theycanbeusedforbothcontexts).</code></p>
<p><code>Indefiniteunitrecord(in&quot;logical&quot;indefiniteunitdatabase)::</code><br />
<code>Anindefiniteunitrecordisthemostgeneralresultoftype-checkingaunitwithoutanyofitsholesinstantiated.Itconsistsofthetypesofthemodulesintheunit(ModIfaces)aswellasthesourcecodeoftheunit(sothatitcanberecompiledintoadefiniteunit).Indefiniteunitrecordscanbeinstalledinthe&quot;indefiniteunitdatabase.&quot;</code></p>
<p><code>Definiteunitrecord(previouslyinstalledpackagerecord,inthedefiniteunitdatabase,previouslytheinstalledpackagedatabase)::</code><br />
<code>Adefiniteunitrecordisafully-instantiatedunitwithitsassociatedlibrary.Itconsistsofthetypesandobjectsofthecompiledunit;theyalsocontainmetadatafortheirassociatedpackage.Definiteunitrecordscanbeinstalledinthe&quot;definiteunitdatabase&quot;(previouslyknownasthe&quot;installedpackagedatabase.&quot;)</code></p>
<p>To handle these, we need some new identifiers:</p>
<p><code>UnitId(previouslynamedPackageKey)::</code><br />
<code>ForBackpackunits,theunitIDisthecomponentIDplusamappingfromholestomodules(unitkeyplusmodulename).Fornon-Backpackunits,theunitIDisequivalenttothecomponentsourcehash(theholemappingisempty).Theseservetheroleof[SYMBOL,LIBRARY,TYPES].(Partiallydefiniteunitkeyscanoccuron-the-flyduringtypechecking.)Whenalloftherequirementsarefilled(sothereisnooccurrenceofHOLE),theunitkeyservesastheprimarykeyfortheinstalledunitdatabase.(Wemightcallthisan&quot;installedunitID&quot;inthiscontext)TheunitID&quot;HOLE&quot;isadistinguishedunitID,whichisforthe&quot;holepackage&quot;,representingmoduleswhicharenotyetimplemented(thereisnotactuallyaunitnamedhole,it'sjustanotationalconvention).</code></p>
<p><code>Module::</code><br />
<code>AunitIDplusamodulename.</code></p>
<h2 id="features">Features</h2>
<p>There are a number of enhancements proposed for how Cabal handles packages, which have often been conflated together. I want to clearly separate them out here:</p>
<p><code>Non-destructiveinstalls::</code><br />
<code>IfIhavepackagefoo-0.2compiledagainstbar-0.1,andadifferentbuildcompiledagainstbar-0.2,Ishouldbeabletoputtheminthesameinstalledpackagedatabase.THISISHIGHPRIORITY.</code></p>
<p><code>Views::</code><br />
<code>IfIhavepackagefoocompiledagainstbar-0.1,andbazcompiledagainstbar-0.2,thesetwopackagesaren'tusabletogether(moduloprivatedependencies,seebelow).ViewsareaUIparadigmmakingiteasierforuserstoworkinauniversewherefooisavailable,orauniversewherebazisavailable,butnotbothsimultaneously.Cabalsandboxesareviewsbutwithoutasharedinstalledpackagedatabase.Thisislowerpriority,becauseifyouusecabal-installtogetacoherentdependencyset,you'llneverseebothfooandbazatthesametime;theprimarybenefitofthisistoassistwithdirectuseofGHC/GHCi,however,itisgenerallybelievedthatnon-destructiveinstallswillmakeitdifficulttouseGHC/GHCibyitself.</code></p>
<p><code>Privatedependencies::</code><br />
<code>IfIhaveapackagefoo-0.2whichdependsonalibrarybar-0.1,butnotinanyexternallyvisibleway,itshouldbeallowedforaclienttoseparatelyusebar-0.2.ThisisLOWpriority;amusingly,in7.10,thisisalreadysupportedbyGHC,butnotbyCabal.</code></p>
<p><code>Hotswappablelibraries::</code><br />
<code>IfIinstallalibraryandit'sassignedABIhash123abc,andthenIinstallanumberoflibrariesthatdependonit,hotswappablelibrarymeansthatIcanreplacethatinstalledlibrarywithanotherversionwiththesameABIhash,andeverythingwillkeepworking.ThisfeatureisaccidentallysupportedbyGHCtoday,butnooneusesit(becauseABIsarenotstableenough);wearewillingtobreakthismodeofusetosupportotherfeatures.</code></p>
<h2 id="constraints">Constraints</h2>
<p>For an implementer, it is best if each problem is solved separately. However, Simon has argued strongly it is best if we REDUCE the amount of package naming concepts. You can see this in pre-7.10 GHC, where the package ID (package name + version) was used fulfill many functions: linker symbols, type identity as well as being a unit of distribution.</p>
<p>So the way I want to go about arguing for the necessity of a given identifier is by showing that it is IMPOSSIBLE (by the intended functions) for a single identifier to serve both roles. Here are the main constraints:</p>
<p><code>-[SYMBOL]and[STRONGNIX]/[STRONGSOURCE]don'tplaynicelytogether.Ifyoumodifyyoursourcecode,a[STRONGNIX/SOURCE]identifiermustchange;ifthismeans[SYMBOL]changestoo,youwillhavetorecompileeverything.However,youcanworkaroundthisproblembyusingfakeidentifiersduringdevelopmenttoavoidrecompilation,recompilingwiththecorrectNIXidentifierwhenit'sfinallytimetoinstall.</code></p>
<p><code>-[SOURCE]and[TYPES]areincompatibleundernon-destructiveinstallsandprivatedependencies.Withprivatedependencies(whichGHCsupports!),Imaylinkagainstthemultipleinstancesofthesamesourcebutcompiledagainstdifferentdependencies;weMUSTNOTconsiderthesetypestobethesame.Note:GHCusedtousepackageIDforbothofthese;socoherencewasguaranteedbyrequiringdestructiveinstalls.</code></p>
<p><code>-[NIX]and[TYPES]areincompatibleunderBackpack.InBackpack,alibraryauthormaydistributeapackagewiththeexplicitintentthatitmaybeusedinthesameclientmultipletimeswithdifferentinstantiationsofitsholes;thesetypesmustbekeptdistinct.</code></p>
<h1 id="rts-configurations">RTS Configurations</h1>
<p>The RTS can be built in several different ways, corresponding to global CPP defines. The flavour of the RTS is chosen by GHC when compiling a Haskell program, in response to certain command-line options: , , etc.</p>
<p>The CPP symbols and their corresponding command-line flags are:</p>
<p><code>::</code><br />
<code>Enablesprofiling.</code><a href="br" title="wikilink"><code>br</code></a><br />
<code>GHCoption:</code><a href="br" title="wikilink"><code>br</code></a><br />
<code>RTSsuffix:</code></p>
<p><code>::</code><br />
<code>EnablesmultithreadingintheRTS,boundthreads,andSMPexecution.</code><a href="br" title="wikilink"><code>br</code></a><br />
<code>GHCoption:</code><a href="br" title="wikilink"><code>br</code></a><br />
<code>RTSsuffix:</code></p>
<p><code>::</code><br />
<code>Enablesextradebuggingcode,assertions,traces,andthe</code><code>options.</code><a href="br" title="wikilink"><code>br</code></a><br />
<code>GHCoption:</code><a href="br" title="wikilink"><code>br</code></a><br />
<code>RTSsuffix:</code></p>
<p><code>::</code><br />
<code>EnablesRTStracingandeventlogging,see</code><a href="GhcFile(rts/Trace.c)" title="wikilink"><code>GhcFile(rts/Trace.c)</code></a><code>.Impliedby`DEBUG`.</code><a href="br" title="wikilink"><code>br</code></a><br />
<code>GHCoption:</code><a href="br" title="wikilink"><code>br</code></a><br />
<code>RTSsuffix:</code></p>
<p>So for example,  is the version of the runtime compiled with  and , and will be linked in if you use the  and  options to GHC.</p>
<p>The ways that the RTS is built in are controlled by the  Makefile variable.</p>
<h2 id="combinations">Combinations</h2>
<p>All combinations are allowed. Only some are built by default though; see [source:mk/config.mk.in] to see how the `GhcRTSWays` variable is set.</p>
<h2 id="other-configuration-options">Other configuration options</h2>
<p><code>::</code><br />
<code>Disabledtheuseofhardwareregistersforthestackpointer(`Sp`),heappointer(`Hp`),etc.Thisis</code><br />
<code>enabledwhenbuilding&quot;unregisterised&quot;code,whichiscontrolledbythe`GhcUnregisterised`buildoption.</code><br />
<code>TypicallythisisnecessarywhenbuildingGHConaplatformforwhichthereisnonativecodegenerator</code><br />
<code>andLLVMdoesnothaveaGHCcallingconvention.</code></p>
<p><code>::</code><br />
<code>EnablestheuseoftheRTS&quot;mini-interpreter&quot;,whichsimulatestail-calls.Again,thisisenabledby</code><br />
<code>`GhcUnregisterised`inthebuildsystem.</code></p>
<p><code>::</code><br />
<code>Controlswhethertheinfotableisplaceddirectlybeforetheentrycodeforaclosureorreturncontinuation.</code><br />
<code>Thisisnormallyturnedoniftheplatformsupportsit,butisturnedoffby`GhcUnregisterised`.</code></p>
<h1 id="contracts-for-haskell">Contracts for Haskell</h1>
<h2 id="involved">Involved</h2>
<p><code>*SimonPeyton-Jones</code><br />
<code>*DimitriosVytiniotis</code><br />
<code>*KoenClaessen</code><br />
<code>*Charles-PierreAstolfi</code></p>
<h2 id="overview-1">Overview</h2>
<p>Contracts, just as types, give a specification of the arguments and return values of a function. For example we can give to head the following contract:</p>
<p></p>
<p>Where Ok means that the result of head is not an error/exception as long as the argument isn't.</p>
<p>Any Haskell boolean expression can be used in a contract, for example  is a contract that means that for every a which is an actual integer (not an error), then fac a &gt;= a</p>
<p>We can also use a higher-order contracts:  This contract means that if we apply map to a non-empty list with a function that takes a non-negative integer and returns an positive integer then map returns a list of values without errors.</p>
<p>For a formal introduction, one can read [1].</p>
<h2 id="the-plan">The plan</h2>
<p>Verifying that a function satisfies a given contract is obviously undecidable, but that does not mean that we can't prove anything interesting. Our plan is to translate Haskell programs to first-order logic (with equality) and then use Koen's automated theorem prover to check contract satisfaction. Given that first-order logic is only semi-decidable, the theorem prover can (and in fact does) hang when fed with contracts that are in contradiction with the function definition.</p>
<h2 id="current-status">Current status</h2>
<p>The current status is described in [3] and some code and examples can be found in [2]. Note that given it's just a prototype the input syntax is slightly different from Haskell. In the end, we should get a ghc extension for contracts.</p>
<h2 id="questions">Questions</h2>
<p><code>*Doweneedcfnesspredicateanymore?ItwasimportantinthePOPLpaperbutisstillrelevant?</code><br />
<code>*UNRshouldberenamedtoalessconfusingname.</code><br />
<code>*Hoarelogicvsliquidtypes</code><br />
<code>*Semantics&amp;domaintheorytoprovethecorrectnessofthetranslation</code><br />
<code>*Unfoldingforprovingcontractsonrecursivefunctions</code></p>
<h2 id="references">References</h2>
<p>[1] : <a href="http://research.microsoft.com/en-us/um/people/simonpj/papers/verify/index.htm" class="uri">http://research.microsoft.com/en-us/um/people/simonpj/papers/verify/index.htm</a> <a href="BR" class="uri" title="wikilink">BR</a> [2] : <a href="https://github.com/cpa/haskellcontracts" class="uri">https://github.com/cpa/haskellcontracts</a> and <a href="https://github.com/cpa/haskellcontracts-examples" class="uri">https://github.com/cpa/haskellcontracts-examples</a> <a href="BR" class="uri" title="wikilink">BR</a> [3] : <a href="https://github.com/cpa/haskellcontracts/blob/master/draft2.pdf" class="uri">https://github.com/cpa/haskellcontracts/blob/master/draft2.pdf</a></p>
<h1 id="the-ghc-commentary-coding-style-guidelines-for-rts-c-code">The GHC Commentary: Coding Style Guidelines for RTS C code</h1>
<h2 id="comments-1">Comments</h2>
<p>These coding style guidelines are mainly intended for use in  and . See [wiki:Commentary/CodingStyle Coding Style Guidelines] for code in .</p>
<p>These are just suggestions. They're not set in stone. Some of them are probably misguided. If you disagree with them, feel free to modify this document (and make your commit message reasonably informative) or mail someone (eg. <script type="text/javascript">
<!--
h='&#104;&#x61;&#x73;&#x6b;&#x65;&#108;&#108;&#46;&#x6f;&#114;&#x67;';a='&#64;';n='&#x67;&#108;&#x61;&#x73;&#x67;&#x6f;&#x77;&#x2d;&#104;&#x61;&#x73;&#x6b;&#x65;&#108;&#108;&#x2d;&#x75;&#x73;&#x65;&#114;&#x73;';e=n+a+h;
document.write('<a h'+'ref'+'="ma'+'ilto'+':'+e+'" clas'+'s="em' + 'ail">'+'&#84;&#104;&#x65;&#32;&#x47;&#72;&#x43;&#32;&#x6d;&#x61;&#x69;&#108;&#x69;&#110;&#x67;&#32;&#108;&#x69;&#x73;&#116;'+'<\/'+'a'+'>');
// -->
</script><noscript>&#84;&#104;&#x65;&#32;&#x47;&#72;&#x43;&#32;&#x6d;&#x61;&#x69;&#108;&#x69;&#110;&#x67;&#32;&#108;&#x69;&#x73;&#116;&#32;&#40;&#x67;&#108;&#x61;&#x73;&#x67;&#x6f;&#x77;&#x2d;&#104;&#x61;&#x73;&#x6b;&#x65;&#108;&#108;&#x2d;&#x75;&#x73;&#x65;&#114;&#x73;&#32;&#x61;&#116;&#32;&#104;&#x61;&#x73;&#x6b;&#x65;&#108;&#108;&#32;&#100;&#x6f;&#116;&#32;&#x6f;&#114;&#x67;&#x29;</noscript>)</p>
<h2 id="references-1">References</h2>
<p>If you haven't read them already, you might like to check the following. Where they conflict with our suggestions, they're probably right.</p>
<p><code>*TheC99standard.Onereasonablereferenceis</code><a href="http://home.tiscalinet.ch/t_wolf/tw/c/c9x_changes.html"><code>here</code></a><code>.</code></p>
<p><code>*WritingSolidCode,MicrosoftPress.(Highlyrecommended.)</code></p>
<p><code>*Autoconfdocumentation.Seealso</code><br />
<code></code><a href="http://peti.gmd.de/autoconf-archive/"><code>The</code> <code>autoconf</code> <code>macro</code> <code>archive</code></a><br />
<code>and</code><a href="http://www.cyclic.com/cyclic-pages/autoconf.html"><code>Cyclic</code> <code>Software's</code> <code>description</code></a><code>.</code></p>
<p><code>*</code><a href="http://www.cs.arizona.edu/~mccann/cstyle.html"><code>Indian</code> <code>Hill</code> <code>C</code> <code>Style</code> <code>and</code> <code>Coding</code> <code>Standards</code></a></p>
<p><code>*</code><a href="http://www.cs.umd.edu/users/cml/cstyle/"><code>A</code> <code>list</code> <code>of</code> <code>C</code> <code>programming</code> <code>style</code> <code>links</code></a></p>
<p><code>*</code><a href="http://www.lysator.liu.se/c/c-www.html"><code>A</code> <code>very</code> <code>large</code> <code>list</code> <code>of</code> <code>C</code> <code>programming</code> <code>links</code></a></p>
<h2 id="portability-issues">Portability issues</h2>
<h3 id="which-c-standard">Which C Standard?</h3>
<p>We try to stick to C99 where possible. We use the following C99 features relative to C89, some of which were previously GCC extensions (possibly with different syntax):</p>
<p><code>*Variablelengtharraysasthelastfieldofastruct.GCChas</code><br />
<code>asimilarextension,butthesyntaxisslightlydifferent:inGCCyou</code><br />
<code>woulddeclarethearrayas</code><code>,whereasinC99itis</code><br />
<code>declaredas</code><code>.</code></p>
<p><code>*Inlineannotationsonfunctions(seelater)</code></p>
<p><code>*Labeledelementsininitialisers.Again,GCChasaslightly</code><br />
<code>differentsyntaxfromC99here,andwestickwiththeGCCsyntax</code><br />
<code>untilGCCimplementstheC99proposal.</code></p>
<p><code>*C++-stylecomments.ThesearepartoftheC99standard,andwe</code><br />
<code>prefertousethemwheneverpossible.</code></p>
<p>In addition we use ANSI-C-style function declarations and prototypes exclusively. Every function should have a prototype; static function prototypes may be placed near the top of the file in which they are declared, and external prototypes are usually placed in a header file with the same basename as the source file (although there are exceptions to this rule, particularly when several source files together implement a subsystem which is described by a single external header file).</p>
<p><code>*WeusethefollowingGCCextensions,butsurroundthemwith</code><code>:</code><br />
<code>*Functionattributes(mostlyjust</code><code>and</code><code>)</code><br />
<code>*Inlineassembly.</code></p>
<h3 id="other-portability-conventions">Other portability conventions</h3>
<p><code>*charcanbesignedorunsigned-alwayssaywhichyoumean</code></p>
<p><code>*OurPOSIXpolicy:trytowritecodethatonlyusesPOSIX</code><br />
<code>(</code><a href="http://www.opengroup.org/onlinepubs/009695399/toc.htm"><code>IEEE</code> <code>Std</code> <code>1003.1</code></a><code>)</code><br />
<code>interfacesandAPIs.Weusedtodefine</code><code>by</code><br />
<code>default,butfoundthatthiscausedmoreproblemsthanitsolved,so</code><br />
<code>nowwerequireanycodethatisPOSIX-complianttoexplicitlysayso</code><br />
<code>byhaving</code><code>atthetop.Trytodothis</code><br />
<code>wheneverpossible.</code></p>
<p><code>*Somearchitectureshavememoryalignmentconstraints.Othersdon't</code><br />
<code>haveanyconstraintsbutgofasterifyoualignthings.These</code><br />
<code>macros(from</code><code>)tellyouwhichalignmenttouse</code></p>
<p></p>
<p><code>*Use</code><code>,</code><code>and</code><code>when</code><br />
<code>reading/writingintsandptrstothestackorheap.Notethat,by</code><br />
<code>definition,</code><code>,</code><code>and</code><code>arethe</code><br />
<code>samesizeandhavethesamealignmentconstraintsevenif</code><br />
<code></code><code>onthatplatform.</code></p>
<p><code>*Use</code><code>,</code><code>,etcwhenyouneedacertain</code><br />
<code>minimumnumberofbitsinatype.Use</code><code>and</code><code>when</code><br />
<code>there'snoparticularconstraint.ANSIConlyguaranteesthatints</code><br />
<code>areatleast16bitsbutwithinGHCweassumetheyare32bits.</code></p>
<p><code>*Use</code><code>and</code><code>forfloatingpointvalues</code><br />
<code>whichwillgoon/havecomefromthestackorheap.Notethat</code><br />
<code></code><code>mayoccupymorethanone</code><code>,butitwill</code><br />
<code>alwaysbeawholenumbermultiple.</code></p>
<p><code>*Use</code><code>,</code><code>toread</code><br />
<code>and</code><code>valuesfromthestack/heap,and</code><br />
<code></code><code>/</code><code>toassign</code><br />
<code>StgFloat/StgDoublevaluestoheap/stacklocations.Thesemacros</code><br />
<code>takecareofalignmentrestrictions.</code></p>
<p><code>*Heap/Stacklocationsarealways</code><code>aligned;the</code><br />
<code>alignmentrequirementsofan</code><code>maybemorethanthat</code><br />
<code>of</code><code>,butwedon'tpadmisaligned</code><br />
<code>becausedoingsowouldbetoomuchhassle(see</code><code>&amp;co</code><br />
<code>above).</code></p>
<p><code>*Avoidconditionalcodelikethis:</code></p>
<p></p>
<p><code>Instead,addanappropriatetesttotheconfigure.acscriptanduse</code><br />
<code>theresultofthattestinstead.</code></p>
<p></p>
<p><code>TheproblemisthatthingschangefromoneversionofanOSto</code><br />
<code>another-thingsgetadded,thingsgetdeleted,thingsgetbroken,</code><br />
<code>somethingsareoptionalextras.Using&quot;featuretests&quot;insteadof</code><br />
<code>&quot;systemtests&quot;makesthingsalotlessbrittle.Thingsalsotendto</code><br />
<code>getdocumentedbetter.</code></p>
<h2 id="debuggingrobustness-tricks">Debugging/robustness tricks</h2>
<p>Anyone who has tried to debug a garbage collector or code generator will tell you: &quot;If a program is going to crash, it should crash as soon, as noisily and as often as possible.&quot; There's nothing worse than trying to find a bug which only shows up when running GHC on itself and doesn't manifest itself until 10 seconds after the actual cause of the problem.</p>
<p>We put all our debugging code inside . The general policy is we don't ship code with debugging checks and assertions in it, but we do run with those checks in place when developing and testing. Anything inside  should not slow down the code by more than a factor of 2.</p>
<p>We also have more expensive &quot;sanity checking&quot; code for hardcore debugging - this can slow down the code by a large factor, but is only enabled on demand by a command-line flag. General sanity checking in the RTS is currently enabled with the  RTS flag.</p>
<p>There are a number of RTS flags which control debugging output and sanity checking in various parts of the system when  is defined. For example, to get the scheduler to be verbose about what it is doing, you would say . See  and  for the full set of debugging flags. To check one of these flags in the code, write:  would check the  flag before generating the output (and the code is removed altogether if  is not defined).</p>
<p>All debugging output should go to .</p>
<p>Particular guidelines for writing robust code:</p>
<p><code>*Useassertions.Uselotsofassertions.Ifyouwriteacomment</code><br />
<code>thatsays&quot;takesa+venumber&quot;addanassertion.Ifyou'recasting</code><br />
<code>aninttoanat,addanassertion.Ifyou'recastinganinttoa</code><br />
<code>char,addanassertion.Weusethe</code><code>macroforwriting</code><br />
<code>assertions;itgoesawaywhen</code><code>isnotdefined.</code></p>
<p><code>*Writespecialdebuggingcodetochecktheintegrityofyourdata</code><br />
<code>structures.(Mostoftheruntimecheckingcodeisin</code><br />
<code></code><code>)Addextraassertionswhichcallthiscodeat</code><br />
<code>thestartandendofanycodethatoperatesonyourdata</code><br />
<code>structures.</code></p>
<p><code>*Whenyoufindahard-to-spotbug,trytothinkofsomeassertions,</code><br />
<code>sanitychecksorwhateverthatwouldhavemadethebugeasierto</code><br />
<code>find.</code></p>
<p><code>*Whendefininganenumeration,it'sagoodideanottouse0for</code><br />
<code>normalvalues.Instead,make0raiseaninternalerror.Theidea</code><br />
<code>hereistomakeiteasiertodetectpointer-relatederrorsonthe</code><br />
<code>assumptionthatrandompointersaremorelikelytopointtoa0</code><br />
<code>thantoanythingelse.</code></p>
<p></p>
<p><code>*Use</code><code>or</code><code>wheneveryouwriteapieceof</code><br />
<code>incomplete/brokencode.</code></p>
<p><code>*Whentesting,trytomakeinfrequentthingshappenoften.For</code><br />
<code>example,makeacontextswitch/gc/etchappeneverytimeacontext</code><br />
<code>switch/gc/etccanhappen.Thesystemwillrunlikeapigbutit'll</code><br />
<code>catchalotofbugs.</code></p>
<h2 id="syntactic-details">Syntactic details</h2>
<p><code>*Pleasekeepto80columns:thelinehastobedrawnsomewhere,and</code><br />
<code>bykeepingitto80columnswecanensurethatcodelooksOKon</code><br />
<code>everyone'sscreen.Longlinesarehardtoread,andasignthat</code><br />
<code>thecodeneedstoberestructuredanyway.</code></p>
<p><code>*Anindentationwidthof4ispreferred(don'tuseactualtabcharacters,usespaces).</code></p>
<p><code>*</code><strong><code>Important:</code></strong><code>Put&quot;redundant&quot;bracesorparensinyourcode.</code><br />
<code>Omittingbracesandparensleadstoveryhardtospotbugs-</code><br />
<code>especiallyifyouusemacros(andyoumighthavenoticedthatGHC</code><br />
<code>doesthisalot!)</code></p>
<p><code>Inparticular,putbracesroundthebodyofforloops,whileloops,</code><br />
<code>ifstatements,etc.evenifthey&quot;aren'tneeded&quot;becauseit's</code><br />
<code>reallyhardtofindtheresultingbugifyoumessup.Indentthem</code><br />
<code>anywayyoulikebutputtheminthere!</code></p>
<p><code>*Whendefiningamacro,alwaysputparensroundargs-justincase.</code><br />
<code>Forexample,write:</code></p>
<p></p>
<p><code>insteadof</code></p>
<p></p>
<p><code>*Don'tdeclareandinitializevariablesatthesametime.</code><br />
<code>Separatingthedeclarationandinitializationtakesmorelines,but</code><br />
<code>makethecodeclearer.</code></p>
<p><code>*Don'tdefinemacrosthatexpandtoalistofstatements.Youcould</code><br />
<code>justusebracesasin:</code></p>
<p></p>
<p><code>(butit'susuallybettertouseaninlinefunctioninstead-seeabove).</code></p>
<p><code>*Don'tevenwritemacrosthatexpandto0statements-theycanmess</code><br />
<code>youupaswell.Usethe</code><code>macroinstead.</code></p>
<p></p>
<p><code>*Thiscode</code></p>
<p></p>
<p><code>lookslikeitdeclarestwopointersbut,infact,onlypisapointer.</code><br />
<code>It'ssafertowritethis:</code></p>
<p></p>
<p><code>Youcouldalsowritethis:</code></p>
<p></p>
<p><code>butitispreferrabletosplitthedeclarations.</code></p>
<p><code>*TrytouseANSIC'senumfeaturewhendefininglistsofconstants</code><br />
<code>ofthesametype.Amongotherbenefits,you'llnoticethatgdb</code><br />
<code>usesthenameinsteadofits(usuallyinscrutable)numberwhen</code><br />
<code>printingvalueswithenumtypesandgdbwillletyouusethename</code><br />
<code>inexpressionsyoutype.</code></p>
<p><code>Examples:</code></p>
<p></p>
<p><code>insteadof</code></p>
<p></p>
<p><code>and</code></p>
<p></p>
<p><code>insteadof</code></p>
<p></p>
<p><code>*Whencommentingoutlargechunksofcode,use</code><code></code><br />
<code>ratherthan</code><code>becauseCdoesn'thave</code><br />
<code>nestedcomments.</code></p>
<p><code>*Whendeclaringatypedefforastruct,givethestructanameas</code><br />
<code>well,sothatotherheaderscanforward-referencethestructname</code><br />
<code>anditbecomespossibletohaveopaquepointerstothestruct.Our</code><br />
<code>conventionistonamethestructthesameasthetypedef,butadda</code><br />
<code>leadingunderscore.Forexample:</code></p>
<p></p>
<p><code>*Donotuse</code><code>insteadofexplicitcomparisonagainst</code><br />
<code>or</code><code>;thelatterismuchclearer.</code></p>
<p><code>*PleasewritecommentsinEnglish.EspeciallyavoidKlingon.</code></p>
<h2 id="inline-functions">Inline functions</h2>
<p>Use inline functions instead of macros if possible - they're a lot less tricky to get right and don't suffer from the usual problems of side effects, evaluation order, multiple evaluation, etc.</p>
<p><code>*Inlinefunctionsgetthenamingissueright.E.g.they</code><br />
<code>canhavelocalvariableswhich(inanexpressioncontext)</code><br />
<code>macroscan't.</code></p>
<p><code>*Inlinefunctionshavecall-by-valuesemanticswhereasmacrosare</code><br />
<code>call-by-name.Youcanbebittenbyduplicatedcomputationifyou</code><br />
<code>aren'tcareful.</code></p>
<p><code>*Youcanuseinlinefunctionsfrominsidegdbifyoucompilewith</code><br />
<code>-O0or-fkeep-inline-functions.Ifyouusemacros,you'dbetterknow</code><br />
<code>whattheyexpandto.</code></p>
<p><code>However,notethatmacroscanserveasbothl-valuesandr-valuesand</code><br />
<code>canbe&quot;polymorphic&quot;astheseexamplesshow:</code></p>
<p></p>
<p>There are three macros to do inline portably. Don't use `inline` directly, use these instead:</p>
<p>`INLINE_HEADER`</p>
<p><code>Aninlinefunctioninaheaderfile.Thisisjustlikeamacro.Weneveremit</code><br />
<code>astandalonecopyofthefunction,soit</code><em><code>must</code></em><code>beinlinedeverywhere.</code></p>
<p>`STATIC_INLINE`</p>
<p><code>AninlinefunctioninaCsourcefile.Again,itisalwaysinlined,andwenever</code><br />
<code>emitastandalonecopy.</code></p>
<p>`EXTERN_INLINE`</p>
<p><code>Afunctionwhichisoptionallyinlined.TheCcompileristoldtoinlineifpossible,</code><br />
<code>butwealsogeneratedastandalonecopyofthefunctionjustincase(seesource:rts/Inlines.c).</code></p>
<h2 id="source-control-issues">Source-control issues</h2>
<p><code>*Don'tbetemptedtore-indentorre-organiselargechunksofcode-</code><br />
<code>itgenerateslargediffsinwhichit'shardtoseewhetheranything</code><br />
<code>elsewaschanged,andcausesextraconflictswhenmovingpatchesto</code><br />
<code>anotherbranch.</code><br />
<code></code><a href="BR" title="wikilink"><code>BR</code></a><a href="BR" title="wikilink"><code>BR</code></a><br />
<code>Ifyoumustre-indentorre-organise,don'tincludeanyfunctional</code><br />
<code>changesthatcommitandgiveadvancewarningthatyou'reabouttodo</code><br />
<code>itincaseanyoneelseischangingthatfile.Formoredetailson</code><br />
<code>sourcecontrolconventions,see[wiki:WorkingConventions/Git].</code></p>
<p>for file in *; do</p>
<p><code>iconv-fascii-tutf-8&quot;$file&quot;-o&quot;${file%.txt}.wiki&quot;</code></p>
<p>done</p>
<h1 id="copying-gc">Copying GC</h1>
<p>GHC uses copying GC by default, while it requires more memory than [wiki:Commentary/Rts/Storage/GC/Compaction mark/compact], it is faster.</p>
<p>The basic copying scheme is <a href="http://en.wikipedia.org/wiki/Cheney%27s_algorithm">Cheney's Algorithm</a>. Starting from the [wiki:Commentary/Rts/Storage/GC/Roots roots], we visit each live object:</p>
<p><code>*Theobjectis</code><em><code>evacuated</code></em><code>(copied)toitsdestinationgeneration.Thedestinationisgivenby`bd-&gt;dest`pointerinthe`bdescr`ofthe</code><br />
<code>blockinwhichitlives;typicallyanobjectispromotedtothenexthighestgeneration,butthebasicpolicyisaffectedby[wiki:Commentary/Rts/Storage/GC/Agingaging]and[wiki:Commentary/Rts/Storage/GC/EagerPromotioneagerpromotion].</code></p>
<p><code>*Theheaderwordoftheoriginalobjectisreplacedbya</code><em><code>forwarding</code> <code>pointer</code></em><code>.Theforwardingpointerisjustthepointertothenewcopy,withtheleastsignificantbitsetto1sothatforwardingpointerscanbedistinguishedfrominfotablepointers.</code></p>
<p><code>*Wescanobjectsthathavebeenevacuated,and</code><em><code>scavenge</code></em><code>eachone.Scavenginginvolvesevacuatingeachofthepointers</code><br />
<code>intheobject,replacingeachpointerwithapointertotheevacuatedcopy.</code></p>
<p><code>*Whentherearenomoreobjectstobescavenged,thealgorithmiscomplete.Thememorycontainingtheevacuatedobjectsisretained,allthememorycontainingtheoldobjectsandforwardingpointersisdiscarded.</code></p>
<p>Evacuation is implemented in the file <a href="GhcFile(rts/sm/Evac.c)" class="uri" title="wikilink">GhcFile(rts/sm/Evac.c)</a>.<a href="br" class="uri" title="wikilink">br</a> Scavenging is implemented in the file <a href="GhcFile(rts/sm/Scav.c)" class="uri" title="wikilink">GhcFile(rts/sm/Scav.c)</a>.<a href="br" class="uri" title="wikilink">br</a></p>
<p>The principle APIs are</p>
<p><code>`voidevacuate(StgClosure**p)`::</code><br />
<code>whichevacuatestheobjectpointedtobythepointerat`p`,andupdates`p`topointtothenewlocation.</code></p>
<p><code>`voidscavenge_block(bdescr*bd)`::</code><br />
<code>whichscavengesalltheobjectsintheblock`bd`(objectsbetween`bd-&gt;u.scan`and`bd-&gt;free`areassumedto</code><br />
<code>beunscavengedsofar).</code></p>
<p>= Core-to-Core optimization pipeline</p>
<p>After the source program has been [wiki:Commentary/Compiler/TypeChecker typechecked] it is desugared into GHC's intermediate language [wiki:Commentary/Compiler/CoreSynType Core]. The Core representation of a program is then optimized by a series of correctness preserving Core-to-Core passes. This page describes the overall structure of the Core-to-Core optimization pipeline. Detailed descriptions of optimizations are available [wiki:Commentary/Compiler/Core2CorePipeline#Furtherreading in the published papers]. An overview of the whole compiler pipeline is available [wiki:Commentary/Compiler/HscMain here].</p>
<p>== Optimizations during desugaring</p>
<p>At the end of desugaring we run the `simpleOptPgm` function that performs some simple optimizations: eliminating dead bindings, and inlining non-recursive bindings that are used only once or where the RHS is trivial. The rest of Core optimisations is performed by the Core-to-Core pipeline.</p>
<p>== The pipeline</p>
<p>The structure of the Core-to-Core pipeline is determined in the `getCoreToDo` function in the <a href="GhcFile(compiler/simplCore/SimplCore.lhs)" class="uri" title="wikilink">GhcFile(compiler/simplCore/SimplCore.lhs)</a> module. Below is an ordered list of performed optimisations. These are enabled by default with `-O1` and `-O2` unless the description says a specific flag is required. The simplifier, which the pipeline description below often refers to, is described in detail in [wiki:Commentary/Compiler/Core2CorePipeline#Simplifier the next section].</p>
<p><code>*</code><strong><code>Static</code> <code>Argument</code> <code>Transformation</code></strong><code>:triestoremoveredundantargumentstorecursivecalls,turningthemintofreevariablesinthosecalls.Onlyenabledwith`-fstatic-argument-transformation`.Ifrunthispassisprecededwitha&quot;gentle&quot;runofthesimplifier.</code></p>
<p><code>*</code><strong><code>Vectorisation</code></strong><code>:runthe[wiki:DataParallelDataParallelHaskell][wiki:DataParallel/Vectorisationvectoriser].Onlyenabledwith`-fvectorise`.TODO:does`-Odph`imply`fvectorise`?</code></p>
<p><code>*</code><strong><code>Simplifier,</code> <code>gentle</code> <code>run</code></strong></p>
<p><code>*</code><strong><code>Specialisation</code></strong><code>:specialisationattemptstoeliminateoverloading.Moredetailscanbefoundinthecommentsin</code><a href="GhcFile(compiler/specialise/Specialise.lhs)" title="wikilink"><code>GhcFile(compiler/specialise/Specialise.lhs)</code></a><code>.</code></p>
<p><code>*</code><strong><code>Full</code> <code>laziness,</code> <code>1st</code> <code>pass</code></strong><code>:floatslet-bindingsoutsideoflambdas.Thispassincludesannotatingbindingswithlevelinformationandthenrunningthefloat-outpass.Inthisfirstpassofthefulllazinesswedon'tfloatpartialapplicationsandbindingsthatcontainfreevariables-thiswillbedonebythesecondpasslaterinthepipeline.See&quot;FurtherReading&quot;sectionbelowforpointerswheretofindthedescriptionofthefulllazinessalgorithm.</code></p>
<p><code>*</code><strong><code>Float</code> <code>in,</code> <code>1st</code> <code>pass</code></strong><code>:theoppositeoffulllaziness,thispassfloatslet-bindingsasclosetotheirusesitesaspossible.Itwillnotundothefulllazinessbysinkingbindingsinsidealambda,unlessthelambdaisone-shot.Atthisstagewehavenotyetrunthedemandanalysis,soweonlyhavedemandinformationforthingsthatweimported.</code></p>
<p><code>*</code><strong><code>Simplifier,</code> <code>main</code> <code>run</code></strong><code>:runthemainpassesofthesimplifier(phases2,1and0).Phase0isrunwithatleast3iterations.</code></p>
<p><code>*</code><strong><code>Call</code> <code>arity</code></strong><code>:attemptstoeta-expandlocalfunctionsbasedonhowtheyareused.Ifrun,thispassisfollowedbya0phaseofthesimplifier.SeeNotesin</code><a href="GhcFile(compiler/simplCore/CallArity.hs)" title="wikilink"><code>GhcFile(compiler/simplCore/CallArity.hs)</code></a><code>andtherelevantpaper.</code></p>
<p><code>*</code><strong><code>Demand</code> <code>analysis,</code> <code>1st</code> <code>pass</code></strong><code>(a.k.a.strictnessanalysis):runsthedemandanalyserfollowedbyworker-wrappertransformationand0phaseofthesimplifier.Thispasstriestodetermineifsomeexpressionsarecertaintobeusedandwhethertheywillbeusedonceormanytimes(cardinalityanalysis).Wecurrentlydon'thavemeansofsayingthatabindingiscertaintobeusedmanytimes.Wecanonlydeterminethatitiscertaintobeone-shot(ie.usedonlyonce)orprobabletobeoneshot.DemandanalysispassonlyannotatesCorewithstrictnessinformation.Thisinformationislaterusedbyworker/wrapperpasstoperformtransformations.CPRanalysisisalsodoneduringdemandanalysis.</code></p>
<p><code>*</code><strong><code>Full</code> <code>laziness,</code> <code>2nd</code> <code>pass</code></strong><code>:anotherfull-lazinesspass.Thistimepartialapplicationsandfunctionswithfreevariablesarefloatedout.</code></p>
<p><code>*</code><strong><code>Common</code> <code>Sub-expression-elimination</code></strong><code>:eliminatesexpressionsthatareidentical.</code></p>
<p><code>*</code><strong><code>Float</code> <code>in,</code> <code>2nd</code> <code>pass</code></strong></p>
<p><code>*</code><strong><code>Check</code> <code>rules,</code> <code>1st</code> <code>pass</code></strong><code>:thispassisnotforoptimisationbutfortroubleshootingtherules.Itisonlyenabledwith`-frule-check`flagthatacceptsastringpattern.Thispasslooksforrulesbeginningwiththatstringpatternthatcouldhavefiredbutdidn'tandprintsthemtostdout.</code></p>
<p><code>*</code><strong><code>Liberate</code> <code>case</code></strong><code>:unrollsrecursivefunctionsonceintheirownRHS,toavoidrepeatedcaseanalysisoffreevariables.It'sabitlikethecall-patternspecialisationbutforfreevariablesratherthanarguments.Followedbyaphase0simplifierrun.Onlyenabledwith`-fliberate-case`flag.</code></p>
<p><code>*</code><strong><code>Call-pattern</code> <code>specialisation</code></strong><code>:Onlyenabledwith`-fspec-constr`flag.TODO:explainwhatitdoes.</code></p>
<p><code>*</code><strong><code>Check</code> <code>rules,</code> <code>2nd</code> <code>pass</code></strong></p>
<p><code>*</code><strong><code>Simplifier,</code> <code>final</code></strong><code>:final0phaseofthesimplifier.</code></p>
<p><code>*</code><strong><code>Damand</code> <code>analysis,</code> <code>2nd</code> <code>pass</code></strong><code>(a.k.a.latedemandanalysis):thispassconsistsofdemandanalysisfollowedbyworker-wrappertransformationandphase0ofthesimplifier.Thereasonforthispassisthatsomeopportunitiesfordiscoveringstrictnesswerenotvisibleearlier;andoptimisationslikecall-patternspecialisationcancreatefunctionswithunusedargumentswhichareeliminatedbylatedemandanalysis.Onlyrunwith`-flate-dmd-anal`.FIXME:butthecardinalitypapersayssomethingelse,namelythatthelatepassismeanttodetectsingleentrythunks.Isitstillthecaseinthecurrentimplementation?</code></p>
<p><code>*</code><strong><code>Check</code> <code>rules,</code> <code>3rd</code> <code>pass</code></strong></p>
<p>The plugin mechanism allows to modify the above pipeline dynamically.</p>
<p>== Simplifier</p>
<p>Simplifier is the workhorse of the Core-to-Core optimisation pipeline. It performs all the local transformations: (TODO: this list is most likely not comprehensive)</p>
<p><code>-constantfolding</code><br />
<code>-applyingtherewriterules</code><br />
<code>-inlining</code><br />
<code>-caseofcase</code><br />
<code>-caseofknownconstructor</code><br />
<code>-etaexpansionandetareduction</code><br />
<code>-combiningadjacentcasts</code><br />
<code>-pushingacastoutofthewayofanapplicatione.g.</code></p>
<p>Video: <a href="http://www.youtube.com/watch?v=EQA69dvkQIk&amp;list=PLBkRCigjPwyeCSD_DFxpd246YIF7_RDDI">GHC Core language</a> (14'04&quot;)</p>
<h1 id="the-type">The  type</h1>
<p>The Core language is GHC's central data types. Core is a very small, explicitly-typed, variant of System F. The exact variant is called [wiki:Commentary/Compiler/FC System FC], which embodies equality constraints and coercions.</p>
<p>The  type, and the functions that operate over it, gets an entire directory <a href="GhcFile(compiler/coreSyn)" class="uri" title="wikilink">GhcFile(compiler/coreSyn)</a>:</p>
<p><code>*</code><a href="GhcFile(compiler/coreSyn/CoreSyn.hs)" title="wikilink"><code>GhcFile(compiler/coreSyn/CoreSyn.hs)</code></a><code>:thedatatypeitself.</code></p>
<p><code>*</code><a href="GhcFile(compiler/coreSyn/PprCore.hs)" title="wikilink"><code>GhcFile(compiler/coreSyn/PprCore.hs)</code></a><code>:pretty-printing.</code><br />
<code>*</code><a href="GhcFile(compiler/coreSyn/CoreFVs.hs)" title="wikilink"><code>GhcFile(compiler/coreSyn/CoreFVs.hs)</code></a><code>:findingfreevariables.</code><br />
<code>*</code><a href="GhcFile(compiler/coreSyn/CoreSubst.hs)" title="wikilink"><code>GhcFile(compiler/coreSyn/CoreSubst.hs)</code></a><code>:substitution.</code><br />
<code>*</code><a href="GhcFile(compiler/coreSyn/CoreUtils.hs)" title="wikilink"><code>GhcFile(compiler/coreSyn/CoreUtils.hs)</code></a><code>:avarietyofotherusefulfunctionsoverCore.</code></p>
<p><code>*</code><a href="GhcFile(compiler/coreSyn/CoreUnfold.hs)" title="wikilink"><code>GhcFile(compiler/coreSyn/CoreUnfold.hs)</code></a><code>:dealingwith&quot;unfoldings&quot;.</code></p>
<p><code>*</code><a href="GhcFile(compiler/coreSyn/CoreLint.hs)" title="wikilink"><code>GhcFile(compiler/coreSyn/CoreLint.hs)</code></a><code>:type-checktheCoreprogram.Thisisanincredibly-valuableconsistencycheck,enabledbytheflag</code><code>.</code></p>
<p><code>*</code><a href="GhcFile(compiler/coreSyn/CoreTidy.hs)" title="wikilink"><code>GhcFile(compiler/coreSyn/CoreTidy.hs)</code></a><code>:partofthe[wiki:Commentary/Compiler/HscMaintheCoreTidypass](therestisin</code><a href="GhcFile(compiler/main/TidyPgm.hs)" title="wikilink"><code>GhcFile(compiler/main/TidyPgm.hs)</code></a><code>).</code><br />
<code>*</code><a href="GhcFile(compiler/coreSyn/CorePrep.hs)" title="wikilink"><code>GhcFile(compiler/coreSyn/CorePrep.hs)</code></a><code>:[wiki:Commentary/Compiler/HscMaintheCorePreppass]</code></p>
<p>Here is the entire Core type <a href="GhcFile(compiler/coreSyn/CoreSyn.hs)" class="uri" title="wikilink">GhcFile(compiler/coreSyn/CoreSyn.hs)</a>:  That's it. All of Haskell gets compiled through this tiny core.</p>
<p> is parameterised over the type of its <em>binders</em>, . This facility is used only rarely, and always temporarily; for example, the let-floater  pass attaches a binding level to every binder. By far the most important type is , which is  with  binders. If you want to learn more about such AST-parametrization, I encourage you to read a blog post about it: <a href="http://blog.ezyang.com/2013/05/the-ast-typing-problem" class="uri">http://blog.ezyang.com/2013/05/the-ast-typing-problem</a> .</p>
<p>Binder is used (as the name suggest) to bind a variable to an expression. The  data type is parametrized by the binder type. The most common one is the  where  comes from <a href="GhcFile(compiler/basicTypes/Var.hs)" class="uri" title="wikilink">GhcFile(compiler/basicTypes/Var.hs)</a>, which in fact is a  with some extra informations attached (like types).</p>
<p>Here are some notes about the individual constructors of .</p>
<p><code>*</code><code>representsvariables.The</code><code>itcontainsisessentiallyan[wiki:Commentary/Compiler/RdrNameType#TheOccNametypeOccName]plusa</code><code>;however,equality</code><code>on</code><code>sisbasedonlyontheir</code><code>'s,so</code><em><code>two</code> <code>s</code> <code>with</code> <code>different</code> <code>types</code> <code>may</code> <code>be</code> <code>-equal</code></em><code>.</code></p>
<p><code>*</code><code>isusedforbothtermandtypeabstraction(smallandbiglambdas).</code></p>
<p><code>*</code><code>appearsonlyintype-argumentpositions(e.g.</code><code>).Toemphasisethis,thetypesynonym</code><code>isusedasdocumentationwhenweexpectthata</code><code>constructormayshowup.Anythingnotcalled</code><code>shouldnotusea</code><code>constructor.AdditionalGHCCoreusessocalledtype-lambdas,theyarelikelambdas,butinsteadoftakingarealargument,theytakeatypeinstead.YoushouldnotconfusethemwithTypeFamilies,becausetype-lambdasareworkingonavaluelevel,whiletypefamiliesarefunctionsonthetypelevel.Thesimpliesexampleforatype-lambdausageisapolymorphicone:</code><code>.ItwillberepresentedinCoreas</code><code>,where</code><code>isa*typeargument*,sowhenspecyfyingtheargumentof</code><code>wecanreferto</code><code>.ThisishowpolymorphismisrepresentedinCore.</code></p>
<p><code>*</code><code>handlesbothrecursiveandnon-recursivelet-bindings;seethethetwoconstructorsfor</code><code>.TheLetconstructorcontainsbothbindersaswellastheresultingexpression.Theresultingexpressionisthe</code><code>inexpression</code><code>.</code></p>
<p><code>*</code><code>expressionsneed[wiki:Commentary/Compiler/CoreSynType#Caseexpressionsmoreexplanation].</code></p>
<p><code>*</code><code>isusedforan[wiki:Commentary/Compiler/FCFCcastexpression].</code><code>isasynonymfor</code><code>.</code></p>
<p><code>*</code><code>isusedtorepresentallthekindsofsourceannotationwesupport:profilingSCCs,HPCticks,andGHCibreakpoints.Wasnamed</code><code>sometimeago.</code></p>
<h2 id="case-expressions">Case expressions</h2>
<p>Case expressions are the most complicated bit of . In the term :</p>
<p><code>*</code><code>isthescrutinee</code><br />
<code>*</code><code>isthe</code><strong><code>case</code> <code>binder</code></strong><code>(seenotesbelow)</code><br />
<code>*</code><code>isthetypeoftheentirecaseexpression(redundantonce[wiki:Commentary/Compiler/FCFC]isinHEAD--wasforGADTs)</code><br />
<code>*</code><code>isalistofthecasealternatives</code></p>
<p>A case expression can scrutinise</p>
<p><code>*</code><strong><code>a</code> <code>data</code> <code>type</code></strong><code>(thealternativesare</code><code>s),or</code><br />
<code>*</code><strong><code>a</code> <code>primitive</code> <code>literal</code> <code>type</code></strong><code>(thealternativesare</code><code>s),or</code><br />
<code>*</code><strong><code>a</code> <code>value</code> <code>of</code> <code>any</code> <code>type</code> <code>at</code> <code>all</code></strong><code>(ifthereisone</code><code>alternative).</code></p>
<p>A case expression is <strong>always strict</strong>, even if there is only one alternative, and it is . (This differs from Haskell!) So  will call , rather then returning .</p>
<p>The  field, called the <strong>case binder</strong>, is an unusual feature of GHC's case expressions. The idea is that <em>in any right-hand side, the case binder is bound to the value of the scrutinee</em>. If the scrutinee was always atomic nothing would be gained, but real expressiveness is added when the scrutinee is not atomic. Here is a slightly contrived example:  (Here, &quot;&quot; is the case binder; at least that is the syntax used by the Core pretty printer.) This expression evaluates ; if the result is , it returns , otherwise it returns the reversed list appended to itself. Since the returned value of  is present in the implementation, it makes sense to have a name for it!</p>
<p>The most common application is to model call-by-value, by using  instead of . For example, here is how we might compile the call  if we knew that  was strict: </p>
<p>Case expressions have several invariants</p>
<p><code>*The</code><code>typeisthesameasthetypeofanyoftheright-handsides(uptorefiningunification--coreRefineTysin</code><a href="GhcFile(compiler/types/Unify.hs)" title="wikilink"><code>GhcFile(compiler/types/Unify.hs)</code></a><code>--inpre-[wiki:Commentary/Compiler/FCFC]).</code><br />
<br />
<code>*Ifthereisa</code><code>alternative,itmustappearfirst.Thismakesfindinga</code><code>alternativeeasy,whenitexists.</code></p>
<p><code>*Theremainingnon-DEFAULTalternativesmustappearinorderof</code><br />
<code>*tag,for</code><code>s</code><br />
<code>*lit,for</code><code>s</code><br />
<code>Thismakesfindingtherelevantconstructoreasy,andmakescomparisoneasiertoo.</code></p>
<p><code>*Thelistofalternativesis</code><strong><code>always</code> <code>exhaustive</code></strong><code>,meaningthatitcovers</code><strong><code>all</code> <code>reachable</code> <code>cases</code></strong><code>.Note,however,thatan&quot;exhausive&quot;casedoesnotnecessarilymentionallconstructors:</code></p>
<p></p>
<p><code>Theinnercasedoesnotneeda</code><code>alternative,becausexcan'tbe</code><code>atthatprogrampoint.Furthermore,GADTtype-refinementmightmeanthatsomealternativesarenotreachable,andhencecanbediscarded.</code></p>
<h2 id="shadowing">Shadowing</h2>
<p>One of the important things when working with Core is that variable shadowing is allowed. In other words, it is possible to come across a definition of a variable that has the same name (`realUnique`) as some other one that is already in scope. One of the possible ways to deal with that is to use `Subst` (substitution environment from <a href="GhcFile(compiler/coreSyn/CoreSubst.hs)" class="uri" title="wikilink">GhcFile(compiler/coreSyn/CoreSubst.hs)</a>), which maintains the list of variables in scope and makes it possible to clone (i.e. rename) only the variables that actually capture names of some earlier ones. For some more explanations about this approach see <a href="http://research.microsoft.com/%7Esimonpj/Papers/inlining/index.htm">Secrets of the Glasgow Haskell Compiler inliner (JFP'02)</a> (section 4 on name capture).</p>
<h2 id="human-readable-core-generation">Human readable Core generation</h2>
<p>If you are interested in the way Core is translated into human readable form, you should check the sources for <a href="GhcFile(compiler/coreSyn/PprCore.hs)" class="uri" title="wikilink">GhcFile(compiler/coreSyn/PprCore.hs)</a>. It is especially usefull if you want to see how the Core data types are being build, especially when there is no Show instance defined for them.</p>
<h1 id="cps-conversion">CPS Conversion</h1>
<p>This part of the compiler is now merged in ghc-HEAD.</p>
<h2 id="overview-2">Overview</h2>
<p>This pass takes Cmm with native proceedure calls and an implicit stack and produces Cmm with only tail calls implemented as jumps and an explicit stack. In a word, it does CPS conversion. (All right, so that's two words.)</p>
<h2 id="design-aspects">Design Aspects</h2>
<p><code>*Proc-PointAnalysis</code><br />
<code>*CallingConventions</code><br />
<code>*LiveValueAnalysis</code><br />
<code>*StackLayout</code></p>
<h2 id="simple-design">Simple Design</h2>
<p><code>*Splitblocksintomultipleblocksatfunctioncalls</code><br />
<code>*TODO:eliminateextrajumpatblockendswhenthereisalreadyajumpattheendofthecall</code><br />
<code>*Dolivenessanalysis</code><br />
<code>*Spliteveryblockintoaseparatefunction</code><br />
<code>*Passalllivevaluesasparameters(probablyslow)</code><br />
<code>*Mustarrangeforboththecallerandcalleetoknowargumentorder</code><br />
<code>*Simpledesign:calleejustchoosessomeorderandallcallersmustcomply</code><br />
<code>*Eventuallycouldbepassedimplicitlybutkeepingthingsexplicitmakesthingseasier</code><br />
<code>*Evantuallycoulduseacustomcallingconvention</code><br />
<code>*Actualsyntaxisprobablyvirtual.(I.e.inanexternaltable,notinactualsyntaxbecausethatwouldrequirechangestothetypeforCmmcode)</code><br />
<code>*Inputcode:</code><br />
<code></code><br />
<code>*Outputcode:</code><br />
<code></code><br />
<code>*Savelivevaluesbeforeacallinthecontinuation</code><br />
<code>*Mustarrangeforboththecallerandcalleetoknowfieldorder</code><br />
<code>*Simpledesign:calleejustchoosessomeorderandallcallersmustcomply</code><br />
<code>*Eventuallyneedstobeoptimizedtoreducecontinuationshuffling</code><br />
<code>*Canregisterallocationalgorithmsbeunifiedwiththisintooneframework?</code></p>
<h2 id="to-be-worked-out">To be worked out</h2>
<p><code>*Thecontinuationsfor</code><code>and</code><code>aredifferent.</code><br />
<code></code><br />
<code>*Couldmakeaforeachthatshufflestheargumentsintoacommonformat.</code><br />
<code>*Couldmakeonebranchprimaryandshuffletheothertomatchit,butthatmightentailunnecessarymemorywrites.</code></p>
<h2 id="pipeline">Pipeline</h2>
<p><code>*CPS</code><br />
<code>*Makeclosuresandstacksmanifest</code><br />
<code>*Makesallcallsaretailcalls</code><br />
<code>*ParameterElimination</code><br />
<code>*Makescallingconventionexplicit</code><br />
<code>*Forexternallyvisiblefunctionscallingconventionsismachinespecific,butnotbackendspecificbecausefunctionscompiledfromdifferentbackendsmustbebeabletocalleachother</code><br />
<code>*Forlocalfunctionscallingconventioncanbeleftuptothebackendbecauseitcantakeadvantageofregisterallocation.</code><br />
<code>*However,thefirstfirstdraftwillspecifythestandardcallingconventionforallfunctionsevenlocalonesbecause:</code><br />
<code>*It'ssimpler</code><br />
<code>*TheCcodegeneratorcan'thandlefunctionparametersbecauseoftheEvilMangler</code><br />
<code>*TheNCGdoesn'tyetunderstandparameters</code></p>
<h2 id="todo">TODO</h2>
<p><code>*Downstream</code><br />
<code>*Argumentpassingconvention</code><br />
<code>*Stackcheck</code><br />
<code>*Needssomewaytosynchronizethebranchlabelwiththeheapcheck</code><br />
<code>*Midstream</code><br />
<code>*Support</code><code>(neededbyrts/Apply.cmm)</code><br />
<code>*Morefactoringandcleanup/documentation</code><br />
<code>*Wikidocumentthedesignedchoosen</code><br />
<code>*Betterstackslotselection</code><br />
<code>*Foreignfunctioncalls</code><br />
<code>*Garbagecollector</code><br />
<code>*Procpoints</code><br />
<code>*Maycausenewblocks</code><br />
<code>*Maycausenewfunctions</code><br />
<code>*Livescouldbepasseseitheronstackorinarguments</code><br />
<code>*Procgroupingofblocks</code><br />
<code>*Upstream</code><br />
<code>*Have</code><code>emitC--withfunctions.</code></p>
<h2 id="current-pipeline">Current Pipeline</h2>
<h3 id="section-1"></h3>
<p>The / pipeline and the / pipeline can each independantly use the CPS pass. However, they currently bypass it untill the CPS code becomes stablized, but they must both use the  pass. This pass converts the header on each function from a  to a .</p>
<h2 id="non-cps-changes">Non-CPS Changes</h2>
<p><code>*CmmSyntaxChanges</code><br />
<code>*Thereturnsparametersofafunctioncallmustbesurroundedbyparenthesis.</code><br />
<code>Forexample</code></p>
<p></p>
<p><code>Thisissimplytoavoidshift-reduceconflictswithassignment.</code><br />
<code>Futurerevisionstotheparsermayeliminatetheneedforthis.</code></p>
<p><code>*Variabledeclarationsmayareannotatedtoindicate</code><br />
<code>whethertheyareGCfollowablepointers.</code></p>
<p></p>
<p><code>*Thebitmapofa</code><code>isnowspecifiedusing</code><br />
<code>aparameterlikesyntax.</code></p>
<p></p>
<p><code>Notethatthesearenotrealparameters,theyarethestacklayout</code><br />
<code>ofthecontinuation.Also,untiltheCPSalgorithm</code><br />
<code>getsproperlyhookedintothe</code><code>paththeparameternamesarenotused.</code><br />
<code>*Thereturnvaluesofafunctioncallmayonlybe</code><code>.</code><br />
<code>Thisisduetochangesinthe</code><code>datatype.</code></p>
<p><code>*CmmDataTypeChanges</code><br />
<code>*Thereturnparametersofa</code><code>are</code><code>insteadof</code><code>.</code><br />
<code>Thisisbecausea</code><code>doesn'thaveawelldefinedpointerhood,</code><br />
<code>andthereturnvalueswillbecomeparameterstocontinuationswhere</code><br />
<code>theirpointerhoodwillbeneeded.</code><br />
<code>*Thetypeofinfotablesisnowaseparateparameterto</code><br />
<code>*Before</code></p>
<p></p>
<p><code>*After</code></p>
<p></p>
<p><code>Thisistosupportusingeither</code><code>or</code><br />
<code>astheheaderofa</code><code>.</code><br />
<code>*Beforeinfotableconversionuse</code></p>
<p></p>
<p><code>*Afterinfotableconversionuse</code></p>
<p></p>
<p><code>Samefor</code><code>and</code><code>.</code><br />
<code>*Newtypealiases</code><code>,</code><code>and</code><code>.</code><br />
<code>Respectivelythesearetheactualparametersofafunctioncall,</code><br />
<code>theformalparametersofafunction,andthe</code><br />
<code>returnresultsofafunctioncallwithpointerhoodannotation</code><br />
<code>(CPSmayconvertthesetoformalparameterofthecall'scontinuation).</code></p>
<h2 id="notes">Notes</h2>
<p><code>*Changedtheparametertoa</code><code>tobe</code><code>insteadof</code><br />
<code>*</code><code>are</code><br />
<code>*Thisfieldseemstonothavebeenbeingused;itonlyrequireatypechange</code><br />
<code>*GCcanbecleanedupb/coftheCPS</code><br />
<code>*Before</code></p>
<p></p>
<p><code>*After</code></p>
<p></p>
<p><code>*WeneedtheNCGtodoaliasinganalysis.AtpresenttheCPSpasswillgeneratethefollowing,andwillassumethattheNCGcanfigureoutwhentheloadsandstorescanbeeliminated.(Theglobalsavespartofa</code><code>isdeadb/cofthis.)</code></p>
<p></p>
<p><code>*Simplecalls</code><br />
<code>*Before</code></p>
<p></p>
<p><code>*OutputofCPS</code></p>
<p></p>
<p><code>*OptimizationbytheNCG</code></p>
<p></p>
<h2 id="loopholes">Loopholes</h2>
<p>There are a number of deviations from what one might expect from a CPS algorithm due to the need to encode existing optimizations and idioms.</p>
<h3 id="gc-blocks">GC Blocks</h3>
<p>For obvious reasons, the stack used by GC blocks does not count tward the maximum amount of stack used by the function.</p>
<p>This loophole is overloaded by the GC <strong>functions</strong> so they don't create their own infinite loop. The main block is marked as being the GC block so its stack usage doesn't get checked.</p>
<h3 id="update-frames">Update Frames</h3>
<p>Update frame have to be pushed onto the stack at the begining of an update function. We could do this by wrapping the update function inside another function that just does the work of calling that other function, but since updates are so common we don't want to pay the cost of that extra jump. Thus a function can be annotated with a frame that should be pushed on entry.</p>
<p>Note that while the frame is equivalent to a tail call at the end of the function, the frame must be pushed at the beginning of the function because parts of the blackhole code look for these update frames to determine what thunks are under evaluation.</p>
<h3 id="user-defined-continuations">User defined continuations</h3>
<p>Pushing an update frame on the stack requires the ability to define a function that will pull that frame from the stack and have access to any values within the frame. This is done with user-defined continuations.</p>
<h3 id="branches-to-continuations">Branches to continuations</h3>
<p>A GC block for a heap check after a call should only take one or two instructions. However the natural code:  would generate a trivial continuation for the  call as well as a trivial continuation for the  call that just calls the proc point .</p>
<p>We solve this by changing the syntax to </p>
<p>Now the  call has the same return signature as  and can use the same continuation. (A call followed by a  thus gets optimized down to just the call.)</p>
<h2 id="not-in-scope-of-current-work">Not in Scope of Current Work</h2>
<p>Improvements that could be made but that will not be implemented durring the curent effort.</p>
<h3 id="static-reference-table-handling-srt">Static Reference Table Handling (SRT)</h3>
<p>As it stands, each function and thus each call site must be annotated with a bitmap and a pointer or offset to the SRT shared by the function. This does not interact with the stack in any way so it ought to be outside the scope of the CPS algorithm. However there is some level of interaction because</p>
<p><code>1.theSRTinformationoneachcallsiteneedstobeattachedtotheresultingcontinuationand</code><br />
<code>2.functionsreadfromaCmmfilemightneedtobeannotatedwiththatSRTinfo.</code></p>
<p>The first is a concern for correctness but may be handled by treating the SRT info as opaque data. The second is a concern for ease of use and thus the likelyhood of mistakes in hand written C-- code. At the moment it appears that all of the C-- functions in the runtime system (RTS) use a null SRT so for now we'll just have the CPS algorithm treat the SRT info as opaque.</p>
<p>In the future it would be nice to have a more satisfactory way to handle both these issues.</p>
<h3 id="cmm-optimization-assumed-by-cps">Cmm Optimization assumed by CPS</h3>
<p>In order to simplify the CPS pass, it makes some assumptions about the optimizer.</p>
<p><code>*TheCPSpassmaygeneratemoreblocksthanstrictlynecessary.Inparticular,</code><br />
<code>itmightbepossibletojointogethertwoblockswhenthesecondblockisonly</code><br />
<code>enteredbythefirstblock.Thisisasimpleoptimizationthatneedstobeimplemented.</code><br />
<code>*TheCPSpassmaygeneratemoreloadsandstoresthanstrictlynecessary.Inparticular,</code><br />
<code>itmayloadalocalregisteronlytostoreitbacktothesamestacklocationafew</code><br />
<code>statementslater.Theremaybeinterveningbranches.Theoptimizer</code><br />
<code>needstobeextendedtoeliminatetheseloadstorepairs.</code></p>
<h2 id="notes-on-future-development">Notes on future development</h2>
<h3 id="handling-gc">Handling GC</h3>
<p></p>
<p></p>
<h1 id="the-ghc-commentary-data-types-and-data-constructors">The GHC Commentary: Data types and data constructors</h1>
<p>This chapter was thoroughly changed Feb 2003. If you are interested in how a particular data type is implemented take a look at [wiki:Commentary/Compiler/CaseStudies/Bool this case study].</p>
<h2 id="data-types">Data types</h2>
<p>Consider the following data type declaration:  The user's source program mentions only the constructors `MkT` and `Nil`. However, these constructors actually <em>do</em> something in addition to building a data value. For a start, `MkT` evaluates its arguments. Secondly, with the flag `-funbox-strict-fields` GHC will flatten (or unbox) the strict fields. So we may imagine that there's the <em>source</em> constructor `MkT` and the <em>representation</em> constructor `MkT`, and things start to get pretty confusing.</p>
<p>GHC now generates three unique `Name`s for each data constructor:  Recall that each occurrence name (OccName) is a pair of a string and a name space (see [wiki:Commentary/Compiler/RdrNameType#TheOccNametype RdrNames, Modules, and OccNames]), and two OccNames are considered the same only if both components match. That is what distinguishes the name of the name of the DataCon from the name of its worker Id. To keep things unambiguous, in what follows we'll write &quot;MkT{d}&quot; for the source data con, and &quot;MkT{v}&quot; for the worker Id. (Indeed, when you dump stuff with &quot;-ddumpXXX&quot;, if you also add &quot;-dppr-debug&quot; you'll get stuff like &quot;Foo {- d rMv -}&quot;. The &quot;d&quot; part is the name space; the &quot;rMv&quot; is the unique key.)</p>
<p>Each of these three names gets a distinct unique key in GHC's name cache.</p>
<h1 id="the-life-cycle-of-a-data-type">The life cycle of a data type</h1>
<p>Suppose the Haskell source looks like this:  When the parser reads it in, it decides which name space each lexeme comes from, thus:  Notice that in the Haskell source <em>all data contructors are named via the &quot;source data con&quot; MkT{d}</em>, whether in pattern matching or in expressions.</p>
<p>In the translated source produced by the type checker (-ddump-tc), the program looks like this: </p>
<p>Notice that the type checker replaces the occurrence of MkT by the <em>wrapper</em>, but the occurrence of Nil by the <em>worker</em>. Reason: Nil doesn't have a wrapper because there is nothing to do in the wrapper (this is the vastly common case).</p>
<p>Though they are not printed out by &quot;-ddump-tc&quot;, behind the scenes, there are also the following: the data type declaration and the wrapper function for MkT.  Here, the <em>wrapper</em> $WMkT evaluates and takes apart the argument p, evaluates the argument t, and builds a three-field data value with the <em>worker</em> constructor MkT{v}. (There are more notes below about the unboxing of strict fields.) The worker $WMkT is called an <em>implicit binding</em>, because it's introduced implicitly by the data type declaration (record selectors are also implicit bindings, for example). Implicit bindings are injected into the code just before emitting code or External Core.</p>
<p>After desugaring into Core (-ddump-ds), the definition of f looks like this:  Notice the way that pattern matching has been desugared to take account of the fact that the &quot;real&quot; data constructor MkT has three fields.</p>
<p>By the time the simplifier has had a go at it, f will be transformed to:  Which is highly cool.</p>
<h2 id="the-constructor-wrapper-functions">The constructor wrapper functions</h2>
<p>The wrapper functions are automatically generated by GHC, and are really emitted into the result code (albeit only after CorePre; see `CorePrep.mkImplicitBinds`). The wrapper functions are inlined very vigorously, so you will not see many occurrences of the wrapper functions in an optimised program, but you may see some. For example, if your Haskell source has  then `$WMkT` will not be inlined (because it is not applied to anything). That is why we generate real top-level bindings for the wrapper functions, and generate code for them.</p>
<h2 id="the-constructor-worker-functions">The constructor worker functions</h2>
<p>Saturated applications of the constructor worker function MkT{v} are treated specially by the code generator; they really do allocation. However, we do want a single, shared, top-level definition for top-level nullary constructors (like True and False). Furthermore, what if the code generator encounters a non-saturated application of a worker? E.g. (`map Just xs`). We could declare that to be an error (CorePrep should saturate them). But instead we currently generate a top-level defintion for each constructor worker, whether nullary or not. It takes the form:  This is a real hack. The occurrence on the RHS is saturated, so the code generator (both the one that generates abstract C and the byte-code generator) treats it as a special case and allocates a MkT; it does not make a recursive call! So now there's a top-level curried version of the worker which is available to anyone who wants it.</p>
<p>This strange definition is not emitted into External Core. Indeed, you might argue that we should instead pass the list of `TyCon`s to the code generator and have it generate magic bindings directly. As it stands, it's a real hack: see the code in CorePrep.mkImplicitBinds.</p>
<h2 id="external-core">External Core</h2>
<p>When emitting External Core, we should see this for our running example:  Notice that it makes perfect sense as a program all by itself. Constructors look like constructors (albeit not identical to the original Haskell ones).</p>
<p>When reading in External Core, the parser is careful to read it back in just as it was before it was spat out, namely: </p>
<h2 id="unboxing-strict-fields">Unboxing strict fields</h2>
<p>If GHC unboxes strict fields (as in the first argument of MkT above), it also transforms source-language case expressions. Suppose you write this in your Haskell source:  GHC will desugar this to the following Core code:  The local let-binding reboxes the pair because it may be mentioned in the case alternative. This may well be a bad idea, which is why `-funbox-strict-fields` is an experimental feature.</p>
<p>It's essential that when importing a type `T` defined in some external module `M`, GHC knows what representation was used for that type, and that in turn depends on whether module M was compiled with `-funbox-strict-fields`. So when writing an interface file, GHC therefore records with each data type whether its strict fields (if any) should be unboxed.</p>
<h2 id="labels-and-info-tables">Labels and info tables</h2>
<p><em>Quick rough notes: SLPJ March 2003.</em></p>
<p>Every data constructor `C` has two info tables:</p>
<p><code>*Thestaticinfotable(label`C_static_info`),usedforstatically-allocatedconstructors.</code><br />
<code>*Thedynamicinfotable(label`C_con_info`),usedfordynamically-allocatedconstructors.</code></p>
<p>Statically-allocated constructors are not moved by the garbage collector, and therefore have a different closure type from dynamically-allocated constructors; hence they need a distinct info table. Both info tables share the same entry code, but since the entry code is physically juxtaposed with the info table, it must be duplicated (`C_static_entry` and `C_con_entry` respectively).</p>
<p><a href="PageOutline" class="uri" title="wikilink">PageOutline</a></p>
<h1 id="demand-analyser-in-ghc">Demand analyser in GHC</h1>
<p>This page explains basics of the so-called demand analysis in GHC, comprising strictness and absence analyses. Meanings of demand signatures are explained and examples are provided. Also, components of the compiler possibly affected by the results of the demand analysis are listed with explanations provided.</p>
<p><code>*The</code><a href="http://research.microsoft.com/en-us/um/people/simonpj/papers/demand-anal/demand.ps"><code>demand-analyser</code> <code>draft</code> <code>paper</code></a><code>isasyetunpublished,butgivesthemostaccurateoverviewofthewayGHC'sdemandanalyserworks.</code></p>
<hr />
<h2 id="demand-signatures">Demand signatures</h2>
<p>Let us compile the following program with `-O2 -ddump-stranal` flags:</p>
<p></p>
<p>The resulting demand signature for function `f` will be the following one:</p>
<p></p>
<p>This should be read as &quot;`f` puts stricts demands on both its arguments (hence, `S`); `f` might use its first and second arguments. but in the second argument (which is a product), the second component is ignored&quot;. The suffix `m` in the demand signature indicates that the function returns <strong>CPR</strong>, a constructed product result (for more information on CPR see the JFP paper <a href="http://research.microsoft.com/en-us/um/people/simonpj/Papers/cpr/index.htm">Constructed Product Result Analysis for Haskell</a>).</p>
<p>Current implementation of demand analysis in Haskell performs annotation of all binders with demands, put on them in the context of their use. For functions, it is assumed, that the result of the function is used strictly. The analysis infers strictness and usage information separately, as two components of a cartesian product domain. The same analysis also performs inference CPR and bottoming properties for functions, which can be read from the suffix of the signature. Demand signatures of inner definitions may also include <em>demand environments</em> that indicate demands, which a closure puts to its free variables, once strictly used, e.g. the signature</p>
<p></p>
<p>indicates that the function has one parameter, which is used lazily (hence `<L,U>`), however, when its result is used strictly, the free variable `skY` in its body is also used strictly.</p>
<h3 id="demand-descriptions">Demand descriptions</h3>
<p>Strictness demands</p>
<p><code>*`B`--a</code><em><code>hyperstrict</code></em><code>demand.Theexpression`e`putsthisdemandonitsargument`x`ifeveryevaluationof`e`isguaranteedtodiverge,regardlessofthevalueoftheargument.Wecallthisdemand</code><em><code>hyperstrict</code></em><code>becauseitissafetoevaluate`x`toarbitrarydepthbeforeevaluating`e`.Thisdemandispolymorphicwithrespecttofunctioncallsandcanbeseenas`B=C(B)=C(C(B))=...`foranarbitrarydepth.</code><br />
<code></code><br />
<code>*`L`--a</code><em><code>lazy</code></em><code>demand.Ifanexpression`e`placesdemand`L`onavariable`x`,wecandeducenothingabouthow`e`uses`x`.`L`isthecompletelyuninformativedemand,thetopelementofthelattice.</code></p>
<p><code>*`S`--a</code><em><code>head-strict</code></em><code>demand.If`e`placesdemand`S`on`x`then`e`evaluates`x`toatleasthead-normalform;thatis,totheoutermostconstructorof`x`.Thisdemandistypicallyplacedbythe`seq`functiononitsfirstargument.Thedemand`S(L...L)`placesalazydemandonallthecomponents,andsoisequivalentto`S`;hencetheidentity`S=S(L...L)`.Anotheridentityisforfunctions,whichstatesthat`S=C(L)`.Indeed,ifafunctioniscertainlycalled,itisevaluatedatlestuptotheheadnormalform,i.e.,</code><em><code>strictly</code></em><code>.However,itsresultmaybeusedlazily.</code></p>
<p><code>*`S(s1...sn)`--astructuredstrictnessdemandonaproduct.Itisatleasthead-strict,andperhapsmore.</code></p>
<p><code>*`C(s)`--a</code><em><code>call-demand</code></em><code>,whenplacedonabinder`x`,indicatesthatthevalueisafunction,whichisalwayscalledanditsresultisusedaccordingtothedemand`s`.</code></p>
<p>Absence/usage demands</p>
<p><code>*`A`--whenplacedonabinder`x`itmeansthat`x`isdefinitelyunused.</code></p>
<p><code>*`U`--thevalueisusedonsomeexecutionpath.Thisdemandisatopofusagedomain.</code></p>
<p><code>*`H`--a</code><em><code>head-used</code></em><code>demand.Indicatesthataproductvalueisuseditself,howeveritscomponentsarecertainlyignored.Thisdemandistypicallyplacedbythe`seq`functiononitsfirstargument.Thisdemandispolymorphicwithrespecttoproductsandfunctions.Foraproduct,thehead-useddemandisexpandedas`U(A,...,A)`andforfunctionsitcanbereadas`C(A)`,asthefunctioniscalled(i.e.,evaluatedtoatleastahead-normalform),butitsresultisignored.</code></p>
<p><code>*`U(u1...un)`--astructuredusagedemandonaproduct.Itisatleasthead-used,andperhapsmore.</code></p>
<p><code>*`C(u)`--a</code><em><code>call-demand</code></em><code>forusageinformation.Whenputonabinder`x`,indicatesthat`x`inallexecutionspathswhere`x`isused,itis</code><em><code>applied</code></em><code>tosomeargument,andtheresultoftheapplicationisusedwithademand`u`.</code></p>
<p>Additional information (demand signature suffix)</p>
<p><code>*`m`--afunctionreturnsa</code><a href="http://research.microsoft.com/en-us/um/people/simonpj/Papers/cpr/index.htm"><code>constructed</code> <code>product</code> <code>result</code></a></p>
<p><code>*`b`--thefunctionisa</code><em><code>bottoming</code></em><code>one,i.e.,somedecorationof`error`andfriends.</code></p>
<h2 id="worker-wrapper-split">Worker-Wrapper split</h2>
<p>Demand analysis in GHC drives the <em>worker-wrapper transformation</em>, which exposes specialised calling conventions to the rest of the compiler. In particular, the worker-wrapper transformation implements the unboxing optimisation.</p>
<p>The worker-wrapper transformation splits each function `f` into a <em>wrapper</em>, with the ordinary calling convention, and a <em>worker</em>, with a specialised calling convention. The wrapper serves as an impedance-matcher to the worker; it simply calls the worker using the specialised calling convention. The transformation can be expressed directly in GHC's intermediate language. Suppose that `f` is defined thus:  and that we know that `f` is strict in its argument (the pair, that is), and uses its components. What worker-wrapper split shall we make? Here is one possibility:  Now the wrapper, `f`, can be inlined at every call site, so that the caller evaluates `p`, passing only the components to the worker `$wf`, thereby implementing the unboxing transformation.</p>
<p>But what if `f` did not use `a`, or `b`? Then it would be silly to pass them to the worker `$wf`. Hence the need for absence analysis. Suppose, then, that we know that `b` is not needed. Then we can transform to:  Since `b` is not needed, we can avoid passing it from the wrapper to the worker; while in the worker, we can use `error &quot;abs&quot;` instead of `b`.</p>
<p>In short, the worker-wrapper transformation allows the knowledge gained from strictness and absence analysis to be exposed to the rest of the compiler simply by performing a local transformation on the function definition. Then ordinary inlining and case elimination will do the rest, transformations the compiler does anyway.</p>
<h2 id="relevant-compiler-parts">Relevant compiler parts</h2>
<p>Multiple parts of GHC are sensitive to changes in the nature of demand signatures and results of the demand analysis, which might cause unexpected errors when hacking into demands. [wiki:Commentary/Compiler/Demand/RelevantParts This list] enumerates the parts of the compiler that are sensitive to demand, with brief summaries of how so.</p>
<h1 id="support-for-deriving-and-instances">Support for deriving , , and  instances</h1>
<p><a href="PageOutline" class="uri" title="wikilink">PageOutline</a></p>
<p>GHC 6.12.1 introduces an extension to the  mechanism allowing for automatic derivation of , , and  instances using the , , and  extensions, respectively. Twan van Laarhoven <a href="https://mail.haskell.org/pipermail/haskell-prime/2007-March/002137.html">first proposed this feature</a> in 2007, and <a href="https://ghc.haskell.org/trac/ghc/ticket/2953">opened a related GHC Trac ticket</a> in 2009.</p>
<h2 id="example">Example</h2>
<p></p>
<p>The derived code would look something like this:</p>
<p></p>
<h2 id="algorithm-description">Algorithm description</h2>
<p>, , and  all operate using the same underlying mechanism. GHC inspects the arguments of each constructor and derives some operation to perform on each argument, which depends of the type of the argument itself. In a  instance, for example  would be applied to occurrences of the last type parameter, but  would be applied to other type parameters. Typically, there are five cases to consider. (Suppose we have a data type .)</p>
<p>1. Terms whose type does not mention  2. Terms whose type mentions  3. Occurrences of  4. Tuple values 5. Function values</p>
<p>After this is done, the new terms are combined in some way. For instance,  instances combine terms in a derived  definition by applying the appropriate constructor to all terms, whereas in  instances, a derived  definition would  the terms together.</p>
<h3 id="section-2"></h3>
<p>A comment in <a href="http://git.haskell.org/ghc.git/blob/9f968e97a0de9c2509da00f6337b612dd72a0389:/compiler/typecheck/TcGenDeriv.hs#l1476">TcGenDeriv.hs</a> lays out the basic structure of , which derives an implementation for .</p>
<p></p>
<p> is special in that it can recurse into function types, whereas  and  cannot (see the section on covariant and contravariant positions).</p>
<h3 id="section-3"></h3>
<p>Another comment in <a href="http://git.haskell.org/ghc.git/blob/9f968e97a0de9c2509da00f6337b612dd72a0389:/compiler/typecheck/TcGenDeriv.hs#l1725">TcGenDeriv.hs</a> reveals the underlying mechanism behind :</p>
<p></p>
<p>In addition to ,  also generates a definition for  as of GHC 7.8.1 (addressing <a href="https://ghc.haskell.org/trac/ghc/ticket/7436">#7436</a>). The pseudo-definition for  would look something like this:</p>
<p></p>
<h3 id="section-4"></h3>
<p>From <a href="http://git.haskell.org/ghc.git/blob/9f968e97a0de9c2509da00f6337b612dd72a0389:/compiler/typecheck/TcGenDeriv.hs#l1800">TcGenDeriv.hs</a>:</p>
<p></p>
<h3 id="covariant-and-contravariant-positions">Covariant and contravariant positions</h3>
<p>One challenge of deriving  instances for arbitrary data types is handling function types. To illustrate this, note that these all can have derived  instances:</p>
<p></p>
<p>but none of these can:</p>
<p></p>
<p>In , , and , all occurrences of the type variable  are in <em>covariant</em> positions (i.e., the  values are produced), whereas in , , and , all occurrences of  are in <em>contravariant</em> positions (i.e., the  values are consumed). If we have a function , we can't apply  to an  value in a contravariant position, which precludes a  instance.</p>
<p>Most type variables appear in covariant positions. Functions are special in that the lefthand side of a function arrow reverses variance. If a function type  appears in a covariant position (e.g.,  above), then  is in a contravariant position and  is in a covariant position. Similarly, if  appears in a contravariant position (e.g.,  above), then  is in a covariant position and  is in a contravariant position.</p>
<p>If we annotate covariant positions with  (for positive) and contravariant positions with  (for negative), then we can examine the above examples with the following pseudo-type signatures:</p>
<p></p>
<p>Since , , and  all use the last type parameter in at least one  position, GHC would reject a derived  instance for each of them.</p>
<h2 id="requirements-for-legal-instances">Requirements for legal instances</h2>
<p>This mechanism cannot derive , , or  instances for all data types. Currently, GHC checks if a data type meets the following criteria:</p>
<p>1. The data type has at least one type parameter. (For example,  cannot have a  instance.) 2. The data type's last type parameter cannot be used contravariantly. (see the section on covariant and contravariant positions.) 3. The data type's last type parameter cannot be used in the &quot;wrong place&quot; in any constructor's data arguments. For example, in , the type parameter  is only ever used as the last type argument in  and , so both  and  values can be ped. However, in , the type variable  appears in a position other than the last, so trying to  an  value would not typecheck.</p>
<p><code>Notethattherearetwoexceptionstothisrule:tupleandfunctiontypes.</code></p>
<p>4. The data type's last type variable cannot used in a  constraint. For example,  would be rejected.</p>
<p>In addition, GHC performs checks for certain classes only:</p>
<p>1. For derived  and  instances, a data type cannot use function types. This restriction does not apply to derived  instances, however. 2. For derived  and  instances, the data type's last type variable must be truly universally quantified, i.e., it must not have any class or equality constraints. This means that the following is legal:</p>
<p></p>
<p><code>butthefollowingisnotlegal:</code></p>
<p></p>
<p><code>Thisrestrictiondoesnotapplytoderived</code><code>instances.Seethefollowingsectionformoredetails.</code></p>
<h3 id="relaxed-universality-check-for">Relaxed universality check for </h3>
<p> and  cannot be used with data types that use existential constraints, since the type signatures of  and  make this impossible. However,  instances are unique in that they do not produce constraints, but only consume them. Therefore, it is permissible to derive  instances for constrained data types (e.g., GADTs).</p>
<p>For example, consider the following GADT:</p>
<p></p>
<p>In the type signatures for  and , the  parameter appears both in an argument and the result type, so pattern-matching on a value of  must not impose any constraints, as neither  nor  would typecheck.</p>
<p>, however, only mentions  in argument types:</p>
<p></p>
<p>Therefore, a derived  instance for  typechecks:</p>
<p></p>
<p>Deriving  instances for GADTs with equality constraints could become murky, however. Consider this GADT:</p>
<p></p>
<p>All four  constructors have the same &quot;shape&quot; in that they all take an argument of type  (or , to which  is constrained to be equal). Does that mean all four constructors would have their arguments folded over? While it is possible to derive perfectly valid code which would do so:</p>
<p></p>
<p>it is much harder to determine which arguments are equivalent to . Also consider this case:</p>
<p></p>
<p>For all we know, it may be that . Does this mean that the  argument in  should be folded over?</p>
<p>To avoid these thorny edge cases, we only consider constructor arguments (1) whose types are <em>syntactically</em> equivalent to the last type parameter and (2) in cases when the last type parameter is a truly universally polymorphic. In the above  example, only  fits the bill, so the derived  instance is actually:</p>
<p></p>
<p>To expound more on the meaning of criterion (2), we want not only to avoid cases like , but also something like this:</p>
<p></p>
<p>In this example, the last type variable is instantiated with , which contains one type variable  applied to another type variable . We would <em>not</em> fold over the argument of type  in this case, because the last type variable should be <em>simple</em>, i.e., contain only a single variable without any application.</p>
<p>For the original discussion on this proposal, see <a href="https://ghc.haskell.org/trac/ghc/ticket/10447">#10447</a>.</p>
<h2 id="alternative-strategy-for-deriving-foldable-and-traversable">Alternative strategy for deriving `Foldable` and `Traversable`</h2>
<p>We adapt the algorithms for `-XDeriveFoldable` and `-XDeriveTraversable` based on that of `-XDeriveFunctor`. However, there is an important difference between deriving the former two typeclasses and the latter one (as of GHC 8.2, addressing <a href="https://ghc.haskell.org/trac/ghc/ticket/11174">Trac #11174</a>), which is best illustrated by the following scenario:</p>
<p></p>
<p>The generated code for the `Functor` instance is straightforward:</p>
<p></p>
<p>But if we use too similar of a strategy for deriving the `Foldable` and `Traversable` instances, we end up with this code:</p>
<p></p>
<p>This is unsatisfying for two reasons:</p>
<p>1. The `Traversable` instance doesn't typecheck! `Int#` is of kind `#`, but `pure` expects an argument whose type is of kind `*`. This effectively prevents `Traversable` from being derived for any datatype with an unlifted argument type (see <a href="https://ghc.haskell.org/trac/ghc/ticket/11174">Trac #11174</a>).</p>
<p>2. The generated code contains superfluous expressions. By the `Monoid` laws, we can reduce `f a &lt;&gt; mempty` to `f a`, and by the `Applicative` laws, we can reduce `fmap WithInt (f a) &lt;*&gt; pure i` to `fmap (\b -&gt; WithInt b i) (f a)`.</p>
<p>We can fix both of these issues by incorporating a slight twist to the usual algorithm that we use for `-XDeriveFunctor`. The differences can be summarized as follows:</p>
<p>1. In the generated expression, we only fold over arguments whose types mention the last type parameter. Any other argument types will simply produce useless `mempty`s or `pure`s, so they can be safely ignored.</p>
<p>2. In the case of `-XDeriveTraversable`, instead of applying `ConName`, we apply `\b_i ... b_k -&gt; ConName a_1 ... a_n`, where</p>
<ul>
<li>`ConName` has `n` arguments</li>
<li>`{b_i, ..., b_k}` is a subset of `{a_1, ..., a_n}` whose indices correspond to the arguments whose types mention the last type parameter. As a consequence, taking the difference of `{a_1, ..., a_n}` and `{b_i, ..., b_k}` yields the all the argument values of `ConName` whose types do not mention the last type parameter. Note that `[i, ..., k]` is a strictly increasing</li>
</ul>
<p><a href="PageOutline" class="uri" title="wikilink">PageOutline</a></p>
<h1 id="llvm-back-end-design">LLVM Back-end Design</h1>
<p>The current design tries to fit into GHC's pipeline stages as an alternative to the C and NCG back-ends as seamlessly as possible. This allows for quicker development and focus on the core task of LLVM code generation.</p>
<p>The LLVM pipeline works as follows:</p>
<p><code>*NewpathforLLVMgeneration,separatefromCandNCG.(pathforksatcompiler/main/CodeOutput.lhs,sameplacewhereCandNCGfork).</code><br />
<code>*LLVMcodegenerationwilloutputLLVMassemblycode.</code><br />
<code>*TheLLVMassemblycodeistranslatedtoanobjectfileasfollows</code><br />
<code>*TheLLVMoptimizerisrunwhichisaseriesofbitcodetobitcodeoptimizationpasses(usingthe</code><code>tool).</code><br />
<code>*FinallyanobjectfileiscreatedfromtheLLVMbitcode(usingthe</code><code>tool)</code><br />
<code>*ThisbringstheLLVMpathbacktotheotherback-ends.</code><br />
<code>*ThefinalstateistheLinkstage,whichusesthesystemlinkeraswiththeotherback-ends.</code></p>
<p>Here is a diagram of the pipeline:</p>
<p></p>
<p>This approach was the easiest and thus quickest way to initially implement the LLVM back-end. Now that it is working, there is some room for additional optimisations. A potential optimisation would be to add a new linker phase for LLVM. Instead of each module just being compiled to native object code ASAP, it would be better to keep them in the LLVM bitcode format and link all the modules together using the LLVM linker. This enable all of LLVM's link time optimisations. All the user program LLVM bitcode will then be compiled to a native object file and linked with the runtime using the native system linker.</p>
<h1 id="implementation">Implementation</h1>
<h2 id="framework">Framework</h2>
<p><code>*New</code><strong><code>-fllvm</code></strong><code>codegenerationpipeline,involvedmodifying:</code><br />
<code>*</code><code>-Selectsappropriateback-endforcodegeneration(C,NCG,LLVM).</code><br />
<code>*</code><code>-StoresGHCconfiguration(commandlineoptions,compiletimeoptions...ect).Added`HscLlvm`targettype.</code><br />
<code>*</code><code>-Storesmodules/filestocompileforghc.AddednewLLVMfilesanddirectorystoredunder`llvmGen`,andnewCPPflagtoenabletheLLVMcodegenerator(`-DLLVM`).</code><br />
<code>*</code><code>-Addednew`GhcWithLlvmCodeGen`optionwhichcanbesetin`build.mk`to`YES`toenabletheLLVMcodegenerator.</code><br />
<code>*</code><code>-Added`LlvmAs`phasetoinvokethecompilationofLLVMbitcode/IRtoanobjectfile.Afterthisphaselinkingcanoccur.</code><br />
<code>*</code><code>-Addedcodefornew`LlvmAs`,`LlvmOpt`and`LlvmLlc`phases.</code><br />
<code>*</code><code>-Invokes`llvm-as`tooltocompileallvmassemblyfile('.ll')toabitcodefile(`.bc`).</code><br />
<code>*</code><code>-Invokesthellvm`opt`tooltooptimisethemodule.Justusethellvmstandardoptimisationgroupsof`O1`,`O2`,`O3`,dependingontheoptimisationlevelpassedto'ghc'bytheuser.</code><br />
<code>*</code><code>-Invokesthellvm`llc`tooltogeneratethemachinecode('.s'file)fromtheoptimisedbitcode.'As'stagerunsnext,partofexisting'ghc'pipeline.</code><br />
<code>*</code><code>-Storesthepathanddefaultsettingsofthesystemtoolsneeded,soforLLVMback-endthisis`llvm-as`,`opt`and`llc`.</code></p>
<p>The LLVM pipeline works as specified above. Code generation phase occurs, using the  option data the appropriate generator is selected (which is the Llvm back-end is `-fllvm` has been specified on the command line). After code generation, the next phase is determined, this is done from the `HscLlvm` target data constructor which is selected at ghc startup by . The next phase is `LlvmAs` which will compile the text IR to an LLVM bitcode file (equivalent to `llvm-as` tool). After this the `LlvmLlc` phase is run, which produces a native object file from the llvm bitcode file (equivalanet to the `llc` tool). At this stage, the output from all three back-ends should be 'equivalent'. After this phase, the `StopLn`, or linking phase occurs which should result in the end result. Compiling some Haskell code with the c-backend and some with the llvm-backend and linking them together is supported.</p>
<h2 id="llvm-code-generation">LLVM Code Generation</h2>
<p>For LLVM code generation we need a method for representing and generating LLVM code. The <a href="http://llvm.org/docs/FAQ.html#langirgen">LLVM FAQ</a> suggest the following possible approaches:</p>
<p><code>*CallintoLLVMLibrariesusingFFI(canprobablyuse</code><a href="http://hackage.haskell.org/package/llvm"><code>Haskell</code> <code>LLVM</code> <code>Bindings</code></a><code>)</code><br />
<code>*EmitLLVMAssembly(approachtakenby</code><a href="http://www.cs.uu.nl/wiki/Ehc/WebHome"><code>EHC's</code></a><code>LLVMBack-end,canusethe</code><a href="https://subversion.cs.uu.nl/repos/project.UHC.pub/trunk/EHC/src/ehc/LLVM.cag"><code>module</code></a><code>developedbythemforthis)</code><br />
<code>*EmitLLVMBitcode(can'tseeanyreasontodothis)</code></p>
<p>The approach taken was to use the LLVM module from <a href="http://www.cs.uu.nl/wiki/Ehc/WebHome">EHC</a>. This module contains an abstract syntax representation of LLVM Assembly and the ability to pretty print it. It has been heavily modified to increase its language coverage as it was missing several LLVM constructs which were needed. Ideally we would like to add a second pretty printer which calls into the LLVM C++ API to generate LLVM Bitcode. This should hopefully decrease the compile times and make the back-end more resilient to future changes to LLVM Assembly. The LLVM Haskell binding (first option) wasn't used as it represents LLVM at a very high level, which isn't appropriate for the back-end.</p>
<h2 id="register-pinning">Register Pinning</h2>
<p>The new back-end supports a custom calling convention to place the STG virtual registers into specific hardware registers. The current approach taken by the C back-end and NCG of having a fixed assignment of STG virtual registers to hardware registers for performance gains is not implemented in the LLVM back-end. Instead, it uses a custom calling convention to support something semantically equivalent to register pinning. The custom calling convention passes the first N variables in specific hardware registers, thus guaranteeing on all function entries that the STG virtual registers can be found in the expected hardware registers. This approach is believed to provide better performance than the register pinning used by NCG/C back-ends as it keeps the STG virtual registers mostly in hardware registers but allows the register allocator more flexibility and access to all machine registers.</p>
<p>For some more information about the use of a custom calling convention see <a href="http://www.nondot.org/sabre/LLVMNotes/GlobalRegisterVariables.txt">here (Discussion between Chris Lattner and David Terei)</a></p>
<h2 id="code-generation">Code Generation</h2>
<p>Code generation consists of translating a list of `GenCmmTop` data types to LLVM code. `GenCmmTop` has the following form:</p>
<p></p>
<p>That is, it consists of two types, static data and functions. Each can largely be handled separately. Just enough information is needed such that pointers can be constructed to them and in many cases this information can be gathered from assumptions and constraints on Cmm.</p>
<p>After all the polymorphic types are bound we get this: </p>
<p>The code generator lives in `llvmGen` with the driver being `llvmGen/LlvmCodeGen.lhs`.</p>
<p>A large part of the code generation is keeping track of defined variables/functions and their type. An `LlvmEnv` construct is used for this. It is simply a dictionary storing function/variable names with their corresponding type information. This is used to create correct references/pointers between variables and functions.</p>
<h3 id="unregisterised-vs.-registerised">Unregisterised Vs. Registerised</h3>
<p>Code generation can take place in two general modes, `unregisterised` and `registerised`. There are two major differences from a back-end code generation point of view. Firstly, in unregisterised mode a optimisation feature called  is disabled. This means that the `h` field of `CmmProc` is empty. In registerised mode it instead contains the `CmmStatic` data for the procedures info table which must be placed just before the procedure in the generated code so that both the info table and procedure can be accessed through one pointer. This optimisation can be disabled separately though in `registerised` mode.</p>
<p>The other major change is the use of pinned global registers. The `Cmm` language includes a concept called registers. These are used like machine registers or variables in C to store the result of expressions. Unlike `LLVM` they are mutable. `Cmm` includes two types of registers as you can see below:</p>
<p></p>
<p>A `LocalReg` is a temporary general purpose register used in a procedure with scope of a single procedure. A `GlobalReg` on the other hand has global scope and a specific use. They are used just like machine registers, with a Stack Pointer and Heap Pointer registers creating a virtual machine (`STG`). `GlobalReg` is of the form:</p>
<p></p>
<p>In unregisterised mode these global registers are all just stored in memory in the heap. A specific pass operating on Cmm that takes place just before code generation thus transforms code such as:</p>
<p></p>
<p>into the following unregisterised form for code generation:</p>
<p></p>
<p>Where `MainCapability` is a label to the start of a RTS defined structure storing all the global registers.</p>
<p>In registerised mode as many of these global registers are assigned permanently to fixed hardware registers. This is done as it greatly improves performance. As these registers are accessed very frequently needing to load and store to memory for accessing adds a great cost. So for example on `x86` the following map between `Cmm` global registers and `x86` hardware registers exists:</p>
<p></p>
<p>These are all the available `callee save` registers on x86. `callee save` are used as in ghc generated code now saving and restoring of these registers are needed due to there new special use and because GHC uses continuation passing style, so a `'ret'` statement is never actually generated. And since they are `callee save`, foreign code can also be called without any need to handle the `Cmm` registers.</p>
<h2 id="cmmdata">!CmmData</h2>
<p>`CmmData` takes the following form:</p>
<p></p>
<p>Code generation takes place mainly in , driven by the main Llvm compiler driver, }.</p>
<p>The code generation for data occurs in two phases, firstly the types and all data is generated except for address values. Then the address values are resolved. This two step method is used as in the first pass, we don't know if a address refers to an external address or a procedure/data structure in the current LLVM module. We also need the type information in LLVM to create a pointer.</p>
<h3 id="st-pass-generation">1st Pass : Generation</h3>
<p>All `CmmStatic` is translated to LLVM structures.</p>
<h2 id="cmmstaticlit">!CmmStaticLit</h2>
<p>These are translated when possible as follows:</p>
<p><code>*`CmmInt`-&gt;ReducedtoIntandthenanappropriate`LMInt`ofcorrectsizeiscreated.AsLLVMsupportsanybitsize,thisisverystraightforward.</code><br />
<code>*`CmmFloat`-&gt;Translatedtoadouble,detectingNANandINFINITYcorrectly.ThencorrectLLVMtype(`float`,`double`,`float80`,`float128`)isselected.</code><br />
<code>*`CmmLabel`-&gt;Leftuntranslatedatfirst,laterresolvedoncewehavedeterminedtypes.Aspointersarecasttowordsizeints,wecanstilldeterminetypes.</code><br />
<code>*`CmmLabelOff`-&gt;Asabove.</code><br />
<code>*`CmmLabelDiffOff`-&gt;Asabove.</code><br />
<code>*`CmmBlock`-&gt;`BlockId`ischangedtoa`CLabel`andthentreatedasa`CmmLabel`statictype.</code><br />
<code>*`CmmHighStackMark`-&gt;Panicoccursifthistypeisencountered.</code></p>
<h4 id="cmmuninitialised">!CmmUninitialised</h4>
<p>For this, a zeroed array of `8bit` values is created of correct size.</p>
<h4 id="cmmalign-cmmdatalabel">!CmmAlign &amp; !CmmDataLabel</h4>
<p>The LLVM back-end can't handle `CmmAlign` or `CmmDataLabel`. A panic occurs if either is encountered. A `CmmDataLabel` is expected at the very start of each list of `CmmStatic`. It is removed and used as the name for the structure and constant instance.</p>
<h4 id="cmmstring">!CmmString</h4>
<p>This is translated into a LLVM string. Ascii characters are used when they are printable, escaped hex values otherwise. A null termination is added.</p>
<h3 id="nd-pass-resolution">2nd Pass : Resolution</h3>
<p>After the first pass, all types have been determined and all data translated except for address values (CLabel's). All generated llvm data is added to a Map of string to `LlvmType`, string being the data structure name. All `CmmProc's` are added to the map as well, they don't need to be properly passed though, just their names retrieved as they have a constant type of void return and no parameters.</p>
<p>Now appropriate pointers can be generated using the type information from the map and LLVM's `getelementptr` instruction. These are then all passed to int's to allow the types of structures to be determined in advance. If a pointer doesn't have a match in the Map, it is assumed to refer to an external (outside of this module) address. An external reference is declared for this address as:</p>
<p></p>
<p>Where i32 is the pointer size. (i64 if on 64 bit).</p>
<h2 id="cmmproc">!CmmProc</h2>
<p>A Cmm procedure is made up of a list of basic blocks, with each basic block being comprised of a list of CmmStmt</p>
<h1 id="desugaring-instance-declarations">Desugaring instance declarations</h1>
<p>These notes compare various ways of desugaring Haskell instance declarations. The tradeoffs are more complicated than I thought!</p>
<h2 id="basic-stuff">Basic stuff</h2>
<p> These desugar to the following Core:  (Notation: I am omitting foralls, big lambdas, and type arguments. I'm also using `f x = e` rather than `f = \x.e`.)</p>
<p>Points worth noting:</p>
<p><code>*Theclassgivesrisetoaneponymousdatatype(inGHCitisactually</code><br />
<code>called`:TC`),thedictionary.</code></p>
<p><code>*Thereisaneponymoustop-levelselectorfunctionforeachclassmethod,</code><br />
<code>`opF`and`opG`inthiscase.</code></p>
<p><code>*Thedefaultmethodfor`opG`becomesatop-levelfunction`$dmopG`.</code><br />
<code>Ittakesthe`(Ca)`dictionaryaargumentbecausetheRHSisallowedtocall</code><br />
<code>othermethodsofC.</code></p>
<p><code>*Theinstancedeclarationdefinesadictionary`dCInt`.Notice</code><br />
<code>thatit'srecursive,becausewemustpass`dCInt`to`opGI`.</code></p>
<p><code>*Crucially,thesimplifieriscarefulnottochoose`dCInt`as</code><br />
<code>aloopbreaker,andhenceifitsees`casedCIntof...`it</code><br />
<code>cansimplifythe`case`.</code></p>
<p><code>*If`$dmopG`isinlined,therecursionisbrokenanyway.</code></p>
<h2 id="dictionary-functions">Dictionary functions</h2>
<p>Now consider an instance declaration that has a context:  Here is one way to desugar it.  Notice that</p>
<p><code>*Ifweinlinetheselector`opF`in`opFd_as`,then</code><br />
<code>wecansimplify`opfl`togiveadirectly-recursivefunction:</code></p>
<p></p>
<p><code>Thisisimportant.</code></p>
<p><code>*TheBADTHINGisthat`dCList`isbig,andhencewon'tbeinlined.</code><br />
<code>That'sbadbecauseitmeansthatifwesee</code></p>
<p></p>
<p><code>wedon'tgettocall`opfl`directly.Insteadwe'llcall`dCList`,build</code><br />
<code>thedictionary,dotheselection,etc.Sospecialiationwon'thappen,</code><br />
<code>evenwhenallthetypesarefixed.</code></p>
<h2 id="the-inline-strategy">The INLINE strategy</h2>
<p>An obvious suggestion, which GHC implemented for a long time, is to give `dCList` an INLINE pragma. Then it'll inline at every call site, the dictionary will be visible to the selectors, and good things happen.</p>
<p>But it leads to a huge code blow-up in some cases. We call these dictionary functions a lot, often in a nested way, and we know programs for which the INLINE-all-dfuns approach generates gigantic code. (Example: Serge's !DoCon.)</p>
<h2 id="the-out-of-line-a-strategy">The out-of-line (A) strategy</h2>
<p>The INLINE strategy would make sense if `dCList` could be guaranteed small. Suppose the original instance declaration had been like this:  This is exactly what GHC 6.10 now does, behind the scenes. Desugaring just as above, we'd get the following:  Notice that</p>
<p><code>*`dCList`isguaranteedsmall,andcouldreasonablybeINLINEd</code><br />
<code>ateverycallsite.Thisgoodbecauseitexposesthedictionary</code><br />
<code>structuretoselectors.</code></p>
<p><code>*`dCList`and`opF_aux`aremutuallyrecursive.Butifwe</code><br />
<code>avoidchoosing`dCList`astheloopbreakerwecaninline</code><br />
<code>`dCList`into`opF_aux`,andthenthe`opF`selector</code><br />
<code>can&quot;see&quot;thedictionarystructure,and`opF_aux`simplifies,thus:</code></p>
<p></p>
<p><code>Good!Now`opF_aux`isself-recursiveasitshouldbe.</code><br />
<code>Thesamethinghappenswithtwomutuallyrecursivemethods</code></p>
<p><code>*BUTnoticethatwereconstructthe`(C[a])`dictionaryon</code><br />
<code>eachiterationoftheloop.AsGaneshpointsoutin#3073,that</code><br />
<code>issometimesbad.</code></p>
<h2 id="the-out-of-line-b-strategy">The out-of-line (B) strategy</h2>
<p>We can avoid reconstructing the dictionary by passing it to `opF_aux`, by recasting latter thus:  Notice the extra `C [a]` in the context of `opF_aux`. (Remember this is all internal to GHC.) Now the same desugaring does this:  The two definitions aren't even recursive. BUT now that `d_as` is an <em>argument</em> of `opF_aux`, the latter can't &quot;see&quot; that it's always a dictionary! Sigh. As a result, the recursion in `opF_aux` always indirects through the (higher order) dictionary argument, using a so-called &quot;unknown&quot; call, which is <em>far</em> less efficient than direct recursion.</p>
<p>Note also that</p>
<p><code>*Typechecking`opF_aux`isabitfragile;see#3018.Troubleisthat</code><br />
<code>whenaconstraint`(C[a])`arisesinitsRHStherearetwoways</code><br />
<code>ofdischargingit:byusingtheargument`d_as`directly,orby</code><br />
<code>calling`(dCListd_a)`.As#3018shows,it'shardtoguaranteethat</code><br />
<code>we'lldotheformer.</code></p>
<h2 id="user-inline-pragmas-and-out-of-line-a">User INLINE pragmas and out-of-line (A)</h2>
<p>There is another difficulty with the out-of-line(A) strategy, that is currently unsolved. Consider something like this:  Then we'll desugar to something like this:  The INLINE on `dCT` is added by the compiler; the INLINE on `opF_aux` is just propagated from the users's INLINE pragma... maybe the RHS is big.</p>
<p>Now the difficulty is that we GHC currently doesn't inline into the RHS of an INLINE function (else you'd get terrible code blowup). So the recursion between `dCT` and `opF_aux` is not broken. One of the two must be chosen as loop breaker, and the simplifier chooses `opF_aux`. Ironcially, therefore the user INLINE pragma has served only to guarantee that it <em>won't</em> be inlined!!</p>
<p>(This issue doesn't arise with out-of-line(B) because (B) doesn't make `dCT` and `opF_aux` mutually recursive.)</p>
<h2 id="summary">Summary</h2>
<p>Here are the current (realistic) options:</p>
<p><code>*Out-of-line(A):GHC6.10doesthis.</code><br />
<code>*Good:recursivemethodsbecomedirectlymutually-recursive</code><br />
<code>*Bad:lackofmemoisation</code><br />
<code>*Bad:difficultywithuserINLINEpragmas</code></p>
<p><code>*Out-of-line(B)</code><br />
<code>*Good:memoisationworks</code><br />
<code>*Verybad:recursivemethodsiterateonlyvia&quot;unknown&quot;calls.</code><br />
<code>*Good:nodifficultywithuserINLINEpragmas</code></p>
<p>My current difficulty is that I see no way to get all the good things at once.</p>
<p>PS: see also the comments at the start of `compiler/typecheck/TcInstDcls.lhs`, which cover some of the same ground.</p>
<h1 id="bugs-other-problems">Bugs &amp; Other Problems</h1>
<p>I've moved all known bugs into the trac bug database, the can be found <a href="http://hackage.haskell.org/trac/ghc/query?status=infoneeded&amp;status=merge&amp;status=new&amp;status=patch&amp;component=Compiler+%28LLVM%29&amp;order=priority&amp;col=id&amp;col=summary&amp;col=status&amp;col=type&amp;col=priority&amp;col=milestone&amp;col=component">here</a></p>
<h1 id="compiling-more-than-one-module-at-once">Compiling more than one module at once</h1>
<p>When compiling a single module, we can assume that all of our dependencies have already been compiled, and query the environment as necessary when we need to do things like look up interfaces to find out what the types in our dependencies are. When we compile more than module at once, as in `--make`, things get a bit more complicated:</p>
<p>1. We have to analyze the dependency structure of the program in question, and come up with a plan for how to compile the various modules, and</p>
<p>2. We have an opportunity to cache and reuse information from interface files which we may load from the environment. This is why, for example, `ghc --make` outperforms parallel one-shot compilation on one core.</p>
<p>This discussion is going to omit concerns related to dynamic code loading in GHC (as would be the case in GHCi).</p>
<h2 id="the-overall-driver">The overall driver</h2>
<p>The meat of this logic is in <a href="GhcFile(compiler/main/GhcMake.hs)" class="uri" title="wikilink">GhcFile(compiler/main/GhcMake.hs)</a>, with primary entry point the function `load` (in the case of `--make`, this function is called with `LoadAllTargets`, instructing all target modules to be compiled, which is stored in `hsc_targets`).</p>
<h3 id="dependency-analysis-1">Dependency analysis</h3>
<p>Dependency analysis is carried out by the `depanal` function; the resulting `ModuleGraph` is stored into `hsc_mod_graph`. Essentially, this pass looks at all of the imports of the target modules (`hsc_targets`), and recursively pulls in all of their dependencies (stopping at package boundaries.) The resulting module graph consists of a list of `ModSummary` (defined in <a href="GhcFile(compiler/main/HscTypes.lhs)" class="uri" title="wikilink">GhcFile(compiler/main/HscTypes.lhs)</a>), which record various information about modules prior to compilation (recompilation checking, even), such as their module identity (the current package name plus the module name), whether or not the file is a boot file, where the source file lives. Dependency analysis inside GHC is often referred to as **downsweep**.</p>
<p>ToDo: say something about how hs-boot files are</p>
<p>The dependency analysis is cached (in `hsc_mod_graph`), so later calls to `depanal` can reuse this information. (This is not germane for `--make`, which only calls `depanal` once.) `discardProg` deletes this information entirely, while `invalidateModSummaryCache` simply &quot;touches&quot; the timestamp associated with the file so that we resummarize it.</p>
<p>The result of dependency analysis is topologically sorted in `load` by `topSortModuleGraph`.</p>
<h3 id="recompilation-checking-and-stability">Recompilation checking and stability</h3>
<p>See also the page on [wiki:Commentary/Compiler/RecompilationAvoidance recompilation avoidance].</p>
<p>ToDo: say something about stability; it's per SCC</p>
<h3 id="compilation">Compilation</h3>
<p>Compilation, also known as **upsweep**, walks the module graph in topological order and compiles everything. Depending on whether or not we are doing parallel compilation, this implemented by `upsweep` or by `parUpsweep`. In this section, we'll talk about the sequential upsweep.</p>
<p>The key data structure which we are filling in as we perform compilation is the **home package table** or HPT (`hsc_HPT`, defined in <a href="GhcFile(compiler/main/HscTypes.lhs)" class="uri" title="wikilink">GhcFile(compiler/main/HscTypes.lhs)</a>). As its name suggests, it contains informations from the *home package*, i.e. the package we are currently compiling. Its entries, `HomeModInfo`, contain the sum total knowledge of a module after compilation: both its pre-linking interface `ModIface` as well as the post-linking details `ModDetails`.</p>
<p>We *clear* out the home package table in the session (for `--make`, this was empty anyway), but we pass in the old HPT.</p>
<p>ToDo: talk about how we fix up loops after we finish the loop</p>
<p>Finally, when the module is completely done being compiled, it is registered in the home package table</p>
<p>ToDo: Talk about what happens when we fail while in the middle of compiling a module cycle</p>
<h1 id="eager-promotion">Eager Promotion</h1>
<p>Eager promotion is a technique we use in GHC to improve the performance of generational GC. It is somewhat specific to the characteristics of lazy evaluation, since it takes advantage of the fact that we have some objects that are mutated just once (i.e. thunks).</p>
<p>The key observation is this: when an object P contains a pointer to an object Q in a younger generation, and P is not mutable, then we know that Q cannot be garbage collected until the generation in which P resides is collected. Hence, we might as well promote Q to this generation immediately, rather than [wiki:Commentary/Rts/Storage/GC/Aging aging] it or promoting it to an intermediate generation. Furthermore, if eager promotion is successful, then the object containing the old-to-new pointers will no longer need to be in the [wiki:Commentary/Rts/Storage/GC/RememberedSets remembered set] for the generation it resides in.</p>
<p>We gave some performance results for this technique in <a href="http://www.haskell.org/~simonmar/papers/multicore-ghc.pdf">Runtime Support for Multicore Haskell</a>; the upshot is that it's worth 10% or so.</p>
<p>Eager promotion works like this. To do eager promtion, the scavenger sets the flag `gct-&gt;eager_promotion` (it can leave the flag set when scavenging multiple objects, this is the usual way), and `gct-&gt;evac_gen` is set to the generation to which to eagerly promote objects. The `evacuate` function will try to move each live object into `gct-&gt;evac_gen` or a higher generation if possible, and set `gct-&gt;failed_to_evac` if it fails (see [wiki:Commentary/Rts/Storage/GC/RememberedSets]). It may fail if the target object has already been moved: we can't move an object twice during GC, because there may be other pointers already updated to point to the new location. It may also fail if the object is in a generation that is not being collected during this cycle.</p>
<p>Objects which are repeatedly mutable should not be subject to eager promotion, because the object may be mutated again, so eagerly promoting the objects it points to may lead to retaining garbage unnecessarily. Hence, when we are scavenging a mutable object (see <a href="GhcFile(rts/sm/Scav.c)" class="uri" title="wikilink">GhcFile(rts/sm/Scav.c)</a>), we temporarily turn off `gct-&gt;eager_promotion`.</p>
<h1 id="eager-version-bumping-strategy">Eager Version Bumping Strategy</h1>
<p>Versioning of GHC core/boot libraries adheres to Haskell's <a href="https://wiki.haskell.org/Package_versioning_policy">Package Versioning Policy</a> whose scope is considered to apply to **released artifacts** (and therefore doesn't prescribe when to //actually// perform version increments during development)</p>
<p>However, in the spirit of continuous integration, GHC releases snapshot artifacts, and therefore it becomes important for early testers/evaluators/package-authors to be presented with accurate PVP-adhering versioning, especially for those who want adapt to upcoming API changes in new major GHC releases early (rather than being hit suddenly by a disruptive version-bump-wave occurring at GHC release time).</p>
<p>So while the usual scheme is to update a package version in the VCS right before a release (and reviewing at that point whether a patchlevel, minor or major version bump is mandated by the PVP), for GHC bundled core/boot packages, the **eager version bumping** scheme is preferred, which basically means:</p>
<p></p>
<p>This becomes particularly easy when also maintaining a `changelog` file during development highlighting the changes for releases, as then one easily keeps track of the last released version, as well as becoming aware more easily of minor/major version increment-worthy API changes.</p>
<p>Video: <a href="http://www.youtube.com/watch?v=pN9rhQHcfCo&amp;list=PLBkRCigjPwyeCSD_DFxpd246YIF7_RDDI">Types and Classes</a> (23'53&quot;)</p>
<h1 id="data-types-for-haskell-entities-and">Data types for Haskell entities: , , , , and </h1>
<p>For each kind of Haskell entity (identifier, type variable, type constructor, data constructor, class) GHC has a data type to represent it. Here they are:</p>
<p><code>*</code><strong><code>Type</code> <code>constructors</code></strong><code>arerepresentedbythe</code><code>type(</code><a href="GhcFile(compiler/types/TyCon.hs)" title="wikilink"><code>GhcFile(compiler/types/TyCon.hs)</code></a><code>).</code><br />
<code>*</code><strong><code>Classes</code></strong><code>arerepresentedbythe</code><code>type(</code><a href="GhcFile(compiler/types/Class.hs)" title="wikilink"><code>GhcFile(compiler/types/Class.hs)</code></a><code>).</code><br />
<code>*</code><strong><code>Data</code> <code>constructors</code></strong><code>arerepresentedbythe</code><code>type(</code><a href="GhcFile(compiler/basicTypes/DataCon.hs)" title="wikilink"><code>GhcFile(compiler/basicTypes/DataCon.hs)</code></a><code>).</code><br />
<code>*</code><strong><code>Pattern</code> <code>synonyms</code></strong><code>arerepresentedbythe</code><code>type(</code><a href="GhcFile(compiler/basicTypes/PatSyn.hs)" title="wikilink"><code>GhcFile(compiler/basicTypes/PatSyn.hs)</code></a><code>).</code><br />
<code>*</code><strong><code>Term</code> <code>variables</code></strong><code></code><code>and</code><strong><code>type</code> <code>variables</code></strong><code></code><code>arebothrepresentedbythe</code><code>type(</code><a href="GhcFile(compiler/basicTypes/Var.hs)" title="wikilink"><code>GhcFile(compiler/basicTypes/Var.hs)</code></a><code>).</code></p>
<p>All of these entities have a , but that's about all they have in common. However they are sometimes treated uniformly:</p>
<p><code>*A</code><strong><code>`TyThing`</code></strong><code>(</code><a href="GhcFile(compiler/types/TypeRep.hs)" title="wikilink"><code>GhcFile(compiler/types/TypeRep.hs)</code></a><code>)issimplythesumofallfour:</code></p>
<p></p>
<p><code>Forexample,atypeenvironmentisamapfrom</code><code>to</code><code>.(Thefactthata</code><code>tellswhatnamespaceitbelongstoallow,forexample,identicallynamedvaluesandtypestositinasinglemap.)</code></p>
<p>All these data types are implemented as a big record of information that tells you everything about the entity. For example, a  contains a list of its data constructors; a  contains its type (which mentions its ); a  contains the s of all its method selectors; and an  contains its type (which mentions type constructors and classes).</p>
<p>So you can see that the GHC data structures for entities is a <em>graph</em> not tree: everything points to everything else. This makes it very convenient for the consumer, because there are accessor functions with simple types, such as . But it means that there has to be some tricky almost-circular programming (&quot;knot-tying&quot;) in the type checker, which constructs the entities.</p>
<h2 id="type-variables-and-term-variables">Type variables and term variables</h2>
<p>Type variables and term variables are represented by a single data type, , thus (<a href="GhcFile(compiler/basicTypes/Var.hs)" class="uri" title="wikilink">GhcFile(compiler/basicTypes/Var.hs)</a>):  It's incredibly convenient to use a single data type for both, rather than using one data type for term variables and one for type variables. For example:</p>
<p><code>*Findingthefreevariablesofatermgivesasetofvariables(bothtypeandtermvariables):</code><code>.</code><br />
<code>*WeonlyneedonelambdaconstructorinCore:</code><code>.</code></p>
<p>The  type distinguishes the two sorts of variable; indeed, it makes somewhat finer distinctions (<a href="GhcFile(compiler/basicTypes/Var.hs)" class="uri" title="wikilink">GhcFile(compiler/basicTypes/Var.hs)</a>):  Every  has fields  and a . The latter is identical to the  in the former, but is cached in the  for fast comparison.</p>
<p>Here are some per-flavour notes:</p>
<p><code>::isselfexplanatory.</code></p>
<p><code>::isusedduringtype-checkingonly.Oncetypecheckingisfinished,therearenomore</code><code>s.</code></p>
<p><code>::isusedfortermvariablesbound</code><em><code>in</code> <code>the</code> <code>module</code> <code>being</code> <code>compiled</code></em><code>.Morespecifically,a</code><code>isboundeither</code><em><code>within</code></em><code>anexpression(lambda,case,locallet),oratthetoplevelofthemodulebeingcompiled.</code><br />
<code>*The</code><code>ofa</code><code>maychangeasthesimplifierrepeatedlybashesonit.</code><br />
<code>*A</code><code>carriesaflagsayingwhetherit'sexported.Thisisusefulforknowingwhetherwecandiscarditifitisnotused.</code></p>
<p></p>
<p><code>::isusedforfixed,immutable,top-leveltermvariables,notablyonesthatareimportedfromothermodules.Thismeansthat,forexample,theoptimizerwon'tchangeitsproperties.</code><br />
<code>*Alwayshasan</code><code>or</code><code>[wiki:Commentary/Compiler/NameTypeName],andhencehasa</code><code>thatisgloballyuniqueacrossthewholeofaGHCinvocation.</code><br />
<code>*Alwaysboundattoplevel.</code><br />
<code>*The</code><code>ofa</code><code>iscompletelyfixed.</code><br />
<code>*AllimplicitIds(dataconstructors,classmethodselectors,recordselectorsandthelike)areare</code><code>sfrombirth,eventheonesdefinedinthemodulebeingcompiled.</code><br />
<code>*Whenfindingthefreevariablesofanexpression(</code><code>),weonlycollect</code><code>andignore</code><code>.</code></p>
<p>All the value bindings in the module being compiled (whether top level or not) are s until the !CoreTidy phase. In the !CoreTidy phase, all top-level bindings are made into s. This is the point when a  becomes &quot;frozen&quot; and becomes a fixed, immutable .</p>
<h2 id="and-implict-ids"> and implict Ids</h2>
<p>s are further classified by their . This type is defined in <a href="GhcFile(compiler/basicTypes/IdInfo.hs)" class="uri" title="wikilink">GhcFile(compiler/basicTypes/IdInfo.hs)</a>, because it mentions other structured types such as . Unfortunately it is <em>used</em> in Var.hs so there's a hi-boot knot to get it there. Anyway, here's the declaration (elided a little):  Some s are called <strong>implicit s</strong>. These are s that are defined by a declaration of some other entity (not just an ordinary variable binding). For example:</p>
<p><code>*Theselectorsofarecordtype</code><br />
<code>*Themethodselectorsofaclass</code><br />
<code>*TheworkerandwrapperIdforadataconstructor</code></p>
<p>It's easy to distinguish these Ids, because the  field says what kind of thing it is: .</p>
<h1 id="hc-files-and-the-evil-mangler">HC files and the Evil Mangler</h1>
<p>GHC no longer has an evil mangler.</p>
<h1 id="strictness-analysis-examples">Strictness analysis: examples</h1>
<p>Consider:</p>
<p></p>
<p>We want to make sure to figure out that f's argument is demanded with type L1X(L1X(LMX)) -- that is, it may or may not be demanded, but if it is, it's always applied to two arguments. This shows why  shouldn't just throw away the argument info: in this case, the  expression has a nonstrict demand placed on it, yet we still care about the arguments.</p>
<p>On the other hand, in:  we want to say that if the result of  has demand  placed on it (i.e., not a call demand), the body of  has demand  placed on it, not . So this case needs to be treated differently from the one above.</p>
<h1 id="system-fc-equality-constraints-and-coercions">System FC: equality constraints and coercions</h1>
<p>For many years, GHC's intermediate language was essentially:</p>
<p><code>*SystemFw,plus</code><br />
<code>*algebraicdatatypes(includingexistentials)</code></p>
<p>But that is inadequate to describe GADTs and associated types. So in 2006 we extended GHC to support System FC, which adds</p>
<p><code>*equalityconstraintsandcoercions</code></p>
<p>You can find a full description of FC in the paper <a href="http://research.microsoft.com/~simonpj/papers/ext-f">3</a>; note that GHC uses the system described in post-publication Appendix C, not the system in the main body of the paper. The notes that follow sketch the implementation of FC in GHC, but without duplicating the contents of the paper.</p>
<p>A coercion `c`, is a type-level term, with a kind of the form `T1 :=: T2`. (`c :: T1 :=: T2`) is a proof that a term of type `T1` can be coerced to type `T2`. Coercions are classified by a new sort of kind (with the form ). Most of the coercion construction and manipulation functions are found in the  module, <a href="GhcFile(compiler/types/Coercion.hs)" class="uri" title="wikilink">GhcFile(compiler/types/Coercion.hs)</a>.</p>
<p>Coercions appear in Core in the form of  expressions: if `t :: T1` and `c :: T1:=:T2`, then . See [wiki:Commentary/Compiler/CoreSynType].</p>
<h2 id="coercions-and-coercion-kinds">Coercions and Coercion Kinds</h2>
<p>The syntax of coercions extends the syntax of types (and the type `Coercion` is just a synonym for `Type`). By representing coercion evidence on the type level, we can take advantage of the existing erasure mechanism and keep non-termination out of coercion proofs (which is necessary to keep the system sound). The syntax of coercions and types also overlaps a lot. A normal type is evidence for the reflexive coercion, i.e.,  Coercion variables are used to abstract over evidence of type equality, as in </p>
<p>There are also coercion constants that are introduced by the compiler to implement some source language features (newtypes for now, associated types soon and probably more in the future). Coercion constants are represented as `TyCon`s made with the constructor `CoercionTyCon`.</p>
<p>Coercions are type level terms and can have normal type constructors applied to them. The action of type constructors on coercions is much like in a logical relation. So if `c1 :: T1 :=: T2` then</p>
<p></p>
<p>and if `c2 :: S1 :=: S2` then  The sharing of syntax means that a normal type can be looked at as either a type or as coercion evidence, so we use two different kinding relations, one to find type-kinds (implemented in Type as `typeKind :: Type -&gt; Kind`) and one to find coercion-kinds (implemented in Coercion as `coercionKind :: Coercion -&gt; Kind`).</p>
<p>Coercion variables are distinguished from type variables, and non-coercion type variables (just like any normal type) can be used as the reflexive coercion, while coercion variables have a particular coercion kind which need not be reflexive.</p>
<h2 id="gadts">GADTs</h2>
<p>The internal representation of GADTs is as regular algebraic datatypes that carry coercion evidence as arguments. A declaration like  would result in a data constructor with type  This means that (unlike in the previous intermediate language) all data constructor return types have the form `T a1 ... an` where `a1` through `an` are the parameters of the datatype.</p>
<p>However, we also generate wrappers for GADT data constructors which have the expected user-defined type, in this case  Where the 4th and 5th arguments given to `T1` are the reflexive coercions </p>
<h2 id="representation-of-coercion-assumptions">Representation of coercion assumptions</h2>
<p>In most of the compiler, as in the FC paper, coercions are abstracted using `ForAllTy cv ty` where `cv` is a coercion variable, with a kind of the form `PredTy (EqPred T1 T2)`. However, during type inference it is convenient to treat such coercion qualifiers in the same way other class membership or implicit parameter qualifiers are treated. So functions like `tcSplitForAllTy` and `tcSplitPhiTy` and `tcSplitSigmaTy`, treat `ForAllTy cv ty` as if it were `FunTy (PredTy (EqPred T1 T2)) ty` (where `PredTy (EqPred T1 T2)` is the kind of `cv`). Also, several of the `dataCon`XXX functions treat coercion members of the data constructor as if they were dictionary predicates (i.e. they return the `PredTy (EqPred T1 T2)` with the theta).</p>
<h2 id="newtypes-are-coerced-types">Newtypes are coerced types</h2>
<p>The implementation of newtypes has changed to include explicit type coercions in the place of the previously used ad-hoc mechanism. For a newtype declared by  the `NewTyCon` for `T` will contain n`t_co = CoT` where:  This `TyCon` is a `CoercionTyCon`, so it does not have a kind on its own; it basically has its own typing rule for the fully-applied version. If the newtype `T` has k type variables, then `CoT` has arity at most k. In the case that the right hand side is a type application ending with the same type variables as the left hand side, we &quot;eta-contract&quot; the coercion. So if we had  then we would generate the arity 0 coercion `CoS : S :=: []`. The primary reason we do this is to make newtype deriving cleaner. If the coercion cannot be reduced in this fashion, then it has the same arity as the tycon.</p>
<p>In the paper we'd write  and then when we used `CoT` at a particular type, `s`, we'd say  which encodes as `(TyConApp instCoercionTyCon [TyConApp CoT [], s])`</p>
<p>But in GHC we instead make `CoT` into a new piece of type syntax (like `instCoercionTyCon`, `symCoercionTyCon` etc), which must always be saturated, but which encodes as  In the vocabulary of the paper it's as if we had axiom declarations like  The newtype coercion is used to wrap and unwrap newtypes whenever the constructor or case is used in the Haskell source code.</p>
<p>Such coercions are always used when the newtype is recursive and are optional for non-recursive newtypes. Whether or not they are used can be easily changed by altering the function mkNewTyConRhs in iface/BuildTyCl.lhs.</p>
<h2 id="roles">Roles</h2>
<p>Roles specify what nature of equality a coercion is proving. See [wiki:Roles] and RolesImplementation.</p>
<h2 id="simplification">Simplification</h2>
<p><code>*exprIsConApp_maybe</code></p>
<p><code>*simplExpr</code></p>
<h1 id="ghc-commentary-runtime-aspects-of-the-ffi">GHC Commentary: Runtime aspects of the FFI</h1>
<h2 id="foreign-import-wrapper">Foreign Import &quot;wrapper&quot;</h2>
<p>Files <a href="GhcFile(rts/Adjustor.c)" class="uri" title="wikilink">GhcFile(rts/Adjustor.c)</a> <a href="GhcFile(rts/AdjustorAsm.S)" class="uri" title="wikilink">GhcFile(rts/AdjustorAsm.S)</a>.</p>
<p>Occasionally, it is convenient to treat Haskell closures as C function pointers. This is useful, for example, if we want to install Haskell callbacks in an existing C library. This functionality is implemented with the aid of adjustor thunks.</p>
<p>An adjustor thunk is a dynamically allocated code snippet that allows Haskell closures to be viewed as C function pointers.</p>
<p>Stable pointers provide a way for the outside world to get access to, and evaluate, Haskell heap objects, with the RTS providing a small range of ops for doing so. So, assuming we've got a stable pointer in our hand in C, we can jump into the Haskell world and evaluate a callback procedure, say. This works OK in some cases where callbacks are used, but does require the external code to know about stable pointers and how to deal with them. We'd like to hide the Haskell-nature of a callback and have it be invoked just like any other C function pointer.</p>
<p>Enter adjustor thunks. An adjustor thunk is a little piece of code that's generated on-the-fly (one per Haskell closure being exported) that, when entered using some 'universal' calling convention (e.g., the C calling convention on platform X), pushes an implicit stable pointer (to the Haskell callback) before calling another (static) C function stub which takes care of entering the Haskell code via its stable pointer.</p>
<p>An adjustor thunk is allocated on the C heap, and is called from within Haskell just before handing out the function pointer to the Haskell (IO) action. User code should never have to invoke it explicitly.</p>
<p>An adjustor thunk differs from a C function pointer in one respect: when the code is through with it, it has to be freed in order to release Haskell and C resources. Failure to do so will result in memory leaks on both the C and Haskell side.</p>
<hr />
<p>CategoryStub</p>
<h1 id="function-calls">Function Calls</h1>
<p>Source files: <a href="GhcFile(rts/Apply.h)" class="uri" title="wikilink">GhcFile(rts/Apply.h)</a>, <a href="GhcFile(rts/Apply.cmm)" class="uri" title="wikilink">GhcFile(rts/Apply.cmm)</a></p>
<p>Dealing with calls is by far the most complicated bit of the execution model, and hence of the code generator. GHC uses an <em>eval/apply</em> strategy for compiling function calls; all the details of the design are in the paper <a href="http://www.haskell.org/~simonmar/papers/eval-apply.pdf">Making a fast curry: push/enter vs. eval/apply for higher-order languages</a>.</p>
<p>First, we need some terminology:</p>
<p><code>*The</code><strong><code>arity</code></strong><code>ofafunctionisthenumberoflambdasstaticallyusedin[wiki:Commentary/Compiler/StgSynTypethelambda-formofitsdefinition].Notethatarityisnotdeduciblefromthetype.Example:</code></p>
<p></p>
<p><code>Here,`f`hasarity1,eventhoughitstypesuggestsittakestwoarguments.Thepointisthatthecompiledcodefor`f`willexpecttobepassedjustoneargument,`x`.</code></p>
<p><code>*The</code><strong><code>entry</code> <code>point</code></strong><code>(sometimescalledthe</code><strong><code>fast</code> <code>entry</code> <code>point</code></strong><code>)ofafunctionofarityNexpectsitsfirstNargumentstobepassedinaccordancewiththestandard[wiki:Commentary/Rts/HaskellExecution/CallingConventioncallingconventions].</code></p>
<p><code>*A</code><strong><code>known</code> <code>call</code></strong><code>isacallofafunctionwhosebindingsiteisstaticallyvisible:</code><br />
<code>*Thefunctionisboundattoplevelinthismodule;or,</code><br />
<code>*Thefunctionisboundattoplevelinanothermodule,andoptimistionison,sowecanseethedetails(notablyarity)ofthefunctioninthemodule'sinterfacefile;or,</code><br />
<code>*Thefunctionisboundbyan`let`bindingthatenclosesthecall.</code></p>
<p>When compiling a call, there are several cases to consider, which are treated separately.</p>
<p><code>*</code><strong><code>Unknown</code> <code>function</code></strong><code>;acallinwhichwedonotstaticallyknowwhatthefunctionis.Inthatcasewemustdoa&quot;genericapply&quot;.Thisissoexcitingthatitdeservesits[wiki:Commentary/Rts/HaskellExecution/FunctionCalls#Genericapplyownsection].</code></p>
<p><code>*</code><strong><code>Known</code> <code>function,</code> <code>saturated</code> <code>call</code></strong><code>.Thefunctionisappliedtoexactlytherightnumberofargumentstosatisfyitsarity.Inthatcase,wesimplyloadtheargumentsaccordingtothestandardentryconvention,andtail-call(jumpto)thefunction'sentrypoint.Onaverage,about80%ofallcallsfallintothiscategory(seetheeval/applypaperformeasurements).</code></p>
<p><code>*</code><strong><code>Known</code> <code>function,</code> <code>too</code> <code>few</code> <code>arguments</code></strong><code>.Inthiscase,wewanttobuildapartialapplication(PAP),andreturnwithapointertothePAPinthereturnregister.SincebuildingaPAPisacomplicatedbusiness,insteadwejustbehaveasforanunknownfunctioncall,whichwillendupcallingintothe</code><a href="ref(Generic_apply)" title="wikilink"><code>ref(Generic</code> <code>apply)</code></a><code>code,whichwillbuildthePAPforus.</code></p>
<p><code>*</code><strong><code>Known</code> <code>function,</code> <code>too</code> <code>many</code> <code>arguments</code></strong><code>.Wewanttosavetheextraargumentsonthestack,pushareturnaddress,andthenbehavejustlikeasaturatedcall.Whentheresultcomesback,weshouldbehavelike&quot;unknowncall&quot;.However,toavoidneedingtogeneratecodeforanewcontinuationhere,thereturnaddressthatwepushonthestackisthatofanappropriate</code><a href="ref(Generic_apply)" title="wikilink"><code>ref(Generic</code> <code>apply)</code></a><code>function,whichwillperformtheapplicationoftheextraargumentstothe(unknown)functionreturnedbythesaturatedcall.</code></p>
<h2 id="generic-apply">Generic apply</h2>
<p>Files: <a href="GhcFile(utils/genapply)" class="uri" title="wikilink">GhcFile(utils/genapply)</a></p>
<p>When compiling a call that has an unknown function, we must generate code to</p>
<p><code>*Evaluatethefunction</code><br />
<code>*Scrutinisethefunctionvaluereturnedtoseeitsarity,anddispatchintothesamethreecasesasinthecaseofknowncalls:</code><br />
<code>*Exactlytherightnumberofarguments:loadthemintothestandardlocationsandtail-callthefunction'sentrypoint</code><br />
<code>*Toofewarguments:buildaPAP</code><br />
<code>*Toomanyarguments:savetheexcessarguments,andtailcallthefunctionasforasaturatedcal.</code></p>
<p>All of this takes quite a lot of code, so we pre-generate a whole bunch of generic-apply code sequencues, one for each combination of arguments. This code is generated by the tool <a href="GhcFile(utils/genapply)" class="uri" title="wikilink">GhcFile(utils/genapply)</a>, and the generated code appears in `rts/AutoApply.cmm`.</p>
<p>For example, if we find a call to an unknown function applied to two (boxed) `Int` arguments, load the function and its two arguments as for the standard entry convention and jump to `stg_ap_pp_fast`. This latter code is in `rts/AutoApply.cmm`, generated by the `genapply` tool. The &quot;`pp`&quot; part is the bit that says the code is specialised for two pointer arguments.</p>
<p>In addition to the family of `stg_ap_<pattern>_fast` functions for making calls to unknown functions with various argument patterns, there is a corresponding family of return addresses `stg_ap_<pattern>_info`. The idea is that you can push a continuation that will make a call to the function that is returned to it. For example, to push a continuation that will apply a single pointer argument, we would push the following words on the stack:</p>
<p>|| arg || || `stg_ap_p_info` ||</p>
<h1 id="the-garbage-collector">The Garbage Collector</h1>
<p>GC concepts:</p>
<p><code>*[wiki:Commentary/Rts/Storage/GC/AgingAging]</code><br />
<code>*[wiki:Commentary/Rts/Storage/GC/PinnedPinnedobjects]</code><br />
<code>*[wiki:Commentary/Rts/Storage/GC/RootsRoots]</code><br />
<code>*[wiki:Commentary/Rts/Storage/GC/EagerPromotionEagerpromotion]</code><br />
<code>*[wiki:Commentary/Rts/Storage/GC/RememberedSetsRememberedsets]</code><br />
<code>*[wiki:Commentary/Rts/Storage/GC/WeakWeakpointersandfinalizers]</code><br />
<code>*[wiki:Commentary/Rts/Storage/GC/CAFsCAFs]</code></p>
<p>GC algorithms supported:</p>
<p><code>*[wiki:Commentary/Rts/Storage/GC/CopyingCopyingGC]</code><br />
<code>*[wiki:Commentary/Rts/Storage/GC/ParallelParallelGC]</code><br />
<code>*[wiki:Commentary/Rts/Storage/GC/MarkingMarking](forcompactionorsweeping)</code><br />
<code>*[wiki:Commentary/Rts/Storage/GC/CompactionCompaction]</code><br />
<code>*[wiki:Commentary/Rts/Storage/GC/SweepingSweeping](formark-regionGC)</code><br />
<code>*[wiki:Commentary/Rts/Storage/GC/ImmixImmix](notsupportedyet)</code></p>
<h2 id="gc-overview">GC overview</h2>
<p>The GC is designed to be flexible, supporting lots of ways to tune its behaviour. Here's an overview of the techniques we use:</p>
<p><code>*GenerationalGC,witharuntime-selectablenumberofgenerations(`+RTS-G</code><n><code>-RTS`,where`n&gt;=1`).Currentlyitisa</code><br />
<code>traditionalgenerationalcollectorwhereeachcollectioncollectsaparticulargenerationandallyoungergenerations.</code><br />
<code>Generalizingthissuchthatanysubsetofgenerationscanbecollectedisapossiblefutureextension.</code></p>
<p><code>*Theheapgrowsondemand.Thisisstraightforwardlyimplementedbybasingthewholestoragemanagerona[wiki:Commentary/Rts/Storage/BlockAllocblockallocator].</code></p>
<p><code>*Aging:objectscanbeagedwithinageneration,toavoidprematurepromotion.See[wiki:Commentary/Rts/Storage/GC/Aging].</code></p>
<p><code>*Theheapcollectionpolicyisruntime-tunable.Youselecthowlargeagenerationgetsbeforeitiscollectedusingthe`+RTS-F</code><n><code>-RTS`option,where`</code><n><code>`isafactorofthegeneration'ssizethelasttimeitwascollected.Thedefaultvalueis2,thatisagenerationisallowedtodoubleinsizebeforebeingcollected.</code></p>
<h2 id="gc-data-structures">GC data structures</h2>
<p><a href="GhcFile(includes/rts/storage/GC.h)" class="uri" title="wikilink">GhcFile(includes/rts/storage/GC.h)</a></p>
<h3 id="generation">generation</h3>
<p>The main data structure is `generation`, which contains:</p>
<p><code>`blocks`::</code><br />
<code>apointertoalistofblocks</code></p>
<p><code>`large_objects`::</code><br />
<code>apointertoalistofblockscontaininglargeobjects</code></p>
<p><code>`threads`::</code><br />
<code>alistofthreadsinthisgeneration</code></p>
<p><code>`mut_list`::</code><br />
<code>the[wiki:Commentary/Rts/Storage/GC/RememberedSetsrememberedset],alistofblockscontainingpointerstoobjectsin</code><em><code>this</code></em><code>generationthatpointtoobjectsin</code><em><code>younger</code></em><code>generations</code></p>
<p>and various other administrative fields (see <a href="GhcFile(includes/rts/storage/GC.h)" class="uri" title="wikilink">GhcFile(includes/rts/storage/GC.h)</a> for the details).</p>
<p>Generations are kept in the array `generations[]`, indexed by the generation number.</p>
<h3 id="nursery">nursery</h3>
<p>A `nursery` is a list of blocks into which the mutator allocates new (small) objects. For reasons of locality, we want to re-use the list of blocks for the nursery after each GC, so we keep the nursery blocks rather than freeing and re-allocating a new nursery after GC.</p>
<p>The struct `nursery` contains only two fields</p>
<p><code>`blocks`::</code><br />
<code>thelistofblocksinthisnursery</code><br />
<code>`n_blocks`::</code><br />
<code>thenumberofblocksintheabovelist</code></p>
<p>In the threaded RTS, there is one nursery per Capability, as each Capability allocates independently into its own allocation area. Nurseries are therefore stored in an array `nurseries[]`, indexed by Capability number.</p>
<p>The blocks of the nursery notionally logically to generation 0, although they are not kept on the list `generations[0].blocks`. The reason is that we want to keep the actual nursery blocks separate from any blocks containing live data in generation 0. Generation 0 may contain live data for two reasons:</p>
<p><code>*objectsliveinthenurseryarenotpromotedtogeneration1immediately,insteadtheyare[wiki:Commentary/Rts/Storage/GC/Agingaged],firstbeingcopiedtogeneration0,andthenbeingpromotedtogeneration1inthenextGCcycleiftheyarestillalive.</code></p>
<p><code>*Ifthereisonlyonegeneration(generation0),thenliveobjectsingeneration0areretainedingeneration0afteraGC.</code></p>
<h1 id="i-know-kung-fu-learning-stg-by-example">I know kung fu: learning STG by example</h1>
<p>The STG machine is an essential part of GHC, the world's leading Haskell compiler. It defines how the Haskell evaluation model should be efficiently implemented on standard hardware. Despite this key role, it is generally poorly understood amongst GHC users. This document aims to provide an overview of the STG machine in its modern, eval/apply-based, pointer-tagged incarnation by a series of simple examples showing how Haskell source code is compiled.</p>
<h2 id="what-is-stg-exactly">What is STG, exactly?</h2>
<p>Haskell code being sucked through GHC has a complex lifecycle. Broadly speaking, it transitions between five representations:</p>
<p></p>
<p>The path from C-- to assembly varies: the three possible backends are C (`-fvia-c`), LLVM (`-fllvm`), and the default backend -- the native code genarator (or NCG), which generates assembly directly from the GHC-internal C-- data type.</p>
<p>STG is a simple functional language, rather like the more famous Core language. It differs in the following main respects:</p>
<p><code>1.Initscurrentincarnation,itisn'ttypedintheHaskellsense,</code><br />
<code>thoughitdoesknowabout</code><em><code>representation</code></em><code>types</code><br />
<code>2.Itisinadministrativenormalform(ANF),whichiswhereevery</code><br />
<code>subexpressionisgivenaname</code><br />
<code>3.Every$\lambda$,constructorapplication,andprimitiveoperator</code><br />
<code>is$\eta$-expanded</code><br />
<code>4.Itisannotatedwithatonofinformationthatthecode</code><br />
<code>generatorisinterestedinknowing</code></p>
<p>STG expressions can be one of the following:</p>
<p><code>1.Atoms(i.e.literalsandvariables)</code><br />
<code>2.`let`-bindings(bothrecursiveandnon-recursive)overanother</code><br />
<code>expression,wherelet-boundthingsareoneof:</code><br />
<code>*Afunctionvaluewithexplicitlambdas</code><br />
<code>*Anunsaturatedapplication</code><br />
<code>*Aconstructorappliedtoatoms</code><br />
<code>*Athunk(i.e.anyexpressionnotfittingintooneoftheabove</code><br />
<code>categories)</code></p>
<p><code>3.Saturatedprimitiveapplicationofaprimitivetovariables</code><br />
<code>4.Applicationofavariabletooneormoreatoms</code><br />
<code>5.Casedeconstructionofanexpression,whereeachbranchmayalso</code><br />
<code>beanexpression</code></p>
<p>The job of the <em>STG machine</em> is to evaluate these expressions in a way which is efficiently implementable on standard hardware. This document will look at how exactly this is achieved by looking at real examples of the C-- code GHC generates for various Haskell expressions.</p>
<p>This document will take a very low-level view of the machine, so if you want to get comfortable with how the STG machine executes at a more abstract level before reading this document, you might want to read the paper <a href="http://research.microsoft.com/en-us/um/people/simonpj/papers/eval-apply/">&quot;How to make a fast curry: push/enter vs. eval/apply&quot;</a>. It presents the STG machine without reference to an explicit stack or registers, but instead as a transition system. This transition system has also been implemented as a Haskell program called <a href="http://hackage.haskell.org/package/ministg">ministg</a> by <a href="http://ww2.cs.mu.oz.au/~bjpop/">Bernie Pope</a>, for those who wish to see it in action on some simple examples.</p>
<h2 id="an-overview-of-the-stg-machine">An overview of the STG machine</h2>
<p>Before we dive in, a note: this document will describe the STG machine as it is implemented on x86-style architectures. I will use the terms &quot;the STG machine&quot; and &quot;the STG machine as implemented on x86 by GHC&quot; interchangeably. The implementation is somewhat different on x64, not least due to the greater number of available registers.</p>
<p>This overview section is rather bare. Readers might be able to fill in any gaps in my explanation by using some of the following sources:</p>
<p><code>*</code><a href="http://hackage.haskell.org/trac/ghc/wiki/Commentary/Rts/HaskellExecution"><code>The</code> <code>Haskell</code> <code>Execution</code> <code>Model</code></a><br />
<code>*</code><a href="http://hackage.haskell.org/trac/ghc/wiki/Commentary/Rts/Storage"><code>Storage</code></a><br />
<code>*</code><a href="http://research.microsoft.com/en-us/um/people/simonpj/Papers/spineless-tagless-gmachine.ps.gz"><code>The</code> <code>Spineless</code> <code>Tagless</code> <code>G-machine</code></a><br />
<code>-nowsadlyratheroutofdate</code><br />
<code>*</code><a href="http://research.microsoft.com/en-us/um/people/simonpj/papers/ptr-tag/ptr-tagging.pdf"><code>Faster</code> <code>laziness</code> <code>through</code> <code>dynamic</code> <code>pointer</code> <code>tagging</code></a></p>
<h3 id="components-of-the-machine">Components of the machine</h3>
<p>In its bare essentials, the STG machine consists of three parts:</p>
<p><code>1.TheSTGregisters:</code><br />
<code>*Thereareratheralotofregistershere:morethancanbe</code><br />
<code>practicablystoredinactualavailableprocessorregistersonmost</code><br />
<code>architectures.</code><br />
<code>*Todealwiththelackofprocessorregisters,mostoftheSTG</code><br />
<code>registersareactuallykeptonthestackinablockofmemory</code><br />
<code>pointedtobyaspecialSTGregistercalledthe&quot;baseregister&quot;(or</code><br />
<code>`BaseReg`).Togetorsetvaluesofregisterswhicharenotkeptin</code><br />
<code>processorregisters,theSTGmachinegeneratesaninstructionto</code><br />
<code>loadorstorefromanaddressrelativetothe`BaseReg`.</code><br />
<code>*Themostimportantfourregistersarethe`BaseReg`,thestack</code><br />
<code>pointer(`Sp`),theheappointer(`Hp`),andthegeneralpurpose</code><br />
<code>register`R1`whichisusedforintermediatevalues,aswellasfor</code><br />
<code>returningevaluatedvalueswhenunwindingthestack.Thesearethe</code><br />
<code>fourregisterswhichareassignedactualprocessorregisterswhen</code><br />
<code>implementingtheSTGmachineonx86.</code><br />
<code>2.TheSTGstack:</code><br />
<code>*Storesfunctionargumentsandcontinuations(i.e.thestack</code><br />
<code>frameswhichareexecutedwhenafunctionreturns)</code><br />
<code>*Growsdownwardsinmemory</code><br />
<code>*ThetopofthestackispointedtobytheSTGregister`Sp`,and</code><br />
<code>themaximumavailablestackpointerisstoredin`SpLim`.Thereis</code><br />
<code>noframepointer.</code></p>
<p><code>3.Theheap:</code><br />
<code>*Usedtostoremanydifferentsortsofheapobject:notably</code><br />
<code>functions,thunksanddataconstructors</code><br />
<code>*Growsupwardsinmemory,towardsthestack</code><br />
<code>*Allallocationoccursusingabump-allocator:theheappointeris</code><br />
<code>simplyincrementedbythenumberofbytesdesired(subjecttotoa</code><br />
<code>checkthatthisdoesnotexhaustavailablememory).Thegarbage</code><br />
<code>collectorisresponsibleformovingobjectsoutoftheareaofthe</code><br />
<code>heapmanagedbythebumpallocatorandintothecareofits</code><br />
<code>generationalcollector.</code><br />
<code>*Thelastaddressinthebump-allocatedpartoftheheapthathas</code><br />
<code>beenusedispointedtobytheSTGregister`Hp`,with`HpLim`</code><br />
<code>holdingthemaximumaddressavailableforbump-allocation.</code></p>
<h3 id="important-concepts-in-the-machine">Important concepts in the machine</h3>
<p>Some of the key concepts in the STG machine include <em>closures</em>, <em>info tables</em> and <em>entry code</em>. We tackle them in reverse order:</p>
<p><code>Entrycode::</code><br />
<code>TheactualmachinecodethattheSTGmachinewillexecuteupon</code><br />
<code>&quot;entry&quot;.Entrymeansdifferentthingsfordifferentheapobjects.</code></p>
<p><code>*For</code><em><code>thunks</code></em><code>,entryiswhenthethunkisforcedbysomedemand</code><br />
<code>foritsvalue,suchasa`case`expressionscrutinisingit</code><br />
<code>*For</code><em><code>functions</code></em><code>,entryiswhenthefunctionisappliedtoas</code><br />
<code>manyargumentsasaredemandedbythearityrecordedinitsinfo</code><br />
<code>table</code><br />
<code>*For</code><em><code>continuations</code></em><code>,entryoccurswhenavalueisreturnedfrom</code><br />
<code>anestedcall,andhencetheneedarisestoconsumethevalueand</code><br />
<code>continueevaluation</code></p>
<p><code>Infotable::</code><br />
<code>Ablockofmemoryallocatedstatically,whichcontainsmetadata</code><br />
<code>aboutaclosure.Themostimportantfieldsforourpurposesarethe</code><br />
<code>entrycodepointerandthearityinformation(ifthisistheinfo</code><br />
<code>tableforathunk,functionorpartialapplication)</code></p>
<p><code>Closure::</code><br />
<code>Essentiallyaheap-allocatedpairofthefreevariablesofsome</code><br />
<code>code,andapointertoitsinfotable(i.e.itsinfopointer).</code></p>
<p>For an example of how these parts work together, consider the following code</p>
<p></p>
<p>The nested lambda will give rise to all of the above objects.</p>
<p>The closure will store a pointer to `x`'s closure (as it is a free variable of the lambda), along with a pointer to an info table. That info table will contain information relevant to a function value, recording information such as the fact that it has an arity of 1 (i.e. the binding for `y`), and the pointer to the entry code for the function `\y -&gt; y + x` itself. This entry code will implement the addition by combining the closure for the free variable `x` (taken from the closure) with the stack-passed `y` variable's closure.</p>
<p>Upon entry to some code, pointers to closures are made available in `R1`. That is to say, before entry code is jumped to, `R1` is set up to point to the associated closure, so that the entry code can access free variables (if any).</p>
<p>Closures for code which contain no free variables (such as the closure for `True` and `False`, and functions applied to no arguments such as `(:)` and `id`) are allocated statically by the compiler in the same manner as info tables are.</p>
<h3 id="overview-of-execution-model-of-the-machine">Overview of execution model of the machine</h3>
<p>This will be covered in more detail in the examples below, so I will use this section to make some general points.</p>
<p>The goal of the STG machine is to reduce the current expression to a value. When it has done so, it:</p>
<p><code>1.StoresataggedpointertoevaluatedclosureintheSTGregister</code><br />
<code>`R1`</code><br />
<code>2.Jumpstotheentrycodeoftheinfotablepointedtobythe</code><br />
<code>valueatthetopoftheSTGstack</code><br />
<code>*Thismayalsobecalledtheinfotableofthe</code><em><code>continuation</code></em><code>of</code><br />
<code>theexpression</code></p>
<p>The continuation code is responsible for popping its info pointer (and stack-allocated free variables, if any) from the stack before returning.</p>
<p>Arguments are passed on the stack, and are popped by the callee. Upon a jump to the entry code for a function, there are always precisely as many arguments on the stack as the (statically known) arity of that function, and those arguments will be followed by the info pointer of a continuation.</p>
<h2 id="saturated-application-to-known-functions">Saturated application to known functions</h2>
<p>Handling application in the STG machine is a big topic, and so in this first section we only look at the case of <em>saturated</em> applications to <em>known</em> functions - i.e. those functions that the compiler statically knows information such as the entry code pointer and arity for.</p>
<h3 id="example-1-function-application-with-sufficient-stack-space">Example 1: function application with sufficient stack space</h3>
<p>Application of functions is the bread and butter of the STG machine. Correspondingly, this first Haskell program</p>
<p></p>
<p>compiles to very simple C-- code</p>
<p></p>
<p></p>
<p>The STG machine passes arguments to functions on the STG stack, and a pointer to the stack top is stored in the STG register `Sp`. Furthermore, because GHC currently uses the eval/apply variant of the STG machine, exactly as many arguments as the function expects to receive are guaranteed to present on the stack.</p>
<p>Therefore, upon entry to the `known_app` function, we are guaranteed that the STG stack has a pointer to a closure of type `()` on top of it. In order to call `known_fun`, we just modify the top of the stack to replace that pointer with a pointer to the statically allocated closure for the literal `10`, and then tail-call into the entry code of `known_fun`.</p>
<h3 id="example-2-function-application-that-needs-to-grow-the-stack">Example 2: function application that needs to grow the stack</h3>
<p>This Haskell code is apparently little more complicated than the previous example</p>
<p></p>
<p>however, it generates radically different C-- code:</p>
<p></p>
<p></p>
<p>As before, upon entry the STG stack is guaranteed to have a single closure pointer at its top. However, in order to call into known_fun_2 we need at least two free stack slots at the top for arguments, which means that we have to grow the stack by one word before we can make the call.</p>
<h4 id="checking-for-sufficient-stack-space">Checking for sufficient stack space</h4>
<p>First, we check to see if growing the stack would overflow allocated stack space, by comparing the STG stack pointer register `Sp` with the stack limit register `SpLim`:</p>
<p></p>
<p>(The stack grows downwards, hence the <em>subtraction</em> of 4 from the current `Sp`). If the stack check fails, we branch to `clH`:</p>
<p></p>
<p>This stores the closure of the current function in `R1`, and then jumps into the hand-written garbage collector code to force it to grow the stack. After the stack has been grown, the collector will call back into `Main_knownzuappzu2_entry` by using the information stored in the (statically-allocated) `Main_knownzuappzu2_closure` closure pointed to by `R1`, and the stack check will be run again - hopefully succeeding this time!</p>
<h4 id="making-the-known-call">Making the known call</h4>
<p>Given that the stack check succeeds, it is easy to make the actual call we are after. We simply grow the stack by the required amount, and write the two arguments to `known_fun_2` into the top two stack slots (overwriting our own first argument in the process, of course):</p>
<p></p>
<p>A simple tail call to the new function finishes us off:</p>
<p></p>
<h2 id="example-3-unsaturated-applications-to-known-functions">Example 3: Unsaturated applications to known functions</h2>
<p>Despite describing an undersaturated call, this Haskell code</p>
<p></p>
<p>compiles to straightforward C-- as follows</p>
<p></p>
<p></p>
<p>The reason that there is no special magic to deal with undersaturated applications to known functions is simple: GHC simply gives `known_undersaturated_app` an arity of 2, so by the time we jump to the entry code the stack must already contain any arguments required by `known_fun_2`.</p>
<h2 id="example-4-applications-to-unknown-functions">Example 4: Applications to unknown functions</h2>
<p>We aren't going to tackle oversaturated calls to known functions until we've considered happens to calls to statically-unknown functions. To see what these look like, we are going to use the following Haskell code</p>
<p></p>
<p>Which compiles to this C-- function</p>
<p></p>
<p></p>
<p>Unlike the previous cases we have looked at, we are compiling an application where we don't statically know either the arity or the info pointer of the function being applied. To deal with such cases, the STG machine uses several pre-compiled &quot;generic apply&quot; functions which inspect the info-table for the function in question and decide how the available arguments should be applied to it.</p>
<h3 id="dealing-with-generic-application">Dealing with generic application</h3>
<p>There are three cases the generic apply functions have to deal with:</p>
<p><code>1.Thefunction'sarity(recorderinthefunctionclosure'sinfo</code><br />
<code>table)exactlymatchesthenumberofargumentsavailableonthe</code><br />
<code>stack</code><br />
<code>*Thisisthebestcase.Inthiscase,thegenericapplyfunction</code><br />
<code>simplymakesatailcallintothefunction'sentrycode</code></p>
<p><code>2.Thefunction'sarityisgreaterthanthenumberofarguments</code><br />
<code>availableonthestack</code><br />
<code>*Inthiscase,thegenericapplycodeallocatesaPAP(partial</code><br />
<code>application)closurewhichclosesoverboththenewargumentsand</code><br />
<code>thefunctionpointer,andreturnsthatvalue,inthenormalSTGish</code><br />
<code>way,tothecontinuationonthetopofthestack</code></p>
<p><code>3.Thefunction'sarityislessthanthenumberofarguments</code><br />
<code>availableonthestack</code><br />
<code>*Inthiscase,anumberofargumentsmatchingthearityarepushed</code><br />
<code>ontopofthestack,followedbyacontinuationwhichusesanother</code><br />
<code>ofthegenericapplyfunctionstoapplytheremainingarguments.</code><br />
<code>Thecodefortheoriginalfunctionisthenentered</code><br />
<code>*Eventuallythecodeforthecontinuationisenteredandanother</code><br />
<code>genericapplyfunctionwillbetail-calledtodealwiththe</code><br />
<code>result</code></p>
<p>Potentially, one generic apply function is required for every &quot;argument pattern&quot;. Some example argument patterns are:</p>
<p></p>
<p>Because the number of patterns is large (actually unbounded, because functions might be of any arity), GHC only generates generic apply functions for enough patterns so that 99.9% of all calls observed in practice have a generic apply function. Generic apply functions for calls of larger arity can be simulated by chaining together several smaller generic apply functions, in a similar manner as when dealing with oversaturated function applications.</p>
<h3 id="making-the-call-to-the-generic-application-code">Making the call to the generic application code</h3>
<p>Let's remind ourselves of the original code:</p>
<p></p>
<p>Knowing about generic apply functions, the call itself is easy to understand. We pop the top of the stack (the function argument) into `R1` and then jump into the generic application code for the case where the stack contains a single pointer argument, which deals with all the cases for `f` described above.</p>
<h2 id="example-5-oversaturated-applications-to-known-functions">Example 5: oversaturated applications to known functions</h2>
<p>This Haskell code</p>
<p></p>
<p>compiles to the following C-- function</p>
<p></p>
<p></p>
<p>As you might see, despite being a call to a known function, this code makes use of the generic apply functions we discussed in the last section. Let's pick the function apart and see how it works.</p>
<p>First, we do the usual stack check. What differs from the last time we saw this check is that we are not only allocating space for arguments on the stack, but also for a <em>continuation</em>. We set up these new stack entries as follows:</p>
<p></p>
<p>i.e. the final stack looks as follows (note that the code overwrites the old pointer to a closure of type ()):</p>
<p></p>
<p>Because `known_fun_2` is of arity 2, when we jump to its entry code, it will only consume the top two arguments from the stack: i.e. the two pointers to `base_GHCziBase_id_closure`. It will then evaluate to some sort of value and transfer control to the entry code for `stg_ap_p_info`.</p>
<p>This is where the magic happens: the entry code for `stg_ap_p_info` will apply the function value that was returned from `known_fun_2` to the (pointer) argument in the &quot;free variable&quot; of its (stack allocated) closure -- and we have arranged that that is `stg_INTLIKE_closure+209`, i.e. the closure for the `Int` literal `10`. This code is shared with the generic application functions for calls to unknown functions, so this will make use of the `stg_ap_p_fast` function we saw before.</p>
<p>Finally, control will be transferred back to the caller for `known_oversat_app`, and all will be well.</p>
<h2 id="example-6-allocation-of-thunks-and-data">Example 6: allocation of thunks and data</h2>
<p>Something that happens all the time in Haskell is allocation. There are three principal types of thing that get allocated: function closures, thunks, and data. These are all treated pretty much the same in the STG machine for the simple reason that they share many common characteristics:</p>
<p><code>*EntrycodewhichtheSTGmachinejumpsto,inordertoevaluate</code><br />
<code>them</code><br />
<code>*Notethatforconstructors,theentrycodeistrivial,asthey</code><br />
<code>arealwaysalreadyevaluated!Inthiscase,controlwillbe</code><br />
<code>transferreddirectlybacktothecaller'scontinuation.</code></p>
<p><code>*Freevariablesstoredinaclosure</code><br />
<code>*Fordata,these&quot;freevariables&quot;willbethevaluesinthefields</code><br />
<code>oftheparticulardataconstructor</code></p>
<p><code>*Info-tablescontainingvariousmiscellaneousmetadataaboutthe</code><br />
<code>heapobject,suchasfunctionarity</code></p>
<p>Let us look at how a thunk and a data constructor get allocated in a simple setting:</p>
<p></p>
<p>This compiles into the following C--:</p>
<p></p>
<p></p>
<p>Let's break this function down slowly.</p>
<h3 id="checking-for-sufficient-heap-space">Checking for sufficient heap space</h3>
<p>Any function that needs to allocate memory might find that the heap has been exhausted. If that happens, it needs to call into the garbage collector in order to get the heap cleaned up and (possibly) enlarged.</p>
<p>Hence, the first thing any such function does is check to see if enough memory is available for its purposes:</p>
<p></p>
<p>This is simple enough. The function needs to allocate 20 bytes (the data constructor takes up 2 words, and the thunk will take up 3), so it speculatively increments Hp and then checks the STG registers `Hp` and `HpLim` (the pointer to the top of the available heap space) against each other.</p>
<p>If memory is insufficient (i.e. we have moved `Hp` past the top of the available heap), the code deals with it by setting the `HpAlloc` register to the number of bytes needed and `R1` to the closure for the function in which the heap check failed, before jumping into the hand-written garbage collector code for the cleanup. The garbage collector will resume execution of the code by using the information from `R1`, after it has freed up enough memory.</p>
<p>Side note: I believe that the line setting `R1` is unnecessary here, because `R1` should anyway always be set to the address of the closure when executing the closure entry code. I could be wrong, though.</p>
<h3 id="performing-the-actual-allocation">Performing the actual allocation</h3>
<p>Once the heap check succeeds, we will be able to enter the body of the function proper. Since the `Hp` has already been incremented, we can just construct the new heap objects directly:</p>
<p></p>
<p>So we get something like this:</p>
<p></p>
<p>The bottom two words are the allocated `Just` value, and the three above that correspond to the `x + 1` closure.</p>
<h3 id="returning-an-allocated-value-to-the-caller">Returning an allocated value to the caller</h3>
<p>Now that we have allocated the data we entered the function in order to construct, we need to return it to the caller. This is achieved by the following code:</p>
<p></p>
<p>To return, the STG machine:</p>
<p><code>1.Sets`R1`tothepointertotheresultofevaluation</code><br />
<code>2.Popsalltheargumentstothefunctionfromthestack</code><br />
<code>3.Jumpstotheentrycodeforthecontinuation.Thisisalways</code><br />
<code>foundatthetopoftheSTGstack,logicallybelowanyarguments</code><br />
<code>thatwerepushedtomakethecall.</code></p>
<p>This is indeed exactly what happens here, with two interesting points: pointer tagging, and the double-deference of the stack pointer. These will be discussed in the next two subsections.</p>
<h4 id="pointer-tagging">Pointer tagging</h4>
<p>One exciting feature is that the code setting `R1`, i.e. `R1 = Hp - 2`. This is setting `R1` to point to the `Just`, we just allocated, but simultaneously tagging that pointer with the value 2. The fact that the tag is non-zero indicates to users of the pointer that the thing pointed to is already evaluated. Furthermore, because `Maybe` has only two constructors, we are able to use the pointer tags to record which constructor it evaluated to: in this case, the 2 indicates the `Just` constructor.</p>
<p>It is compulsory to tag pointers before jumping to the address of the continuation entry code: the entry code can and will rely on those tags being present!</p>
<h4 id="tables_next_to_code">`TABLES_NEXT_TO_CODE`</h4>
<p>Because I have compiled GHC without `TABLES_NEXT_TO_CODE`, the entry code for the continuation is found by dereferencing the pointer to the info table we found at the top of the STG stack - i.e. a double-dereference.</p>
<p>The layout of heap objects without `TABLES_NEXT_TO_CODE` is as follows:</p>
<p></p>
<p>With `TABLES_NEXT_TO_CODE` on, the situation looks more like this:</p>
<p></p>
<p>The `TABLES_NEXT_TO_CODE` optimisation removes the need for that second dereference during the return, because the entry code is always right next to the info table. However, it requires special support from the backend for ensuring that data (i.e. the info table) and code are contiguous in memory, so it cannot always be used.</p>
<h2 id="example-7-case-expressions">Example 7: `case` expressions</h2>
<p>Let us now examine how `case` expressions are handled. Compiling the following Haskell</p>
<p></p>
<p>Produces this C-- code</p>
<p></p>
<p></p>
<p>Notice that GHC has generated <em>two</em> functions: `Main_casezuscrut_entry` and `scj_ret` correspond to the code for forcing the argument to the `case`, and for the <em>continuation</em> of the `case` respectively. Let's pick them apart and see how they work!</p>
<h3 id="forcing-the-scrutinee-of-the-case">Forcing the scrutinee of the `case`</h3>
<p>When we first call the `case_scrut` function, its entry code begins executing:</p>
<p></p>
<p>This is a function of arity 1 (i.e. with a single argument), so upon entry the machine state looks like this:</p>
<p></p>
<p>Because this is a top level function, the closure is statically allocated and contains no free variables. However, as discussed previously, the single argument to the function is guaranteed to be present at the top of the stack.</p>
<p>The code starts off by saving this argument (the `x`) temporarily into `R1`:</p>
<p></p>
<p>The next thing the code does is overwrites this argument on the stack with a pointer to the info-table of the continuation code. This is the code that will be invoked after `x` has been evaluated into WHNF, and which will do the test to decide whether to continue as the `Nothing` or as the `Just` branch of the case:</p>
<p></p>
<p>As we saw earlier, any time that the STG machine decides that it has a value in its hand, it will continue evaluation by tail-calling the entry code found by dereferencing the info-table pointer at the top of the stack. So by putting the address of our continuation in here, we ensure that the entry code for `scj_info` is executed after `x` becomes a value.</p>
<p>Now, what we need to do is to start the evaluation of `x`. We could just jump into `x`'s entry code and hope for the best, but thanks to GHC's pointer tagging we can sometimes avoid doing this indirect branch.</p>
<p>So, instead, we test to see if the `x` pointer has a tag. If it is tagged, then we know that it is already evaluated and hence jump directly to the code for the continuation. If it is not tagged, we are forced to make the jump into the entry code for `x`. This choice is embodied by the following code:</p>
<p></p>
<p>Note the test `R1 &amp; 3 != 0`: this reflects the fact that pointer tags are stored in the lower 2 bits of the pointer on 32 bit machines. Another interesting feature is how the `jump` instructions find the entry code: again, we see a deference of the info pointer because `TABLES_NEXT_TO_CODE` is turned off.</p>
<p>As we saw, the `case` scrutinisation code ended with one of two things happening: 1. A direct call into the continuation code `scj_ret` if the scrutinee was already evaluated 2. A call into the entry code for the scrutinee, if the scrutinee was not evaluated (or it <em>was</em> evaluated, but the pointer was somehow not tagged with that information) - Because we pushed `scj_info` onto the STG stack, control will eventually return to `scj_ret` after the evaluation of `x` has finished</p>
<p>It is now time to examine the continuation code to see what happens after `x` becomes a value.</p>
<h3 id="dealing-with-the-forced-scrutinee">Dealing with the forced scrutinee</h3>
<p>The continuation code is a little more complicated:</p>
<p></p>
<p>Whenever the STG machine evaluates to a value it will return the value by jumping to the entry point at the top of the stack. In this case, `R1` is guaranteed to be a (tagged) pointer to the thing that was just evaluated. Because we are scrutinising a `Maybe` type (which has fewer than 4 constructors) the code for the `case` continuation is able to use the tag bits on the returned pointer to decide which of the two branches to take:</p>
<p></p>
<p>If we were scrutinising a data type with more constructors, the tag bits would only tell us that the thing was evaluated, not which constructor it was evaluated to. In this case, we would have to read the constructor tag by dereferencing `R1` and testing the resulting info table pointer against all possibilities.</p>
<p>If the tag was greater than or equal to 2, we go to the `ccv` branch, which deals with what happens if we had a `Just`. In this case, we need to continue by forcing the thunk inside the `Just` and returning that value to our caller, which is what these lines are doing:</p>
<p></p>
<p>To access the thing inside the `Just`, the code assumes that the `R1` pointer is tagged with the 2 that indicates a `Just` constructor, and hence finds the first free variable (stored 4 bytes into the closure) using `I32[R1 + 2]`, which is then saved into `R1`. It pops the address of `scj_info` that was pushed onto the stack in `Main_casezuscrut_entry` by moving `Sp` up 4 bytes (remember that the STG stack grows downwards) and then untags and jumps into the entry code for the `R1` thunk, using the same double-dereference pattern discussed earlier.</p>
<p>There seems to be a small missed opportunity here: the code could check the pointer tag on `R1`, and then return directly if it is set. I imagine that this isn't being done in order to reduce possible code bloat.</p>
<h2 id="example-8-thunks-and-thunk-update">Example 8: thunks and thunk update</h2>
<p>You might be wondering how the `x + 1` thunk we saw allocated in a previous section will behave when it is actually forced. To remind you, the thunk we saw was constructed by the following Haskell code:</p>
<p></p>
<p>So how does the `x + 1` thunk work? An excellent question! Let's take a look at the C-- for its entry code and find out:</p>
<p></p>
<p></p>
<p>The original Haskell code read `x + 1`, but GHC has inlined the actual code for the addition operation on `Int`s, which looks something like:</p>
<p></p>
<p>The second pattern match (to get `b`) has been performed statically by GHC, obtaining the machine literal 1, which shows up directly in the generated code. Therefore, the code only need to evaluate and case-decompose the unknown free variable `x` of our closure, to get the `a` argument to `plusInt`.</p>
<h3 id="thunk-entry-point">Thunk entry point</h3>
<p>This evaluation is what is being done by the thunk entry code `slk_entry`. Ignoring the stack check, the C-- begins thusly:</p>
<p></p>
<p>Remembering that upon entry to the thunk entry code, `R1` points to the thunk's closure, the new stack looks as follows:</p>
<p></p>
<p>The C-- statement `R1 = I32[R1 + 8]` is pulling out the pointer to the free variable of the thunk (which was set up in `Main_buildzudata_entry`) into `R1`.</p>
<p>Finally, the entry code evaluates that free variable (checking the tag bits of the pointer first, as usual):</p>
<p></p>
<p>Because we put `soN_info` at the top of the stack, when evaluation of `x` is complete the STG machine will continue by executing the `soN_ret` code.</p>
<p>The most interesting feature of this code is the extra stuff that has been pushed onto the stack below `soN_ret`: an info pointer called `stg_upd_frame_info`, and a pointer to the thunk currently being evaluated.</p>
<p>This is all part of the STG machine's thunk update mechanism. When the `soN_ret` continuation returns, it will transfer control <em>not</em> to the code forcing the thunk, but to some code which overwrites the contents of the current thunk closure with a closure representing an &quot;indirection&quot;. The entry code for such an indirection closure is trivial: it immediately returns a pointer to the thing that was returned from the `soN_ret` continuation in `R1`.</p>
<p>These indirections are the mechanism which ensures that the STG machine never repeats the work of evaluating a thunk more than once: after the first evaluation, any code forcing the thunk jumps into the indirection entry code rather than `slk_entry`.</p>
<p>That being said, let us look at how the continuation responsible for actually finding the value of `x + 1` works:</p>
<h3 id="continuation-of-the-thunk">Continuation of the thunk</h3>
<p>Upon entry to the continuation code, we have the evaluated `x` in `R1`: it now needs to do the addition and allocate a `I#` constructor to hold the result of the addition. Because of the allocation, `soN_ret` begins with a heap check. Ignoring that check, we have the following code:</p>
<p></p>
<p>This is mostly standard stuff. Because the `R1` pointer is guaranteed tagged, and there is only one possible constructor, the tag must be 1 and so the `Int#` value inside the `Int` is pulled out using `I32[R1 + 3]`. This is then put into a newly heap-allocated `I#` constructor, which is returned in `R1` after we pop the `soN_info` pointer from the stack.</p>
<p>The only interesting point is where we return to: rather than dereference `Sp` to find the info pointer at the top of the STG stack, GHC has generated code that takes advantage of the fact that the `Sp` is guaranteed to point to `stg_upd_frame_info`. This avoids one pointer dereference.</p>
<h2 id="conclusion">Conclusion</h2>
<p>This document has left much of the detail of how STG is implemented out: notable omissions include CAFs, and the precise behaviour of the garbage collector. Nonetheless, my hope is that it has helped you to gain some more insight into the weird and wonderful way the Haskell evaluation model is implemented.</p>
<h1 id="support-for-generic-programming">Support for generic programming</h1>
<p><a href="PageOutline" class="uri" title="wikilink">PageOutline</a></p>
<p>GHC includes a new (in 2010) mechanism to let you write generic functions. It is described in paper <a href="http://www.dreixel.net/research/pdf/gdmh_nocolor.pdf">A generic deriving mechanism for Haskell</a>. This page sketches the specifics of the implementation; we assume you have read the paper. The <a href="http://www.haskell.org/haskellwiki/Generics">HaskellWiki page</a> gives a more general overview.</p>
<p>This mechanism replaces the <a href="http://www.haskell.org/ghc/docs/6.12.2/html/users_guide/generic-classes.html">previous generic classes implementation</a>. What we describe until the &quot;Kind polymorphic overhaul&quot; section is implemented and released in GHC 7.2.1.</p>
<h2 id="status">Status</h2>
<p>Use <strong>Keyword</strong> = `Generics` to ensure that a ticket ends up on this auto-generated list</p>
<p>Open Tickets: <a href="TicketQuery(status=infoneeded,status=new" title="wikilink">patch|infoneeded,keywords=~Generics)</a></p>
<p>Closed Tickets: <a href="TicketQuery(status=infoneeded,status=closed,keywords=~Generics)" class="uri" title="wikilink">TicketQuery(status=infoneeded,status=closed,keywords=~Generics)</a></p>
<h2 id="main-components">Main components</h2>
<p><code>*`TcDeriv.tcDeriving`nowallowsderiving`Generic`instances.</code></p>
<p><code>*Therepresentationtypesandcorefunctionalityofthelibraryliveon`GHC.Generics`(onthe`ghc-prim`package).</code></p>
<p><code>*Manynameshavebeenaddedasknownin`prelude/PrelNames`</code></p>
<p><code>*Mostofthecodegenerationishandledby`types/Generics`</code></p>
<h2 id="things-that-have-been-removed">Things that have been removed</h2>
<p><code>*Allofthe</code><a href="http://www.haskell.org/ghc/docs/6.12.2/html/users_guide/generic-classes.html"><code>generic</code> <code>classes</code> <code>stuff</code></a><code>.Inparticular,thefollowinghavebeenremoved:</code><br />
<code>*`hasGenerics`fieldfrom`TyCon`;</code><br />
<code>*`HsNumTy`constructorfrom`HsType`;</code><br />
<code>*`TypePat`constructorfrom`Pat`.</code></p>
<p><code>*The`-XGenerics`flagisnowdeprecated.</code></p>
<h2 id="what-already-works">What already works</h2>
<p><code>*`Generic`and`Generic1`instancescanbederivedwhen`-XDeriveGeneric`isenabled.</code></p>
<p><code>*The`default`keywordcanusedforgenericdefaultmethodsignatureswhen`-XDefaultSignatures`isenabled.</code></p>
<p><code>*Genericdefaultsareproperlyinstantiatedwhengivinganinstancewithoutdefiningthegenericdefaultmethod.</code></p>
<p><code>*Basetypeslike`[]`,`Maybe`,tuples,comewithGenericinstances.</code></p>
<h2 id="testing">Testing</h2>
<p><code>*Testsareavailableunderthe`generics`directoryofthetestsuite.</code></p>
<h1 id="kind-polymorphic-overhaul">Kind polymorphic overhaul</h1>
<p>With the new `-XPolyKinds` functionality we can make the support for generic programming better typed. The basic idea is to define the universe codes (`M1`, `:+:`, etc.) as constructors of a datatype. Promotion then lifts these constructors to types, which we can use as before, only that now we have them all classified under a new kind. The overhaul of the main module is explained below; for easier comparison with the current approach, names are kept the same whenever possible.</p>
<h2 id="generic-representation-universe">Generic representation universe</h2>
<p>`m` is the only real parameter here. `f` and `x` are there because we can't write kinds directly, since `Universe` is also a datatype (even if we're only interested in its promoted version). So we pass `f` and `x` only to set them to `* -&gt; *` and `*`, respectively, in `Interprt`. `m` is different: it stands for the kind of metadata representation types, and we really want to be polymorphic over that, since each user datatype will introduce a new metadata kind. </p>
<h2 id="universe-interpretation">Universe interpretation</h2>
<p>As promised, we set `f` to `* -&gt; *` and `x` to `*`. Unfortunately we don't have [GhcKinds#Explicitkindvariables explicit kind variable annotations] yet, so we cannot leave `m` polymorphic! So this code doesn't compile: </p>
<h3 id="names">Names</h3>
<p>As an aside, note that we have to come up with names like `UU` and `KK` for the `Universe` even though we really just wanted to use `U1` and `K1`, like before. Then we would have a type and a constructor with the same name, but that's ok. However, `Universe` defines both a type (with constructors) and a kind (with types). So if we were to use `U1` in the `Universe` constructors, then we could no longer use that name in the `Interprt` constructors. It's a bit annoying, because we are never really interested in the type `Universe` and its constructors: we're only interested in its promoted variant. This is a slight annoyance of automatic promotion: when you define a &quot;singleton type&quot; (like our GADT `Interprt` for `Universe`) you cannot reuse the constructor names.</p>
<h2 id="metadata-representation">Metadata representation</h2>
<p> There's more of these, but they don't add any new concerns.</p>
<h2 id="conversion-between-user-datatypes-and-generic-representation">Conversion between user datatypes and generic representation</h2>
<p>We now get a more precise kind for `Rep`:</p>
<p></p>
<h2 id="example-generic-function-fmap-kind--">Example generic function: `fmap` (kind `* -&gt; *`)</h2>
<p>User-visible class, exported: </p>
<p>Defined by the generic programmer, not exported: </p>
<p>Note that previously `Functor` and `GFunctor` had exactly the same types. Now we can make clear what the difference between them is.</p>
<h2 id="example-generic-function-show-kind-uses-metadata">Example generic function: `show` (kind `*`, uses metadata)</h2>
<p>User-visible class, exported: </p>
<p>Defined by the generic programmer, not exported: </p>
<p>The other cases do not add any further complexity.</p>
<h2 id="example-datatype-encoding-lists-derived-by-the-compiler">Example datatype encoding: lists (derived by the compiler)</h2>
<p></p>
<p>Note that we use only one datatype; more correct would be to use 3, one for `DList`, another for the constructors, and yet another for the selectors (or maybe even n datatypes for the selectors, one for each constructor?) But we don't do that because `Universe` is polymorphic only over `m`, so a single metadata representation type. If we want a more fine-grained distinction then we would need more parameters in `Universe`, and also to split the `MM` case. </p>
<h3 id="digression">Digression</h3>
<p>Even better would be to index the metadata representation types over the type they refer to. Something like:  But now we are basically asking for promotion of data families, since we want to use promoted `DList`. Also, the case for `MM` in `Universe` would then be something like:  But I'm not entirely sure about this.</p>
<h2 id="ghc-8.0-and-later">GHC 8.0 and later</h2>
<h3 id="type-level-metadata-encoding">Type-level metadata encoding</h3>
<p>Because what we've described so far is rather backwards-incompatible, we wanted to at least try to improve the encoding of metadata, which was currently rather clunky prior to GHC 8.0 (giving rise to lots of empty, compiler-generated datatypes and respective instances). We can accomplished that by changing `M1` to keep the meta-information <em>at the type level</em>: </p>
<p>Why did we need to add `FixityI`? Because `Fixity` does not promote. Yet, we wanted to expose `Fixity` to the user, not `FixityI`. Note that the meta-data classes remained mostly unchanged (aside from some enhancements to <a href="https://ghc.haskell.org/trac/ghc/ticket/10030">Datatype</a> and <a href="https://ghc.haskell.org/trac/ghc/ticket/10716">Selector</a>): </p>
<p>But now, using the magic of singletons, we give <em>one single instance</em> for each of these classes, instead of having to instantiate them each time a user derives `Generic`: </p>
<p>Naturally, we require singletons for `Bool`, `Maybe`, `FixityI`, `Associativity`, `SourceUnpackedness`, `SourceStrictness`, and `DecidedStrictness`, but that is one time boilerplate code, and is not visible for the user. (In particular, this is where we encode that the demotion of (the kind) `FixityI` is (the type) `Fixity`.)</p>
<p>I believe this change is almost fully backwards-compatible, and lets us simplify the code for `deriving Generic` in GHC. Furthermore, I suspect it will be useful to writers of generic functions, who can now match at the type-level on things such as whether a constructor is a record or not.</p>
<p>I say &quot;almost fully backwards-compatible&quot; because handwritten `Generic` instances might break with this change. But we've never recommended doing this, and I think users who do this are more than aware that they shouldn't rely on it working across different versions of GHC.</p>
<h4 id="example-1">Example</h4>
<p>Before GHC 8.0, the following declaration:</p>
<p></p>
<p>Would have generated all of this:</p>
<p></p>
<p>But on GHC 8.0 and later, this is all that is generated (assuming it was compiled with no strictness optimizations):</p>
<p></p>
<p>Not bad!</p>
<h3 id="strictness">Strictness</h3>
<p>The `Selector` class now looks like this:</p>
<p></p>
<p>This design draws much inspiration from the way Template Haskell handles strictness as of GHC 8.0 (see <a href="https://ghc.haskell.org/trac/ghc/ticket/10697">here</a> for what motivated the change). We make a distinction between the <em>source</em> strictness annotations and the strictness GHC actually <em>decides</em> during compilation. To illustrate the difference, consider the following data type:</p>
<p></p>
<p>If we were to encode the source unpackedness and strictness of each of `T`'s fields, they were be `SourceUnpack`/`SourceStrict`, `NoSourceUnpackedness`/`SourceStrict`, and `NoSourceUnpackedness`/`NoSourceStrictness`, no matter what. Source unpackedness/strictness is a purely syntactic property.</p>
<p>The strictness that the user writes, however, may be different from the strictness that GHC decides during compilation. For instance, if we were to compile `T` with no optimizations, the decided strictness of each field would be `DecidedStrict`, `DecidedStrict`, and `DecidedLazy`. If we enabled `-O2`, however, they would be `DecidedUnpack`, `DecidedStrict`, and `DecidedLazy`.</p>
<p>Things become even more interesting when `-XStrict` and `-O2` are enabled. Then the strictness that GHC would decided is `DecidedUnpack`, `DecidedStrict`, and `DecidedStrict`. And if you enable `-XStrict`, `-O2`, <em>and</em> `-funbox-strict-fields`, then the decided strictness is `DecidedUnpack`, `DecidedUnpack`, and `DecidedUnpack`.</p>
<p>The variety of possible `DecidedStrictness` combinations demonstrates that strictness is more just annotation</p>
<h2 id="source-tree-layout">Source Tree Layout</h2>
<p>An overview of the source tree may be found [wiki:Commentary/SourceTree here].</p>
<h2 id="build-system-basics">Build System Basics</h2>
<p>Detailed information about the build system may be found [wiki:Building here]; what follows is a quick overview, highlighting the areas where GHC's build system diverges substantially from the way  is used in most other projects.</p>
<p>Most projects keep the parts of their build machinery in files called  found in many/most subdirectories of the source tree. GHC uses the filename  instead; you'll find a file with this name in quite a number of subdirectories.</p>
<p>Other build system files are in  and .</p>
<h2 id="coding-style">Coding Style</h2>
<p>The [wiki:WorkingConventions Coding style guidelines] may be found on the wiki.</p>
<h1 id="the-ghc-commentary-ghci">The GHC Commentary: GHCi</h1>
<p>This isn't a coherent description of how GHCi works, sorry. What it is (currently) is a dumping ground for various bits of info pertaining to GHCi, which ought to be recorded somewhere.</p>
<h2 id="debugging-the-interpreter">Debugging the interpreter</h2>
<p>The usual symptom is that some expression / program crashes when running on the interpreter (commonly), or gets wierd results (rarely). Unfortunately, finding out what the problem really is has proven to be extremely difficult. In retrospect it may be argued a design flaw that GHC's implementation of the STG execution mechanism provides only the weakest of support for automated internal consistency checks. This makes it hard to debug.</p>
<p>Execution failures in the interactive system can be due to problems with the bytecode interpreter, problems with the bytecode generator, or problems elsewhere. From the bugs seen so far, the bytecode generator is often the culprit, with the interpreter usually being correct.</p>
<p>Here are some tips for tracking down interactive nonsense:</p>
<p><code>*Findthesmallestsourcefragmentwhichcausestheproblem.</code></p>
<p><code>*UsinganRTScompiledwith`-DDEBUG`,runwith`+RTS-Di`togetalistingingreatdetailfromtheinterpreter.Notethatthelistingissovoluminousthatthisisimpracticalunlessyouhavebeendiligentinthepreviousstep.</code></p>
<p><code>*Atleastinprinciple,usingthetraceandabitofGDBpokingaroundatthetimeofdeath(Seealso[wiki:Debugging]),youcanfigureoutwhattheproblemis.Inpracticeyouquicklygetdepressedatthehopelessnessofevermakingsenseofthemassofdetails.Well,Ido,anyway.</code></p>
<p><code>*`+RTS-Di`trieshardtoprintusefuldescriptionsofwhat'sonthestack,andoftensucceeds.However,ithasnowaytomapaddressestonamesincode/dataloadedbyourruntimelinker.SotheCfunction`ghci_enquire`isprovided.Givenanaddress,itsearchestheloadedsymboltablesforsymbolsclosetothataddress.YoucanrunitfrominsideGDB:</code></p>
<p></p>
<p><code>Inthiscasetheenquired-aboutaddressis`PrelBase_ZMZN_static_entry`.Ifnosymbolsareclosetothegivenaddr,nothingisprinted.Notagreatmechanism,butbetterthannothing.</code></p>
<p><code>*Wehavehadvariousproblemsinthepastduetothebytecodegenerator(compiler/ghci/ByteCodeGen.lhs)beingconfusedaboutthetruesetoffreevariablesofanexpression.Thecompilationschemefor`let`sappliestheBCOfortheRHSofthe`let`toitsfreevariables,soifthefree-varannotationiswrongormisleading,youendupwithcodewhichhaswrongstackoffsets,whichisusuallyfatal.</code></p>
<p><code>*Followingthetracesisoftenproblematicbecauseexecutionhopsbackandforthbetweentheinterpreter,whichistraced,andcompiledcode,whichyoucan'tsee.ParticularlyannoyingiswhenthestacklooksOKintheinterpreter,thencompiledcoderunsforawhile,andlaterwearrivebackintheinterpreter,withthestackcorrupted,andusuallyinacompletelydifferentplacefromwhereweleftoff.</code></p>
<p><code>Ifthisisbitingyoubaaaad,itmaybeworthcopyingsourcesforthecompiledfunctionscausingtheproblem,intoyourinterpretedmodule,inthehopethatyoustayintheinterpretermoreofthetime.</code></p>
<p><code>*Therearevariouscommented-outpiecesofcodeinInterpreter.cwhichcanbeusedtogetthestacksanity-checkedaftereveryentry,andevenafteraftereverybytecodeinstructionexecuted.Notethatsomebytecodes(`PUSH_UBX`)leavethestackinanunwalkablestate,sothe`do_print_stack`localvariableisusedtosuppressthestackwalkafterthem.</code></p>
<h2 id="useful-stuff-to-know-about-the-interpreter">Useful stuff to know about the interpreter</h2>
<p>The code generation scheme is straightforward (naive, in fact). `-ddump-bcos` prints each BCO along with the Core it was generated from, which is very handy.</p>
<p><code>*Simple`let`sarecompiledin-line.Forthegeneralcase,`letv=Ein...`,theexpression`E`iscompiledintoanewBCOwhichtakesasargsitsfreevariables,and`v`isboundto`AP(thenewBCO,freevarsofE)`.</code></p>
<p><code>*`case`sasusual,become:pushthereturncontinuation,enterthescrutinee.Thereissomemagictomakeallcombinationsofcompiled/interpretedcallsandreturnswork,describedbelow.Intheinterpretedcase,all`case`altsarecompiledintoasinglebigreturnBCO,whichcommenceswithinstructionsimplementingaswitchtree.</code></p>
<h3 id="stack-management">Stack management</h3>
<p>There isn't any attempt to stub the stack, minimise its growth, or generally remove unused pointers ahead of time. This is really due to laziness on my part, although it does have the minor advantage that doing something cleverer would almost certainly increase the number of bytecodes that would have to be executed. Of course we `SLIDE` out redundant stuff, to get the stack back to the sequel depth, before returning a HNF, but that's all. As usual this is probably a cause of major space leaks.</p>
<h3 id="building-constructors">Building constructors</h3>
<p>Constructors are built on the stack and then dumped into the heap with a single `PACK` instruction, which simply copies the top N words of the stack verbatim into the heap, adds an info table, and zaps N words from the stack. The constructor args are pushed onto the stack one at a time. One upshot of this is that unboxed values get pushed untaggedly onto the stack (via `PUSH_UBX`), because that's how they will be in the heap. That in turn means that the stack is not always walkable at arbitrary points in BCO execution, although naturally it is whenever GC might occur.</p>
<p>Function closures created by the interpreter use the AP-node (tagged) format, so although their fields are similarly constructed on the stack, there is never a stack walkability problem.</p>
<h3 id="perspective">Perspective</h3>
<p>I designed the bytecode mechanism with the experience of both STG hugs and Classic Hugs in mind. The latter has an small set of bytecodes, a small interpreter loop, and runs amazingly fast considering the cruddy code it has to interpret. The former had a large interpretative loop with many different opcodes, including multiple minor variants of the same thing, which made it difficult to optimise and maintain, yet it performed more or less comparably with Classic Hugs.</p>
<p>My design aims were therefore to minimise the interpreter's complexity whilst maximising performance. This means reducing the number of opcodes implemented, whilst reducing the number of insns despatched. In particular, very few (TODO: How many? Which?) opcodes which deal with tags. STG Hugs had dozens of opcodes for dealing with tagged data. Finally, the number of insns executed is reduced a little by merging multiple pushes, giving `PUSH_LL` and `PUSH_LLL`. These opcode pairings were determined by using the opcode-pair frequency profiling stuff which is ifdef-d out in Interpreter.c. These significantly improve performance without having much effect on the ugliness or complexity of the interpreter.</p>
<p>Overall, the interpreter design is something which turned out well, and I was pleased with it. Unfortunately I cannot say the same of the bytecode generator.</p>
<h2 id="case-returns-between-interpreted-and-compiled-code">case returns between interpreted and compiled code</h2>
<p>Variants of the following scheme have been drifting around in GHC RTS documentation for several years. Since what follows is actually what is implemented, I guess it supersedes all other documentation. Beware; the following may make your brain melt. In all the pictures below, the stack grows downwards.</p>
<h3 id="returning-to-interpreted-code.">Returning to interpreted code.</h3>
<p>Interpreted returns employ a set of polymorphic return infotables. Each element in the set corresponds to one of the possible return registers (R1, D1, F1) that compiled code will place the returned value in. In fact this is a bit misleading, since R1 can be used to return either a pointer or an int, and we need to distinguish these cases. So, supposing the set of return registers is {R1p, R1n, D1, F1}, there would be four corresponding infotables, stg_ctoi_ret_R1p_info, etc. In the pictures below we call them stg_ctoi_ret_REP_info.</p>
<p>These return itbls are polymorphic, meaning that all 8 vectored return codes and the direct return code are identical.</p>
<p>Before the scrutinee is entered, the stack is arranged like this: </p>
<p>On entry, the interpreted contination BCO expects the stack to look like this: </p>
<p>A machine code return will park the returned value in R1/F1/D1, and enter the itbl on the top of the stack. Since it's our magic itbl, this pushes the returned value onto the stack, which is where the interpreter expects to find it. It then pushes the BCO (again) and yields. The scheduler removes the BCO from the top, and enters it, so that the continuation is interpreted with the stack as shown above.</p>
<p>An interpreted return will create the value to return at the top of the stack. It then examines the return itbl, which must be immediately underneath the return value, to see if it is one of the magic stg_ctoi_ret_REP_info set. Since this is so, it knows it is returning to an interpreted contination. It therefore simply enters the BCO which it assumes it immediately underneath the itbl on the stack.</p>
<h3 id="returning-to-compiled-code.">Returning to compiled code.</h3>
<p>Before the scrutinee is entered, the stack is arranged like this: </p>
<p>The scrutinee value is then entered. The case continuation(s) expect the stack to look the same, with the returned HNF in a suitable return register, R1, D1, F1 etc.</p>
<p>A machine code return knows whether it is doing a vectored or direct return, and, if the former, which vector element it is. So, for a direct return we jump to `Sp[0]`, and for a vectored return, jump to `((CodePtr*)(Sp[0]))[ - ITBL_LENGTH - vector number ]`. This is (of course) the scheme that compiled code has been using all along.</p>
<p>An interpreted return will, as described just above, have examined the itbl immediately beneath the return value it has just pushed, and found it not to be one of the ret_REP_ctoi_info set, so it knows this must be a return to machine code. It needs to pop the return value, currently on the stack, into R1/F1/D1, and jump through the info table. Unfortunately the first part cannot be accomplished directly since we are not in Haskellised-C world.</p>
<p>We therefore employ a second family of magic infotables, indexed, like the first, on the return representation, and therefore with names of the form stg_itoc_ret_REP_info. (Note: itoc; the previous bunch were ctoi). This is pushed onto the stack (note, tagged values have their tag zapped), giving: </p>
<p>We then return to the scheduler, asking it to enter the itbl at t.o.s. When entered, stg_itoc_ret_REP_info removes itself from the stack, pops the return value into the relevant return register, and returns to the itbl to which we were trying to return in the first place.</p>
<p>Amazingly enough, this stuff all actually works! Well, mostly ...</p>
<h2 id="unboxed-tuples-a-right-royal-spanner-in-the-works">Unboxed tuples: a Right Royal Spanner In The Works</h2>
<p>The above scheme depends crucially on having magic infotables stg_{itoc,ctoi}_ret_REP_info for each return representation REP. It unfortunately fails miserably in the face of unboxed tuple returns, because the set of required tables would be infinite; this despite the fact that for any given unboxed tuple return type, the scheme could be made to work fine.</p>
<p>This is a serious problem, because it prevents interpreted code from doing IO-typed returns, since IO t is implemented as `(# t, RealWorld# #)` or thereabouts. This restriction in turn rules out FFI stuff in the interpreter. Not good.</p>
<p>Although we have no way to make general unboxed tuples work, we can at least make IO-types work using the following ultra-kludgey observation: `RealWorld#` doesn't really exist and so has zero size, in compiled code. In turn this means that a type of the form `(# t, RealWorld# #)` has the same representation as plain t does. So the bytecode generator, whilst rejecting code with general unboxed tuple returns, recognises and accepts this special case. Which means that IO-typed stuff works in the interpreter. Just.</p>
<p>If anyone asks, I will claim I was out of radio contact, on a 6-month walking holiday to the south pole, at the time this was ... er ... dreamt up.</p>
<h1 id="porting-ghc-using-llvm-backend">Porting GHC using LLVM backend</h1>
<p>This document is kind of short porting roadmap which serves as a high-level overview for porters of GHC who decided to use LLVM instead of implementing new NCG for their target platform. Please have [wiki:Commentary/Compiler/Backends/LLVM/Design Design &amp; Implementation] at hand since this contains more in-depth information. The list of steps needed for new GHC/LLVM port is:</p>
<p><strong>(1)</strong> Make sure GHC unregisterised build is working on your target platform (using the C backend). This guide isn't intended for porting GHC to a completely unsupported platform. If the platform in question doesn't have a GHC unregisterised build then follow the [wiki:Building/Porting GHC Porting Guide] first.</p>
<p><strong>(2)</strong> Now try to compile some very simple programs such as 'hello world' or simpler using the GHC you just built. Try with the C backend First to make sure everything is working. Then try with the LLVM backend. If the llvm backend built programs are failing find out why. This is done using a combination of things such as the error message you get when the program fails, [wiki:Debugging/CompiledCode tracing the execution with GDB] and also just comparing the assembly code produced by the C backend to what LLVM produces. This last method is often the easiest and you can occasionally use techniques like doing doing a 'binary search' for the bug by merging the assembly produced by the C backend and LLVM backend.</p>
<p><strong>(3)</strong> When the programs you throw at the LLVM backend are running, try running the GHC testsuite. First run it against the C backend to get a baseline, then run it against the LLVM backend. Fix any failures that are LLVM backend specific.</p>
<p><strong>(4)</strong> If the testsuite is passing, now try to build GHC itself using the LLVM backend. This is a very tough test. When working though its a good proof that the LLVM backend is working well on your platform.</p>
<p><strong>(5)</strong> Now you have LLVM working in unregistered mode, so the next thing is to implement the GHC calling convention in LLVM that is used by GHC's LLVM backend. This should then allow you to get the LLVM backend working in registered mode but with (TABLES_NEXT_TO_CODE = NO in your build.mk). Majority of this step involves hacking inside the LLVM code. Usually lib/Target/<your target platform name> is the best way to start. Also you might study what David Terei did for <a href="http://lists.cs.uiuc.edu/pipermail/llvmdev/2010-March/030031.html">x86 support</a> and his <a href="http://lists.cs.uiuc.edu/pipermail/llvmdev/attachments/20100307/714e5c37/attachment-0001.obj">patch itself</a> to get an idea what's really needed.</p>
<p><strong>(6)</strong> Once <strong>(5)</strong> is working you have it all running except TABLES_NEXT_TO_CODE. So change that to Yes in your build.mk and get that working. This will probably involve changing the mangler used by LLVM to work on the platform you are targeting.</p>
<h2 id="registerised-mode">Registerised Mode</h2>
<p>Here is an expanded version of what needs to be done in step 5 and 6 to get a registerised port of LLVM working:</p>
<p>1. GHC in registerised mode stores some of its virtual registers in real hardware registers for performance. You will need to decide on a mapping of GHC's virtual registers to hardware registers. So how many registers you want to map and which virtual registers to store and where. GHC's design for this on X86 is basically to use as many hardware registers as it can and to store the more frequently cessed virtual registers like the stack pointer in callee saved registers rather than caller saved registers. You can find the mappings that GHC currently uses for supported architectures in 'includes/stg/MachRegs.h'.</p>
<p>2. You will need to implement a custom calling convention for LLVM for your platform that supports passing arguments using the register map you decided on. You can see the calling convention I have created for X86 in the llvm source file 'lib/Target/X86/X86CallingConvention.td'.</p>
<p>3. Get GHC's build system running on your platform in registerised mode.</p>
<p>4. Add new inline assembly code for your platform to ghc's RTS. See files like 'rts/StgCRun.c' that include assembly code for the architectures GHC supports. This is the main place as its where the boundary between the RTS and haskell code is but I'm sure there are definitely other places that will need to be changed. Just grep the source code to find existing assembly and add code for your platform appropriately.</p>
<p>5. Will need to change a few things in LLVM code gen.</p>
<p>5.1 'compiler/llvmGen/LlvmCodeGen/Ppr.hs' defines a platform specific string that is included in all generated llvm code. Add one for your platform. This string specifies the datalayout parameters for the platform (e.g pointer size, word size..). If you don't include one llvm should still work but wont optimise as aggressively.</p>
<p>5.2 'compiler/llvmGen/LlvmCodeGen/CodeGen.hs' has some platform specific code on how write barriers should be handled.</p>
<p>6. Probably some stuff elsewhere in ghc that needs to be changed (most likely in the main/ subfolder which is where most the compiler driver lives or in codegen/ which is the Cmm code generator).</p>
<p>7. This is just what I know needs to be done, I'm sure there is many small pieces missing although they should all fall into one of the above categories. In the end just trial and error your way to success.</p>
<p><a href="PageOutline" class="uri" title="wikilink">PageOutline</a></p>
<h1 id="packages-in-ghc">Packages in GHC</h1>
<p>This page summarises our current proposal for packages in GHC. (See also [wiki:Commentary/Packages/PackageNamespacesProposal an extended proposal] to make namespaces first-class. The two proposals are mutually exclusive.)</p>
<h2 id="the-problem">The problem</h2>
<p>A vexed question in the current design of Haskell is the issue of whether a single program can contain two modules with the same name. In Haskell 98 that is absolutely ruled out. As a result, packages are fundamentally non-modular: to avoid collisions <em>every</em> module in <em>every</em> package written by <em>anyone</em> must have different module names. That's like saying that every function must have different local variables, and is a serious loss of modularity.</p>
<p>GHC 6.6 makes a significant step forward by lifting this restriction. However it leaves an open question, which is what this page is about.</p>
<h2 id="assumptions">Assumptions</h2>
<p>Before we start, note that we take for granted the following</p>
<p><code>*</code><strong><code>Each</code> <code>package</code> <code>has</code> <code>a</code> <code>globally-unique</code> <code>name</code></strong><code>,organisedbysomesocialprocess.ThisassumptionisdeeplybuiltintoCabal,andlotsofthingswouldneedtochangeifitwasn'tmet.</code></p>
<p><code>*</code><strong><code>Module</code> <code>names</code> <code>describe</code> <em><code>purpose</code></em> <code>(what</code> <code>it's</code> <code>for,</code> <code>e.g.</code> <code>),</code> <code>whereas</code> <code>package</code> <code>names</code> <code>describe</code> <em><code>provenance</code></em> <code>(where</code> <code>it</code> <code>comes</code> <code>from,</code> <code>e.g.</code> <code>)</code></strong><code>.Weshouldnotmixthesetwoup,andthatisagoodreasonfornotcombiningpackageandmodulenamesintoasinglegrandname.Onequitefrequentlywantstogloballychangeprovenancebutnotpurpose(e.g.compilemyprogramwithanewversionofpackage&quot;foo&quot;),withoutrunningthroughallthesourcefilestochangetheimportstatements.</code></p>
<p><code>*</code><strong><code>New:</code> <code>a</code> <code>module</code> <code>name</code> <code>must</code> <code>be</code> <code>unique</code> <code>within</code> <code>its</code> <code>package</code> <code>(only)</code></strong><code>.Thatis,asingleprogramcanusetwomoduleswiththesamemodulename,providedtheycomefromdifferentpackages.ThisisnewinGHC6.6.</code></p>
<p>For all this to work, GHC must incorporate the package name (and version) into the names of entities the package defines. That means that when compiling a module M you must say what package it is part of:  Then C.o will contain symbols like &quot;&quot; etc. In effect, the &quot;original name&quot; of a function  in module  of package  is .</p>
<h2 id="the-open-question">The open question</h2>
<p>The remaining question is this: <strong>When you say , from what package does A.B.C come?</strong>. Three alternatives are under consideration:</p>
<p><code>*PlanA(GHC'scurrentstory)</code><br />
<code>*PlanB:grafting.AnenhancementofplanA;see[wiki:Commentary/Packages/PackageMountingProposalFrederikEaton'sproposal]</code><br />
<code>*PlanC:optionallyspecifythepackageintheimport.Analternativeto(B),describedina[wiki:Commentary/Packages/PackageImportsProposalseparatepage].</code></p>
<hr />
<h2 id="plan-a-ghcs-current-story">Plan A: GHC's current story</h2>
<p>GHC already has a fairly elaborate scheme (perhaps too elaborate; <a href="http://www.haskell.org/ghc/dist/current/docs/users_guide/packages.html">documentation here</a>) for deciding what package you mean when you say &quot;import A.B.C&quot;:</p>
<p><code>*Forastart,itonlylooksin</code><em><code>installed</code></em><code>packages.</code><br />
<code>*Evenforinstalledpackages,thepackagemayormaynotbe</code><em><code>exposed</code></em><code>bydefault(reasoning:youmaywantoldversionsofpackageXtobeinstalled,butnotinscopebydefault).</code><br />
<code>*Then,youcanusethe</code><code>flagtohideanotherwise-exposedpackage,andthe</code><code>flagtoexposeanotherwise-hiddenpackage.</code></p>
<p>So, you can expose package P1 when compiling module M (say), and expose P2 when compiling module N by manipulating these flags. Then M and N could both import module A.B.C, which would come from P1 and P2 respectively. But:</p>
<p><code>*WhatifyouwantedtoimportA.B.CfromP1andA.B.CfromP2intothe</code><em><code>same</code></em><code>module?</code><br />
<code>*Whatifyouwanttoonlyreplace</code><em><code>parts</code></em><code>ofP1(e.g.,youwanttouseanupdatedversionofamodulein</code><code>)?</code><br />
<code>*Compilingdifferentmoduleswithdifferentflagsinawaythataffectsthe</code><em><code>semantics</code></em><code>(ratherthan,say,theoptimisationlevel)seemsundesirable.</code><br />
<code>*Tosupport</code><code>inthissituationwe'dneedtoallow</code><code>flagsintheper-module</code><code>pragmas,whichisn'tcurrentlysupported.(</code><code>alreadygathersthoseoptionstogetherforthelinkstep.)</code><em><code>This</code> <code>is</code> <code>not</code> <code>yet</code> <code>implemented,</code> <code>but</code> <code>it</code> <code>is</code> <code>close</code> <code>to</code> <code>being</code> <code>implemented.</code></em></p>
<p>If we did implement the &quot;`-package` in `OPTIONS` pragma&quot; fix, then is is not clear how pressing the need is for anything more. It's still impossible to import M from P1, and M from P2, into the same module. But how often will that happen?</p>
<hr />
<h2 id="plan-b-package-mounting">Plan B: package mounting</h2>
<p>This proposal is described by a [wiki:Commentary/Packages/PackageMountingProposal separate page].</p>
<hr />
<h2 id="plan-c-mention-the-package-in-the-import">Plan C: mention the package in the import</h2>
<p>This proposal is described by a [wiki:Commentary/Packages/PackageImportsProposal separate page].</p>
<p>This wiki discusses how bringing <a href="https://nixos.org/nix/">Nix</a>-style package management facilities to cabal can solve various cabal problems and help in effective mitigation of cabal hell. It also contains the goals and implementation plan for the GSoC project. It is based on a <a href="http://www.well-typed.com/blog/2015/01/how-we-might-abolish-cabal-hell-part-2/">blog post by Duncan Coutts</a>.</p>
<h1 id="problems">Problems</h1>
<h2 id="breaking-re-installations">Breaking re-installations</h2>
<p><a href="Image(http://www.well-typed.com/blog/aux/images/cabal-hell/install-example1.png)" class="uri" title="wikilink">Image(http://www.well-typed.com/blog/aux/images/cabal-hell/install-example1.png)</a></p>
<p>There are situations where Cabal's chosen solution would involve reinstalling an existing version of a package but built with different dependencies. In this example, after installing app-1.1, app-1.0 and other-0.1 will be broken. The root of the problem is having to delete or mutate package instances when installing new packages. This is due to the limitation of only being able to have one instance of a package version installed at once.</p>
<h2 id="type-errors-when-using-packages-together">Type errors when using packages together</h2>
<p><a href="Image(http://www.well-typed.com/blog/aux/images/cabal-hell/install-example2.png)" class="uri" title="wikilink">Image(http://www.well-typed.com/blog/aux/images/cabal-hell/install-example2.png)</a></p>
<p>The second, orthogonal, problem is that it is possible to install two packages and then load them both in GHCi and find that you get type errors when composing things defined in the two different packages. Effectively you cannot use these two particular installed packages together. The fundamental problem is that developers expect to be able to use combinations of their installed packages together, but the package tools do not enforce consistency of the developer's environment.</p>
<h1 id="goals">Goals</h1>
<ul>
<li>Fix breaking re-installs (Persistent package store)</li>
<li>Implement garbage collection to free unreachable packages</li>
<li>Enable sharing of packages between sandbox</li>
<li>Enforce development environment consistency (Giving error earlier and better)</li>
<li>Implement package manager tools in cabal-install(cabal upgrade and cabal remove)</li>
</ul>
<h1 id="implementation-plan">Implementation Plan</h1>
<h2 id="persistent-package-store">Persistent package store</h2>
<p>A <a href="https://github.com/ghc/ghc/commit/dd3a7245d4d557b9e19bfa53b0fb2733c6fd4f88">patch</a> has been pushed for ghc-7.11 that allows multiple instance of the same package to be installed. So the remaining work is in cabal tool for never modifying installed packages. I have written a <a href="https://github.com/fugyk/cabal/commit/45ec5edbaada1fd063c67d6109e69efa0e732e6a">patch to make cabal (almost)non-destructive</a>. This patch makes all the changes to Package database non-destructive if Installed Package ID is different. To make it fully non-mutable, Thomas Tuegel suggested to</p>
<ul>
<li>change installed package IDs to be computed by hash of the sdist tarball.</li>
<li>Enforce that a package is never overwritten by taking out a lock when updating the database.(before building the package)</li>
</ul>
<p>It will have additional benefit that package will not be built again if same source has already been built earlier, thus saving time.</p>
<h2 id="views">Views</h2>
<p>Views will the subset of packages of package store whose modules can be imported. Views will be present as various *.view file in <Package DB location>/views like default.view. The view file contains list of installed package IDs. There will exist a default view which contains packages installed by cabal install outside sandbox. If a package name is installed two times, default view will contain the instance of package which is installed at last. Views' packages will also act like GC roots.</p>
<p>To facilitate views, ghc-pkg will need some new commands:</p>
<ul>
<li>Create a view / Symlink a view</li>
<li>Delete a view</li>
<li>List all views</li>
<li>Modify a view</li>
<li>Add a package</li>
<li>Remove a package</li>
</ul>
<p>Sandbox will be a view. Cabal needs to set view when using sandbox. It also needs the ability to make a view and also add a package to the view. Packages can be shared between views. View path will be passed to ghc using -package-env. The view file that sandbox creates lies in the same directory and is symlinked from the package database view file for allowing GC. It will have a benefit that when we just delete the sandbox directory without deleting the view, GC can free that sandbox package.</p>
<p>It looks similar to nix development environment but has some differences. nix environments are like everything that is visible. It is kind of like imported packages with dependency closure. nix needs to make directories visible, while here we already have one more layer. Here we only need exposed package and ghc can make complete environment already. Views are just exposed packages of the environment. So, dependency of the package need not be in the view that the package is in. The problem that we are trying to solve with views is consistent way of managing packages and sandboxes, allowing packages to be shared between sandboxes and its packages being used as GC root.</p>
<p>Summary of design details</p>
<p>When installing a package outside sandbox</p>
<ul>
<li>Package is added to default view / modified in default view</li>
</ul>
<p>Making a sandbox</p>
<ul>
<li>A view is made in the directory</li>
<li>The new view is symlinked from the database</li>
<li>Packages that are installed are added to that view. Sandboxes cannot affect any other things outside sandbox.</li>
</ul>
<p>Within sandbox</p>
<ul>
<li>All the cabal commands pass view name to ghc and ghc will use relevant package</li>
</ul>
<h2 id="consistent-developer-environment">Consistent developer environment</h2>
<p>It will require additional constraint to check that there is no other instance of the same package or its dependencies is in the environment(packages from which we have imported the modules with their dependency closure) when we are importing the module from a package. It also needs to be checked when cabal is configuring the package, that a package do not directly or indirectly depends on two version of same package. If it is violated it needs to give out an error.</p>
<h2 id="garbage-collection">Garbage collection</h2>
<p>This will firstly involve determining the root packages and package list. Root packages are the packages which are in some view. Then we find list of all packages in the database. As there will be single database after implementing views, we don't need to call it for every sandbox database. Then we need to do mark-sweep and find which package are not in the reachable package list and select it for garbage collection. Then the selected packages will be deleted from the package store and also unregistered from database with ghc-pkg.</p>
<h2 id="cabal-remove">cabal remove</h2>
<p>With everything implemented above, it is just removing a package from default view. If package is unreachable it can be freed from disk by GC. It is guaranteed to not break any package except the package that is removed.</p>
<h2 id="cabal-upgrade">cabal upgrade</h2>
<p>cabal upgrade is just installing every package that is present in default view that has update available.</p>
<h2 id="current-status-1">Current Status</h2>
<p>It is possible to install multiple instances of the same package version with my forks of cabal and ghc. Quite a few problems remain.</p>
<p>See also [wiki:Commentary/Packages/MultiInstances]</p>
<h3 id="unique-install-location">Unique Install Location</h3>
<p>When specifying the install location there is a new variable $unique available. It is resolved to a random number by cabal-install during configuring. The default libsubdir for cabal-install should be &quot;$packageid-$unique&quot; for example &quot;mtl-2.1.2-1222131559&quot;. Cabal the library does not understand $unique so multiple instances of the same package version installed via &quot;runhaskell Setup.hs install&quot; are still problematic.</p>
<h3 id="ghc-pkg">ghc-pkg</h3>
<p>ghc-pkg never removes registered packages when registering a new one. Even if a new package with the same `InstalledPackageId` as an existing package is registered. Or if a new package that points to the same install directory is registered. `ghc-pkg` should probably check this and issue a warning.</p>
<h3 id="adhoc-dependency-resolution">Adhoc dependency resolution</h3>
<p>A new field `timestamp` was added to `InstalledPackageInfo`. It is set by Cabal the library when registering a package. It is used by Cabal the library, GHC and cabal-install to choose between different instances of the same package version.</p>
<h3 id="detect-whether-an-overwrite-happens-and-warn-about-it">Detect whether an overwrite happens and warn about it</h3>
<p>Currently cabal-install still warns about dangerous reinstalls and requires `--force-reinstalls` when it is sure a reinstall would happen. The correct behaviour here would be to detect if a reinstall causes overwriting (because of a version of ghc-pkg that does this) and warn only in this case. In this implementation reinstalls are not dangerous anymore.</p>
<h3 id="communicate-the-installedpackageid-back-to-cabal-install">Communicate the `InstalledPackageId` back to cabal-install</h3>
<p>An `InstallPlan` contains installed packages as well as packages to be installed and dependencies between those. We want to specify all of these dependencies with an `InstalledPackageId`. Unfortunately the `InstalledPackageId` is determined after installation and therefore not available for not yet installed packages. After installation it would have to be somehow communicated back to cabal-install. The current workaround is to only specify those packages that were previously installed with an `InstalledPackageId` and trust on Cabal picking the instance that was most recently (during execution of this install plan) installed for the other ones.</p>
<h3 id="garbage-collection-1">Garbage Collection</h3>
<p>A garbage collection should offer the removal of a certain package specified by `InstalledPackageId`, the removal of broken packages and the removal of probably unnecessary packages. A package is unnecessary if all packages that depend on it are unnecessary (this includes the case that no package depends on it) and it is not the most recently installed instance for its version. All of this should be accompanied by a lot of &quot;are you sure&quot; questioning.</p>
<h3 id="about-shadowing">About Shadowing</h3>
<p>GHC has the concept of shadowing. It was introduced as far as i understand (correct me please) because when combining the global and the user package databases you could end up with two instances of the same package version. The instance in the user database was supposed to shadow the one in the global database. Now that there are multiple instances of the same package version even in one package database this concepts needs to be rethought. This is non-trivial because flags asking for a package version as well as flags requiring a certain instance need to be taken into account.</p>
<h3 id="about-unique-identifier">About Unique Identifier</h3>
<p>Currently a big random number is created by cabal-install during configuration and passed to Cabal to be appended to the `InstalledPackageId` before registering. The reason is that the `InstalledPackageId` still contains the ABI hash which is only known after compilation. I personally would like the `InstalledPackageId` to be the name of the package, the version and a big random number. This could be determined before compilation, used as the `libsubdir` and baked into `package_Paths.hs`. Since it would be determined by cabal-install it would also make communicating the InstalledPackageId back to cabal-install after an installation unnecessary. The problem is that the `InstalledPackageId` would not be deterministic anymore.</p>
<h2 id="original-plan">Original Plan</h2>
<p>Cabal and GHC do not support multiple instances of the same package version installed at the same time. If a second instance of a package version is installed it is overwritten on the file system as well as in the `PackageDB`. This causes packages that depended upon the overwritten instance to break. The idea is to never overwrite an installed package. As already discussed in <a href="http://hackage.haskell.org/trac/ghc/wiki/Commentary/Packages/MultiInstances">4</a> the following changes need to be made:</p>
<p><code>*Cabalshouldinstallpackagestoalocationthatdoesnotjustdependonnameandversion,</code><br />
<code>*`ghc-pkg`shouldalwaysaddinstancestothe`PackageDB`andneveroverwritethem,</code><br />
<code>*`ghc--make`,`ghci`,andtheconfigurephaseofCabalshouldselectsuitableinstancesaccordingtosomeruleofthumb(similartothecurrentresolutiontechnique),</code><br />
<code>*wewanttobeabletomakemorefine-graineddistinctionsbetweenpackageinstancesthancurrentlypossible,forexamplebydistinguishingdifferentbuildflavoursor&quot;ways&quot;(profiling,etc.)</code><br />
<code>*`cabal-install`shouldstillfindan`InstallPlan`,andstillavoidunnecessarilyrebuildingpackageswheneveritmakessense</code><br />
<code>*someformofgarbagecollectionshouldbeofferedtohaveachancetoreducetheamountofinstalledpackages</code></p>
<h2 id="hashes-and-identifiers">Hashes and identifiers</h2>
<p>There are three identifiers:</p>
<p><code>*`XXXX`:theidentifierappendedtotheinstallationdirectorysothatinstalledpackagesdonotclashwitheachother</code><br />
<code>*`YYYY`:the`InstalledPackageId`,whichisanidentifierusedtouniquelyidentifyapackageinthepackagedatabase.</code><br />
<code>*`ZZZZ`:theABIhashderivedbyGHCaftercompilingthepackage</code></p>
<p>The current situation:</p>
<p><code>*`XXXX`:isempty,whichisbad(twoinstancesofapackageinstallinthesameplace)</code><br />
<code>*`YYYY`:iscurrentlyequalto`ZZZZ`,whichisbadbecauseweneedtomakemoredistinctions:</code><br />
<code>*weneedtodistinguishbetweentwopackagesthathaveidenticalABIsbutdifferentbehaviour(e.g.abugwasfixed)</code><br />
<code>*weneedtodistinguishbetweentwoinstancesofapackagethatarecompiledagainstdifferentdependencies,orwithdifferentoptions,orcompiledinadifferentway(profiling,dynamic)</code></p>
<p>Some notes:</p>
<p><code>*`XXXX`mustbedecided</code><em><code>before</code></em><code>webegincompiling,becausewehavetogeneratethe`Paths_P.hs`filethatiscompiledalongwiththepackage,whereas`ZZZZ`isonlyavailable</code><em><code>after</code></em><code>wehavecompiledthepackage.</code><br />
<code>*`ZZZZ`isnotuniquelydeterminedbythecompilationinputs(see#4012),althoughinthefuturewehopeitwillbe</code><br />
<code>*Itisdesirablethatwhentwopackageshaveidentical`YYYY`values,thentheyarecompatible,eveniftheywerebuiltonseparatesystems.Notethatthisisnotguaranteedevenif`YYYY`isadeterministicfunctionofthecompilationinputs,because`ZZZZ`isnon-deterministic(previouspoint).Hence`YYYY`mustbedependenton`ZZZZ`.</code><br />
<code>*Itisdesirablethat`YYYY`beasdeterministicaspossible,i.e.wewouldrathernotuseaGUID,but`YYYY`shouldbedeterminedbythecompilationinputsand`ZZZZ`.Weknowthat`ZZZZ`iscurrentlynotdeterministic,butinthefutureitwillbe,andatthatpoint`YYYY`willbecomedeterministictoo,inthemeantime`YYYY`shouldbenolessdeterministicthan`ZZZZ`.</code></p>
<p>Our proposal:</p>
<p><code>*Wedefineanew</code><em><code>Cabal</code> <code>Hash</code></em><code>thathashesthecompilationinputs(the`LocalBuildInfo`andthecontentsofthesourcefiles)</code><br />
<code>*`XXXX`isaGUID.</code><br />
<code>*Whynotusethe</code><em><code>Cabal</code> <code>Hash</code></em><code>?Wecould,butthentherecouldconceivablybeaclash.(Andres-pleaseexpandthispoint,Ihaveforgottenthefullrationale).</code><br />
<code>*`YYYY`isthecombinationofthe</code><em><code>Cabal</code> <code>Hash</code></em><code>and`ZZZZ`(concatenated)</code><br />
<code>*`ZZZZ`isrecordedinthepackagedatabaseasanewfield`abi-hash`.</code><br />
<code>*Whentwopackageshaveidentical`ZZZZ`sthentheyareinterface-compatible,andtheusermightinthefuturewanttochangeaparticulardependencytouseadifferentpackagebutthethesame`ZZZZ`.Wedonotwanttomakethischangeautomatically,becauseevenwhentwopackageshaveidentical`ZZZZ`s,theymayhavedifferentbehaviour(e.g.bugfixes).</code></p>
<h2 id="install-location-of-installed-cabal-packages">Install location of installed Cabal packages</h2>
<p>Currently the library part of packages is installed to `$prefix/lib/$pkgid/$compiler`. For example the `GLUT` package of version 2.3.0.0 when compiled with GHC 7.4.1 when installed globally lands in `/usr/local/lib/GLUT-2.3.0.0/ghc-7.4.1/`. This is the default path. It is completely customizable by the user. In order to allow multiple instances of this package to coexist we need to change the install location to a path that is unique for each instance. Several ways to accomplish this have been discussed:</p>
<h3 id="hash">Hash</h3>
<p>Use a hash to uniquely identify package instances and make the hash part of both the InstalledPackageId and the installation path.</p>
<p>The ABI hash currently being used by GHC is not suitable for unique identification of a package, because it is nondeterministic and not necessarily unique. In contrast, the proposed Cabal hash should be based on all the information needed to build a package.</p>
<p>This approach requires that we know the hash prior to building the package, because there is a data directory (per default under $prefix/share/$pkgid/) that is baked into Paths_foo.hs in preparation of the build process.</p>
<h3 id="unique-number">Unique number</h3>
<p>Use a unique number as part of the installation path.</p>
<p>A unique number could be the number of packages installed, or the number of instances of this package version already installed, or a random number. It is important that the numbers are guaranteed to be unique system-wide, so the counter-based approaches are somewhat tricky.</p>
<p>The advantage over using a hash is that this approach should be very simple to implement. On the other hand, identifying installed packages (see below) could possibly become more difficult, and migrating packages to other systems is only possible if the chance of collisions is reasonably low (for example, if random numbers are being used).</p>
<p><code>1.Theuniquenumberisalsopartoftheinstalledpackageid.</code></p>
<p><code>2.Wecanuseanotheruniqueidentifier(forexample,aCabalhash)toidentifyinstalledpackages.Inthiscase,thatidentifierwouldbeallowedtodependontheoutputofapackagebuild.</code></p>
<h2 id="ghc-pkg-1">`ghc-pkg`</h2>
<p>`ghc-pkg` currently identifies each package by means of an `InstalledPackageId`. At the moment, this id has to be unique per package DB and is thereby limiting the amount of package instances that can be installed in a single package DB at one point in time.</p>
<p>In the future, we want the `InstalledPackageId` to still uniquely identify installed packages, but in addition to be unique among all package instances that could possibly be installed on a system. There's still the option that one InstalledPackageId occurs in several package DBs at the same time, but in this case, the associated packages should really be completely interchangeable. [If we want to be strict about this, we'd have to include the ABI hash in the `InstalledPackageId`.]</p>
<p>Even though, as discussed above, the ABI hash is not suitable for use as the `InstalledPackageId` given these changed requirements, we will need to keep the ABI hash as an essential piece of information for ghc itself.</p>
<p>`ghc-pkg` is responsible for storing all information we have about installed packages. Depending on design decisions about the solver and the Cabal hash, further information may be required in `ghc-pkg`'s description format (see below).</p>
<p>The following fields will be added to the description format:</p>
<p>A field <em>Way</em> of type `[String]`. It tracks the way in which the package was compiled. It is a subset of `{v,d,p}`. &quot;v&quot; means vanilla, &quot;d&quot; means dynamic linking and &quot;p&quot; means profiling. Other ways may be added later.</p>
<p>A `timestamp` of the time when the package was installed (or built?). It is used by GHC and Cabal to put a preference on the latest package of a certain version.</p>
<p>A currently empty but extensible set of fields starting with &quot;x-cabal-...&quot;. `ghc-pkg` ignores them when parsing. During the resolution phase `cabal-install` might use them to decide compatibility between packages.</p>
<p>A field abi-hash that contains the ABI hash because it is no longer stored implicitly as part of the `InstalledPackageId`.</p>
<h2 id="simplistic-dependency-resolution">Simplistic dependency resolution</h2>
<p>The best tool for determining suitable package instances to use as build inputs is `cabal-install`. However, in practice there will be many situations where users will probably not have the full `cabal-install` functionality available:</p>
<p><code>1.invokingGHCifromthecommandline,</code><br />
<code>2.invokingGHCdirectlyfromthecommandline,</code><br />
<code>3.invokingtheconfigurephaseofCabal(withoutusing`cabal-install`).</code></p>
<p>In these cases, we have to come up with a suitable selection of package instances, and the only info we have available are the package DBs plus potential command line flags. Cabal will additionally take into account the local constraints of the package it is being invoked for, whereas GHC will only consider command-line flags, but not modules it has been invoked with.</p>
<p>Currently if GHC is invoked by the user it does some adhoc form of dependency resolution. The most common case of this is using ghci. If there are multiple instances of the same package in the `PackageDBStack` the policy used to select a single one prefers DBs higher in the stack. It then prefers packages with a higher version. Once we allow package instances with the same version within a single package DB, we need to refine the algorithm. Options are:</p>
<p><code>*pickarandom/unspecifiedinstances</code><br />
<code>*usethetimeofinstallation</code><br />
<code>*user-specifiedpriorities</code><br />
<code>*usetheorderinthe`PackageDB`</code><br />
<code>*lookatthetransitiveclosureofdependenciesandtheirversions</code><br />
<code>*buildacomplexsolverintoGHC</code></p>
<p>Picking a random version is a last resort. A combination of installation time and priorities seems rather feasible. It makes conflicts unlikely, and allows to persistently change the priorities of installed packages. Using the order in the package DB is difficult if directories are being used as DBs. Looking at the transitive closure of dependencies makes it hard to define a total ordering of package instances. Adding a complex solver is unattractive unless we find a way to reuse `cabal-install`'s functionality within GHC, but probably we do not want to tie the two projects together in this way.</p>
<h2 id="build-flavours">Build flavours</h2>
<p>Once we distinguish several package instances with the same version, we have a design decision how precise we want that distinction to be.</p>
<p>The minimal approach would be to just take the transitive dependencies into account. However, we might also want to include additional information about builds such as Cabal flag settings, compiler options, profiling, documentation, build tool versions, external (OS) dependencies, and more.</p>
<p>These differences have to be tracked. The two options we discuss are to store information in the `ghc-pkg` format, or to incorporate them in a Cabal hash (which is then stored). Both options can be combined.</p>
<h3 id="the-cabal-hash">The Cabal hash</h3>
<p>[A few notes about where to find suitable information in the source code:]</p>
<p>A build configuration consists of the following:</p>
<p>The Cabal hashes of all the package instances that are actually used for compilation. This is the environment. It is available in the `installedPkgs` field of `LocalBuildInfo` which is available in every step after configuration. It can also be extracted from an `InstallPlan` after dependency resolution.</p>
<p>The compiler, its version and its arguments and the tools and their version and their arguments. Available from LocalBuildInfo also. More specifically: `compiler`, `withPrograms`, `withVanillaLib`, `withProfLib`, `withSharedLib`, `withDynExe`, `withProfExe`, `withOptimization`, `withGHCiLib`, `splitObjs`, `stripExes`. And a lot more. [Like what?]</p>
<p>The source code. This is necessary because if the source code changes the result of compilation changes. For released packages I would assume that the version number uniquely identifies the source code. A hash of the source code should be available from hackage to avoid downloading the source code. For an unreleased package we need to find all the source files that are needed for building it. Including non-haskell source files. One way is to ask a source tarball to be built as if the package was released and then hash all the sources included in that.</p>
<p>OS dependencies are not taken into account because i think it would be very hard.</p>
<h3 id="released-and-unreleased-packages">Released and Unreleased packages</h3>
<p>If we cabal install a package that is released on hackage we call this a <strong>clean install</strong>. If we cabal install an unreleased package we call this a <strong>dirty install</strong>. Clean installs are mainly used to bring a package into scope for ghci and to install applications. While they can be used to satisfy dependencies this is discouraged. For released packages the set of source files needed for compilation is known. For unreleased packages this is currently not the case.</p>
<h2 id="dependency-resolution-in-cabal-install">Dependency resolution in cabal-install</h2>
<p>There are two general options for communicating knowledge about build flavors to the solver:</p>
<p><code>1.</code><strong><code>the</code> <code>direct</code> <code>way</code></strong><code>:i.e.,allinfoisavailabletoghc-pkgandcanbecommunicatedbacktoCabalandthereforethesolvercanfigureoutifaparticularpackageissuitabletouseornot,inadvance;</code></p>
<p><code>2.</code><strong><code>the</code> <code>agnostic</code> <code>way</code></strong><code>:thisisbasedontheideathatthesolveratfirstdoesn'tconsiderinstalledpackagesatall.It'lljustdoresolutiononthesourcepackagesavailable.Then,takingallbuildparametersintoaccount,Cabalhasheswillbecomputed,whichcanthenbecomparedtohashesofinstalledpackages.</code></p>
<p>Reusing installed packages instead of rebuilding them is then an optimization of the install plan.</p>
<p>The agnostic way does not require `ghc-pkg` to be directly aware of all the build parameters, as long as the hash computation is robust</p>
<p>The options are to support either both by putting all info into `InstalledPackageInfo` or to support only the second option by just putting a hash into `InstalledPackageInfo`. The disadvantage of supporting both is that `InstalledPackageInfo` would have to change more often. This could be fixed by explicitly making the `InstalledPackageInfo` format extensible in a backwards-compatible way.</p>
<p>The advantages of having all info available, independently of the solver algorihm, are that the info might be useful for other tools and user feedback.</p>
<p>Possible disadvantages of the agnostic approach could be that is is a rather significant change and can probably not be supported in a similar way for other Haskell implementation. Also, in the direct approach, we could in principle allow more complex compatibility rules, such as allowing non-profiling libraries to depend on profiling libraries.</p>
<p>Also, even if we go for the agnostic approach, we still have to be able to handle packages such as base or ghc-prim which are in general not even available in source form.</p>
<p>On the other hand, the agnostic approach might lead to more predictable and reproducible solver results across many different systems.</p>
<h2 id="garbage-collection-2">Garbage Collection</h2>
<p>The proposed changes will likely lead to a dramatic increase of the number of installed package instances on most systems. This is particularly relevant for package developers who will conduct lots of dirty builds that lead to new instances being installed all the time.</p>
<p>It should therefore be possible to have a garbage collection to remove unneeded packages. However, it is not possible for Cabal to see all potential reverse dependencies of a package, so automatic garbage collection would be extremely unsafe.</p>
<p>Options are to either offer an interactive process where packages that look unused are suggested for removal, or to integrate with a sandbox mechanism. If, for example, dirty builds are usually installed into a separate package DB, that package DB could just be removed completely by a user from time to time.</p>
<p>The garbage collection functionality is part of cabal-install not of ghc-pkg. As a first approximation gc does not remove files only unregisters packages from the `PackageDB`.</p>
<h2 id="currently-open-design-decisions">Currently open design decisions</h2>
<h3 id="installedpackageid-and-install-path">`InstalledPackageId` and install path</h3>
<p>Options for uniquely identifying `InstalledPackageId`:</p>
<p><code>*Cabalhashonly</code><br />
<code>*Cabal+ABIhash(trulyunique)</code><br />
<code>*randomnumber</code></p>
<p>Options for identifying install path:</p>
<p><code>*Cabalhash</code><br />
<code>*randomnumber</code></p>
<p>ABI hash cannot be in install path because it's only available after build.</p>
<h3 id="handling-of-dirty-builds">Handling of dirty builds</h3>
<p>How should hash computation work for dirty builds?</p>
<p><code>*Usearandomnumberevenifweotherwiseusehashes</code><br />
<code>*Hashthecompletebuilddirectory</code><br />
<code>*Attempttomakeaclean(sdist-like)copyorlinkedcopyofthesourcesandhashandbuildfromthat.</code><br />
<code>*UsetheCabalfiletodeterminethefilesthatwouldendupinansdistandhashthosedirectlywithoutcopying.</code></p>
<p>The third option has the advantage(?) that the build is more guaranteed to use only files actually mentioned in the Cabal file.</p>
<h3 id="build-flavours-1">Build flavours</h3>
<p>To what degree should we distinguish package instances?</p>
<p><code>*Onlypackageversionstransitively</code><br />
<code>*WaysandCabalflags</code><br />
<code>*EverythingHaskell-specificinfothatwecanquery</code><br />
<code>*Evennon-Haskell-specificinputssuchasOSdependencies</code></p>
<h3 id="installedpackageinfo-and-solver-algorithm">`InstalledPackageInfo` and solver algorithm</h3>
<p>Options for `InstalledPackageInfo`:</p>
<p><code>*OnlyaddCabalhash.</code><br />
<code>*Add(nearly)allinformation,butinanextensibleformat.</code><br />
<code>*Addallinformationinawaythat`ghc-pkg`itselfcanuseit.</code></p>
<p>[These aren't necessarily mutually exclusive.]</p>
<p>Options for the solver:</p>
<p><code>*Direct(seeabove):requiresacertainamountofinfointhe`InstalledPackageInfo`.</code></p>
<p><code>*Agnostic(exceptforbuiltinpackages):couldbedonewithonlytheCabalhashin`InstalledPackageInfo`.</code></p>
<h3 id="simplistic-dependency-resolution-1">Simplistic dependency resolution</h3>
<p>Options (in order of preference):</p>
<p><code>*usethetimeofinstallation</code><br />
<code>*user-specifiedpriorities</code><br />
<code>*pickarandom/unspecifiedinstances</code><br />
<code>*(buildacomplexsolverintoGHC)</code></p>
<p>A combination of the first two seems possible and useful.</p>
<h2 id="related-topics">Related topics</h2>
<p>In the following, we discuss some other issues which are related to the multi-instance problem, but not necessarily directly relevant in order to produce an implementation.</p>
<h3 id="separating-storage-and-selection-of-packages">Separating storage and selection of packages</h3>
<p>Currently the two concepts of storing package instances (cabal store) and selecting package instances for building (environment) are conflated into a `PackageDB`. Sandboxes are used as a workaround to create multiple different environments. But they also create multiple places to store installed packages. The disadvantages of this are disk usage, compilation time and one might lose the overview. Also if the multi-instance restriction is not lifted sandboxes will eventually suffer from the same unintended breakage of packages as non-sandboxed `PackageDB`s. There should be a separation between the set of all installed packages called the cabal store and a subset of these called an environment. While the cabal store can contain multiple instances of the same package version an environment needs to be consistent. An environment is consistent if for every package version it contains only one instance of that package version.</p>
<h3 id="first-class-environments">First class environments</h3>
<p>It would be nice if we had some explicit notion of an environment.</p>
<h2 id="questions-to-remember">Questions to remember</h2>
<p>Should the cabal version be part of the hash?</p>
<p>Does the hash contain characters conflicting under windows?</p>
<p>What about builtin packages like ghc-prim, base, rts and so on?</p>
<p>Inplace Registration?</p>
<p>Who has assumptions about the directory layout of installed packages?</p>
<p>Executables?</p>
<p>Haddock?</p>
<p>Installation Planner?</p>
<p>Custom Builds and BuildHooks?</p>
<p>Other Compilers, backwards compatibility?</p>
<p>What is ComponentLocalBuildInfo for?</p>
<h1 id="the-haskell-execution-model">The Haskell Execution Model</h1>
<p>The [wiki:Commentary/Compiler/StgSynType STG language] has a clear <em>operational</em> model, as well as having a declarative lambda-calculus reading. The business of the [wiki:Commentary/Compiler/CodeGen code generator] is to translate the STG program into `C--`, and thence to machine code, but that is mere detail. From the STG program you should be able to understand:</p>
<p><code>*Whatfunctionsareinthecompiledprogram,andwhattheirentryandreturnconventionsare</code><br />
<code>*Whatheapobjectsareallocated,when,andwhattheirlayoutis</code></p>
<p>GHC uses an eval/apply execution model, described in the paper <a href="http://research.microsoft.com/%7Esimonpj/papers/eval-apply">How to make a fast curry: push/enter vs eval/apply</a>. This paper is well worth reading if you are interested in this section.</p>
<p>Contents:</p>
<p><code>*[wiki:Commentary/Rts/HaskellExecution/RegistersRegisters]</code><br />
<code>*[wiki:Commentary/Rts/HaskellExecution/FunctionCallsFunctionCalls]</code><br />
<code>*[wiki:Commentary/Rts/HaskellExecution/CallingConventionCallandReturnConventions]</code><br />
<code>*[wiki:Commentary/Rts/HaskellExecution/HeapChecksHeapandStackchecks]</code><br />
<code>*[wiki:Commentary/Rts/HaskellExecution/UpdatesUpdates]</code><br />
<code>*[wiki:Commentary/Rts/HaskellExecution/PointerTaggingPointerTagging]</code></p>
<h1 id="heap_alloced">HEAP_ALLOCED</h1>
<p>This page is about the `HEAP_ALLOCED()` macro/function in the runtime system. See #8199 which is about getting rid of `HEAP_ALLOCED`.</p>
<p></p>
<p>It is defined in `rts/sm/MBlock.h`. The purpose of `HEAP_ALLOCED()` is to return true if the given address is part of the dynamically-allocated heap, and false otherwise. Its primary use is in the Garbage Collector: when examining a pointer, we need to get to the block descriptor for that object. Static objects don't have block descriptors, because they live in static code space, so we need to establish whether the pointer is into the dynamic heap first, hence `HEAP_ALLOCED()`.</p>
<p>On a 32-bit machine, `HEAP_ALLOCED()` is implemented with a 4096-entry byte-map, one byte per megabyte of the address space (the dynamic heap is allocated in units of aligned megabytes).</p>
<p>On a 64-bit machine, it's a bit more difficult. The current method (GHC 6.10.1 and earlier) uses a cache, with a 4096-entry map and a 32-bit tag. If the upper 32 bits of the pointer match the tag, we look up in the map, otherwise we back off to a slow method that searches a list of mappings (bug #2934 is about the lack of thread-safety in the slow path here). This arrangement works fine for small heaps, but is pessimal for large (multi-GB) heaps, or heaps that are scattered around the address space.</p>
<h2 id="speeding-up-heap_alloced">Speeding up `HEAP_ALLOCED()`</h2>
<p>We should consider how to speed up `HEAP_ALLOCED()` for large heaps on 64-bit machines. This involves some kind of cache arrangement - the memory map is like a page table, and we want a cache that gives us quick access to commonly accessed parts of that map.</p>
<p><a href="attachment:faster-heap-alloced.patch.gz">5</a> implements one such scheme. Measurements show that it slows down GC by about 20% for small heaps (hence it wasn't committed), though it would probably speed up GC on large heaps.</p>
<h2 id="eliminating-heap_alloced-completely">Eliminating `HEAP_ALLOCED` completely</h2>
<p>Can we eliminate `HEAP_ALLOCED` altogether? We must arrange that all closure pointers have a valid block descriptor.</p>
<h3 id="method-1-put-static-closures-in-an-aligned-section">Method 1: put static closures in an aligned section</h3>
<p>ELF sections can be arbitrarily aligned. So we could put all our static closures in a special section, align the section to 1MB, and arrange that there is space at the beginning of the section for the block descriptors.</p>
<p>This almost works (see <a href="attachment:eliminate-heap-alloced.patch.gz">6</a>), but sadly fails for shared libraries: the system dynamic linker doesn't honour section-alignment requests larger than a page, it seems. Here is a simple test program which shows the problem on Linux:</p>
<p></p>
<p></p>
<p>Compare static linking and dynamic linking:</p>
<p></p>
<h3 id="method-2-copy-static-closures-into-a-special-area-at-startup">Method 2: copy static closures into a special area at startup</h3>
<p>We could arrange that we access all static closures via indirections, and then at startup time we copy all the static closures into a special area with block descriptors.</p>
<p>Disadvantages:</p>
<p><code>*referencestostaticobjectsgothroughanotherindirection.(ThisincludesalloftheRTScode!)</code><br />
<code>*whendoingdynamiclinking,referencestostaticobjectsinanotherpackage</code><br />
<code>alreadygothroughanindirectionandwecouldarrangethatonlyoneindirectionisrequired.</code><br />
<code>*Referencestostaticclosuresfromthethefieldsofastaticconstructorwouldnotincurtheextraindirection,</code><br />
<code>onlydirectreferencestostaticclosuresfromcode.</code><br />
<code>*wecurrentlyreferencethestaticclosureofafunctionfromtheheap-check-failcode,butinfact</code><br />
<code>weonlyreallyneedtopasstheinfopointer.</code></p>
<p>Advantages</p>
<p><code>*wegettofixupallthetagbitsinstaticclosurepointers</code><br />
<code>*wegettoeliminateHEAP_ALLOCED,speedingupGCandremovingcomplexity</code><br />
<code>*CAFsmightgetabitsimpler,sincetheyarealreadyindirectionsintotheheap</code></p>
<h1 id="heap-and-stack-checks">Heap and Stack checks</h1>
<p>Source files: <a href="GhcFile(rts/HeapStackCheck.cmm)" class="uri" title="wikilink">GhcFile(rts/HeapStackCheck.cmm)</a></p>
<p>When allocating a heap object, we bump `Hp` and compare to `HpLim`. If the test fails we branch to ???. Usually this code tests an interrupt flag (to see if execution should be brought tidily to a halt); grabs the next block of allocation space; makes `Hp` point to it and `HpLim` to its end; and returns. If there are no more allocation-space blocks, garbage collection is triggered.</p>
<hr />
<p>CategoryStub</p>
<p><a href="PageOutline" class="uri" title="wikilink">PageOutline</a></p>
<h1 id="ghc-commentary-the-layout-of-heap-objects">GHC Commentary: The Layout of Heap Objects</h1>
<h2 id="terminology">Terminology</h2>
<p><code>*A</code><em><code>lifted</code></em><code>typeisonethatcontainsbottom(_|_),converselyan</code><em><code>unlifted</code></em><code>typedoesnotcontain_|_.</code><br />
<code>Forexample,</code><code>islifted,but</code><code>isunlifted.</code></p>
<p><code>*A</code><em><code>boxed</code></em><code>typeisrepresentedbyapointertoanobjectintheheap,an</code><em><code>unboxed</code></em><code>objectisrepresentedbyavalue.</code><br />
<code>Forexample,</code><code>isboxed,but</code><code>isunboxed.</code></p>
<p>The representation of _|_ must be a pointer: it is an object that when evaluated throws an exception or enters an infinite loop. Therefore, only boxed types may be lifted.</p>
<p>There are boxed unlifted types: eg. . If you have a value of type , it definitely points to a heap object with type  (see below), rather than an unevaluated thunk.</p>
<p>Unboxed tuples  are both unlifted and unboxed. They are represented by multiple values passed in registers or on the stack, according to the [wiki:Commentary/Rts/HaskellExecution return convention].</p>
<p>Unlifted types cannot currently be used to represent terminating functions: an unlifted type on the right of an arrow is implicitly lifted to include `_|_`.</p>
<hr />
<h2 id="heap-objects">Heap Objects</h2>
<p>All heap objects have the same basic layout, embodied by the type  in [source:includes/rts/storage/Closures.h Closures.h]. The diagram below shows the layout of a heap object:</p>
<p><a href="Image(heap-object.png)" class="uri" title="wikilink">Image(heap-object.png)</a></p>
<p>A heap object always begins with a <em>header</em>, defined by  in [source:includes/rts/storage/Closures.h Closures.h]:</p>
<p></p>
<p>The most important part of the header is the <em>info pointer</em>, which points to the info table for the closure. In the default build, this is all the header contains, so a header is normally just one word. In other builds, the header may contain extra information: eg. in a profiling build it also contains information about who built the closure.</p>
<p>Most of the runtime is insensitive to the size of ; that is, we are careful not to hardcode the offset to the payload anywhere, instead we use C struct indexing or . This makes it easy to extend  with new fields if we need to.</p>
<p>The compiler also needs to know the layout of heap objects, and the way this information is plumbed into the compiler from the C headers in the runtime is described here: [wiki:Commentary/Compiler/CodeGen#Storagemanagerrepresentations].</p>
<hr />
<h2 id="info-tables">Info Tables</h2>
<p>The info table contains all the information that the runtime needs to know about the closure. The layout of info tables is defined by  in [source:includes/rts/storage/InfoTables.h InfoTables.h]. The basic info table layout looks like this:</p>
<p><a href="Image(basic-itbl.png)" class="uri" title="wikilink">Image(basic-itbl.png)</a></p>
<p>Where:</p>
<p><code>*The</code><em><code>closure</code> <code>type</code></em><code>isaconstantdescribingthekindofclosurethisis(function,thunk,constructoretc.).All</code><br />
<code>theclosuretypesaredefinedin[source:includes/rts/storage/ClosureTypes.hClosureTypes.h],andmanyofthemhavecorrespondingCstruct</code><br />
<code>definitionsin[source:includes/rts/storage/Closures.hClosures.h].</code></p>
<p><code>*The</code><em><code>SRT</code> <code>bitmap</code></em><code>fieldisusedtosupport[wiki:Commentary/Rts/Storage/GC/CAFsgarbagecollectionofCAFs].</code></p>
<p><code>*The</code><em><code>layout</code></em><code>fielddescribesthelayoutofthepayloadforthegarbagecollector,andisdescribedinmore</code><br />
<code>detailin</code><a href="ref(Types_of_Payload_Layout)" title="wikilink"><code>ref(Types</code> <code>of</code> <code>Payload</code> <code>Layout)</code></a><code>below.</code></p>
<p><code>*The</code><em><code>entry</code> <code>code</code></em><code>fortheclosureisusuallythecodethatwill</code><em><code>evaluate</code></em><code>theclosure.Thereisoneexception:</code><br />
<code>forfunctions,theentrycodewillapplythefunctiontotheargumentsgiveninregistersoronthestack,according</code><br />
<code>tothecallingconvention.Theentrycodeassumesalltheargumentsarepresent-toapplyafunctiontofewerarguments</code><br />
<code>ortoapplyanunknownfunction,the[wiki:Commentary/Rts/HaskellExecution/FunctionCalls#Genericapplygenericapplyfunctions]must</code><br />
<code>beused.</code></p>
<p>Some types of object add more fields to the end of the info table, notably functions, return addresses, and thunks.</p>
<p>Space in info tables is a premium: adding a word to the standard info table structure increases binary sizes by 5-10%.</p>
<h3 id="section-5"></h3>
<p>Note that the info table is followed immediately by the entry code, rather than the code being at the end of an indirect pointer. This both reduces the size of the info table and eliminates one indirection when jumping to the entry code.</p>
<p>GHC can generate code that uses the indirect pointer instead; the  turns on the optimised layout. Generally  is turned off when compiling unregisterised.</p>
<p>When  is off, info tables get another field, , which points to the entry code. In a generated object file, each symbol  representing an info table will have an associated symbol  pointing to the entry code (in , the entry symbol is omitted to keep the size of symbol tables down).</p>
<hr />
<h2 id="types-of-payload-layout">Types of Payload Layout</h2>
<p>The GC needs to know two things about the payload of a heap object: how many words it contains, and which of those words are pointers. There are two basic kinds of layout for the payload: <em>pointers-first</em> and <em>bitmap</em>. Which of these kinds of layout is being used is a property of the <em>closure type</em>, so the GC first checks the closure type to determine how to interpret the layout field of the info table.</p>
<h3 id="pointers-first-layout">Pointers-first layout</h3>
<p>The payload consists of zero or more pointers followed by zero or more non-pointers. This is the most common layout: constructors, functions and thunks use this layout. The layout field contains two half-word-sized fields:</p>
<p><code>*Numberofpointers</code><br />
<code>*Numberofnon-pointers</code></p>
<h3 id="bitmap-layout">Bitmap layout</h3>
<p>The payload consists of a mixture of pointers and non-pointers, described by a bitmap. There are two kinds of bitmap:</p>
<p><strong>Small bitmaps.</strong> A small bitmap fits into a single word (the layout word of the info table), and looks like this:</p>
<p>|| Size (bits 0-4) || Bitmap (bits 5-31) ||</p>
<p>(for a 64-bit word size, the size is given 6 bits instead of 5).</p>
<p>The size field gives the size of the payload, and each bit of the bitmap is 1 if the corresponding word of payload contains a pointer to a live object.</p>
<p>The macros , , and  in [source:includes/rts/storage/InfoTables.h InfoTables.h] provide ways to conveniently operate on small bitmaps.</p>
<p><strong>Large bitmaps.</strong> If the size of the stack frame is larger than the 27 words that a small bitmap can describe, then the fallback mechanism is the large bitmap. A large bitmap is a separate structure, containing a single word size and a multi-word bitmap: see  in [source:includes/rts/storage/InfoTables.h InfoTables.h].</p>
<hr />
<h2 id="dynamic-vs.-static-objects">Dynamic vs. Static objects</h2>
<p>Objects fall into two categories:</p>
<p><code>*</code><em><code>dynamic</code></em><code>objectsresideintheheap,andmaybemovedbythegarbagecollector.</code></p>
<p><code>*</code><em><code>static</code></em><code>objectsresideinthecompiledobjectcode.Theyarenevermoved,becausepointerstosuchobjectsare</code><br />
<code>scatteredthroughtheobjectcode,andonlythelinkerknowswhere.</code></p>
<p>To find out whether a particular object is dynamic or static, use the [wiki:Commentary/Rts/Storage/HeapAlloced HEAP_ALLOCED()] macro, from [source:rts/sm/HeapAlloc.h]. This macro works by consulting a bitmap (or structured bitmap) that tells for each [wiki:Commentary/Rts/Storage#Structureofblocks megablock] of memory whether it is part of the dynamic heap or not.</p>
<h3 id="dynamic-objects">Dynamic objects</h3>
<p>Dynamic objects have a minimum size, because every object must be big enough to be overwritten by a forwarding pointer (<a href="ref(Forwarding_Pointers)" title="wikilink">ref(Forwarding Pointers)</a>) during GC. The minimum size of the payload is given by  in [source:includes/rts/Constants.h].</p>
<h3 id="static-objects">Static objects</h3>
<p>All static objects have closure types ending in , eg.  for static data constructors.</p>
<p>Static objects have an additional field, called the <em>static link field</em>. The static link field is used by the GC to link all the static objects in a list, and so that it can tell whether it has visited a particular static object or not - the GC needs to traverse all the static objects in order to [wiki:Commentary/Rts/CAFs garbage collect CAFs].</p>
<p>The static link field resides after the normal payload, so that the static variant of an object has compatible layout with the dynamic variant. To access the static link field of a closure, use the  macro from [source:includes/rts/storage/ClosureMacros.h].</p>
<hr />
<h2 id="types-of-object">Types of object</h2>
<h3 id="data-constructors">Data Constructors</h3>
<p>All data constructors have pointers-first layout:</p>
<p>|| Header || Pointers... || Non-pointers... ||</p>
<p>Data constructor closure types:</p>
<p><code>*</code><code>:avanilla,dynamicallyallocatedconstructor</code><br />
<code>*</code><code>:aconstructorwhoselayoutisencodedintheclosuretype(eg.</code><code>hasonepointer</code><br />
<code>andzeronon-pointers.HavingtheseclosuretypesspeedsupGCalittleforcommonlayouts.</code><br />
<code>*</code><code>:astaticallyallocatedconstructor.</code><br />
<code>*</code><code>:TODO:Needsdocumentation</code></p>
<p>The entry code for a constructor returns immediately to the topmost stack frame, because the data constructor is already in WHNF. The return convention may be vectored or non-vectored, depending on the type (see [wiki:Commentary/Rts/HaskellExecution/CallingConvention]).</p>
<p>Symbols related to a data constructor X:</p>
<p><code>*X_</code><code>:infotableforadynamicinstanceofX</code><br />
<code>*X_</code><code>:infotableforastaticinstanceofX</code><br />
<code>*X_</code><code>:the</code><em><code>wrapper</code></em><code>forX(afunction,equivalenttothe</code><br />
<code>curriedfunction</code><code>inHaskell,see</code><br />
<code>[wiki:Commentary/Compiler/EntityTypes]).</code><br />
<code>*X_</code><code>:staticclosureforX'swrapper</code></p>
<h3 id="function-closures">Function Closures</h3>
<p>A function closure represents a Haskell function. For example:  Here,  would be represented by a static function closure (see below), and  a dynamic function closure. Every function in the Haskell program generates a new info table and entry code, and top-level functions additionally generate a static closure.</p>
<p>All function closures have pointers-first layout:</p>
<p>|| Header || Pointers... || Non-pointers... ||</p>
<p>The payload of the function closure contains the free variables of the function: in the example above, a closure for  would have a payload containing a pointer to .</p>
<p>Function closure types:</p>
<p><code>*</code><code>:avanilla,dynamicallyallocatedfunction</code><br />
<code>*</code><code>:same,specialisedforlayout(seeconstructorsabove)</code><br />
<code>*</code><code>:astatic(top-level)functionclosure</code></p>
<p>Symbols related to a function :</p>
<p><code>*</code><code>:f'sinfotableandcode</code><br />
<code>*</code><code>:f'sstaticclosure,iffisatop-levelfunction.</code><br />
<code>Thestaticclosurehasnopayload,becausetherearenofree</code><br />
<code>variablesofatop-levelfunction.Itdoeshaveastaticlink</code><br />
<code>field,though.</code></p>
<h3 id="thunks">Thunks</h3>
<p>A thunk represents an expression that is not obviously in head normal form. For example, consider the following top-level definitions:  Here the right-hand sides of  and  are both thunks; the former is static while the latter is dynamic.</p>
<p>Thunks have pointers-first layout:</p>
<p>|| Header || (empty) || Pointers... || Non-pointers... ||</p>
<p>As for function closures, the payload contains the free variables of the expression. A thunk differs from a function closure in that it can be [wiki:Commentary/Rts/HaskellExecution#Updates updated].</p>
<p>There are several forms of thunk:</p>
<p><code>*</code><code>,</code><code>:vanilla,dynamicallyallocated</code><br />
<code>thunks.Dynamicthunksareoverwrittenwithnormalindirections</code><br />
<code></code><code>whenevaluated.</code></p>
<p><code>*</code><code>:astaticthunkisalsoknownasa''constant</code><br />
<code>applicativeform'',or</code><em><code>CAF</code></em><code>.Staticthunksareoverwrittenwith</code><br />
<code>staticindirections(</code><code>).</code></p>
<p>The only label associated with a thunk is its info table:</p>
<p><code>*</code><code>isf'sinfotable.</code></p>
<p>The empty padding is to allow thunk update code to overwrite the target of an indirection without clobbering any of the saved free variables. This means we can do thunk update without synchronization, which is a big deal.</p>
<h3 id="selector-thunks">Selector thunks</h3>
<p> is a (dynamically allocated) thunk whose entry code performs a simple selection operation from a data constructor drawn from a single-constructor type. For example, the thunk  is a selector thunk. A selector thunk is laid out like this:</p>
<p>|| Header || Selectee pointer ||</p>
<p>The `layout` word contains the byte offset of the desired word in the selectee. Note that this is different from all other thunks.</p>
<p>The garbage collector &quot;peeks&quot; at the selectee's tag (in its info table). If it is evaluated, then it goes ahead and does the selection, and then behaves just as if the selector thunk was an indirection to the selected field. If it is not evaluated, it treats the selector thunk like any other thunk of that shape.</p>
<p>This technique comes from the Phil Wadler paper <a href="http://homepages.inf.ed.ac.uk/wadler/topics/garbage-collection.html">Fixing some space leaks with a garbage collector</a>, and later Christina von Dorrien who called it &quot;Stingy Evaluation&quot;.</p>
<p>There is a fixed set of pre-compiled selector thunks built into the RTS, representing offsets from 0 to , see [source:rts/StgStdThunks.cmm]. The info tables are labelled  where  is the offset. Non-updating versions are also built in, with info tables labelled .</p>
<p>These thunks exist in order to prevent a space leak. For example, if y is a thunk that has been evaluated, and y is unreachable, but x is reachable, the risk is that x keeps both the a and b components of y live. By making the selector thunk a special case, we make it possible to reclaim the memory associated with b. (The situation is further complicated when selector thunks point to other selector thunks; the garbage collector sees all, knows all.)</p>
<h3 id="partial-applications">Partial applications</h3>
<p>Partial applications are tricky beasts.</p>
<p>A partial application, closure type , represents a function applied to too few arguments. Partial applications are only built by the [wiki:Commentary/Rts/HaskellExecution/FunctionCalls#Genericapply generic apply functions] in [source:rts/Apply.cmm].</p>
<p>|| Header || Arity || No. of words || Function closure || Payload... ||</p>
<p>Where:</p>
<p><code>*</code><em><code>Arity</code></em><code>isthearityofthePAP.Forexample,afunctionwith</code><br />
<code>arity3appliedto1argumentwouldleaveaPAPwitharity2.</code></p>
<p><code>*</code><em><code>No.</code> <code>of</code> <code>words</code></em><code>referstothesizeofthepayloadinwords.</code></p>
<p><code>*</code><em><code>Function</code> <code>closure</code></em><code>isthefunctiontowhichtheargumentsare</code><br />
<code>applied.Notethatthisisalwaysapointertooneofthe</code><br />
<code></code><code>family,nevera</code><code>.Ifa</code><code>isapplied</code><br />
<code>tomoreargumentstogiveanew</code><code>,theargumentsfrom</code><br />
<code>theoriginal</code><code>arecopiedtothenewone.</code></p>
<p><code>*Thepayloadisthesequenceofargumentsalreadyappliedto</code><br />
<code>thisfunction.Thepointerhoodofthesewordsaredescribed</code><br />
<code>bythefunction'sbitmap(see</code><code>in</code><br />
<code>[source:rts/sm/Scav.c]foranexampleoftraversingaPAP).</code></p>
<p>There is just one standard form of PAP. There is just one info table too, called . A PAP should never be entered, so its entry code causes a failure. PAPs are applied by the generic apply functions in .</p>
<h3 id="generic-application">Generic application</h3>
<p>An  object is very similar to a , and has identical layout:</p>
<p>|| Header || Arity || No. of words || Function closure || Payload... ||</p>
<p>The difference is that an  is not necessarily in WHNF. It is a thunk that represents the application of the specified function to the given arguments.</p>
<p>The arity field is always zero (it wouldn't help to omit this field, because it is only half a word anyway).</p>
<p> closures are used mostly by the byte-code interpreter, so that it only needs a single form of thunk object. Interpreted thunks are always represented by the application of a  to its free variables.</p>
<h3 id="stack-application">Stack application</h3>
<p>An  is a special kind of object:</p>
<p>|| Header || Size || Closure || Payload... ||</p>
<p>It represents computation of a thunk that was suspended midway through evaluation. In order to continue the computation, copy the payload onto the stack (the payload was originally the stack of the suspended computation), and enter the closure.</p>
<p>Since the payload is a chunk of stack, the GC can use its normal stack-walking code to traverse it.</p>
<p> closures are built by  in [source:rts/RaiseAsync.c] when an [wiki:Commentary/Rts/AsyncExceptions asynchronous exception] is raised. It's fairly typical for the end of an AP_STACK's payload to have another AP_STACK: you'll get one per update frame.</p>
<h3 id="indirections">Indirections</h3>
<p>Indirection closures just point to other closures. They are introduced when a thunk is updated to point to its value. The entry code for all indirections simply enters the closure it points to.</p>
<p>The basic layout of an indirection is simply</p>
<p>|| Header || Target closure ||</p>
<p>There are several variants of indirection:</p>
<p><code>*</code><code>:isthevanilla,dynamically-allocatedindirection.</code><br />
<code>Itisremovedbythegarbagecollector.An</code><code>onlyexistsintheyoungestgeneration.</code><br />
<code>Theupdatecode(</code><code>andfriends)checkswhethertheupdateeisintheyoungest</code><br />
<code>generationbeforedecidingwhichkindofindirectiontouse.</code><br />
<code>*</code><code>:astaticindirection,ariseswhenweupdatea</code><code>.Anew</code><br />
<code>isplacedonthemutablelistwhenitiscreated(see</code><code>in[source:rts/sm/Storage.c]).</code></p>
<h3 id="byte-code-objects">Byte-code objects</h3>
<p></p>
<h3 id="black-holes">Black holes</h3>
<p>, </p>
<p>Black holes represent thunks which are under evaluation by another thread (that thread is said to have claimed the thunk). Attempting to evaluate a black hole causes a thread to block until the thread who claimed the thunk either finishes evaluating the thunk or dies. You can read more about black holes in the paper 'Haskell on a Shared-Memory Multiprocessor'. Black holes have the same layout as indirections.</p>
<p>|| Header || Target closure ||</p>
<p>Sometimes black holes are just ordinary indirection. Check `stg_BLACKHOLE_info` for the final word: if the indirectee has no tag, then we assume that it is the TSO that has claimed the thunk; if the indirectee is tagged, then it is just a normal indirection. (EZY: I think this optimization is to avoid having to do two memory writes on thunk update; we don't bother updating the header, only the target.)</p>
<p>When eager blackholing is enabled, the black hole that is written is not a true black hole, but an eager black hole. True black holes are synchronized, and guarantee that only one black hole is claimed (this property is used to implement non-dupable unsafePerformIO). Eager black holes are not synchronized; eager black hole are converted into true black holes in ThreadPaused.c. Incidentally, this facility is also used to convert update frames to black holes; this is important for eliminating a space leak caused by the thunk under evaluation retaining too much data (overwriting it with a black hole frees up variable.)</p>
<h3 id="arrays">Arrays</h3>
<p>, , , , </p>
<p>Non-pointer arrays are straightforward:</p>
<p>||| Header ||| Bytes ||| Array payload |||</p>
<p>Arrays with pointers are a little more complicated, they include a card table, which is used by the GC to know what segments of the array to traverse as roots (the card table is modified by the GC write barrier):</p>
<p>||| Header ||| Ptrs ||| Size ||| Array payload + card table |||</p>
<p>You can access the card table by using `mutArrPtrsCard(array, element index)`, which gives you the address of the card for that index.</p>
<h3 id="mvars">MVars</h3>
<p></p>
<p>MVars have a queue of the TSOs blocking on them along with their value:</p>
<p>|| Header || Head of queue || Tail of queue || Value ||</p>
<p>An MVar can be in several states. It can be empty (in which case the value is actually just a `stg_END_TSO_QUEUE_closure`) or it can be full. When it is full, the queue of TSOs are those waiting to put; when it is empty, the queue of TSOs are those waiting to read and take (with readers first). Like many mutable objects, MVars have CLEAN and DIRTY headers to avoid reapplying a write barrier when an MVar is already dirty.</p>
<h3 id="weak-pointers">Weak pointers</h3>
<p></p>
<h3 id="stable-names">Stable Names</h3>
<p></p>
<h3 id="thread-state-objects">Thread State Objects</h3>
<p>Closure type  is a Thread State Object. It represents the complete state of a thread, including its stack.</p>
<p>TSOs are ordinary objects that live in the heap, so we can use the existing allocation and garbage collection machinery to manage them. This gives us one important benefit: the garbage collector can detect when a blocked thread is unreachable, and hence can never become runnable again. When this happens, we can notify the thread by sending it the  exception.</p>
<p>GHC keeps divides stacks into stack chunks, with logic to handle stack underflow and overflow: <a href="http://hackage.haskell.org/trac/ghc/blog/stack-chunks" class="uri">http://hackage.haskell.org/trac/ghc/blog/stack-chunks</a></p>
<p>The TSO structure contains several fields. For full details see [source:includes/rts/storage/TSO.h]. Some of the more important fields are:</p>
<p><code>*</code><em><code>link</code></em><code>:fieldforlinkingTSOstogetherinalist.Forexample,thethreadsblockedonan</code><code>arekeptin</code><br />
<code>aqueuethreadedthroughthelinkfieldofeachTSO.</code><br />
<code>*</code><em><code>global_link</code></em><code>:linksallTSOstogether;theheadofthislistis</code><code>in[source:rts/Schedule.c].</code><br />
<code>*</code><em><code>what_next</code></em><code>:howtoresumeexecutionofthisthread.Thevalidvaluesare:</code><br />
<code>*</code><code>:continuebyreturningtothetopstackframe.</code><br />
<code>*</code><code>:continuebyinterpretingtheBCOontopofthestack.</code><br />
<code>*</code><code>:thisthreadhasreceivedanexceptionwhichwasnotcaught.</code><br />
<code>*</code><code>:thisthreadranoutofstackandhasbeenrelocatedtoalargerTSO;thelinkfieldpoints</code><br />
<code>toitsnewlocation.</code><br />
<code>*</code><code>:thisthreadhasfinishedandcanbegarbagecollectedwhenitisunreachable.</code><br />
<code>*</code><em><code>why_blocked</code></em><code>:forablockedthread,indicateswhythethreadisblocked.See[source:includes/rts/Constants.h]for</code><br />
<code>thelistofpossiblevalues.</code><br />
<code>*</code><em><code>block_info</code></em><code>:forablockedthread,givesmoreinformationaboutthereasonforblockage,eg.whenblockedonan</code><br />
<code>MVar,block_infowillpointtotheMVar.</code><br />
<code>*</code><em><code>bound</code></em><code>:pointertoa[wiki:Commentary/Rts/Scheduler#TaskTask]ifthisthreadisbound</code><br />
<code>*</code><em><code>cap</code></em><code>:the[wiki:Commentary/Rts/Scheduler#CapabilitiesCapability]onwhichthisthreadresides.</code></p>
<h3 id="stm-objects">STM objects</h3>
<p>These object types are used by [wiki:Commentary/Rts/STM STM]: , , , .</p>
<h3 id="forwarding-pointers">Forwarding Pointers</h3>
<p>Forwarding pointers appear temporarily during [wiki:Commentary/Rts/Storage/GC garbage collection]. A forwarding pointer points to the new location for an object that has been moved by the garbage collector. It is represented by replacing the info pointer for the closure with a pointer to the new location, with the least significant bit set to 1 to distinguish a forwarding pointer from an info pointer.</p>
<h2 id="how-to-add-new-heap-objects">How to add new heap objects</h2>
<p>There are two This page is a stub.</p>
<h2 id="change-history">Change History</h2>
<p><code>*</code><em><code>History</code> <code>of</code> <code>when</code> <code>Hoopl</code> <code>was</code> <code>integrated</code> <code>into</code> <code>a</code> <code>GHC</code> <code>back</code> <code>end</code></em></p>
<p><code>*AfterthepublicationoftheHooplpaper,acontributor(sorryIhaveforgottenwho)didquiteabittointegratethesupplyof</code><code>sintoHoopl.(Time?Person?)</code></p>
<p><code>*</code><em><code>Note</code> <code>that</code> <code>the</code> <code>new</code> <code>code</code> <code>generator</code> <code>appears</code> <code>about</code> <code>10x</code> <code>slower</code> <code>than</code> <code>the</code> <code>old.</code> <code>Slowdown</code> <code>attributed</code> <code>to</code> <code>Hoopl</code> <code>dataflow.</code></em><code>See</code><a href="https://plus.google.com/107890464054636586545/posts/dBbewpRfw6R"><code>Google</code> <code>Plus</code> <code>post</code> <code>by</code> <code>Simon</code> <code>Marlow</code></a><code>.</code></p>
<p><code>*Fixed-pointalgorithmrewrittentoreduceduplicatecomputation.(SimonMarlowinlate2011.AlsoEdwardYanginspring2011.)Isthereanymore?Isuggestlookingattracesinthesimplecases.</code></p>
<p><code>*Changeinrepresentationofblocks,SimonMarlow,late2011.(Details?)Performancedifferencealmosttoosmalltobemeasurable,butSimonMlikesthenewrepanyway.</code></p>
<h2 id="speculation-and-commentary">Speculation and Commentary</h2>
<p><code>*SimonPJhadquestionsabout&quot;optimizationfuel&quot;fromthebeginning.Normanmaintainsthatoptimizationfuelisaninvaluabledebuggingaid,butthatinaproductioncompiler,onewouldlikeittobeturnedoff.Atsomepointwehadabstractedoverthe</code><code>sothatwecouldmakea&quot;zero&quot;fuelmonadthatdidnothingandcostnothing.AsofJanuary2012,Normandoesn'tknowwhatthestateofthatplanisorwhetherGHC'soptimisercanactuallyeliminatetheoverheads.</code></p>
<p><code>*UnlikeFuel,asupplyof</code><code>swasbelievedtobeanabsolutenecessity:anoptimisermustbeabletorewriteblocks,andinthegeneralcase,itmustbeabletointroducenewblocks.ItwasbelievedthattheonlywaytodothisconsistentwithGHCwastoplumbinaUniqsupply.</code><em><code>Query</code></em><code>:wasthisintegratedwithFuelsomehow?</code></p>
<p><code>*ThepublishedversionofHooplpassesanexplicitdictionarythatcontainsallthedataflowfactsforallthelabels.EarlierversionsofHooplkeptthisinformationinamonad.It'snotknownwhetherthechangehasimplicationsforperformance,butitisprobablyeasiertomanagethespeculativerewritingwithoutamonad.</code></p>
<p><code>*Normanhasalwaysbeenuneasyaboutthedictionariespassedtothe</code><code>function.Heconjecturesthatmostblockshaveasmallnumberofoutedges,andprobablynotthatmanyinedgeseither(caseexpressionsandtheAdamsoptimisationnotwithstanding).Hewondersifinsteadofsomekindoftriestructurewithworst-caselogarithmicperformance,wemightnotbebetteroffwithasimpleassociationlist---especiallybecauseitiscommontosimplyjoin</code><em><code>all</code></em><code>factsflowingintoablock.</code><strong><code>Query:</code> <code>Is</code> <code>there</code> <code>a</code> <code>way</code> <code>to</code> <code>measure</code> <code>the</code> <code>costs</code> <code>of</code> <code>using</code> <code>dictionaries</code> <code>in</code> <code>this</code> <code>fashion?</code> <code>Cost</code> <code>centers,</code> <code>perhaps?</code></strong></p>
<p><code>*TherewasaGooglePlusthreadinwhichCPSwascriticized(byJanMaessen,Ithink).Theoriginalauthorshadmanybigfights,andoneofthemwasaboutCPS.AtsomepointNormandraftedadataflowanalyserthatwasveryaggressivelyCPS.SimonPJfoundtheextensiveCPSdifficulttoread.Normandoesn'tremembertheeventualoutcome.IsitpossiblethattheCPSiscausingtheallocationoftoomanyfunctionclosures?CouldtheCPSberewritten,perhapsbyadifferentwayofnestingfunctions,toeliminatetheneedtoallocateclosuresintheinnerloop?JohanTibelltriedoptimizingpostorder_dfs,butwasputoffbytheCPSstyleofcode.(Wespeculatethatcachingtheresultoftoposortmayhelp.)</code></p>
<p><code>*AnotherimportantthingtokeepinmindisthatsomeoftheexistingpassesusedbyGHCmaybeimplementedinefficiently(ofnofaultofHooplitself.)Forexample,therewriteassignmentspasstakesaround15%oftheentirecompilationtime;webelievethisisbecauseithastorewritetheentiregraphintoanewrepresentationbeforedoinganytransformations,andthenrewriteitbacktotheoriginal.Optimizationshere(forexample,storingtheinformationinanexternalmapasopposedtotheASTitself)wouldprobablywouldhelpalot.</code></p>
<h2 id="record-of-performance-improvements-made-to-the-hoopl-library-starting-january-2012">Record of performance improvements made to the Hoopl library starting January 2012</h2>
<h1 id="haskell-program-coverage">Haskell Program Coverage</h1>
<p>This page describes the Haskell Program Coverage implementation inside GHC. Background information can be found in the paper <a href="http://www.ittc.ku.edu/~andygill/papers/Hpc07.pdf">Haskell Program Coverage</a> by Andy Gill and Colin Runciman, and the Haskell wiki page <a href="https://wiki.haskell.org/Haskell_program_coverage">Haskell program coverage</a>.</p>
<p>The basic idea is this</p>
<p><code>*Foreach(sub)expressionintheHaskellSyntax,writethe(sub)expressionina</code><br />
<code>`HsTick`</code><br />
<code>*Each`HsTick`hasamodulelocalindexnumber.</code><br />
<code>*Thereisatable(TheMixdatastructure)thatmapsthisindexnumbertooriginalsourcelocation.</code><br />
<code>*Each`HsTick`ismappedintheDesugarpasswith:</code></p>
<p></p>
<p><code>*Thistickisaspecialtypeof`Id`,a`TickOpId`whichtakesnocore-levelargument,buthastwopre-appliedarguments;themodulenameandthemodule-localticknumber.</code><br />
<code>*WestorebothmodulenameandticknumbertoallowthisIdtobepassed(inlined)insideothermodules.</code><br />
<code>*This`Id`hastype</code><strong><code>State#</code> <code>World#</code></strong><br />
<code>*Thecoresimplifiermustnotremovethiscase,butitcanmoveit.</code><br />
<code>*Thedo-not-removeisenforcedviathe...functionin....</code><br />
<code>*Thesemanticsaretickif-and-when-and-asyouenterthe`DEFAULT`case.Butachainofconsecutivetickscanbeexecutedinanyorder.</code><br />
<code>*The!CoreToStgPasstranslatestheticksinto`StgTick`</code></p>
<p></p>
<p><code>*The`Cmm`codegeneratortranslates`StgTick`toa64bitincrement.</code></p>
<p>Other details</p>
<p><code>*Aexecutablestartuptime,weperformadepthfirsttraversalsomemodule</code><br />
<code>specificcode,gatheringalistofallHpcregisteredmodules,andthe</code><br />
<code>modulespecificticktable.</code><br />
<code>*Thereisonetablepermodule,sowecanlinktheincrementstatically,</code><br />
<code>withoutneedingtoknowtheglobalticknumber.</code><br />
<code>*ThemoduleHpc.cintheRTShandlesallthereadingofthesetable.</code><br />
<code>*Atstartup,ifa.tixfileisfound,Hpc.cchecksthatthisisthesame</code><br />
<code>binaryasgeneratedthe.tixfile,andifso,pre-loadsallthetickcounts</code><br />
<code>inthemodulespecificlocations.</code><br />
<code>*(Iamlookingforagoodwayofcheckingthebinariesforsameness)</code><br />
<code>*Atshutdown,wewritebackoutthe.tixfiles,fromthemodule-localtables.</code></p>
<h3 id="binary-tick-boxes">Binary Tick Boxes</h3>
<p>There is also the concept of a binary tick box. This is a syntactical boolean, like a guard or conditional for an if. We use tick boxes to record the result of the boolean, to check for coverage over True and False.</p>
<p><code>*Each`HsBinaryTick`ismappedintheDesugarpasswith:</code></p>
<p></p>
<ul>
<li>After desugaring, there is no longer any special code for binary tick box.</li>
</ul>
<h2 id="machine-generated-haskell">Machine Generated Haskell</h2>
<p>Sometimes, Haskell is the target language - for example, Happy and Alex. In this case, you want to be able to check for coverage of your <strong>original</strong> program. So we have a new pragma.</p>
<p></p>
<p>This means that the expression was obtained from the given file and locations. This might be code included verbatim (for example the actions in Happy), or be generated from a specification from this location.</p>
<h1 id="compiling-one-module-hscmain">Compiling one module: !HscMain</h1>
<p>Here we are going to look at the compilation of a single module. There is a picture that goes with this description, which appears at the bottom of this page, but you'll probably find it easier to open [wiki:Commentary/Compiler/HscPipe this link] in another window, so you can see it at the same time as reading the text.</p>
<p>You can also watch a <strong>video</strong> of Simon Peyton-Jones explaining the compilation pipeline here: <a href="http://www.youtube.com/watch?v=Upm_kYMgI_c&amp;list=PLBkRCigjPwyeCSD_DFxpd246YIF7_RDDI">Compiler Pipeline II</a> (10'16&quot;)</p>
<p>Look at the picture first. The yellow boxes are compiler passes, while the blue stuff on the left gives the data type that moves from one phase to the next. The entire pipeline for a single module is run by a module called !HscMain (<a href="GhcFile(compiler/main/HscMain.hs)" class="uri" title="wikilink">GhcFile(compiler/main/HscMain.hs)</a>). Each data type's representation can be dumped for further inspection using a `-ddump-*` flag. (Consider also using `-ddump-to-file`: some of the dump outputs can be large!) Here are the steps it goes through:</p>
<p><code>*The</code><strong><code>Front</code> <code>End</code></strong><code>processestheprograminthe[wiki:Commentary/Compiler/HsSynTypebigHsSyntype].</code><code>isparameterisedoverthetypesofthetermvariablesitcontains.Thefirstthreepasses(thefrontend)ofthecompilerworklikethis:</code><a href="BR" title="wikilink"><code>BR</code></a><a href="BR" title="wikilink"><code>BR</code></a><br />
<code>*The</code><strong><code>[wiki:Commentary/Compiler/Parser</code> <code>Parser]</code></strong><code>produces</code><code>parameterisedby</code><strong><code>[wiki:Commentary/Compiler/RdrNameType</code> <code>RdrName]</code></strong><code>.Toafirstapproximation,a</code><code>isjustastring.(`-ddump-parsed`)</code><a href="BR" title="wikilink"><code>BR</code></a><a href="BR" title="wikilink"><code>BR</code></a><br />
<code>*The</code><strong><code>[wiki:Commentary/Compiler/Renamer</code> <code>Renamer]</code></strong><code>transformsthisto</code><code>parameterisedby</code><strong><code>[wiki:Commentary/Compiler/NameType</code> <code>Name]</code></strong><code>.Toafirstappoximation,a</code><code>isastringplusa</code><code>(number)thatuniquelyidentifiesit.Inparticular,therenamerassociateseachidentifierwithitsbindinginstanceandensuresthatalloccurrenceswhichassociatetothesamebindinginstanceshareasingle</code><code>.(`-ddump-rn`)</code><a href="BR" title="wikilink"><code>BR</code></a><a href="BR" title="wikilink"><code>BR</code></a><br />
<code>*The</code><strong><code>[wiki:Commentary/Compiler/TypeChecker</code> <code>Typechecker]</code></strong><code>transformsthisfurther,to</code><code>parameterisedby</code><strong><code>[wiki:Commentary/Compiler/EntityTypes</code> <code>Id]</code></strong><code>.Toafirstapproximation,an</code><code>isa</code><code>plusatype.Inaddition,thetype-checkerconvertsclassdeclarationsto</code><code>es,andtypedeclarationsto</code><code>sand</code><code>s.Andofcourse,thetype-checkerdealsin</code><code>sand</code><code>s.The[wiki:Commentary/Compiler/EntityTypesdatatypesfortheseentities](</code><code>,</code><code>,</code><code>,</code><code>,</code><code>)arepervasivethroughouttherestofthecompiler.(`-ddump-tc`)</code></p>
<p><code>Thesethreepassescanalldiscoverprogrammererrors,whicharesortedandreportedtotheuser.</code><br />
<br />
<code>*The</code><strong><code>Desugarer</code></strong><code>(</code><a href="GhcFile(compiler/deSugar/Desugar.hs)" title="wikilink"><code>GhcFile(compiler/deSugar/Desugar.hs)</code></a><code>)convertsfromthemassive</code><code>typeto[wiki:Commentary/Compiler/CoreSynTypeGHC'sintermediatelanguage,CoreSyn].ThisCore-languagedatatypeisunusuallytiny:justeightconstructors.)(`-ddump-ds`)</code><a href="BR" title="wikilink"><code>BR</code></a><a href="BR" title="wikilink"><code>BR</code></a><br />
<code>Generallyspeaking,thedesugarerproducesfewusererrorsorwarnings.Butitdoesproduce</code><em><code>some</code></em><code>.Inparticular,(a)pattern-matchoverlapwarningsareproducedhere;and(b)whendesugaringTemplateHaskellcodequotations,thedesugarermayfindthat`THSyntax`isnotexpressiveenough.Inthatcase,wemustproduceanerror(</code><a href="GhcFile(compiler/deSugar/DsMeta.hs)" title="wikilink"><code>GhcFile(compiler/deSugar/DsMeta.hs)</code></a><code>).</code><a href="BR" title="wikilink"><code>BR</code></a><a href="BR" title="wikilink"><code>BR</code></a><br />
<code>Thislatedesugaringissomewhatunusual.Itismuchmorecommontodesugartheprogrambeforetypechecking,orrenaming,becausethatpresentstherenamerandtypecheckerwithamuchsmallerlanguagetodealwith.However,GHC'sorganisationmeansthat</code><br />
<code>*errormessagescandisplaypreciselythesyntaxthattheuserwrote;and</code><br />
<code>*desugaringisnotrequiredtopreservetype-inferenceproperties.</code><a href="BR" title="wikilink"><code>BR</code></a><a href="BR" title="wikilink"><code>BR</code></a></p>
<p><code>*The</code><strong><code>!SimplCore</code></strong><code>pass(</code><a href="GhcFile(compiler/simplCore/SimplCore.hs)" title="wikilink"><code>GhcFile(compiler/simplCore/SimplCore.hs)</code></a><code>)isabunchofCore-to-Corepassesthatoptimisetheprogram;see</code><a href="http://research.microsoft.com/%7Esimonpj/Papers/comp-by-trans-scp.ps.gz"><code>A</code> <code>transformation-based</code> <code>optimiser</code> <code>for</code> <code>Haskell</code> <code>(SCP'98)</code></a><code>foramore-or-lessaccurateoverview.See[wiki:Commentary/Compiler/Core2CorePipeline]foranoverviewoftheCore-to-Coreoptimisationpipeline.Themainpassesare:</code><a href="BR" title="wikilink"><code>BR</code></a><a href="BR" title="wikilink"><code>BR</code></a><br />
<code>*The</code><strong><code>Simplifier</code></strong><code>,whichapplieslotsofsmall,localoptimisationstotheprogram.Thesimplifierisbigandcomplicated,becauseitimplementsa</code><em><code>lot</code></em><code>oftransformations;andtriestomakethemcascadenicely.Thetransformation-basedoptimiserpapergiveslotsofdetails,buttwootherpapersareparticularlyrelevant:</code><a href="http://research.microsoft.com/%7Esimonpj/Papers/inlining/index.htm"><code>Secrets</code> <code>of</code> <code>the</code> <code>Glasgow</code> <code>Haskell</code> <code>Compiler</code> <code>inliner</code> <code>(JFP'02)</code></a><code>and</code><a href="http://research.microsoft.com/%7Esimonpj/Papers/rules.htm"><code>Playing</code> <code>by</code> <code>the</code> <code>rules:</code> <code>rewriting</code> <code>as</code> <code>a</code> <code>practical</code> <code>optimisation</code> <code>technique</code> <code>in</code> <code>GHC</code> <code>(Haskell</code> <code>workshop</code> <code>2001)</code></a><code>.(`-ddump-simpl`)</code><a href="BR" title="wikilink"><code>BR</code></a><a href="BR" title="wikilink"><code>BR</code></a><br />
<code>*The</code><strong><code>float-out</code></strong><code>and</code><strong><code>float-in</code></strong><code>transformations,whichmovelet-bindingsoutwardsandinwardsrespectively.See</code><a href="http://research.microsoft.com/%7Esimonpj/papers/float.ps.gz"><code>Let-floating:</code> <code>moving</code> <code>bindings</code> <code>to</code> <code>give</code> <code>faster</code> <code>programs</code> <code>(ICFP</code> <code>'96)</code></a><code>.</code><a href="BR" title="wikilink"><code>BR</code></a><a href="BR" title="wikilink"><code>BR</code></a><br />
<code>*The</code><strong><code>strictness</code> <code>analyser</code></strong><code>.Thisactuallycomprisestwopasses:the</code><strong><code>analyser</code></strong><code>itselfandthe</code><strong><code>worker/wrapper</code></strong><code>transformationthatusestheresultsoftheanalysistotransformtheprogram.(Furtherdescribedin[wiki:Commentary/Compiler/DemandDemandanalysis].)Thesameanalyseralsodoes</code><a href="http://research.microsoft.com/%7Esimonpj/Papers/cpr/index.htm"><code>Constructed</code> <code>Product</code> <code>Result</code> <code>analysis</code></a><code>and</code><a href="http://research.microsoft.com/en-us/um/people/simonpj/papers/usage-types/cardinality-extended.pdf"><code>Cardinality</code> <code>analysis</code></a><code>.(`-ddump-stranal`)</code><a href="BR" title="wikilink"><code>BR</code></a><a href="BR" title="wikilink"><code>BR</code></a><br />
<code>*The</code><strong><code>liberate-case</code></strong><code>transformation.</code><a href="BR" title="wikilink"><code>BR</code></a><a href="BR" title="wikilink"><code>BR</code></a><br />
<code>*The</code><strong><code>constructor-specialialisation</code></strong><code>transformation.</code><a href="BR" title="wikilink"><code>BR</code></a><a href="BR" title="wikilink"><code>BR</code></a><br />
<code>*The</code><strong><code>common</code> <code>sub-expression</code> <code>eliminiation</code></strong><code>(CSE)transformation.(`-ddump-cse`)</code></p>
<p><code>*Thenthe</code><strong><code>!CoreTidy</code> <code>pass</code></strong><code>getsthecodeintoaforminwhichitcanbeimportedintosubsequentmodules(whenusing</code><code>)and/orputintoaninterfacefile.</code><br />
<br />
<code>Itmakesadifferencewhetherornotyouareusing`-O`atthisstage.With`-O`(orrather,with`-fomit-interface-pragmas`whichisaconsequenceof`-O`),thetidiedprogram(producedby`tidyProgram`)hasunfoldingsforIds,andRULES.Without`-O`theunfoldingsandRULESareomittedfromthetidiedprogram.Andthat,inturn,affectstheinterfacefilegeneratedsubsequently.</code></p>
<p><code>Therearegoodnotesatthetopofthefile</code><a href="GhcFile(compiler/main/TidyPgm.hs)" title="wikilink"><code>GhcFile(compiler/main/TidyPgm.hs)</code></a><code>;themainfunctionis</code><code>,documentedas&quot;PlanB&quot;(&quot;PlanA&quot;isasimplifiedtidypassthatisrunwhenwehaveonlytypechecked,buthaven'trunthedesugarerorsimplifier).</code></p>
<p><code>*Atthispoint,thedataflowforks.First,thetidiedprogramisdumpedintoaninterfacefile.Thisparthappensintwostages:</code><br />
<code>*Itis</code><strong><code>converted</code> <code>to</code> </strong><code>(definedin</code><a href="GhcFile(compiler/iface/IfaceSyn.hs)" title="wikilink"><code>GhcFile(compiler/iface/IfaceSyn.hs)</code></a><code>and</code><a href="GhcFile(compiler/iface/IfaceType.hs)" title="wikilink"><code>GhcFile(compiler/iface/IfaceType.hs)</code></a><code>).</code><br />
<code>*The</code><code>is</code><strong><code>serialised</code> <code>into</code> <code>a</code> <code>binary</code> <code>output</code> <code>file</code></strong><code>(</code><a href="GhcFile(compiler/iface/BinIface.hs)" title="wikilink"><code>GhcFile(compiler/iface/BinIface.hs)</code></a><code>).</code><br />
<code>Theserialisationdoes(prettymuch)nothingexceptserialise.Alltheintelligenceisinthe`Core`-to-`IfaceSyn`conversion;or,rather,inthereverseofthatstep.</code></p>
<p><code>*Thesame,tidiedCoreprogramisnowfedtotheBackEnd.Firstthereisatwo-stageconversionfrom</code><code>to[wiki:Commentary/Compiler/StgSynTypeGHC'sintermediatelanguage,StgSyn].</code><br />
<code>*Thefirststepiscalled</code><strong><code>!CorePrep</code></strong><code>,aCore-to-CorepassthatputstheprogramintoA-normalform(ANF).InANF,theargumentofeveryapplicationisavariableorliteral;morecomplicatedargumentsarelet-bound.Actually`CorePrep`doesquiteabitmore:thereisadetailedlistatthetopofthefile</code><a href="GhcFile(compiler/coreSyn/CorePrep.hs)" title="wikilink"><code>GhcFile(compiler/coreSyn/CorePrep.hs)</code></a><code>.</code><br />
<code>*Thesecondstep,</code><strong><code>!CoreToStg</code></strong><code>,movestothe</code><code>datatype(</code><a href="GhcFile(compiler/stgSyn/CoreToStg.hs)" title="wikilink"><code>GhcFile(compiler/stgSyn/CoreToStg.hs)</code></a><code>).Theoutputof!CorePrepiscarefullyarrangedtoexactlymatchwhat</code><code>allows(notablyANF),sothereisverylittleworktodo.However,</code><code>isdecoratedwithlotsofredundantinformation(freevariables,let-no-escapeindicators),whichisgeneratedon-the-flyby</code><code>.</code></p>
<p><code>*Next,the</code><strong><code>[wiki:Commentary/Compiler/CodeGen</code> <code>Code</code> <code>Generator]</code></strong><code>convertstheSTGprogramtoa</code><code>program.ThecodegeneratorisaBigMother,andlivesindirectory</code><a href="GhcFile(compiler/codeGen)" title="wikilink"><code>GhcFile(compiler/codeGen)</code></a><code></code></p>
<p><code>*Nowthepathforksagain:</code><br />
<code>*IfwearegeneratingGHC'sstylisedCcode,wecanjustpretty-printthe</code><code>codeasstylisedC(</code><a href="GhcFile(compiler/cmm/PprC.hs)" title="wikilink"><code>GhcFile(compiler/cmm/PprC.hs)</code></a><code>)</code><br />
<code>*Ifwearegeneratingnativecode,weinvokethenativecodegenerator.ThisisanotherBigMother(</code><a href="GhcFile(compiler/nativeGen)" title="wikilink"><code>GhcFile(compiler/nativeGen)</code></a><code>).</code><br />
<code>*IfwearegeneratingLLVMcode,weinvoketheLLVMcodegenerator.Thisisareasonablysimplecodegenerator(</code><a href="GhcFile(compiler/llvmGen)" title="wikilink"><code>GhcFile(compiler/llvmGen)</code></a><code>).</code></p>
<h1 id="the-diagram">The Diagram</h1>
<p>This diagram is also located [wiki:Commentary/Compiler/HscPipe here], so that you can open it in a separate window.</p>
<p><a href="Image(Commentary/Compiler/HscPipe:HscPipe2.png)" class="uri" title="wikilink">Image(Commentary/Compiler/HscPipe:HscPipe2.png)</a></p>
<h1 id="picture-of-the-main-compiler-pipeline">Picture of the main compiler pipeline</h1>
<p>See [wiki:Commentary/Compiler compiling one module] for the commentary on this diagram.</p>
<p><a href="Image(HscPipe2.png)" class="uri" title="wikilink">Image(HscPipe2.png)</a></p>
<p><a href="PageOutline" class="uri" title="wikilink">PageOutline</a></p>
<p>Video: <a href="http://www.youtube.com/watch?v=lw7kbUvAmK4&amp;list=PLBkRCigjPwyeCSD_DFxpd246YIF7_RDDI">Abstract Syntax Types</a> (1hr03')</p>
<h1 id="the-types">The  types</h1>
<p>The program is initially parsed into &quot;<strong></strong>&quot;, a collection of data types that describe the full abstract syntax of Haskell.  is a pretty big collection of types: there are 52 data types at last count. Many are pretty trivial, but a few have a lot of constructors ( has 40).  represents Haskell in its full glory, complete with all syntactic sugar.</p>
<p>The  modules live in the <a href="GhcFile(compiler/hsSyn)" class="uri" title="wikilink">GhcFile(compiler/hsSyn)</a> directory. Each module declares a related group of declarations, <em>and</em> gives their pretty-printer.</p>
<p><code>*</code><a href="GhcFile(compiler/hsSyn/HsSyn.hs)" title="wikilink"><code>GhcFile(compiler/hsSyn/HsSyn.hs)</code></a><code>:therootmodule.Itexportseverythingyouneed,andit'sgenerallywhatyoushouldimport.</code><br />
<code>*</code><a href="GhcFile(compiler/hsSyn/HsBinds.hs)" title="wikilink"><code>GhcFile(compiler/hsSyn/HsBinds.hs)</code></a><code>:bindings.</code><br />
<code>*</code><a href="GhcFile(compiler/hsSyn/HsImpExp.hs)" title="wikilink"><code>GhcFile(compiler/hsSyn/HsImpExp.hs)</code></a><code>:importsandexports.</code><br />
<code>*</code><a href="GhcFile(compiler/hsSyn/HsDecls.hs)" title="wikilink"><code>GhcFile(compiler/hsSyn/HsDecls.hs)</code></a><code>:top-leveldeclarations.</code><br />
<code>*</code><a href="GhcFile(compiler/hsSyn/HsExpr.hs)" title="wikilink"><code>GhcFile(compiler/hsSyn/HsExpr.hs)</code></a><code>:expressions,matchexpressions,comprehensions.</code><br />
<code>*</code><a href="GhcFile(compiler/hsSyn/HsLit.hs)" title="wikilink"><code>GhcFile(compiler/hsSyn/HsLit.hs)</code></a><code>:literals.</code><br />
<code>*</code><a href="GhcFile(compiler/hsSyn/HsPat.hs)" title="wikilink"><code>GhcFile(compiler/hsSyn/HsPat.hs)</code></a><code>:patterns.</code><br />
<code>*</code><a href="GhcFile(compiler/hsSyn/HsTypes.hs)" title="wikilink"><code>GhcFile(compiler/hsSyn/HsTypes.hs)</code></a><code>:types.</code><br />
<code>*</code><a href="GhcFile(compiler/hsSyn/HsUtils.hs)" title="wikilink"><code>GhcFile(compiler/hsSyn/HsUtils.hs)</code></a><code>:utilityfunctions(nodatatypes).</code></p>
<p>There is significant mutual recursion between modules, and hence a couple of  files. Look at [wiki:ModuleDependencies] to see the dependencies.</p>
<h2 id="decorating-hssyn-with-type-information">Decorating `HsSyn` with type information</h2>
<p>The type checker adds type information to the syntax tree, otherwise leaving it as undisturbed as possible. This is done in two ways:</p>
<p><code>*Someconstructorshaveafieldoftype</code><code>,whichisjustasynonymfor</code><code>.Forexample:</code></p>
<p></p>
<p><code>An</code><code>representstheexplicitlistconstructinHaskell(e.g.&quot;</code><code>&quot;).Theparserfillsthe</code><code>fieldwithanerrorthunk</code><code>;andtherenamerdoesnottouchit.Thetypecheckerfiguresoutthetype,andfillsinthevalue.Sountilthetypechecker,wecannotexamineorprintthe</code><code>fields.</code></p>
<p><code>Theerrorthunksmeanthatwecan'tconvenientlypretty-printthe`PostTcType`fields,becausethepretty-printerwouldpoketheerrorthunkswhenrunonpre-typcheckedcode.Wecouldhavedefined`PostTcType`tobe`MaybeType`,butthatwouldhavemeantunwrappinglotsof`Just`constructors,whichismessy.Itwouldbenicertoparameterise`HsSyn`overthe`PostTcType`fields.Thus:</code></p>
<p></p>
<p><code>ThiswouldbeaGoodThingtodo.</code></p>
<p><code>*Inafewcases,thetypecheckermovesfromoneconstructortoanother.Example:</code></p>
<p></p>
<p><code>Theparserandrenameruse</code><code>;thetypecheckergeneratesa</code><code>.Thisnamingconventionisusedconsistently.</code></p>
<p><code>*Thereareafewconstructorsaddedbytypechecker(ratherthanreplacinganinputconstructor),particularly:</code><br />
<code>*</code><code>,inthe</code><code>type.</code><br />
<code>*</code><code>,inthe</code><code>type.</code><br />
<code>Theseareinvariablytodowithtypeabstractionandapplication,sinceHaskellsourceisimplicitlygeneralizedandinstantiated,whereasGHC'sintermediateformisexplicitlygeneralizedandinstantiated.</code></p>
<h2 id="source-locations">Source Locations</h2>
<p>`HsSyn` makes heavy use of the `Located` type (<a href="GhcFile(compiler/basicTypes/SrcLoc.hs)" class="uri" title="wikilink">GhcFile(compiler/basicTypes/SrcLoc.hs)</a>):  A `Located t` is just a pair of a `SrcSpan` (which describes the source location of `t`) and a syntax tree `t`. The module `SrcLoc` defines two other types:</p>
<p><code>*`SrcLoc`specifiesaparticularsourcelocation:(filename,linenumber,characterposition)</code><br />
<code>*`SrcSpan`specifesarangeofsourcelocations:(filename,startlinenumberandcharacterposition,endlinenumberandcharacterposition)</code></p>
<p>More details in <a href="GhcFile(compiler/basicTypes/SrcLoc.hs)" class="uri" title="wikilink">GhcFile(compiler/basicTypes/SrcLoc.hs)</a>.</p>
<p>Naming convention within the code: &quot;`LHs`&quot; means located Haskell, e.g. </p>
<h1 id="interface-files">Interface files</h1>
<p>An <strong>interface file</strong> supports separate compilation by recording the information gained by compiling  in its interface file . Morally speaking, the interface file  is part of the object file ; it's like a super symbol-table for .</p>
<p>Interface files are kept in binary, GHC-specific format. The format of these files changes with each GHC release, but not with patch-level releases. The contents of the interface file is, however, completely independent of the back end you are using (`-fviaC`, `-fasm`, `-fcmm` etc).</p>
<p>Although interface files are kept in binary format, you can print them in human-readable form using the command:  This textual format is not particularly designed for machine parsing. Doing so might be possible, but if you want to read GHC interface files you are almost certainly better off using the [wiki:Commentary/Compiler/API GHC API] to do so. If you are wondering how some particular language feature is represented in the interface file, this command is really useful! Cross-reference its output with the `Outputable` instance defined in <a href="GhcFile(compiler/iface/LoadIface.hs)" class="uri" title="wikilink">GhcFile(compiler/iface/LoadIface.hs)</a></p>
<p>Here are some of the things stored in an interface file </p>
<p><code>*TheversionofGHCusedtocompilethemodule,aswellasthecompilationwayandotherknick-knacks</code><br />
<code>*Alistofwhat</code><code>exports.</code><br />
<code>*Thetypesofexportedfunctions,definitionofexportedtypes,andsoon.</code><br />
<code>*Versioninformation,usedtodrivethe[wiki:Commentary/Compiler/RecompilationAvoidancerecompilationchecker].</code><br />
<code>*Thestrictness,arity,andunfoldingofexportedfunctions.Thisiscrucialforcross-moduleoptimisation;butitisonlyincludedwhenyoucompilewith</code><code>.</code></p>
<p>The contents of an interface file is the result of serialising the <strong></strong> family of data types. The data types are in <a href="GhcFile(compiler/iface/IfaceSyn.lhs)" class="uri" title="wikilink">GhcFile(compiler/iface/IfaceSyn.lhs)</a> and <a href="GhcFile(compiler/iface/IfaceType.lhs)" class="uri" title="wikilink">GhcFile(compiler/iface/IfaceType.lhs)</a>; the binary serialisation code is in <a href="GhcFile(compiler/iface/BinIface.hs)" class="uri" title="wikilink">GhcFile(compiler/iface/BinIface.hs)</a>. The definition of a module interface is the <strong></strong> data type in <a href="GhcFile(compiler/main/HscTypes.lhs)" class="uri" title="wikilink">GhcFile(compiler/main/HscTypes.lhs)</a>.</p>
<p>Details of some of the types involved in GHC's representation of Modules and Interface files can be found [wiki:Commentary/Compiler/ModuleTypes here].</p>
<h2 id="when-is-an-interface-file-loaded">When is an interface file loaded?</h2>
<p>The act of loading an interface file can cause various parts of the compiler to behave differently; for instance, a type class instance will only be used if the interface file which defines it was loaded. Additionally, GHC tries to avoid loading interface files if it can avoid it, since every loaded interface file requires going to the file system and parsing the result.</p>
<p>The big situations when we load an interface file:</p>
<ul>
<li>When you import it (either explicitly using an `import`, or implicitly, e.g. through `-fimplicit-import-qualified` in GHCi; `loadSrcInterface`)</li>
<li>When we need to get the type for an identifier (`loadInterface` in `importDecl`)</li>
<li>When it is listed as an orphan of an imported module (`loadModuleInterfaces &quot;Loading orphan modules&quot;`)</li>
</ul>
<p>We also load interface files in some more obscure situations:</p>
<ul>
<li>When it is used as the backing implementation of a signature (`loadSysInterface` in `tcRnSignature`)</li>
<li>When we look up its family instances (`loadSysInterface` in `getFamInsts`)</li>
<li>When its information or safety (`getModuleInterface` in `hscGetSafe`)</li>
<li>When we an identifier is explicitly used (including a use from Template Haskell), we load the interface to check if the identifier is deprecated (`loadInterfaceForName` in `warnIfDeprecated`/`loadInterfaceforName` in `rn_bracket`)</li>
<li>Recompilation checking (`needInterface` in `checkModUsage`)</li>
<li>When we need the fixity for an identifier (`loadInterfaceForName` in `lookupFixityRn`)</li>
<li>When we reify a module for Template Haskell (`loadInterfaceForModule` in `reifyModule`)</li>
<li>When we use a wired-in type constructor, since otherwise the interface file would not be loaded because the compiler already has the type for the identifier. (`Loading instances for wired-in things`)</li>
<li>When `-XParallelArrays` or `-fvectorise` are specified for DPH (`loadModule` in `initDs`)</li>
<li>When we load a plugin (`DynamicLoading`)</li>
<li>To check consistency against the `hi-boot` of a module</li>
<li>To check the old interface file for recompilation avoidance</li>
</ul>
<h1 id="immix-garbage-collector">Immix Garbage Collector</h1>
<p>In a <a href="http://socghop.appspot.com/gsoc/student_project/show/google/gsoc2010/haskell/t127230760695">Google Summer of Code project</a>, <a href="http://wiki.debian.org/MarcoSilva">marcot</a> started an implementation of the Immix Garbage Collector in GHC. It's not in a state where it can be included in GHC yet, but it's functional, don't have known bugs and gets better results than the default GC in the <a href="http://www.dcs.gla.ac.uk/fp/software/ghc/nofib.html">nofib</a> suite. On the other hand, it gets worse results than the default GC for the nofib/gc suite. The implementation was reported on these blog posts: <a href="http://marcotmarcot.wordpress.com/2010/05/17/google-summer-of-code-weekly-report-1/">1</a> <a href="http://marcotmarcot.wordpress.com/2010/05/31/summer-of-code-weekly-report-3/">3</a> <a href="http://marcotmarcot.wordpress.com/2010/06/04/summer-of-code-weekly-report-4/">4</a> <a href="http://marcotmarcot.wordpress.com/2010/06/15/summer-of-code-weekly-report-5/">5</a> <a href="http://marcotmarcot.wordpress.com/2010/06/18/immix-on-ghc-summer-of-code-weekly-report-6/">6</a> <a href="http://marcotmarcot.wordpress.com/2010/06/29/immix-on-ghc-summer-of-code-weekly-report-7/">7</a> <a href="http://marcotmarcot.wordpress.com/2010/07/05/immix-on-ghc-summer-of-code-weekly-report-8/">8</a> <a href="http://marcotmarcot.wordpress.com/2010/07/07/immix-on-ghc-summer-of-code-weekly-report-9/">9</a> <a href="http://marcotmarcot.wordpress.com/2010/07/21/immix-on-ghc-summer-of-code-weekly-report-10/">10</a> <a href="http://marcotmarcot.wordpress.com/2010/08/10/immix-on-ghc-summer-of-code-report-11/">11</a> <a href="http://marcotmarcot.wordpress.com/2010/08/13/immix-on-ghc-summer-of-code-report-12-debconf-debian-day-bh/">12</a></p>
<h1 id="the-patches">The patches</h1>
<p>There are <a href="http://people.debian.org/~marcot/immix/">some patches available</a>.</p>
<h2 id="the-main-patch">The main patch</h2>
<p><code>*</code><a href="http://people.debian.org/~marcot/immix/immix.patch"><code>Generated</code> <code>with</code> <code>darcs</code> <code>diff</code> <code>-u</code></a><br />
<code>*</code><a href="http://people.debian.org/~marcot/immix/immix.dpatch"><code>Darcs</code> <code>bundle</code></a></p>
<p>This patch includes the basic implementation of Immix. It's tested, and has no known bugs. In <a href="http://people.debian.org/~marcot/immix/log.tar.gz">the measurements</a>, it has shown these results:</p>
<p>|| || <strong>Runtime</strong> || <strong>Memory used</strong> || || <strong>nofib</strong> || -2.9% || -1.7% || || <strong>nofib/gc</strong> || +4.3% || +1.2% ||</p>
<p>Currently, it overwrites the [wiki:Commentary/Rts/Storage/GC/Sweeping mark/sweep algorithm]. It uses the same mark bits as [wiki:Commentary/Rts/Storage/GC/Marking mark/compact and mark/sweep], but consider these bits in groups of 32 or 64, depending on the architecture used, which are called lines. It creates a list of free lines for each <a href="http://hackage.haskell.org/trac/ghc/wiki/Commentary/Rts/Storage/GC/Aging">generation</a>, and allocates on them when possible.</p>
<p>As only the first part of each object in memory is marked in the [wiki:Commentary/Rts/Storage/GC/Marking bitmap], it skips the first free line for each group of subsequent lines, because it's possible that an object that starts in the previous line is using part of it. Also, it doesn't deal with [wiki:Commentary/Rts/Storage/BlockAlloc blocks] that objects bigger than the size of a line, called medium sized objects, marked with `BF_MEDIUM`.</p>
<p>The mark stack is used to ensure that the objects allocated on lines get scavenged.</p>
<h2 id="line-before-inscreasing-block-size">Line before inscreasing block size</h2>
<p><code>*</code><a href="http://people.debian.org/~marcot/immix/order.patch"><code>Generated</code> <code>with</code> <code>darcs</code> <code>diff</code> <code>-u</code></a><br />
<code>*</code><a href="http://people.debian.org/~marcot/immix/order.dpatch"><code>Darcs</code> <code>bundle</code></a></p>
<p>Before the implementation of Immix, the code in todo_block_full did the following:</p>
<p><code>1.Trytoincreasetheblocksize.</code><br />
<code>2.Ifitcouldnotbeincreased,getanewblock.</code></p>
<p>With Immix, it turned to:</p>
<p><code>1.Ifwewereallocatinginablock,trytoincreasetheblocksize.</code><br />
<code>2.Ifitcouldnotbeincreased,searchforaline.</code><br />
<code>3.Ifthere'renofreelines,getanewblock.</code></p>
<p>Another possibility for it is:</p>
<p><code>1.Searchforaline.</code><br />
<code>2.Iftherearenofreelines</code><strong><code>and</code></strong><code>wewereallocatinginablock,trytoincreasetheblock.</code><br />
<code>3.Ifitcouldnotbeincreased,getanewblock.</code></p>
<p>Basically, this swaps 1 and 2, making it prefer allocating on lines than increasing the block size. In the measurements done so far, it has not shown significative improvements over the way the code is now, so I'll keep it here to benchmark again when another thing changes, like:</p>
<h2 id="allocate-in-lines-in-minor-gcs">Allocate in lines in minor GCs</h2>
<p><code>*</code><a href="http://people.debian.org/~marcot/immix/minor.patch"><code>Generated</code> <code>with</code> <code>darcs</code> <code>diff</code> <code>-u</code></a><br />
<code>*</code><a href="http://people.debian.org/~marcot/immix/minor.dpatch"><code>Darcs</code> <code>bundle</code></a></p>
<p>This small patch makes it possible to allocate on lines during minor GCs, removing the check about being in a major GC for the search for lines and for the creating of the mark stack. Maybe it shouldn't be so small, because it's not working. The code is being debugged, and possibly there will be a fix soon.</p>
<h2 id="remove-partial-list">Remove partial list</h2>
<p>With the allocation on lines, it's possible not to allocate on partially full blocks. By making all blocks full (with possibly free lines), there'll be no need to use the list of partial blocks. This is not done yet.</p>
<h1 id="to-do">To do</h1>
<p><code>*MakeitfasteranduselessmemorythanthedefaultGCforallbenchmarks</code><br />
<code>*Correct&quot;AllocateinlinesinminorGCs&quot;</code><br />
<code>*Implementandbechmark&quot;Removepartiallists&quot;</code></p>
<p><a href="PageOutline" class="uri" title="wikilink">PageOutline</a></p>
<h1 id="ghc-source-tree-roadmap-includes">GHC Source Tree Roadmap: includes/</h1>
<p>This directory contains C header files that are included in a GHC distribution. The headers fall into several categories.</p>
<h2 id="external-apis">External APIs</h2>
<p>These are header files that define an external API to the RTS that can be used by client code. These interfaces are intended to be relatively stable:</p>
<p><code>[source:includes/HsFFI.hHsFFI.h]::</code><br />
<code>TheexternalFFIapi,asrequiredbytheFFIspec</code></p>
<p><code>[source:includes/RtsAPI.hRtsAPI.h]::</code><br />
<code>TheAPIforcallingintotheRTS.Usedbytheimplementation</code><br />
<code>of`foreignexport`calls,butmayalsobeusedbyexternal</code><br />
<code>clients.</code></p>
<p><code>[source:includes/Rts.hRts.h]::</code><br />
<code>Thisheaderfiledefineseverythingthatisvisible</code><br />
<code>externallytotheRTS.Itincludes`Stg.h`andeverything</code><br />
<code>inthe`rts`subdirectory.</code></p>
<h2 id="derived-constants">Derived Constants</h2>
<p>The canonical definition of certain structures are in C header files. For example, the layout of closures and info tables are defined in the headers [source:includes/rts/storage/Closures.h Closures.h] and [source:includes/rts/storage/InfoTables.h InfoTables.h] respectivesly. How do we get the information about the layout of these structures to the parts of the system that are not written in C, such as the compiler itself, or the C-- code in the RTS?</p>
<p>Our solution is the Haskell program in [source:utils/deriveConstants/DeriveConstants.hs]. It determines the sizes and fields offsets from the C header files by invoking the C compiler for the target platform, and then looking at the resulting object file (we can't <em>run</em> the code generated by the target C compiler, because this is the host platform).</p>
<p>The !DeriveConstants program generates a few header files, notably `includes/dist-derivedconstants/header/DerivedConstants.h`, which contains C `#define`s for each of the derived constants; this file is used by C-- code in the RTS. It also generates a few files of Haskell code which are included into GHC itself, in the `DynFlags` module.</p>
<h2 id="used-when-compiling-via-c">Used when compiling via C</h2>
<p>These header files are `#included` into the `.hc` file generated by GHC when it compiles Haskell code to C. They are also `#included` by `Rts.h`, so the definitions from these files are shared by the RTS code.</p>
<p>These days the amount of stuff included this way is kept to a minimum. In particular, there are no function prototypes: all calls to C functions from `.hc` files are given types at the call site.</p>
<p><code>[source:includes/Stg.hStg.h]::</code><br />
<code>Thetopofthehierarchyis`Stg.h`,whichincludeseverything</code><br />
<code>requiredby`.hc`code.Mostfiles`#included`by`Stg.h`areinthe</code><br />
<code>`stg`subdirectory.</code></p>
<p><code>[source:includes/ghcconfig.hghcconfig.h]::</code><br />
<code>Configurationinfoderivedbythe`configure`script.</code><br />
<code>[source:includes/MachDeps.hMachDeps.h]::</code><br />
<code>Sizesofvariousbasictypes(shouldbeinthe`stg`subdirectory,</code><br />
<code>butlefthereforbackwards-compatibilityreasons).</code><br />
<code>[source:includes/stg/DLL.hstg/DLL.h]::</code><br />
<code>StuffrelatedtoWindowsDLLs.</code><br />
<code>[source:includes/stg/MachRegs.hstg/MachRegs.h]::</code><br />
<code>Globalregisterassignmentsforthisprocessor.</code><br />
<code>[source:includes/stg/MiscClosures.hstg/MiscClosures.h]::</code><br />
<code>Declarationsforclosures&amp;infotablesbuilt-intotheRTS</code><br />
<code>[source:includes/stg/Regs.hstg/Regs.h]::</code><br />
<code>&quot;registers&quot;inthevirtualmachine.</code><br />
<code>[source:includes/stg/SMP.hstg/SMP.h]::</code><br />
<code>AtomicmemoryoperationsforSMPsupport</code><br />
<code>[source:includes/stg/Ticky.hstg/Ticky.h]::</code><br />
<code>Declarationsforticky-tickycounters</code><br />
<code>[source:includes/stg/Types.hstg/Types.h]::</code><br />
<code>Basictypesspecifictothevirtualmachine(eg.`StgWord`).</code></p>
<h2 id="the-rts-external-apis">The RTS external APIs</h2>
<p>The header [source:includes/Rts.h Rts.h] includes all the headers below the `rts` subdirectory, which together define the RTS external API. Virtually all RTS code `#includes` `Rts.h`.</p>
<p>The rts header files are divided into a few directories:</p>
<p><code>*[source:includes/rtsincludes/rts]:Mostof</code><br />
<code>theexternalRTSAPIs,inseparateheaderfilesper-subsystem</code></p>
<p><code>*[source:includes/rts/storageincludes/rts/storage]:Definitionsofthelayoutofheapandstack</code><br />
<code>objects,infotables,structuresthatdefinememoryareasmanaged</code><br />
<code>bytheGC,andmemorymanagementAPIs.</code></p>
<p><code>*[source:includes/rts/profincludes/rts/prof]:</code><br />
<code>Interfacesanddefinitionsforprofiling.</code></p>
<h2 id="included-into-c---.cmm-code">Included into C-- (`.cmm`) code</h2>
<p><code>[source:includes/Cmm.hCmm.h]::</code><br />
<code>includedinto`.cmm`sourceonly;providesusefulmacrosforwriting</code><br />
<code>low-levelC--codeforGHC.</code></p>
<p><a href="PageOutline" class="uri" title="wikilink">PageOutline</a></p>
<h1 id="installing-using-the-llvm-back-end">Installing &amp; Using the LLVM Back-end</h1>
<h2 id="installing">Installing</h2>
<p>The LLVM backend is now included in GHC HEAD. Just grab the git HEAD version of GHC and build it. The backend now also supports all modes that GHC can be built in so you shouldn't need to change your build.mk file either.</p>
<p>For instructions on building GHC go <a href="http://hackage.haskell.org/trac/ghc/wiki/Building">here</a></p>
<h2 id="llvm-support">LLVM Support</h2>
<p>The LLVM backend only supports LLVM version <strong>2.7</strong> or later. Problems with LLVM &gt;= 2.9 and GHC 7.0.3 currently exist (see bug #5103). GHC 7.2 and later works fine with LLVM &gt;= 2.9.</p>
<p>Simply install GHC and make sure the various llvm tools (opt, llc) are available on your path.</p>
<h2 id="using">Using</h2>
<p>Once built you can check that you have the LLVM backend GHC will support these extra options:</p>
<p><code>*</code><em><code>-fllvm</code></em><code>-Compilecodeusingthellvmbackend</code><br />
<code>*</code><em><code>-pgmlo</code></em><code>-Theprogramtouseasthellvmoptimiser</code><br />
<code>*</code><em><code>-pgmlc</code></em><code>-Theprogramtouseasthellvmcompiler</code><br />
<code>*</code><em><code>-optlo</code></em><code>-Extraoptionstopasstothellvmoptimiser</code><br />
<code>*</code><em><code>-optlc</code></em><code>-Extraoptionstopasstothellvmcompiler</code><br />
<code>*</code><em><code>-ddump-llvm</code></em><code>-DumpsthellvmIRwhilecompiling</code><br />
<code>*</code><em><code>-keep-llvm-files</code></em><code>-Keepacopyofthellvmintermediatefilearound</code></p>
<h2 id="supported-platforms-correctness">Supported Platforms &amp; Correctness</h2>
<p><code>*Linuxx86-32/x86-64:Currentlywellsupported.Theback-endcanpassthetestsuiteandbuildaworkingversionofGHC(bootstraptest).</code><br />
<code>*Windowsx86-32:Currentlywellsupported.Theback-endcanpassthetestsuiteandbuildaworkingversionofGHC(bootstraptest).</code><br />
<code>*MacOSX10.5/10.6(x86-32/x86-64):Currentlywellsupported.Theback-endcanpassthetestsuiteandbootstrapGHC.OSXhascausedalotmoreproblemsthenLinuxorWindowsanddoesafewthingsslightlydifferentlythenthem.Itisquitestablethesedaysthough.</code><br />
<code>*ARM:WorkiscurrentlyprogressingtofullysupportGHCusingtheLLVMbackendonARM.Youcanseeablogwithinfoaboutthis</code><a href="http://ghcarm.wordpress.com/"><code>here</code></a><code>.</code><br />
<code>*Otherplatformshaven'tbeentestedatall.</code></p>
<h2 id="shared-libraries">Shared Libraries</h2>
<p>Shared libraries are supported on Linux x64 and Mac OSX x64. Other platforms aren't supported.</p>
<h2 id="performance">Performance</h2>
<p>(All done on linux/x86-32)</p>
<p>A quick summary of the results are that for the 'nofib' benchmark suite, the LLVM code generator was 3.8% slower than the NCG (the C code generator was 6.9% slower than the NCG). The DPH project includes a benchmark suite which I (David Terei) also ran and for this type of code using the LLVM back-end shortened the runtime by an average of 25% compared to the NCG. Also, while not included in my thesis paper as I ran out of time, I did do some benchmarking with the 'nobench' benchmark suite. It gave performance ratios for the back-ends of around:</p>
<p>||NCG || 1.11|| ||C || 1.05|| ||LLVM || 1.14||</p>
<p>A nice demonstration of the improvements the LLVM back-end can bring to some code though can be see at <a href="http://donsbot.wordpress.com/2010/02/21/smoking-fast-haskell-code-using-ghcs-new-llvm-codegen/" class="uri">http://donsbot.wordpress.com/2010/02/21/smoking-fast-haskell-code-using-ghcs-new-llvm-codegen/</a></p>
<p><a href="PageOutline" class="uri" title="wikilink">PageOutline</a></p>
<h1 id="ghc-commentary-librariesinteger">GHC Commentary: Libraries/Integer</h1>
<p>GHC is set up to allow different implementations of the `Integer` type to be chosen at build time.</p>
<h2 id="selecting-an-integer-implementation">Selecting an Integer implementation</h2>
<p>You can select which implementation of Integer is used by defining `INTEGER_LIBRARY` in `mk/build.mk`. This tells the build system to build the library in `libraries/$(INTEGER_LIBRARY)`, and the `cIntegerLibrary` and `cIntegerLibraryType` values in `Config.hs` are defined accordingly.</p>
<p>The default value is `integer-gmp`, which uses the <a href="http://gmplib.org/">GNU Multiple Precision Arithmetic Library (GMP)</a> to define the Integer type and its operations.</p>
<p>The other implementation currently available is `integer-simple`, which uses a simple (but slow, for larger Integers) pure Haskell implementation.</p>
<h2 id="the-integer-interface">The Integer interface</h2>
<p>All Integer implementations should export the same set of types and functions from `GHC.Integer` (within whatever `integer` package you are using). These exports are used by the `base` package However, all of these types and functions must actually be defined in `GHC.Integer.Type`, so that GHC knows where to find them. Specifically, the interface is this:</p>
<p></p>
<h2 id="how-integer-is-handled-inside-ghc">How Integer is handled inside GHC</h2>
<p><code>*</code><strong><code>Front</code> <code>end</code></strong><code>.Integersarerepresentedusingthe`HsInteger`constructorof`HsLit`fortheearlyphasesofcompilation(e.g.typechecking)</code></p>
<p><code>*</code><strong><code>Core</code></strong><code>.In`Core`representation,anintegerliteralisrepresentedbythe`LitInteger`constructorofthe`Literal`type.</code></p>
<p></p>
<p><code>While`Integer`saren't&quot;machineliterals&quot;liketheother`Core``Literal`constructors,itismoreconvenientwhenwritingconstantfoldingRULEStopretendthattheyareliteralsratherthanhavingtounderstandtheirconcreterepresentation.(Especiallyastheconcreterepresentationvariesfrompackagetopackage.)Wealsocarryarounda`Type`,representingthe`Integer`type,intheconstructor,asweneedaccesstoitinafewfunctions(e.g.`literalType`).</code></p>
<p><code>*</code><strong><code>Constant</code> <code>folding</code></strong><code>.Therearemanyconstant-foldingoptimisationsfor`Integer`expressedasbuilt-inrulesin</code><a href="GhcFile(compiler/prelude/PrelRules.lhs)" title="wikilink"><code>GhcFile(compiler/prelude/PrelRules.lhs)</code></a><code>;lookat`builtinIntegerRules`.Allofthetypesandfunctionsinthe`Integer`interfacehavebuilt-innames,e.g.`plusIntegerName`,definedin</code><a href="GhcFile(compiler/prelude/PrelNames.lhs)" title="wikilink"><code>GhcFile(compiler/prelude/PrelNames.lhs)</code></a><code>andincludedin`basicKnownKeyNames`.Thisallowsustomatchonallofthefunctionsin`builtinIntegerRules`in</code><a href="GhcFile(compiler/prelude/PrelRules.lhs)" title="wikilink"><code>GhcFile(compiler/prelude/PrelRules.lhs)</code></a><code>,sowecanconstant-foldIntegerexpressions.AnimportantthingaboutconstantfoldingofIntegerdivisionsisthattheydependoninlining.Here'safragmentof`IntegralInteger`instancedefinitionfrom`libraries/base/GHC/Real.lhs`:</code></p>
<p></p>
<p><code>Constantfoldingrulesfordivisionsaredefinedfor`quotInteger`andotherdivisionfunctionsfrom`integer-gmp`library.If`quot`wasnotinlinedconstantfoldingruleswouldnotfire.Theruleswouldalsonotfireifcallto`quotInteger`wasinlined,butthisdoesnothappenbecauseitismarkedwithNOINLINEpragma-seebelow.</code></p>
<p><code>*</code><strong><code>Converting</code> <code>between</code> <code>Int</code> <code>and</code> <code>Integer</code></strong><code>.It'squitecommonlythecasethat,aftersomeinlining,wegetsomethinglike`integerToInt(intToIntegeri)`,whichconvertsan`Int`toan`Integer`andback.This</code><em><code>must</code></em><code>optimiseaway(see#5767).Wedothisbyrequiringthatthe`integer`packageexposes</code></p>
<p></p>
<p><code>Nowwecandefine`intToInteger`(or,moreprecisely,the`toInteger`methodofthe`IntegralInt`instancein`GHC.Real`)thus</code></p>
<p></p>
<p><code>AndwehaveaRULEfor`integerToInt(smallIntegeri)`.</code></p>
<p><code>*</code><strong><code>Representing</code> <code>integers</code></strong><code>.Westicktothe`LitInteger`representation(whichhidestheconcreterepresentation)aslateaspossibleinthecompiler.Inparticular,it'simportantthatthe`LitInteger`representationisusedinunfoldingsininterfacefiles,sothatconstantfoldingcanhappenonexpressionsthatgetinlined.</code></p>
<p><code>Wefinallyconvert`LitInteger`toapropercorerepresentationofIntegerin</code><a href="GhcFile(compiler/coreSyn/CorePrep.lhs)" title="wikilink"><code>GhcFile(compiler/coreSyn/CorePrep.lhs)</code></a><code>,whichlooksuptheIdfor`mkInteger`andusesittobuildanexpressionlike`mkIntegerTrue[123,456]`(wherethe`Bool`representsthesign,andthelistof`Int`sare31bitchunksoftheabsolutevaluefromlowesttohighest).</code></p>
<p><code>However,thereisaspecialcasefor`Integer`sthatarewithintherangeof`Int`whenthe`integer-gmp`implementationisbeingused;inthatcase,weusethe`S#`constructor(via`integerGmpSDataCon`in</code><a href="GhcFile(compiler/prelude/TysWiredIn.lhs)" title="wikilink"><code>GhcFile(compiler/prelude/TysWiredIn.lhs)</code></a><code>)tobreaktheabstractionanddirectlycreatethedatastructure.</code></p>
<p><code>*</code><strong><code>Don't</code> <code>inline</code> <code>integer</code> <code>functions</code></strong><code>.MostofthefunctionsintheIntegerimplementationinthe`integer`packagearemarked`NOINLINE`.Forexamplein`integer-gmp`wehave</code></p>
<p></p>
<p><code>Notonlyisthisabigfunctiontoinline,butinliningittypicallydoesnogoodbecausetherepresentationofliteralsisabstact,sonopattern-matchingcancellationhappens.Andevenifyouhave`(a+b+c)`,theconditionalsmeanthatnocancellationhappens,oryougetanexponentialcodeexplosion!</code></p>
<h1 id="an-integrated-code-generator-for-ghc">An Integrated Code Generator for GHC</h1>
<p>We propose reworking GHC's back end into an <strong>Integrated Code Generator</strong>, which will widen the interface between machine-independent and machine-dependent parts of the back end. We wish to <strong>dissolve the barrier</strong> between the current machine-independent transformations (CPS conversion, stack layout, etc) and the native-code generators (instruction selection, calling conventions, register allocation -- including spilling to the C stack, etc). The goal is instead to have a code generator that <strong>integrates both machine-independent and machine-dependent components</strong>, which will interact through wide but well-specified interfaces. From this refactoring we expect the following benefits:</p>
<p><code>*</code><strong><code>The</code> <code>back</code> <code>end</code> <code>will</code> <code>be</code> <code>simpler</code> <code>overall</code></strong><code>,primarilybecausethe</code><br />
<code>refactoringwillreduceoreliminateduplicationofcode</code></p>
<p><code>*</code><strong><code>Complexity</code> <code>will</code> <code>be</code> <code>isolated</code></strong><code>intwomoduleswithwell-defined</code><br />
<code>interfaces:adataflowengineandaregisterallocator</code></p>
<p><code>*</code><strong><code>GHC</code> <code>will</code> <code>generate</code> <code>better</code> <code>machine</code> <code>code</code></strong><code>,primarilybecause</code><br />
<code>importantdecisionsaboutregisterusagewillbemadeatalater</code><br />
<code>stageoftranslationandwillexploitknowledgeoftheactual</code><br />
<code>targetmachine.</code></p>
<h2 id="design-elements">Design elements</h2>
<p>The important elements of our design are as follows:</p>
<p><code>0.Buildtwobighammers,andhitasmanynailsaspossible.(Thebighammersarethe</code><strong><code>dataflow</code> <code>optimization</code> <code>engine</code></strong><code>anda</code><strong><code>coalescing</code> <code>register</code> <code>allocator.</code></strong><code>Formoreontheiruses,seeour[wiki:Commentary/Compiler/IntegratedCodeGen#Designphilosophydesignphilosophy].)Thehammeritselfmaybebigandcomplicated,but</code><strong><code>using</code> <code>a</code> <code>big</code> <code>hammer</code> <code>should</code> <code>be</code> <code>easy</code></strong><code>andshouldgiveeasilypredictableresults.</code><br />
<code>0.Loadallbackendsintoeveryinstanceofthecompiler,and</code><strong><code>treat</code> <code>every</code> <code>compilation</code> <code>as</code> <code>a</code> <code>cross-compilation.</code></strong><code>Despitehavingbeenusedinproductioncompilersforatleasttwentyyears,thistechniqueisstillseenassomewhatunorthodox,butitremovesmany</code><code>sandsavessignificantcomplexityatcompiler-configurationtime.Removing</code><code>salsomitigatesproblemswithvalidatingthecompilerunderdifferentbuildconfigurations.</code></p>
<h2 id="design-philosophy">Design philosophy</h2>
<p>State-of-the art dataflow optimization and register allocation both require complex implementations. We live with this complexity because <strong>creating new clients is easy.</strong></p>
<p><code>*</code><strong><code>Dataflow</code> <code>optimization:</code></strong><code>Wecandefineanew</code><br />
<code>optimizationsimplybydefiningalatticeofdataflowfacts(akin</code><br />
<code>toaspecializedlogic)andthenwritingthedataflow-transfer</code><br />
<code>functionsfoundincompilertextbooks.Handingthesefunctionsto</code><br />
<code>thedataflowengineproducesanewoptimizationthatisnotonly</code><br />
<code>usefulonitsown,butthatcaneasilybecomposedwithother</code><br />
<code>optimizationstocreateanintegrated&quot;superoptimization&quot;thatis</code><br />
<code>strictlymorepowerfulthananysequenceofindividualoptimizations,</code><br />
<code>nomatterhowmanytimestheyarere-run.</code><br />
<code>Thedataflowengineisbasedon</code><br />
<code></code><a href="http://citeseer.ist.psu.edu/old/lerner01composing.html"><code>(Lerner,</code> <code>Grove,</code> <code>and</code> <code>Chambers</code> <code>2002)</code></a><code>;</code><br />
<code>youcanfindafunctionalimplementationofthedataflowenginepresentedin</code><br />
<code></code><a href="http://www.cs.tufts.edu/~nr/pubs/zipcfg-abstract.html"><code>(Ramsey</code> <code>and</code> <code>Dias</code> <code>2005)</code></a><code>.</code></p>
<p><code>*</code><strong><code>Coalescing</code> <code>register</code> <code>allocator:</code></strong><code>Thebackendcanusefreshtemporariesandregister-registermoves</code><br />
<code>withabandon,knowingthatastate-of-the-artregisterallocator</code><br />
<code>willeliminatealmostallmoveinstructions.</code></p>
<p><code>*</code><strong><code>Back</code> <code>ends:</code></strong><code>Ourultimategoalistomakeaddinganewbackendeasyaswell.</code><br />
<code>Inthelongrun,wewishtoapplyJohnDias'sdissertationworktoGHC.</code><br />
<code>Intheshortrun,however,we</code><br />
<code>thinkitmoresensibletorepresenteachtarget-machineinstruction</code><br />
<code>setwithanalgebraicdatatype.Weproposetousetypeclassesto</code><br />
<code>definecommonfunctionssuchasidentifyingtheregistersreadand</code><br />
<code>writtenbyeachinstruction.</code></p>
<h2 id="proposed-compilation-pipeline">Proposed compilation pipeline</h2>
<p><code>0.Convertfrom</code><code>toancontrolflowgraph</code><code>:</code><br />
<code>0.Instructionselection:</code><br />
<code>0.Optimise:</code><br />
<code>0.Proc-pointanalysis,andtransformation</code><br />
<code>0.Registerallocation</code><br />
<code>0.Stacklayout</code><br />
<code>0.Tidyup</code></p>
<h3 id="convert-from-stg-to-control-flow-graph">Convert from STG to control flow graph</h3>
<p>Convert from  to an control flow graph  (<a href="GhcFile(compiler/cmm/ZipCfg.hs)" class="uri" title="wikilink">GhcFile(compiler/cmm/ZipCfg.hs)</a>, <a href="GhcFile(compiler/cmm/ZipCfgCmmRep.hs)" class="uri" title="wikilink">GhcFile(compiler/cmm/ZipCfgCmmRep.hs)</a>). This step is Simon PJ's &quot;new code generator&quot; from September 2007. This conversion may introduce new variables, stack slots, and compile-time constants. </p>
<p><code>*Implementscallingconventionsforcall,jump,andreturninstructions:allparameterpassingisturnedintodata-movementinstructions(register-to-registermove,load,orstore),andstack-pointeradjustmentsareinserted.Afterthispoint,calls,returns,andjumpsarejustcontrol-transferinstructions--theparameterpassinghasbeencompiledaway.</code><br />
<code>*Howdowerefertolocationsonthestackwhenwehaven'tlaiditoutyet?Thecompilernamesastackslotusingtheideaofa&quot;latecompile-timeconstant,&quot;whichisjustasymbolicconstantthatwillbereplacedwithanactualstackoffsetwhenthestacklayoutischosen.Onedeparturefromtheoldcodegeneratoristhat</code><strong><code>we</code> <code>do</code> <code>not</code> <code>build</code> <code>a</code>  <code>abstract-syntax</code> <code>tree;</code></strong><code>insteadwegostraighttoacontrol-flowgraph.</code></p>
<p>In practice, we first generate an &quot;abstract control flow graph&quot;, `CmmAGraph`, which makes the business of generating fresh `BlockId`s more convenient, and convert that to a `CmmGraph`. The former is convenient for <em>construction</em> but cannot be analysed; the latter is concrete, and can be analyzed, transformed, and optimized.</p>
<h3 id="instruction-selection">Instruction selection</h3>
<p>Instruction selection: each   and  node in the control-flow graph is replaced with a new graph in which the nodes are machine instructions.  The  type represents computational machine instructions; the  type represents control-transfer instructions. The choice of representation is up to the author of the back end, but for continuity with the existing native code generators, we expect to begin by using algebraic data types inspired by the existing definitions in <a href="GhcFile(compiler/nativeGen/MachInstrs.hs)" class="uri" title="wikilink">GhcFile(compiler/nativeGen/MachInstrs.hs)</a>.</p>
<p>Note that the graph still contains:</p>
<p><code>*</code><strong><code>Variables</code></strong><code>(ielocalregisterthatarenotyetmappedtoparticularmachineregisters)</code><br />
<code>*</code><strong><code>Stack-slot</code> <code>addressing</code> <code>modes</code></strong><code>,whichincludelate-boundcompile-timeconstants,suchastheoffsetintheframeoftheavariablespilllocation,or!BlockIdstack-top-on-entry.</code></p>
<p>The invariant is that each node could be done by one machine instruction, provided each `LocalReg` maps to a (suitable) physical register; and an instruction involving a stack-slot can cope with (Sp+n).</p>
<p>An <strong>extremely important distinction</strong> from the existing code is that we plan to eliminate  and instead provide multiple datatypes, e.g., in , , , and so on.</p>
<p>Similarly, we expect a an instruction selector for <em>each</em> back end, so for example, we might have a transformation that maps  (with variables, stack slots, and compile-time constants)  (with variables, stack slots, and compile-time constants).</p>
<p>We expect to <strong>abstract away from the details of these representations</strong> by borrowing some abstractions from <a href="http://www.eecs.harvard.edu/hube/software/nci/overview.html">Machine SUIF</a>. In the longer term we would like to support RTL-based representations such as are used in gcc, vpo and Quick C--. What this means is that `I386.Middle` (etc) is an abstract type, an instance of type class that supports the functions that the rest of the pipeline needs. For example:  This allows us to <strong>make code improvements machine-independent</strong>, by using machine-dependent functions to capture the semantics of instructions. Figuring out precisely what the interface should be is a key step. For example, to support copy propagation we might want an operation  Similarly, to support peephole optimsation (eg transform `x = y+2; p = bits32[x]` to `p = bits32[y+2]`) we might want something like  The `substExprs` operation returns a `Just` iff a substitution took place.</p>
<p>Interfaces like these would require the machine-specific abstract type `i` to contain enough information to reconstruct a `LocalReg` or `CmmExpr`. Later one, we'll need to construct SRTs too, so we must continue to track pointer-hood.</p>
<p>One possible implementation for `I386` or `Sparc` would be to use a generic RTL representation, together with a recogniser to maintain the machine invariant. Our initial idea, though, is that is an implementation choice. It's still possible that a machine-independent optimisation could take advantage of the representation being an RTL. For example, we could provide a function in the `Instr` class  which is particularly cheap for architectures that do use `RTL` as the representation type.</p>
<h3 id="optimisation">Optimisation</h3>
<p>Optimise the code.  (with variables, stack slots, and compile-time constants)  (with variables, stack slots, and compile-time constants), such as</p>
<p><code>*Branchchainelimination.</code><br />
<code>*Removeunreachableblocks(deadcode).</code><br />
<code>*Constantpropagation.</code><br />
<code>*Copypropagation.</code><br />
<code>*Lazycodemotion(hoisting,sinking,partialredundancyelimination).</code><br />
<code>*Blockconcatenation.branchtoK;andthisistheonlyuseofK.</code><br />
<code>*CommonBlockElimination(likeCSE).ThisessentiallyimplementstheAdamsoptimisation,webelieve.</code><br />
<code>*Consider(sometime):blockduplication.branchtoK;andKisashortblock.Branchchaineliminationisjustaspecialcaseofthis.</code><br />
<code>*Peepholeoptimisation.Thedifficultyofimplementingagoodpeepholeoptimizervariesgreatlywiththerepresentationofinstructions.WeproposetopostponeseriousworkonpeepholeoptimizationuntilwehaveabackendcapableofrepresentingmachineinstructionsasRTLs,whichmakespeepholeoptimizationtrivial.</code></p>
<h3 id="proc-point-analysis">Proc-point analysis</h3>
<p> Both input and output still have variables and stack-slot addressing modes.</p>
<p><code>*Procpointsarefound,andtheappropriatecontrol-transferinstructionsareinserted.</code><br />
<code>*Whysoearly(beforeregisterallocation,stacklayout)?Dependingonthebackend(thinkofCastheworstcase),theproc-pointanalysismighthavetosatisfysomehorriblecallingconvention.Wewanttomaketheserequirementsexplicitbeforewegettotheregisterallocator.Wealsowantto</code><strong><code>exploit</code> <code>the</code> <code>register</code> <code>allocator</code></strong><code>tomakethebestpossibledecisionsabout</code><em><code>which</code> <code>live</code> <code>variables</code> <code>(if</code> <code>any)</code> <code>should</code> <code>be</code> <code>in</code> <code>registers</code> <code>at</code> <code>a</code> <code>proc</code> <code>point</code></em><code>.</code></p>
<h3 id="register-allocation">Register allocation</h3>
<p>Register allocation replaces variable references with machine register and stack slots. This may introduce spills and reloads (to account for register shortage), which which is why we may get new stack-slot references.</p>
<p>That is, register allocation takes  (with variables, stack slots)  (with stack slots only). No more variables!</p>
<p>We no longer need to spill to the C stack, because we have fully allocated everything to machine registers.</p>
<h3 id="stack-layout">Stack layout</h3>
<p>Stack Layout:  (with stack slots, and compile-time constants) </p>
<p><code>*Chooseastacklayout.</code><br />
<code>*Replacereferencestostackslotswithaddressesonthestack.</code><br />
<code>*Replacecompile-timeconstantswithoffsetsintothestack.</code></p>
<p>No more stack-slot references.</p>
<h3 id="tidy-up">Tidy up</h3>
<p><code>0.Proc-pointsplitting:</code><code></code><br />
<code>*Eachprocpointgetsitsownprocedure.</code><br />
<code>0.Codelayout:</code><br />
<code>*Areversepostorderdepth-firsttraversalsimultaneouslyconvertsthegraphtosequentialcodeandconvertseachinstructionintoanassembly-codestring:</code><strong><code>Assembly</code> <code>code</code> <code>ahoy</code></strong><code>!</code></p>
<h2 id="machine-dependence">Machine-dependence</h2>
<p>A key property of the design is that the scopes of machine-dependent code and machine-dependent static types are limited as much as possible:</p>
<p><code>0.Therepresentationofmachineinstructionsmaybemachine-dependent(algebraicdatatype),orwemayuseamachine-independentrepresentationthatsatisfiesamachine-dependentdynamicinvariant(RTLs).Thebackendshouldbedesignedinsuchawaythatmostpassesdon'tknowthedifference;weintendtoborrowheavilyfromMachineSUIF.Todefinetheinterfaceusedtoconcealthedifference,MachineSUIFusesC++classes;wewilluseHaskell'stypeclasses.</code><br />
<code>0.Instructionselectionisnecessarilymachine-dependent,andmoreover,itmustknowtherepresentationofmachineinstructions</code><br />
<code>0.Mostoftheoptimizerneednotknowtherepresentationofmachineinstructions.</code><br />
<code>0.Otherpasses,includingregisterallocation,stacklayout,andsoon,shouldbecompletelymachine-independent.</code><br />
<code>0.RTLsarenotanewrepresentation;theyareatrivialextensionofexisting</code><code>representations.</code></p>
<h1 id="ghc-commentary-the-byte-code-interpreter-and-dynamic-linker">GHC Commentary: The byte-code interpreter and dynamic linker</h1>
<h2 id="linker">Linker</h2>
<p>The linker lives in `rts/Linker.c` and is responsible for handling runtime loading of code into a Haskell process. This is something of a big blob of unpleasant code, and see DynamicGhcPrograms for information about efforts to reduce our dependence on this linker.</p>
<p>Nevertheless, GHC's linker certainly adds functionality, and this has been enough to earn its keep (for now). In particular, the linker knows how to **relocate static libraries** (e.g. `.o` and `.a` libraries). This is a pretty rare feature to find: ordinarily, libraries that are to be loaded at runtime are compiled as position independent code (-fPIC), which allows the same physical code pages to be shared between processes, reducing physical memory usage. At runtime, GHC rewrites the relocations, meaning that the resulting page cannot be shared across processes, but that the result is just as efficient as if the code had been statically linked to begin with.</p>
<p>Implementation of the linker cuts three axes: object file format (ELF, Mach-O, PEi386), operating system (Linux, MingW, Darwin, etc), and architecture (i386, x86_64, powerpc, arm), and there are corresponding sets of macros for fiddling with each (`OBJFORMAT_*`, `*_HOST_OS` and `*_HOST_ARCH`). Are large part of the unpleasantness of the current linker is the fact that all of these different concerns are jumbled in one file; refactoring these out to separate files would be a very nice service.</p>
<p>(write more here)</p>
<h2 id="bytecode-interpreter">Bytecode Interpreter</h2>
<hr />
<p>CategoryStub</p>
<h1 id="the-io-manager">The I/O Manager</h1>
<p>This page describes the internals of the I/O manager, the latest version of which can be found in <a href="http://hackage.haskell.org/packages/archive/base/latest/doc/html/GHC-Event.html">GHC.Event</a>. The I/O manager's job is to to provide a blocking I/O API to the user without forcing the RTS to create one operating system thread per Haskell thread. We here focus on the <em>threaded</em> RTS on non-Windows platforms.</p>
<p>ezyang: <strong>WARNING: some of this information may be out of date</strong></p>
<p>The RTS keeps a global list of pending events, unsuprising called `pendingEvents`, containing a elements of the following data type:</p>
<p></p>
<p>When a thread wants to read from a file descriptor `fd` it calls `threadWaitRead` which in turn calls `waitForReadEvent`.</p>
<p></p>
<p>`waitForReadEvent` creates a new `MVar`, adds it to `pendingEvents` and finally blocks on it. `pendingEvents` gets read by the I/O manager thread which runs the event loop, in GHC called `service_loop`. It roughly performs these steps:</p>
<p><code>1.PickupnewI/Orequestsfrom`pendingRequests`andsetthevariabletotheemptylist.</code><br />
<code>2.Createdatastructuresappropriateforcalling`select`.</code><br />
<code>3.Foreach`Read`requestin`pendingEvents`checkifthefiledescriptorisinthereadysetreturnedby`select`.Ifsoperforma`putMVar`onthe`MVar`associatedwiththatrequesttowakeuptheblockedthread.</code><br />
<code>4.Repeatfromstep1.</code></p>
<h1 id="key-data-types">Key data types</h1>
<p>The key to understanding GHC is to understand its key data types. There are pages describing many of them here (please add new pages!). The diagram below shows their inter-dependencies.</p>
<p><code>*[wiki:Commentary/Compiler/HsSynTypeThesourcelanguage:HsSyn]</code><br />
<code>*[wiki:Commentary/Compiler/RdrNameTypeRdrNames,Modules,andOccNames]</code><br />
<code>*[wiki:Commentary/Compiler/ModuleTypesModIface,ModDetails,ModGuts]</code><br />
<code>*[wiki:Commentary/Compiler/UniqueUniques]:Notdrawninthediagram,becausenearlyeverythingdependsonUniques.</code><br />
<code>*[wiki:Commentary/Compiler/NameTypeNames]</code><br />
<code>*[wiki:Commentary/Compiler/EntityTypesEntities]:variables,typeconstructors,dataconstructors,andclasses.</code><br />
<code>*Types:[wiki:Commentary/Compiler/TypeTypeTypeandKind],[wiki:Commentary/Compiler/FCequalitytypesandcoercions]</code><br />
<code>*[wiki:Commentary/Compiler/CoreSynTypeThecorelanguage]</code><br />
<code>*[wiki:Commentary/Compiler/StgSynTypeTheSTGlanguage]</code><br />
<code>*[wiki:Commentary/Compiler/CmmTypeTheCmmlanguage]</code><br />
<code>*[wiki:Commentary/Compiler/BackEndTypesBackendtypes]</code></p>
<p><a href="Image(types.png)" class="uri" title="wikilink">Image(types.png)</a></p>
<h1 id="kinds">Kinds</h1>
<p>Kinds classify types. So for example:  The base kinds are these:</p>
<p><code>*&quot;`*`&quot;isthekindofboxedvalues.Thingslike`Int`and`MaybeFloat`havekind`*`.</code><br />
<code>*&quot;`#`&quot;isthekindofunboxedvalues.Thingslike`Int#`havekind`#`.</code><br />
<code>*Withtheadventof[wiki:GhcKindsdatatypepromotionandkindpolymorphism]wecanhavealotmorekinds.</code></p>
<p>(Unboxed tuples used to have a distinct kind, but in 2012 we combined unboxed tuples with other unboxed values in a single kind &quot;`#`&quot;.)</p>
<h2 id="representing-kinds">Representing kinds</h2>
<p>Kinds are represented by the data type `Type` (see [wiki:Commentary/Compiler/TypeType]):  Basic kinds are represented using type constructors, e.g. the kind `*` is represented as  where `liftedTypeKindTyCon` is a built-in `PrimTyCon`. The arrow type constructor is used as the arrow kind constructor, e.g. the kind `* -&gt; *` is represented internally as  It's easy to extract the kind of a type, or the sort of a kind:  The &quot;sort&quot; of a kind is always one of the sorts: `TY` (for kinds that classify normal types) or `CO` (for kinds that classify coercion evidence). The coercion kind, `T1 :=: T2`, is represented by `PredTy (EqPred T1 T2)`.</p>
<h2 id="kind-subtyping">Kind subtyping</h2>
<p>There is a small amount of sub-typing in kinds. Suppose you see `(t1 -&gt; t2)`. What kind must `t1` and `t2` have? It could be `*` or `#`. So we have a single kind `OpenKind`, which is a super-kind of both, with this simple lattice:</p>
<p><a href="Image(https://docs.google.com/drawings/pub?id=1M5yBP8iAWTgqdI3oG1UNnYihVlipnvvk2vLInAFxtNM&amp;w=359&amp;h=229)" class="uri" title="wikilink">Image(https://docs.google.com/drawings/pub?id=1M5yBP8iAWTgqdI3oG1UNnYihVlipnvvk2vLInAFxtNM&amp;w=359&amp;h=229)</a></p>
<p>(You can edit this picture <a href="https://docs.google.com/drawings/d/1M5yBP8iAWTgqdI3oG1UNnYihVlipnvvk2vLInAFxtNM/edit?hl=en_GB">here</a>.)</p>
<h1 id="linearity">Linearity</h1>
<p>The solution is to distinguish call demands from product demands. Consider again:  The demands placed on  by the first and second call get bothed together to yield . But this is incorrect. Consider:  Here, the demands placed on  by the body of  and by the call to  in the -body get bothed together: . Note that this is the same as the demand placed on  above, yet we want to distinguish between the two situations, because in the first example, the inner lambda in 's rhs is only called once.</p>
<p>The solution is to treat call demands and product demands differently, and to define the  function for call demands to have the same behavior as . Then in the first example,  has demand  placed on it, and in the second, . This is what we want; now, if  has demand  placed on it, that implies  is always called with two arguments.</p>
<p>Why does this make sense? Consider what it means if we see an example like:  (where  is lazy in , and  is strict in  and ).  is used both with demand  (in the call to  and with demand  (in the call to ). This means it's perfectly same to strictly evaluate , so when we both together the two demands, we should get . On the other hand, if a function is <em>called</em> once with one argument and once with two, we don't want to treat it as a function that's always called with two arguments; we're only interested in functions that are <em>always</em> called with <em>n</em> arguments for a given <em>n</em>. Hence, both should behave the same way as lub for call demands.</p>
<h1 id="ticky">Ticky</h1>
<p>(NB out-of-date, but maybe historically useful; cf [wiki:Debugging/TickyTicky])</p>
<p>The following code inserts extra fields into closures when ticky is enabled (and so had to be commented out):  in <a href="GhcFile(compiler/codeGen/CgTicky.hs)" class="uri" title="wikilink">GhcFile(compiler/codeGen/CgTicky.hs)</a>.</p>
<p>Other relevant functions:  in <a href="GhcFile(compiler/codeGen/CgTicky.hs)" class="uri" title="wikilink">GhcFile(compiler/codeGen/CgTicky.hs)</a> (called by  in <a href="GhcFile(compiler/codeGen/CgClosure.lhs)" class="uri" title="wikilink">GhcFile(compiler/codeGen/CgClosure.lhs)</a>).</p>
<p>Argh! I spent days tracking down this bug:  in <a href="GhcFile(compiler/cmm/CLabel.hs)" class="uri" title="wikilink">GhcFile(compiler/cmm/CLabel.hs)</a> needs to return  for labels of type  (i.e., labels for ticky counters.) By default, it was returning , which caused the ticky counter labels to get declared with the wrong type in the generated C, which caused C compiler errors.</p>
<h2 id="declarations-for-ticky-counters">Declarations for ticky counters</h2>
<p> spits out C declarations that look like this:  Here,  is actually an  (this type is declared in <a href="GhcFile(includes/StgTicky.h)" class="uri" title="wikilink">GhcFile(includes/StgTicky.h)</a>). The counters get used by  in <a href="GhcFile(rts/Ticky.c)" class="uri" title="wikilink">GhcFile(rts/Ticky.c)</a>, which prints out the ticky reports. The counter fields are accessed using offsets defined in <a href="GhcFile(includes/GHCConstants.h)" class="uri" title="wikilink">GhcFile(includes/GHCConstants.h)</a> (), which in turn get generated from <a href="GhcFile(includes/mkDerivedConstants.c)" class="uri" title="wikilink">GhcFile(includes/mkDerivedConstants.c)</a> (change it and then run  in .</p>
<p><s>Note that the first 3 fields of the counters are 16-bit ints and so the generated ticky-counter registration code has to reflect that (I fixed a bug where the first field was getting treated as a 32-bit int.)</s> I modified the  type so that all fields are s, because it seems that the code generator can't cope with anything else anyway (i.e., in the declaration above,  is an array of s, even though the C type declaration implies that some fields are halfwords.)</p>
<p>In  in <a href="GhcFile(compiler/codeGen/CgClosure.lhs)" class="uri" title="wikilink">GhcFile(compiler/codeGen/CgClosure.lhs)</a>, &quot;eager blackholing&quot; was getting employed in the case where ticky was turned on; this was causing programs to  when they wouldn't with ticky disabled, so I turned that off.</p>
<h1 id="strictness-and-let-floating">Strictness and let-floating</h1>
<p>We run into the following problem in the  nofib benchmark: suppose we have:  where  doesn't depend on . Demand analysis says that  has a strict demand placed on it. Later,  gets floated to the top level because it doesn't depend on  (in reality it's more complicated because in this case  probably would have gotten floated out before demand analysis, but bear with me).  still has a strict demand signature, which a top-level binding isn't allowed to have. Currently this manifests itself as an assertion failure in <a href="GhcFile(compiler/simplCore/SimplEnv.lhs)" class="uri" title="wikilink">GhcFile(compiler/simplCore/SimplEnv.lhs)</a>.</p>
<p>There are two possible easy solutions: don't float out bindings for strict things, or &quot;both&quot; the demand for a binder with Lazy when its binding gets floated out. The question is, is it better to do the let-floating and lose the strictness into or to evaluate something strictly but lose sharing?</p>
<h1 id="coercions">Coercions</h1>
<p>When we run into an expression like  that we're placing demand  on, we analyze  to get , then check whether the depth of  is equal to the depth of  or not. This is necessary because we might be casting a function to a non-function type. So, if  and  have equal depth, we return  as is; if 's arity is less, we drop the appropriate number of args from ; if 's arity is less, we add the appropriate number of dummy argument demands to it.</p>
<h1 id="warn-arity">WARN: arity /</h1>
<p>dmdTypeDepth rhs_dmd_ty &amp;&amp; not (exprIsTrivial rhs) =</p>
<p>This warning was happening for (at least) two reasons: - lambdas with a strict non-call demand placed on them were being handled wrong (see the first two examples in [wiki:Commentary/Compiler/StrictnessAnalysis/Examples]) - coercions were being handled wrong, resulting in a demand type with depth 0 being assigned to an rhs consisting of a cast from/to a function type</p>
<h1 id="explaining-demand-transformers">Explaining demand transformers</h1>
<p>For those who, like me, are a little slow, this example might go in section 5.1 of the paper:</p>
<p>(a):  (b): </p>
<p>In both (a) and (b), 's rhs places a strict demand on . So if we see:  with a strict demand placed on it, it wouldn't be sound to look at 's demand signature and say that  places a strict demand on  under  -- because we don't know whether  is like (a) or like (b). This is why when we see a partial application of , we discard all of the argument information in 's demand type.</p>
<h1 id="nofib-stuff">Nofib stuff</h1>
<p>I've had weird problems with the  and  commands under MSYS but I think it's just when running nofib. At some point I wrote down:</p>
<p>TIME needs to be  not </p>
<p>and</p>
<p>MSYS  does not work, use cygwin </p>
<p>but of *course* I no longer remember what I meant. <a href="PageOutline" class="uri" title="wikilink">PageOutline</a></p>
<h1 id="ghc-commentary-libraries">GHC Commentary: Libraries</h1>
<p>All GHC build trees contain a set of libraries, called the <strong>Boot Packages</strong>. These are the libraries that GHC's source code imports. Obviously you need the boot packages to build GHC at all. The boot packages are those packages in the file [source:packages] that have a `-` in the &quot;tag&quot; column.</p>
<p>The repository structure of a GHC source tree is described in [wiki:Repositories].</p>
<p>You can see exactly which versions of what packages GHC depends on by looking in [source:compiler/ghc.cabal.in]. The versions of the boot packages (including the `base` library) associated with each GHC release are tabulated in <a href="wiki:Commentary/Libraries/VersionHistory" title="wikilink">GHC Boot Library Version History</a>.</p>
<h1 id="building-packages-that-ghc-doesnt-depend-on">Building packages that GHC doesn't depend on</h1>
<p>You can make the build system build extra packages, on which GHC doesn't strictly depend, by adding them to the `$(TOP)/packages` file, with an `extra` tag. Then set `BUILD_EXTRA_PKGS=YES` in your `mk/build.mk` file.</p>
<p>It should be exceptional, but you can make the build system provide per-package compiler flags, by adding some definitions in `$(TOP)/ghc.mk`, just below the comment </p>
<hr />
<h1 id="classifying-boot-packages">Classifying boot packages</h1>
<p>A <strong>boot package</strong> is, by definition, a package that can be built by GHC's build system.</p>
<p>Boot packages can be classified in four different ways:</p>
<p><code>*Requiredvsoptional</code><br />
<code>*Wired-invsindependent</code><br />
<code>*Zero-bootvsnotzero-boot</code><br />
<code>*Installedvsnotinstalled</code></p>
<p>These distinctions are described in the following sub-sections.</p>
<h2 id="required-or-optional">Required or optional</h2>
<p>Most boot packages <strong>required</strong> to build `ghc-stage2`, or one of the supporting utilities such as `ghc-pkg`, `hsc2hs`, etc.</p>
<p>However a few are <strong>optional</strong>, and are built only</p>
<p><code>*Toensurethattheydoindeedbuildcleanly;theyarestresstestsofGHC.E.g.`dph`</code><br />
<code>*Becausetheyareusedinregressiontests</code></p>
<h2 id="coupling-to-ghc">Coupling to GHC</h2>
<p>An important classification of the boot packages is as follows:</p>
<p><code>*</code><strong><code>Wired</code> <code>in</code> <code>packages</code></strong><code>aretotallyspecifictoGHC.Seethelistin`compiler/main/Packages.lhs`function`findWiredInPackages`,andc.f.[wiki:Commentary/Compiler/Packages].Atthemomenttheseare:</code><br />
<code>*`ghc-prim`</code><br />
<code>*`integer-gmp`,`integer-simple`</code><br />
<code>*`base`</code><br />
<code>*`template-haskell`</code><br />
<code>*`dph`</code></p>
<p><code>*</code><strong><code>Independent</code></strong><code>packagesarelooselycoupledtoGHC,andoftenmaintainedbyothers.Mostbootpackagesareindependent;e.g.`containers`,`binary`,`haskeline`andsoon.</code></p>
<p>Independent libraries may have a master repository somewhere separate from the GHC repositories. Whenever we release GHC, we ensure that the installed boot libraries (i.e. that come with GHC) that are also independent are precisely sync'd with a particular released version of that library.</p>
<h2 id="zero-boot-packages">Zero-boot packages</h2>
<p>Since GHC's source code imports the boot packages, <em>even the bootstrap compiler must have the boot packages available</em>. (Or, more precisely, all the types and values that are imported must be available from some package in the bootstrap compiler; the exact set of packages does not need to be identical.)</p>
<p>For the most part we simply assume that the bootstrap compiler already has the boot packages installed. The <strong>Zero-boot Packages</strong> are a set of packages for which this assumption does not hold. Two reasons dominate:</p>
<p><code>*Forcertainfast-movingbootpackages(notably`Cabal`),wedon'twanttorelyontheuserhavinginstalledabang-up-to-dateversionofthepackage.</code><br />
<code>*Theonlypackagesthatwecan&quot;assumethatthebootstrapcompileralreadyhas&quot;arethosepackagesthatcomewithGHCitself;i.e.theinstalledbootpackages.Sonon-installedbootpackagesarealsozero-bootpackages.Example:`bin-package-db`or`hoopl`.</code></p>
<p>So we begin the entire build process by installing the zero-boot packages in the bootstrap compiler. (This installation is purely local to the build tree.) This is done in `ghc.mk` by setting `PACKAGES_STAGE0` to the list of zero-boot packages; indeed this is the only way in which zero-boot packages are identified in the build system.</p>
<p>As time goes on, a Zero-boot package may become an ordinary boot package, because the bootstrap compiler is expected to have (a sufficiently up to date) version of the package already. Remember that we support bootstrapping with two previous versions of GHC.</p>
<p>To find out which packages are currently zero-boot packages, do the following in a GHC build: </p>
<p>Some Zero-boot packages are <strong>maintained by other people</strong>. In order to avoid GHC being exposed to day-by-day changes in these packages, we maintain a &quot;lagging&quot; Git repository for each that we occasionally sync with the master repository. We never push patches to lagging repository; rather we push to the master (in discussion with the package maintainer), and pull the patches into the lagging repo. The current Zero-boot packages of this kind are:</p>
<p><code>*`Cabal`:wefrequentlyupdateCabalandGHCinsync</code><br />
<code>*`binary`(renamedto`ghc-binary`inthe6.12branch):requiredby`bin-package-db`.</code></p>
<p>Other Zero-boot packages are <strong>maintained by us</strong>. There is just one Git repo for each, the master. When we make a GHC release, we simultaneously tag and release each of these packages. They are:</p>
<p><code>*`hpc`</code><br />
<code>*`extensible-exceptions`:thisisashimthatprovidesanAPItoolderversionsofGHCthatiscompatiblewithwhatthecurrent`base`packagenowexports.So,unusually,`extensible-exceptions`isazero-bootpackage,butnotabootpackage.</code><br />
<code>*`bin-package-db`:aGHC-specificpackagethatprovidesbinaryserialisationofthepackagedatabase,useby`ghc-pkg`andGHCitself.</code></p>
<h2 id="installation">Installation</h2>
<p>When we build a distribution of GHC, it includes at least some libraries, otherwise it would be utterly useless. Since GHC is part of the Haskell Platform, any library that is installed with GHC is necessarily part of the Haskell Platform, so we have to be a bit careful what we include.</p>
<p>Alas, since the `ghc` package (implementing the GHC API) is certainly an installed package, all the packages on which it depends must also be installed, and hence willy-nilly become part of the Haskell Platform. In practice that means that almost all the Boot Packages are installed. In some cases that is unfortunate. For example, we currently have a special version of the `binary` library, which we don't really expect Haskell users to use; in this case, we call it `ghc-binary`, and informally discourage its use.</p>
<p>Currently the Boot Packages that are not installed are `haskeline`, `mtl`, and `terminfo`; these are needed to build the GHC front-end, but not to build the `ghc` <em>package</em>.</p>
<p><strong>QUESTION</strong>: where in the build system is the list of installed packages defined?</p>
<hr />
<h1 id="boot-packages-dependencies">Boot packages dependencies</h1>
<p><code>*Attherootofthehierarchywehave</code><strong><code>`ghc-prim`</code></strong><code>.Asthenameimplies,thispackagecontainsthemostprimitivetypesandfunctions.Itonlycontainsahandfulofmodules,including`GHC.Prim`(whichcontains`Int#`,`+#`,etc)and`GHC.Bool`,containingthe`Bool`datatype.See&quot;WARNING:patternmatching&quot;below.</code></p>
<p><code>*Above`ghc-prim`arethepackages</code><br />
<code>*`integer-gmp`</code><br />
<code>*`integer-simple`</code><br />
<code>Thetwohavethesameinterface,andonlyoneofthetwoisused.(Whenwewanttobevagueaboutwhichone,wecallit`integer-impl`.)Theyprovideadefinitionofthe`Integer`type(ontopoftheC`gmp`library,orinplainHaskell,respectively).Whichfunctionalityisprovidedin`ghc-prim`ismostlydrivenbywhatfunctionalitythe`integer-impl`packagesneed.Bydefault`integer-gmp`isused;touse`integer-simple`define`INTEGER_LIBRARY=integer-simple`in`mk/build.mk`.</code></p>
<p><code>See&quot;WARNING:patternmatching&quot;below.</code></p>
<p><code>*Nextisthe</code><strong><code>`base`</code></strong><code>package.Thiscontainsalargenumberofmodules,manyofwhichareinonebigcyclicimportknot,mostlyduetothe`Exception`type.</code></p>
<p><code>*Ontopofbaseareanumberofother,morespecialisedpackages,whosepurposeisgenerallyclearfromtheirname.Ifnot,youcangetmoredetailfromthedescriptionsintheirCabalfiles.Theup-to-datelistofpackagescanbefoundinthefile[source:packages].</code></p>
<p>The `haskell98`, `old-time`, `old-locale` and `random` packages are mostly only needed for Haskell 98 support, although `dph` currently uses `random` too.</p>
<h2 id="warning-pattern-matching-in-ghc-prim-integer-simple-and-integer-gmp">WARNING: Pattern matching in `ghc-prim`, `integer-simple`, and `integer-gmp`</h2>
<p>Note that `ghc-prim` and `integer-impl` are below the dependency chain from Exception (in `base`), which means they must not raise generate code to raise an exception (it's not enough that this code will never run). One particularly subtle case of GHC exception-raising code is in the case of (complete!) pattern matches. Consider the unboxed form of Integers, which has the constructor S# or J#.</p>
<p></p>
<p>GHC will incorrectly generate core that pattern matches against the second argument twice, the second match being a partial one with (dead) exception raising code. When compiled with optimizations, the dead code is eliminated. However, this breaks with -O0, thus:  The fix is to explicitly spell out the constructor in the second and third line, so that GHC does not generate calls to `patError`:</p>
<p></p>
<h1 id="repositories">Repositories</h1>
<p>The list of repository locations has moved to [wiki:Repositories].</p>
<h1 id="the-llvm-backend">The LLVM backend</h1>
<p>David Terei wrote a new code generator for GHC which targets the LLVM compiler infrastructure. Most of the work was done as part of an honours thesis at the University of New South Wales under the supervision of Manuel Chakravarty. It was merged into GHC Head around May of 2010 and has been included in GHC since the 7.0 release.</p>
<p>Documentation:</p>
<p><code>*[wiki:Commentary/Compiler/Backends/LLVM/InstallingInstalling&amp;Using]</code><br />
<code>*[wiki:Commentary/Compiler/Backends/LLVM/DesignDesign&amp;Implementation]</code><br />
<code>*[wiki:Commentary/Compiler/Backends/LLVM/ManglerLLVMMangler]</code><br />
<code>*[wiki:Commentary/Compiler/Backends/LLVM/DevelopmentNotesBugs&amp;OtherProblems]</code><br />
<code>*[wiki:Commentary/Compiler/Backends/LLVM/GHC_LLVMPortingPortingGHC/LLVMtoanotherplatform]</code></p>
<p>Work in Progress:</p>
<p><code>*[wiki:SIMDSIMDinstructionsandLLVM]</code><br />
<code>*[wiki:Commentary/Compiler/Backends/LLVM/AliasImprovingAliasAnalysis]</code></p>
<p>Future Ideas:</p>
<p><code>*[wiki:Commentary/Compiler/Backends/LLVM/WIPToDoListofSorts]</code><br />
<code>*[wiki:Commentary/Compiler/Backends/LLVM/ReplacingNCGReplacingtheNativeCodeGenerator]</code><br />
<code>*</code><a href="http://dterei.blogspot.com/2011/09/ghc-project-for-all.html"><code>David</code> <code>Terei</code> <code>blog</code> <code>post</code> <code>of</code> <code>LLVM-related</code> <code>projects</code></a></p>
<p>Other information:</p>
<p><code>*The</code><a href="http://www.cse.unsw.edu.au/~pls/thesis/davidt-thesis.pdf"><code>thesis</code> <code>paper</code></a><code>whichoffersadetailedperformanceevaluation,aswellasthemotivationanddesignoftheback-end.</code><br />
<code>*</code><a href="http://blog.llvm.org/2010/05/glasgow-haskell-compiler-and-llvm.html"><code>Blog</code> <code>post</code></a><code>ontheLLVMblogaboutthebackend.</code><br />
<code>*Amorerecent</code><a href="http://www.cse.unsw.edu.au/~chak/papers/TC10.html"><code>paper</code></a><code>submittedtotheHaskellSymposium'10,givesupdateddesignoverviewandperformancenumbers.</code></p>
<h1 id="loopification">Loopification</h1>
<p>Loopification is a C-- optimisation pass that turns tail recursion into proper loops.</p>
<p>Here is a summary of relevant links and tickets</p>
<ul>
<li><a href="http://research.microsoft.com/en-us/um/people/simonpj/tmp/wos-diss-draft.pdf">Krzysztof Wos's project</a> in which he reports great performance improvements by turning tail recursion into loops in C--.</li>
</ul>
<ul>
<li>Tickets:</li>
</ul>
<p><code>*#8285</code><br />
<code>*#8793,#11372;seecomment15of#8793)etc,whereitseemsthatwearemissingloopificationforasimpleIOfunction</code><br />
<code>*#8585concernedgettingthelooptostart</code><em><code>after</code></em><code>thestackcheck</code></p>
<h1 id="llvm-mangler">LLVM Mangler</h1>
<p>The LLVM backend sadly includes a 'mangler'. This is a Haskell written program (well pass of GHC) that runs on the assembly code generated by the LLVM compiler. We do this as there are a few issues with communicating to LLVM exactly what we want generated as object code and so, for now, it is easiest to post-process the assembly.</p>
<p>Long term we ideally would submit patches to LLVM and get rid of the mangler. The work required to do that may be quite high and the patches needed potentially fairly specific to GHC. So no one has done that yet.</p>
<p>Below are the issues that the LLVM Mangler addresses in the assembly code.</p>
<h2 id="tables_next_to_code-tntc">TABLES_NEXT_TO_CODE (TNTC)</h2>
<p>TODO</p>
<h2 id="stack-alignment">Stack Alignment</h2>
<p>LLVM requires that the C stack be properly aligned for spills. One Win32 the stack is 4-byte aligned, which is not enough for SSE spills, and even on x64 platforms the stack is only 16-byte aligned, which is not enough for AVX spills. When the stack is not properly aligned for spills, LLVM generates prologue/epilogue code that fiddles with the base pointer, which GHC uses as its stack pointer, and disables tail call optimization. Both are very bad. Therefore we currently tell LLVM to always assume the stack is properly aligned and then rewrite all aligned SSE/AVX move instructions to their unaligned counterparts inside the mangler.</p>
<h2 id="simd-avx">SIMD / AVX</h2>
<h1 id="migrating-old-commentary">Migrating Old Commentary</h1>
<p>Below you will find a table with a line for each section of the <a href="http://darcs.haskell.org/ghc/docs/comm/">old commentary</a>. Please replace <em>unknown</em> with <strong>done</strong> if you believe that the wiki commentary completely captures <em>all</em> of the information in that section of the old commentary, and that there is no longer any reason for people to read that section of the commentary.</p>
<h2 id="before-the-show-begins">Before the Show Begins</h2>
<p>||Feedback||<strong>done</strong>|| ||Other Sources of Wisdom||<strong>done</strong>||</p>
<h2 id="genesis">Genesis</h2>
<p>||Outline of the Genesis||<strong>done</strong>|| ||Mindboggling Makefiles||<strong>done</strong>|| ||GHC's Marvellous Module Structure||<strong>done</strong>||</p>
<h2 id="the-beast-dissected">The Beast Dissected</h2>
<p>||Coding style used in the compiler||<strong>done</strong>|| ||The Glorious Driver||Sections 1 &amp; 2 <strong>done</strong>, <em>Other sections mostly outdated</em>|| ||Primitives and the Prelude||<em>unknown</em>|| ||Just Syntax||<em>unknown</em>|| ||The Basics||<em>unknown</em>|| ||Modules, !ModuleNames and Packages||<em>unknown</em>|| ||The truth about names: Names and !OccNames||<em>unknown</em>|| ||The Real Story about Variables, Ids, !TyVars, and the like||<em>unknown</em>|| ||Data types and constructors||<em>unknown</em>|| ||The Glorious Renamer||<em>unknown</em>|| ||Hybrid Types||<em>unknown</em>|| ||Checking Types||<em>unknown</em>|| ||Sugar Free: From Haskell To Core||<em>unknown</em>|| ||The Mighty Simplifier||<em>unknown</em>|| ||The Evil Mangler||<strong>done</strong>|| ||Alien Functions||<em>unknown</em>|| ||You Got Control: The STG-language||<em>unknown</em>|| ||The Native Code Generator||<em>unknown</em>|| ||GHCi||<em>unknown</em>|| ||Implementation of foreign export||<em>unknown</em>|| ||Compiling and running the Main module||<em>unknown</em>||</p>
<h2 id="rts-libraries">RTS &amp; Libraries</h2>
<p>||Coding Style Guidelines||<strong>done</strong>|| ||Spineless Tagless C||<em>unknown</em>|| ||Primitives||<em>unknown</em>|| ||Prelude Foundations||<em>unknown</em>|| ||Cunning Prelude Code||<em>unknown</em>|| ||On why we have !ForeignPtr||<em>unknown</em>|| ||Non-blocking I/O for Win32||<em>unknown</em>|| ||Supporting multi-threaded interoperation||<em>unknown</em>||</p>
<h2 id="extensions-or-making-a-complicated-system-more-complicated">Extensions, or Making a Complicated System More Complicated</h2>
<p>||Template Haskell||<em>unknown</em>|| ||Parallel Arrays||<em>unknown</em>||</p>
<h1 id="the-marvellous-module-structure-of-ghc">The Marvellous Module Structure of GHC</h1>
<p><code>*</code><strong><code>See</code> <code>also:</code> <code>[ModuleDependencies/Hierarchical</code> <code>Proposal</code> <code>for</code> <code>hierarchical</code> <code>module</code> <code>structure]</code></strong></p>
<p><code>*</code><strong><code>NOTE:</code></strong><code>Possiblyoutdated.</code></p>
<p>GHC is built out of about 245 Haskell modules. It can be quite tricky to figure out what the module dependency graph looks like. It can be important, too, because loops in the module dependency graph need to be broken carefully using .hi-boot interface files.</p>
<p>This section of the commentary documents the subtlest part of the module dependency graph, namely the part near the bottom.</p>
<p><code>*Thelistisgivenincompilationorder:thatis,modulenearthetoparemoreprimitive,andarecompiledearlier.</code><br />
<code>*Eachmoduleislistedtogetherwithitsmostcriticaldependenciesinparentheses;thatis,thedependenciesthatpreventitbeingcompiledearlier.</code><br />
<code>*Modulesinthesamebulletdon'tdependoneachother.</code><br />
<code>*Loopsaredocumentedbyadependencysuchas&quot;loopType.Type&quot;.ThismeansthathemoduleimportsType.Type,butmoduleTypehasnotyetbeencompiled,sotheimportcomesfromType.hi-boot.</code></p>
<h2 id="compilation-order-is-as-follows">Compilation order is as follows:</h2>
<p><code>*Firstcomesalayerofmodulesthathavefewinterdependencies,andwhichimplementverybasicdatatypes:</code><br />
<code>*Util</code><br />
<code>*!OccName</code><br />
<code>*Pretty</code><br />
<code>*Outputable</code><br />
<code>*!StringBuffer</code><br />
<code>*!ListSetOps</code><br />
<code>*Maybes</code><br />
<code>*etc</code></p>
<p><code>*Nowcomesthemainsubtlelayer,involvingtypes,classes,typeconstructorsidentifiers,expressions,rules,andtheiroperations.</code><br />
<code>*Name,!PrimRep</code><br />
<code>*!PrelNames</code><br />
<code>*Var(Name,loop!IdInfo.!IdInfo,loopType.Type,loopType.Kind)</code><br />
<code>*!VarEnv,!VarSet,!ThinAir</code><br />
<code>*Class(loop!TyCon.!TyCon,loopType.Type)</code><br />
<code>*!TyCon(loopType.Type,loop!DataCon.!DataCon,loopGenerics.!GenInfo)</code><br />
<code>*!TypeRep(loop!DataCon.!DataCon,loopSubst.substTyWith)</code><br />
<code>*Type(loop!PprType.pprType,loopSubst.substTyWith)</code><br />
<code>*!FieldLabel(Type),!TysPrim(Type)</code><br />
<code>*Literal(!TysPrim,!PprType),!DataCon(loop!PprType,loopSubst.substTyWith,!FieldLabel.!FieldLabel)</code><br />
<code>*!TysWiredIn(loop!MkId.mkDataConIds)</code><br />
<code>*!TcType(lotsof!TysWiredInstuff)</code><br />
<code>*!PprType(lotsof!TcTypestuff)</code><br />
<code>*!PrimOp(!PprType,!TysWiredIn)</code><br />
<code>*!CoreSyn[doesnotimportId]</code><br />
<code>*!IdInfo(!CoreSyn.Unfolding,!CoreSyn.!CoreRules)</code><br />
<code>*Id(lotsfrom!IdInfo)</code><br />
<code>*CoreFVs,!PprCore</code><br />
<code>*!CoreUtils(!PprCore.pprCoreExpr,CoreFVs.exprFreeVars,!CoreSyn.isEvaldUnfolding!CoreSyn.maybeUnfoldingTemplate)</code><br />
<code>*!CoreLint(!CoreUtils),!OccurAnal(!CoreUtils.exprIsTrivial),!CoreTidy(!CoreUtils.exprArity)</code><br />
<code>*!CoreUnfold(!OccurAnal.occurAnalyseGlobalExpr)</code><br />
<code>*Subst(!CoreUnfold.Unfolding,CoreFVs),Generics(!CoreUnfold.mkTopUnfolding),Rules(!CoreUnfold.Unfolding,!PprCore.pprTidyIdRules)</code><br />
<code>*!MkId(!CoreUnfold.mkUnfolding,Subst,Rules.addRule)</code><br />
<code>*!PrelInfo(!MkId),!HscTypes(Rules.!RuleBase)</code></p>
<p><code>*Thatistheendoftheinfrastructure.Nowwegetthemainlayerofmodulesthatperformusefulwork.</code><br />
<code>*!CoreTidy(!HscTypes.!PersistentCompilerState)</code></p>
<h2 id="typechecker-stuff">Typechecker stuff</h2>
<p><code>*!TcType</code><br />
<code>*!TcEvidence(!TcType)</code><br />
<code>*TcMType(!TcEvidence)</code><br />
<code>*!TcUnify(TcMType)</code><br />
<code>*TcSMonad(TcMType)</code><br />
<code>*!TcSimplify(TcSMonad)</code><br />
<code>*!TcValidity(!TcSimplify.simplifyTop,!TcUnify.tcSubType)</code><br />
<code>*!TcHsType(!TcValidity.checkValidType,!TcValidity.checkValidInstance)</code></p>
<h2 id="hssyn-stuff">!HsSyn stuff</h2>
<p><code>*!HsPat.hs-boot</code><br />
<code>*!HsExpr.hs-boot(loop!HsPat.LPat)</code><br />
<code>*!HsTypes(loop!HsExpr.!HsSplice)</code><br />
<code>*!HsBinds(!HsTypes.LHsType,loop!HsPat.LPat,!HsExpr.pprFunBindandothers)!HsLit(!HsTypes.!SyntaxName)</code><br />
<code>*!HsPat(!HsBinds,!HsLit)!HsDecls(!HsBinds)</code><br />
<code>*!HsExpr(!HsDecls,!HsPat)</code></p>
<h2 id="library-stuff-base-package">Library stuff: base package</h2>
<p><code>*GHC.Base</code><br />
<code>*Data.Tuple(GHC.Base),GHC.Ptr(GHC.Base)</code><br />
<code>*GHC.Enum(Data.Tuple)</code><br />
<code>*GHC.Show(GHC.Enum)</code><br />
<code>*GHC.Num(GHC.Show)</code><br />
<code>*GHC.ST(GHC.Num),GHC.Real(GHC.Num)</code><br />
<code>*GHC.Arr(GHC.ST)GHC.STRef(GHC.ST)</code><br />
<code>*GHC.!IOBase(GHC.Arr)</code><br />
<code>*Data.Bits(GHC.Real)</code><br />
<code>*Data.!HashTable(Data.Bits,Control.Monad)</code><br />
<code>*Data.Typeable(GHC.IOBase,Data.!HashTable)</code><br />
<code>*GHC.Weak(Data.Typeable,GHC.IOBase)</code></p>
<h2 id="high-level-dependency-graph">High-level Dependency Graph</h2>
<p>Dark red edges indicate that only one module in one group depends on a module in the other group. Dark green means 11 or more dependencies. Arrows point from the importing module to the imported module.</p>
<p><a href="Image(dep5.png)" class="uri" title="wikilink">Image(dep5.png)</a></p>
<h1 id="module-types">Module Types</h1>
<p>Here we attempt to describe some of the main data structures involved in GHC's representation and handling of Haksell modules. GHC uses a number of different data types to represent modules, for efficiency (some types load less information) and categorising how other modules relate to the one being compiled. Most these types are defined in <a href="GhcFile(compiler/main/HscTypes.lhs)" class="uri" title="wikilink">GhcFile(compiler/main/HscTypes.lhs)</a>.</p>
<h2 id="module">Module</h2>
<p>Location: <a href="GhcFile(compiler/basicTypes/Module.lhs)" class="uri" title="wikilink">GhcFile(compiler/basicTypes/Module.lhs)</a></p>
<p>The <strong>Module</strong> data type is simply an identifier of a module; its fully qualified name.</p>
<p></p>
<h2 id="modiface">!ModIface</h2>
<p>Location: <a href="GhcFile(compiler/main/HscTypes.lhs)" class="uri" title="wikilink">GhcFile(compiler/main/HscTypes.lhs)</a></p>
<p>The <strong>!ModIface</strong> data type is one of the fullest representations of a module. It is a complete representation of a modules interface file (<strong>.hi</strong>). It is this data structure that is serialised to produce a modules <strong>.hi</strong> file.</p>
<h2 id="moddetails">!ModDetails</h2>
<p>Location: <a href="GhcFile(compiler/main/HscTypes.lhs)" class="uri" title="wikilink">GhcFile(compiler/main/HscTypes.lhs)</a></p>
<p><strong>!ModDetails</strong> is essentially a cache for information in the <strong>!ModIface</strong> for home modules only. It stores information about a module after linking has taken place. <strong>!ModIface</strong> stores information about a module before linking. Information stored in a <strong>!ModDetails</strong> is created from a <strong>!ModIface</strong>, typically during type checking.</p>
<h3 id="modguts">!ModGuts</h3>
<p>Location: <a href="GhcFile(compiler/main/HscTypes.lhs)" class="uri" title="wikilink">GhcFile(compiler/main/HscTypes.lhs)</a></p>
<p>A <strong>!ModGuts</strong> is carried through the compiler, accumulating stuff as it goes. There is only one <strong>!ModGuts</strong> at any time, the one for the module being compiled right now. Once it is compiled, a <strong>!ModIface</strong> and <strong>!ModDetails</strong> are extracted and the <strong>!ModGuts</strong> is discarded.</p>
<h2 id="modsummary">!ModSummary</h2>
<p>Location: <a href="GhcFile(compiler/main/HscTypes.lhs)" class="uri" title="wikilink">GhcFile(compiler/main/HscTypes.lhs)</a></p>
<p>A <strong>!ModSummary</strong> stores a summary of a module that is suitable for recompilation checking. A <strong>!ModSummary</strong> is a node in the compilation manager's dependency graph.</p>
<h2 id="homemodinfo">!HomeModInfo</h2>
<p>Location: <a href="GhcFile(compiler/main/HscTypes.lhs)" class="uri" title="wikilink">GhcFile(compiler/main/HscTypes.lhs)</a></p>
<p>A <strong>!HomeModInfo</strong> stores information about a module in the package being compiled. It simply stores for the <strong>!ModIface</strong>, <strong>!ModDetails</strong> and linkage information about a single module.</p>
<h2 id="homepackagetable">!HomePackageTable</h2>
<p>Location: <a href="GhcFile(compiler/main/HscTypes.lhs)" class="uri" title="wikilink">GhcFile(compiler/main/HscTypes.lhs)</a></p>
<p>The home package table describes already-compiled home-package modules, /excluding/ the module we are compiling right now.</p>
<h2 id="externalpackagestate">!ExternalPackageState</h2>
<p>Location: <a href="GhcFile(compiler/main/HscTypes.lhs)" class="uri" title="wikilink">GhcFile(compiler/main/HscTypes.lhs)</a></p>
<p>Stores information about other packages that we have pulled in while compiling the current module.</p>
<h1 id="multi-instance-packages">Multi-instance packages</h1>
<p>This page is about how to change the package system to allow multiple instances of a package to be installed at the same time. There are two reasons we want to be able to do this:</p>
<p><code>*Tobeabletotrackthedifferent&quot;ways&quot;inwhichapackageisavailable:e.g.profiling,dynamic.Atthemoment,thepackagedatabasedoesn'ttrackthisinformation,withtheresultthattheuserhastoreinstallpackageswith`--enable-profiling`onatrial-and-errorbasisinordertogetprofilingsupportforpackagestheyhavealreadyinstalled.</code><br />
<code>Thesameholds,inprinciple,fordifferentflagsettingsorotherconfigurationvariationsofapackage.</code></p>
<p><code>*Tomakeinstallingnewpackagesmorerobust.Wheninstallinganewpackage,wesometimesneedtoupgradepackagesthatarealreadyinstalledtonewversions,whichmayrequirerecompilingotherpackagesagainstthenewversion.Forexample,ifwehaveP1installed,Q1dependsonP(anyversion),andweneedtoinstallRthatdependsonbothP2andQ1.WeneedtobuildP2,rebuildQ1againstP2,andfinallybuildRagainstP2andthenewQ1.WewouldliketodothiswithoutremovingP1ortheoldQ1fromthepackagedatabase,becauseotherpackagesmaybedependingontheoldQ1,andwedon'twanttobreakthosepackages(whichiswhatcurrentlyhappenswithGHC7.0).</code></p>
<p>See also</p>
<p><code>*[wiki:Commentary/PackagesCommentarypagesaboutpackages]</code><br />
<code>*PhilippSchuster'sGSoCproject</code><a href="http://www.google-melange.com/gsoc/proposal/review/google/gsoc2012/phischu/1"><code>proposal</code> <code>(DEAD)</code></a><code>,</code><a href="http://www.google-melange.com/gsoc/project/google/gsoc2012/phischu/19001"><code>GSoC</code> <code>project</code> <code>page</code> <code>(DEAD)</code></a><code>,[wiki:Commentary/GSoCMultipleInstancesTracwikipage],</code><a href="https://github.com/phischu/cabal"><code>git</code> <code>repo</code></a><code>,and</code><a href="https://www.youtube.com/watch?v=h4QmkyN28Qs"><code>video</code></a><code>.</code><br />
<code>*</code><a href="http://coldwa.st/e/blog/2013-08-20-Cabal-sandbox.html"><code>Mikhail's</code> <code>post</code></a><code>aboutCabalsandboxes.</code><br />
<code>*Mailingliststuff</code><a href="http://comments.gmane.org/gmane.comp.lang.haskell.ghc.devel/443"><code>here</code></a><code>and</code><a href="http://markmail.org/message/4qvegvx32lhlo66g#query:+page:1+mid:bwdgykv4g2hzqg5t+state:results"><code>here</code></a><code>.</code></p>
<h2 id="todo-list">!ToDo list</h2>
<p><code>*ghc-pkg:donotoverwritepreviousinstancesinthepackageDB</code><br />
<code>*butweneedtothinkaboutthecasewhereweoverwriteanexistingpackageonthefilesystemandre-register.Thiswillhappenwithlocal(orin-place)packageregistrationthatoccurswhenbuildingabunchofrelatedcomponents.Inthiscasethetoolshouldknowit'sdoingthatandunregistertheoldinstancefirst(thoughreliablytrackingthatstatemaybetricky,sinceuserscanmakecleanetc).Weshouldcheckmakeitacheckederrortore-registerinthesamefilesystemlocationwithnewpackageid,withoutunregisteringtheoldonefirst.Perhapswecanidentifysomekeyfile.</code></p>
<p><code>*GHC:discardconflictinginstancesduringitsshadowingphase</code><br />
<code>*SDM:GHCwillcurrentlydo*something*here,butitmightendupwitharesultthattheuserdidn'twant/expect.Onewaytoimprovethingsistoprioritisepackagesthatwereinstalledmorerecently.</code><br />
<code>*AndressuggeststhatGHCshouldbemuchcleverer,andlookattheactualdependenciesofthemodulesbeingcompiledbeforedecidingwhichpackagestoenable.Thiswouldalmostcertainlyresultinmorethingsworkingandpossiblylesssurprisingbehavioursometimes,butSimonthinksthat(a)itistoohard,(b)ifusersneedthis,theyshoulduseCabalanditsdependencyresolver,whichwilldoagoodjob,(c)youcanoftenresolveproblemsbyadding`-packageX`,and(d)eventuallywewillwantasystemwhereusersmanageseparatesessions,sotheycansetupanenvironmentinwhichthepackagestheywantareavailable.Thishasalotincommonwith`cabal-dev`andsandboxes,sothemechanisms(andconcepts)shouldbeshared.(kosmikus:perhapsanalternativeistoforcetheusertomakeanactivedecisionincaseofconflicts,i.e.,tocreateasandboxthatexposesaconsistentpackageset).</code></p>
<p><code>*GHC:allowspecifyingapackageinstanceinthe-packageflags</code><br />
<code>*SDM:alreadydone(-package-idflag)</code><br />
<code>*DC:alreadyusedbyCabal</code></p>
<p><code>*Cabal:allowspecifyingapackageinstancewhendoingSetup.hsconfigure</code><br />
<code>*DC:currentlyonly==versionconstraintscanbeused,notinstalledpackageid.Shouldn'tbetoohardtoaddhowever.</code><br />
<code>*JT:DoneaccordingtoDC.</code></p>
<p><code>*instancesofpackagesmustinstallinadifferentlocation</code><br />
<code>*installdirectoryincludeshash?</code><br />
<code>*SDM:notdoneyet.Oneproblemisthatwedon'tknowthehashuntilthepackageisbuilt,butweneedtoknowtheinstalllocationsearlierbecausewebaketheminto`Paths_foo.hs`.</code><br />
<code>*SimonandAndresdiscussedthatoneoptionistoletCabalcomputeitsownhash.However,thenwe'dhavetwohashestodealwith.OnlyusingtheCabal-computedhashisn'tanoptioneitheraccordingtoSimon,becauseapparentlyGHC'sABIhashcomputationisnon-deterministic,sowemightendupwithsituationswhereCabal'shashisstable,butGHCcomputesanABI-incompatibleversion.Thisissomewhatworrying...</code><br />
<code>*DuncanthinksthatweshouldstorebothapackageidentityandapackageABIhash.Currentlyweformthepackageidfromthename,versionandABIhash.WeshouldstoretheABIhashseparatelyanywaybecauseeventuallywewillwanttoknowit,toknowwhichpackagesareABIcompatible.SoCabalcancomputeapackageIdinadvance,howeverissensible,andtheABIhashiscalculatedasnow,afterthebuild.TheinstallationdirectoryfollowsthepackageId.</code></p>
<p><code>*Cabal:willthedependencysolverworkcorrectlyinthepresenceofmultiplepackageinstances?</code><br />
<code>*Andresclaimsitwillusingthenewsolver.(Thereisnownopointinupdatingtheoldsolver,thoughit'dbetechnicallypossible.)Alittlebitmoredetail:themodularsolverhasnoconceptofshadowing,onlyofpreference.SoifseveralinstancesareprovidedbyoneormorepackageDBs,they'llallbevalidchoices.</code></p>
<p><code>*ghc-pkgcleanup:removeold/unusedinstancesofpackages</code><br />
<code>*howcanwetellwhensomethingisunnecessary?ThisisactuallyratherhardbecauseunlikeNixwedonottrackeveryrandomexecutablethattheusercompiles.</code></p>
<h2 id="next-step-dealing-with-ways">Next step: dealing with ways</h2>
<p><code>*Addthe&quot;way&quot;toInstalledPackageInfo,includethewayinthehash</code></p>
<p><code>*GHC:slicethepackageDBduringstartupaccordingtothecorrectway</code></p>
<p><code>*Cabal:fixupthedepresolver(kosmikus:anythingstillneededthere?)</code></p>
<p><code>*Cabal:ways?(thiswouldbereallyeasy,ifwecouldgetmoreinformationaboutinstalledpackagesbackfromghc-pkg)</code></p>
<p><code>*Tohandleflagsandotherconfig,addtwonewfieldstoInstalledPackageInfo:`install-agent:{agent-id}`whichidentifiescabal/rpm/etcandthen`configuration:{freetext}`.Theinterpretationoftheconfigurationstringdependsontheinstallationagent,andneedbeknownonlytothatagent.Thisway,agentscanseeifitwasthemthatinstalledapackage,andsotheyshouldknowhowtointerprettheconfigstring.Forcabalthiswouldincludeconfigflagsetc.Itshouldmakeitpossibletoreproduceapackage,e.g.ifwehavetorebuildforsomereason,ortogettheprofilingequivofanormalinstance.</code></p>
<h1 id="the-type-1">The  type</h1>
<p>Every entity (type constructor, class, identifier, type variable) has a . The Name type is pervasive in GHC, and is defined in <a href="GhcFile(compiler/basicTypes/Name.hs)" class="uri" title="wikilink">GhcFile(compiler/basicTypes/Name.hs)</a>. Here is what a  looks like, though it is private to the Name module: </p>
<p><code>*The</code><code>fieldsayswhatsortofnamethisis:see</code><strong><code>[wiki:Commentary/Compiler/NameType#TheNameSortofaName</code> <code>NameSort]</code></strong><code>below.</code><br />
<code>*The</code><code>fieldgivesthe&quot;occurrencename&quot;,or</code><strong><code>[wiki:Commentary/Compiler/RdrNameType#TheOccNametype</code> <code>OccName]</code></strong><code>,oftheName.</code><br />
<code>*The</code><code>fieldallowsfasttestsforequalityofNames.</code><br />
<code>*The</code><code>fieldgivessomeindicationofwherethenamewasbound.</code></p>
<h2 id="the-of-a-name">The  of a Name</h2>
<p>There are four flavours of Name: </p>
<p><code>,</code><code>::</code><br />
<code>An</code><code></code><code>hasonlyanoccurrencename.Distinct</code><code></code><code>mayhavethesameoccurrencename;the</code><code>distinguishesthem.</code></p>
<p><code>Thereisonlyatinydifferencebetween</code><code>and</code><code>;theformersimplyremembersthatthenamewasoriginallywrittenbytheprogrammer,whichhelpswhengeneratingerrormessages.</code></p>
<p><code>::</code><br />
<code>An</code><code></code><code>hasaglobally-unique(module,occurrencename)pair,namelytheoriginalnameoftheentity,thatdescribeswherethethingwasoriginallydefined.Soforexample,ifwehave</code></p>
<p></p>
<p><code>theninmodule</code><code>,thefunction</code><code>hasanExternalName</code><code>.</code></p>
<p><code>DuringanyinvocationofGHC,each(module,occurrence-name)getsone,andonlyone,</code><code>,storedinthe</code><code>fieldofthe</code><code>.ThisassociationremainsfixedevenwhenGHCfinishesonemoduleandstartstocompileanother.Thisassociationbetween(module,occurrence-name)pairsandthecorresponding</code><code>(withits</code><code>field)ismaintainedbytheNameCache.</code></p>
<p><code></code><code>::</code><br />
<code>A</code><code></code><code>isaspecialsortof</code><code></code><code>,onethatiscompletelyknowntothecompiler(e.g.the</code><code>typeconstructor).See[wiki:Commentary/Compiler/WiredIn].</code></p>
<p><code>The</code><code>fieldisjustabooleanyes/noflagthatidentifiesentitiesthataredenotedbybuilt-insyntax,suchas</code><code>fortheemptylist.These</code><code>aren't&quot;inscope&quot;assuch,andweoccasionallyneedtoknowthat.</code></p>
<h2 id="entities-and">Entities and </h2>
<p>Here are the sorts of Name an entity can have:</p>
<p><code>*Class:alwayshasan</code><code>Name.</code></p>
<p><code>*!TyCon:alwayshasan</code><code>or</code><code>Name.</code></p>
<p><code>*!TyVar:canhave</code><code>,or</code><code>Names;theformerareonesarisefrominstantiatingprogrammer-writtentypesignatures.</code></p>
<p><code>*Ids:canhave</code><code>,</code><code>,or</code><code>Names.</code><br />
<code>*Before!CoreTidy,theIdsthatweredefinedattoplevelintheoriginalsourceprogramget</code><code>Names,whereasextratop-levelbindingsgenerated(say)bythetypecheckerget</code><code>Names.Thisdistinctionisoccasionallyusefulforfilteringdiagnosticoutput;e.g.for</code><code>.</code><br />
<code>*After!CoreTidy:AnIdwithan</code><code>Namewillgeneratesymbolsthatappearasexternalsymbolsintheobjectfile.AnIdwithan</code><code>Namecannotbereferencedfromoutsidethemodule,andsogeneratesalocalsymbolintheobjectfile.The!CoreTidypassmakesthedecisionaboutwhichnamesshouldbeExternalandwhichInternal.</code></p>
<h1 id="native-code-generator-ncg">Native Code Generator (NCG)</h1>
<p>For other information related to this page, see:</p>
<p><code>*[wiki:BackEndNotes]foroptimisationideasregardingthecurrentNCG</code><br />
<code>*[wiki:Commentary/Compiler/CmmTypeTheCmmlanguage](theNCGcodeworksfromHaskell'simplementationofC--andmanyoptimisationsintheNCGrelatetoCmm)</code><br />
<code>*[wiki:Commentary/Compiler/Backends/NCG/RegisterAllocatorTheregisterallocator].</code></p>
<p>On some platforms (currently x86 and x86_64, with possibly bitrotted support for PowerPC and Sparc), GHC can generate assembly code directly. The NCG is enabled by default on supported platforms.</p>
<p>The NCG has always been something of a second-class citizen inside GHC, an unloved child, rather. This means that its integration into the compiler as a whole is rather clumsy, which brings some problems described below. That apart, the NCG proper is fairly cleanly designed, as target-independent as it reasonably can be, and so should not be difficult to retarget.</p>
<p>NOTE! The native code generator was largely rewritten as part of the C-- backend changes, around May 2004. Unfortunately the rest of this document still refers to the old version, and was written with relation to the CVS head as of end-Jan 2002. Some of it is relevant, some of it isn't.</p>
<h3 id="files-parts">Files, Parts</h3>
<p>After GHC has produced [wiki:Commentary/Compiler/CmmType Cmm] (use -ddump-cmm or -ddump-opt-cmm to view), the Native Code Generator (NCG) transforms Cmm into architecture-specific assembly code. The NCG is located in <a href="GhcFile(compiler/nativeGen)" class="uri" title="wikilink">GhcFile(compiler/nativeGen)</a> and is separated into eight modules:</p>
<p><code>*</code><a href="GhcFile(compiler/nativeGen/AsmCodeGen.lhs)" title="wikilink"><code>GhcFile(compiler/nativeGen/AsmCodeGen.lhs)</code></a><a href="BR" title="wikilink"><code>BR</code></a><br />
<code>top-levelmodulefortheNCG,importedby</code><a href="GhcFile(compiler/main/CodeOutput.lhs)" title="wikilink"><code>GhcFile(compiler/main/CodeOutput.lhs)</code></a><code>;alsodefinestheMonadforoptimisinggenericCmmcode,</code><a href="BR" title="wikilink"><code>BR</code></a><a href="BR" title="wikilink"><code>BR</code></a><br />
<code>*</code><a href="GhcFile(compiler/nativeGen/MachCodeGen.hs)" title="wikilink"><code>GhcFile(compiler/nativeGen/MachCodeGen.hs)</code></a><a href="BR" title="wikilink"><code>BR</code></a><br />
<code>generatesarchitecture-specificinstructions(aHaskell-representationofassembler)fromCmmcode</code><a href="BR" title="wikilink"><code>BR</code></a><a href="BR" title="wikilink"><code>BR</code></a><br />
<code>*</code><a href="GhcFile(compiler/nativeGen/MachInstrs.hs)" title="wikilink"><code>GhcFile(compiler/nativeGen/MachInstrs.hs)</code></a><a href="BR" title="wikilink"><code>BR</code></a><br />
<code>containsdatadefinitionsandsomefunctions(comparison,size,simpleconversions)formachineinstructions,mostlycarriedoutthroughthe</code><code>datatype,definedhere</code><a href="BR" title="wikilink"><code>BR</code></a><a href="BR" title="wikilink"><code>BR</code></a><br />
<code>*</code><a href="GhcFile(compiler/nativeGen/NCGMonad.hs)" title="wikilink"><code>GhcFile(compiler/nativeGen/NCGMonad.hs)</code></a><a href="BR" title="wikilink"><code>BR</code></a><br />
<code>definesthethemainmonadintheNCG:theNativecodeMachineinstructionMonad,</code><code>,andrelatedfunctions.</code><em><code>Note:</code> <code>the</code> <code>NCG</code> <code>switches</code> <code>between</code> <code>two</code> <code>monads</code> <code>at</code> <code>times,</code> <code>especially</code> <code>in</code> <code>:</code>  <code>and</code> <code>the</code>  <code>Monad</code> <code>used</code> <code>throughout</code> <code>the</code> <code>compiler.</code></em><a href="BR" title="wikilink"><code>BR</code></a><a href="BR" title="wikilink"><code>BR</code></a><br />
<code>*</code><a href="GhcFile(compiler/nativeGen/PIC.hs)" title="wikilink"><code>GhcFile(compiler/nativeGen/PIC.hs)</code></a><a href="BR" title="wikilink"><code>BR</code></a><br />
<code>handlesgenerationofpositionindependentcodeandissuesrelatedtodynamiclinkingintheNCG;relatedtomanyothermodulesoutsidetheNCGthathandlesymbolimport,exportandreferences,including</code><code>,</code><code>,</code><code>andtheRTS,andtheMangler</code><a href="BR" title="wikilink"><code>BR</code></a><a href="BR" title="wikilink"><code>BR</code></a><br />
<code>*</code><a href="GhcFile(compiler/nativeGen/PprMach.hs)" title="wikilink"><code>GhcFile(compiler/nativeGen/PprMach.hs)</code></a><a href="BR" title="wikilink"><code>BR</code></a><br />
<code>Prettyprintsmachineinstructions(</code><code>)toassemblercode(currentlyreadablebyGNU's</code><code>),withsomesmallmodifications,especiallyforcomparingandaddingfloatingpointnumbersonx86architectures</code><a href="BR" title="wikilink"><code>BR</code></a><a href="BR" title="wikilink"><code>BR</code></a><br />
<code>*</code><a href="GhcFile(compiler/nativeGen/RegAllocInfo.hs)" title="wikilink"><code>GhcFile(compiler/nativeGen/RegAllocInfo.hs)</code></a><a href="BR" title="wikilink"><code>BR</code></a><br />
<code>definesthemainregisterinformationfunction,</code><code>,whichtakesasetofrealandvirtualregistersandreturnstheactualregistersusedbyaparticular</code><code>;registerallocationisinAT&amp;Tsyntaxorder(source,destination),inaninternalfunction,</code><code>;definesthe</code><code>datatype</code><a href="BR" title="wikilink"><code>BR</code></a><a href="BR" title="wikilink"><code>BR</code></a><br />
<code>*</code><a href="GhcFile(compiler/nativeGen/RegisterAlloc.hs)" title="wikilink"><code>GhcFile(compiler/nativeGen/RegisterAlloc.hs)</code></a><a href="BR" title="wikilink"><code>BR</code></a><br />
<code>oneofthemostcomplicatedmodulesintheNCG,</code><code>managestheallocationofregistersforeach</code><em><code>basic</code> <code>block</code></em><code>ofHaskell-abstractedassemblercode:managementinvolves</code><em><code>liveness</code></em><code>analysis,allocationordeletionoftemporaryregisters,</code><em><code>spilling</code></em><code>temporaryvaluestothe</code><em><code>spill</code> <code>stack</code></em><code>(memory)andmanyoptimisations.''See[wiki:Commentary/Compiler/CmmTypeTheCmmlanguage]forthedefinitionofa</code><em><code>basic</code> <code>block</code></em><code>(inHaskell,</code><em></em><code>).''</code></p>
<p>and one header file:</p>
<p><code>*</code><a href="GhcFile(compiler/nativeGen/NCG.h)" title="wikilink"><code>GhcFile(compiler/nativeGen/NCG.h)</code></a><a href="BR" title="wikilink"><code>BR</code></a><br />
<code>definesmacrosusedtoseparatearchitecture-specificcodeintheHaskellNCGfiles;sinceGHCcurrentlyonlygeneratesmachinecodeforthearchitectureonwhichitwascompiled(GHCisnotcurrentlyacross-compiler),theHaskellNCGfilesbecomeconsiderablysmallerafterpreprocessing;ideallyallarchitecture-specificcodewouldresideinseparatefilesandGHCwouldhavethemavailabletosupportcross-compilercapabilities.</code></p>
<p>The NCG has <strong>machine-independent</strong> and <strong>machine-dependent</strong> parts.</p>
<p>The <strong>machine-independent</strong> parts relate to generic operations, especially optimisations, on Cmm code. The main machine-independent parts begin with <em>Cmm blocks.</em> (A <em>Cmm block</em> is a compilation unit of Cmm code, a file. See [wiki:Commentary/Compiler/CmmType The Cmm language] for a discussion of what a <em>Cmm block</em> is but note that <em>Cmm</em> is a type synonym for .) A machine-specific (assembler) instruction is represented as a . The machine-independent NCG parts:</p>
<p><code>1.optimiseeachCmmblockbyreorderingitsbasicblocksfromtheoriginalorder(the</code><code>orderfromthe</code><code>)tominimisethenumberofbranchesbetweenbasicblocks,inotherwords,bymaximisingfallthroughofexecutionfromonebasicblocktothenext.</code><a href="BR" title="wikilink"><code>BR</code></a><a href="BR" title="wikilink"><code>BR</code></a><br />
<code>1.lazilyconverteachCmmblocktoabstractmachineinstructions(</code><code>)operatingonaninfinitenumberofregisters--sincetheNCGHaskellfilesonlycontaininstructionsforthehostcomputeronwhichGHCwascompiled,these</code><code>aremachine-specific;and,</code><a href="BR" title="wikilink"><code>BR</code></a><a href="BR" title="wikilink"><code>BR</code></a><br />
<code>1.lazilyallocaterealregistersforeachbasicblock,basedonthenumberofavailableregistersonthetarget(currently,onlythehost)machine;forexample,32integerand32floating-pointregistersonthePowerPCarchitecture.TheNCGdoesnotcurrentlyhavesupportforSIMDregisterssuchasthevectorregistersforAltivecoranyvariationofSSE.</code><a href="BR" title="wikilink"><code>BR</code></a><em><code>Note</code></em><code>:ifabasicblocksimultaneouslyrequiresmoreregistersthanareavailableonthetargetmachineandthetemporaryvariableneedstobeused(wouldsillbe</code><em><code>live</code></em><code>)afterthecurrentinstruction,itwillbemoved(</code><em><code>spilled</code></em><code>)intomemory.</code></p>
<p>The <strong>machine-dependent</strong> parts:</p>
<p><code>1.definetheabstract(Haskell)assembler</code><code>forthetarget(host)machineandconverteveryCmmblockintoit;</code><br />
<code>1.define,manageandallocatetherealregistersavailableonthetargetsystem;</code><br />
<code>1.pretty-printtheHaskell-assemblertoGNUAS(GAS)assemblercode</code></p>
<h2 id="overview-3">Overview</h2>
<p>The top-level code generator function is  The returned `SDoc` is for debugging, so is empty unless you specify `-ddump-stix`. The `Pretty.Doc` bit is the final assembly code. Translation involves three main phases, the first and third of which are target-independent.</p>
<h4 id="translation-into-the-stix-representation">Translation into the Stix representation</h4>
<p>Stix is a simple tree-like RTL-style language, in which you can mention:</p>
<p><code>*Aninfinitenumberoftemporary,virtualregisters.</code><br />
<code>*TheSTG&quot;magic&quot;registers(`MagicId`),suchastheheapandstackpointers.</code><br />
<code>*Literalsandlow-levelmachineops(`MachOp`).</code><br />
<code>*Simpleaddresscomputations.</code><br />
<code>*Readsandwritesof:memory,virtualregs,andvariousSTGregs.</code><br />
<code>*Labelsand`if...goto...`stylecontrol-flow.</code></p>
<p>Stix has two main associated types:</p>
<p><code>*`StixStmt`--treesexecutedfortheirsideeffects:assignments,controltransfers,andauxiliaryjunksuchassegmentchangesandliteraldata.</code><br />
<code>*`StixExpr`--treeswhichdenoteavalue.</code></p>
<p>Translation into Stix is almost completely target-independent. Needed dependencies are knowledge of word size and endianness, used when generating code to do deal with half-word fields in info tables. This could be abstracted out easily enough. Also, the Stix translation needs to know which `MagicId`s map to registers on the given target, and which are stored in offsets from `BaseReg`.</p>
<p>After initial Stix generation, the trees are cleaned up with constant-folding and a little copy-propagation (&quot;Stix inlining&quot;, as the code misleadingly calls it). We take the opportunity to translate `MagicId`s which are stored in memory on the given target, into suitable memory references. Those which are stored in registers are left alone. There is also a half-hearted attempt to lift literal strings to the top level in cases where nested strings have been observed to give incorrect code in the past.</p>
<p>Primitive machine-level operations will already be phrased in terms of `MachOp`s in the presented Abstract C, and these are passed through unchanged. We comment only that the `MachOp`s have been chosen so as to be easy to implement on all targets, and their meaning is intended to be unambiguous, and the same on all targets, regardless of word size or endianness.</p>
<p><strong>A note on `MagicId`s</strong>. Those which are assigned to registers on the current target are left unmodified. Those which are not are stored in memory as offsets from `BaseReg` (which is assumed to permanently have the value (`&amp;MainCapability.r`)), so the constant folder calculates the offsets and inserts suitable loads/stores. One complication is that not all archs have `BaseReg` itself in a register, so for those (sparc), we instead generate the address as an offset from the static symbol `MainCapability`, since the register table lives in there.</p>
<p>Finally, `BaseReg` does occasionally itself get mentioned in Stix expression trees, and in this case what is denoted is precisely (`&amp;MainCapability.r`), not, as in all other cases, the value of memory at some offset from the start of the register table. Since what it denotes is an r-value and not an l-value, assigning `BaseReg` is meaningless, so the machinery checks to ensure this never happens. All these details are taken into account by the constant folder.</p>
<h4 id="instruction-selection-1">Instruction selection</h4>
<p>This is the only majorly target-specific phase. It turns Stix statements and expressions into sequences of `Instr`, a data type which is different for each architecture. Instr, unsurprisingly, has various supporting types, such as `Reg`, `Operand`, `Imm`, etc. The generated instructions may refer to specific machine registers, or to arbitrary virtual registers, either those created within the instruction selector, or those mentioned in the Stix passed to it.</p>
<p>The instruction selectors live in `MachCode.lhs`. The core functions, for each target, are:</p>
<p></p>
<p>The insn selectors use the &quot;maximal munch&quot; algorithm. The bizarrely-misnamed `getRegister` translates expressions. A simplified version of its type is:  That is: it (monadically) turns a StixExpr into a sequence of instructions, and a register, with the meaning that after executing the (possibly empty) sequence of instructions, the (possibly virtual) register will hold the resulting value. The real situation is complicated by the presence of fixed registers, and is detailed below.</p>
<p>Maximal munch is a greedy algorithm and is known not to give globally optimal code sequences, but it is good enough, and fast and simple. Early incarnations of the NCG used something more sophisticated, but that is long gone now.</p>
<p>Similarly, `getAmode` translates a value, intended to denote an address, into a sequence of insns leading up to a (processor-specific) addressing mode. This stuff could be done using the general `getRegister` selector, but would necessarily generate poorer code, because the calculated address would be forced into a register, which might be unnecessary if it could partially or wholly be calculated using an addressing mode.</p>
<p>Finally, `assignMem_IntCode` and `assignReg_IntCode` create instruction sequences to calculate a value and store it in the given register, or at the given address. Because these guys translate a statement, not a value, they just return a sequence of insns and no associated register. Floating-point and 64-bit integer assignments have analogous selectors.</p>
<p>Apart from the complexities of fixed vs floating registers, discussed below, the instruction selector is as simple as it can be. It looks long and scary but detailed examination reveals it to be fairly straightforward.</p>
<h4 id="register-allocation-1">Register allocation</h4>
<p>The register allocator, `AsmRegAlloc.lhs` takes sequences of Instrs which mention a mixture of real and virtual registers, and returns a modified sequence referring only to real ones. It is gloriously and entirely target-independent. Well, not exactly true. Instead it regards `Instr` (instructions) and `Reg` (virtual and real registers) as abstract types, to which it has the following interface:  `insnFuture` is used to (re)construct the graph of all possible control transfers between the insns to be allocated. `regUsage` returns the sets of registers read and written by an instruction. And `patchRegs` is used to apply the allocator's final decision on virtual-to-real reg mapping to an instruction.</p>
<p>Clearly these 3 fns have to be written anew for each architecture. They are defined in `RegAllocInfo.lhs`. Think twice, no, thrice, before modifying them: making false claims about insn behaviour will lead to hard-to-find register allocation errors.</p>
<p>`AsmRegAlloc.lhs` contains detailed comments about how the allocator works. Here is a summary. The head honcho  takes a list of instructions and a list of real registers available for allocation, and maps as many of the virtual regs in the input into real ones as it can. The returned `Bool` indicates whether or not it was successful. If so, that's the end of it. If not, the caller of `allocUsingTheseRegs` will attempt spilling. More of that later. What `allocUsingTheseRegs` does is:</p>
<p><code>*Implicitlynumbereachinstructionbyitspositionintheinputlist.</code><br />
<code>*Using`insnFuture`,createthesetofallflowedges--possiblecontroltransfers--withinthissetofinsns.</code><br />
<code>*Using`regUsage`anditeratingaroundtheflowgraphfromthepreviousstep,calculate,foreachvirtualregister,thesetofflowedgesonwhichitislive.</code><br />
<code>*Makeareal-registercommittmentmap,whichgivesthesetofedgesforwhicheachrealregisteriscommitted(inuse).Thesesetsareinitiallyempty.Foreachvirtualregister,attempttofindarealregisterwhosecurrentcommittmentdoesnotintersectthatofthevirtualregister--ie,isuncommittedonalledgesthatthevirtualregislive.Ifsuccessful,thismeansthevregcanbeassignedtotherealreg,soaddthevreg'ssettotherealreg'scommittment.</code><br />
<code>*Ifallthevregswereassignedtoarealreg,use`patchInstr`toapplythemappingtotheinsnsthemselves.</code></p>
<h3 id="spilling">Spilling</h3>
<p>If `allocUsingTheseRegs` fails, a baroque mechanism comes into play. We now know that much simpler schemes are available to do the same thing and give better results. Anyways:</p>
<p>The logic above `allocUsingTheseRegs`, in `doGeneralAlloc` and `runRegAllocate`, observe that allocation has failed with some set R of real registers. So they apply `runRegAllocate` a second time to the code, but remove (typically) two registers from R before doing so. This naturally fails too, but returns a partially-allocated sequence. `doGeneralAlloc` then inserts spill code into the sequence, and finally re-runs `allocUsingTheseRegs`, but supplying the original, unadulterated R. This is guaranteed to succeed since the two registers previously removed from R are sufficient to allocate all the spill/restore instructions added.</p>
<p>Because x86 is very short of registers, and in the worst case needs three removed from R, a softly-softly approach is used. `doGeneralAlloc` first tries with zero regs removed from R, then if that fails one, then two, etc. This means `allocUsingTheseRegs` may get run several times before a successful arrangement is arrived at. `findReservedRegs` cooks up the sets of spill registers to try with.</p>
<p>The resulting machinery is complicated and the generated spill code is appalling. The saving grace is that spills are very rare so it doesn't matter much. I did not invent this -- I inherited it.</p>
<h3 id="dealing-with-common-cases-fast">Dealing with common cases fast</h3>
<p>The entire reg-alloc mechanism described so far is general and correct, but expensive overkill for many simple code blocks. So to begin with we use `doSimpleAlloc`, which attempts to do something simple. It exploits the observation that if the total number of virtual registers does not exceed the number of real ones available, we can simply dole out a new realreg each time we see mention of a new vreg, with no regard for control flow. `doSimpleAlloc` therefore attempts this in a single pass over the code. It gives up if it runs out of real regs or sees any condition which renders the above observation invalid (fixed reg uses, for example).</p>
<p>This clever hack handles the majority of code blocks quickly. It was copied from the previous reg-allocator (the Mattson/Partain/Marlow/Gill one).</p>
<h2 id="complications-observations-and-possible-improvements">Complications, observations, and possible improvements</h2>
<h3 id="real-vs-virtual-registers-in-the-instruction-selectors">Real vs virtual registers in the instruction selectors</h3>
<p>The instruction selectors for expression trees, namely `getRegister`, are complicated by the fact that some expressions can only be computed into a specific register, whereas the majority can be computed into any register. We take x86 as an example, but the problem applies to all archs.</p>
<p>Terminology: `rreg` means real register, a real machine register. `vreg` means one of an infinite set of virtual registers. The type `Reg` is the sum of `rreg` and `vreg`. The instruction selector generates sequences with unconstrained use of vregs, leaving the register allocator to map them all into rregs.</p>
<p>Now, where was I ? Oh yes. We return to the type of `getRegister`, which despite its name, selects instructions to compute the value of an expression tree. </p>
<p>At first this looks eminently reasonable (apart from the stupid name). `getRegister`, and nobody else, knows whether or not a given expression has to be computed into a fixed rreg or can be computed into any rreg or vreg. In the first case, it returns `Fixed` and indicates which rreg the result is in. In the second case it defers committing to any specific target register by returning a function from `Reg` to `InstrBlock`, and the caller can specify the target reg as it sees fit.</p>
<p>Unfortunately, that forces `getRegister`'s callers (usually itself) to use a clumsy and confusing idiom in the common case where they do not care what register the result winds up in. The reason is that although a value might be computed into a fixed rreg, we are forbidden (on pain of segmentation fault :) from subsequently modifying the fixed reg. This and other rules are record in &quot;Rules of the game&quot; inside `MachCode.lhs`.</p>
<p>Why can't fixed registers be modified post-hoc? Consider a simple expression like `Hp+1`. Since the heap pointer `Hp` is definitely in a fixed register, call it R, `getRegister` on subterm `Hp` will simply return Fixed with an empty sequence and R. But we can't just emit an increment instruction for R, because that trashes `Hp`; instead we first have to copy it into a fresh vreg and increment that.</p>
<p>With all that in mind, consider now writing a `getRegister` clause for terms of the form `(1 + E)`. Contrived, yes, but illustrates the matter. First we do `getRegister` on `E`. Now we are forced to examine what comes back.  This seems unreasonably cumbersome, yet the instruction selector is full of such idioms. A good example of the complexities induced by this scheme is shown by `trivialCode` for x86 in `MachCode.lhs`. This deals with general integer dyadic operations on x86 and has numerous cases. It was difficult to get right.</p>
<p>An alternative suggestion is to simplify the type of `getRegister` to this:  and then we could safely write  which is about as straightforward as you could hope for. Unfortunately, it requires `getRegister` to insert moves of values which naturally compute into an rreg, into a vreg. Consider:  On x86 the ccall result is returned in rreg `%eax`. The resulting sequence, prior to register allocation, would be:  If, as is likely, `%eax` is not held live beyond this point for any other purpose, the move into a fresh register is pointless; we'd have been better off leaving the value in `%eax` as long as possible.</p>
<p>The simplified `getRegister` story is attractive. It would clean up the instruction selectors significantly and make it simpler to write new ones. The only drawback is that it generates redundant register moves. I suggest that eliminating these should be the job of the register allocator. Indeed:</p>
<p><code>*Therehasbeensomeworkonthisalready(&quot;Iteratedregistercoalescing&quot;?),sothisisn'tanewidea.</code></p>
<p><code>*Youcouldarguethattheexistingschemeinappropriatelyblurstheboundarybetweentheinstructionselectorandtheregisterallocator.Theinstructionselectorshould..well..justselectinstructions,withouthavingtofutzaroundworryingaboutwhatkindofregisterssubtreesgetgeneratedinto.Registerallocationshouldbe</code><em><code>entirely</code></em><code>thedomainoftheregisterallocator,withtheprovisothatitshouldendeavourtoallocateregisterssoastominimisethenumberofnon-redundantreg-regmovesinthefinaloutput.</code></p>
<h2 id="selecting-insns-for-64-bit-valuesloadsstores-on-32-bit-platforms">Selecting insns for 64-bit values/loads/stores on 32-bit platforms</h2>
<p>Note that this stuff doesn't apply on 64-bit archs, since the `getRegister` mechanism applies there. The relevant functions are: </p>
<p>`iselExpr64` is the 64-bit, plausibly-named analogue of `getRegister`, and `ChildCode64` is the analogue of `Register`. The aim here was to generate working 64 bit code as simply as possible. To this end, I used the simplified `getRegister` scheme described above, in which iselExpr64generates its results into two vregs which can always safely be modified afterwards.</p>
<p>Virtual registers are, unsurprisingly, distinguished by their `Unique`s. There is a small difficulty in how to know what the vreg for the upper 32 bits of a value is, given the vreg for the lower 32 bits. The simple solution adopted is to say that any low-32 vreg may also have a hi-32 counterpart which shares the same unique, but is otherwise regarded as a separate entity. `getHiVRegFromLo` gets one from the other.  Apart from that, 64-bit code generation is really simple. The sparc and x86 versions are almost copy-n-pastes of each other, with minor adjustments for endianness. The generated code isn't wonderful but is certainly acceptable, and it works.</p>
<h2 id="shortcomings-and-inefficiencies-in-the-register-allocator">Shortcomings and inefficiencies in the register allocator</h2>
<h3 id="redundant-reconstruction-of-the-control-flow-graph">Redundant reconstruction of the control flow graph</h3>
<p>The allocator goes to considerable computational expense to construct all the flow edges in the group of instructions it's allocating for, by using the `insnFuture` function in the `Instr` pseudo-abstract type.</p>
<p>This is really silly, because all that information is present at the abstract C stage, but is thrown away in the translation to Stix. So a good thing to do is to modify that translation to produce a directed graph of Stix straight-line code blocks, and to preserve that structure through the insn selector, so the allocator can see it.</p>
<p>This would eliminate the fragile, hacky, arch-specific `insnFuture` mechanism, and probably make the whole compiler run measurably faster. Register allocation is a fair chunk of the time of non-optimising compilation (10% or more), and reconstructing the flow graph is an expensive part of reg-alloc. It would probably accelerate the vreg liveness computation too.</p>
<h3 id="really-ridiculous-method-for-doing-spilling">Really ridiculous method for doing spilling</h3>
<p>This is a more ambitious suggestion, but ... reg-alloc should be reimplemented, using the scheme described in &quot;Quality and speed in linear-scan register allocation.&quot; (Traub?) For straight-line code blocks, this gives an elegant one-pass algorithm for assigning registers and creating the minimal necessary spill code, without the need for reserving spill registers ahead of time.</p>
<p>I tried it in Rigr, replacing the previous spiller which used the current GHC scheme described above, and it cut the number of spill loads and stores by a factor of eight. Not to mention being simpler, easier to understand and very fast.</p>
<p>The Traub paper also describes how to extend their method to multiple basic blocks, which will be needed for GHC. It comes down to reconciling multiple vreg-to-rreg mappings at points where control flow merges.</p>
<h3 id="redundant-move-support-for-revised-instruction-selector-suggestion">Redundant-move support for revised instruction selector suggestion</h3>
<p>As mentioned above, simplifying the instruction selector will require the register allocator to try and allocate source and destination vregs to the same rreg in reg-reg moves, so as to make as many as possible go away. Without that, the revised insn selector would generate worse code than at present. I know this stuff has been done but know nothing about it. The Linear-scan reg-alloc paper mentioned above does indeed mention a bit about it in the context of single basic blocks, but I don't know if that's sufficient.</p>
<h2 id="x86-arcana-that-you-should-know-about">x86 arcana that you should know about</h2>
<p>The main difficulty with x86 is that many instructions have fixed register constraints, which can occasionally make reg-alloc fail completely. And the FPU doesn't have the flat register model which the reg-alloc abstraction (implicitly) assumes.</p>
<p>Our strategy is: do a good job for the common small subset, that is integer loads, stores, address calculations, basic ALU ops (+, -, and, or, xor), and jumps. That covers the vast majority of executed insns. And indeed we do do a good job, with a loss of less than 2% compared with gcc.</p>
<p>Initially we tried to handle integer instructions with awkward register constraints (mul, div, shifts by non-constant amounts) via various jigglings of the spiller et al. This never worked robustly, and putting platform-specific tweaks in the generic infrastructure is a big No-No. (Not quite true; shifts by a non-constant amount are still done by a giant kludge, and should be moved into this new framework.)</p>
<p>Fortunately, all such insns are rare. So the current scheme is to pretend that they don't have any such constraints. This fiction is carried all the way through the register allocator. When the insn finally comes to be printed, we emit a sequence which copies the operands through memory (`%esp`-relative), satisfying the constraints of the real instruction. This localises the gruesomeness to just one place. Here, for example, is the code generated for integer divison of `%esi` by `%ecx`:  This is not quite as appalling as it seems, if you consider that the division itself typically takes 16+ cycles, whereas the rest of the insns probably go through in about 1 cycle each.</p>
<p>This trick is taken to extremes for FP operations.</p>
<p>All notions of the x86 FP stack and its insns have been removed. Instead, we pretend, to the instruction selector and register allocator, that x86 has six floating point registers, `%fake0` .. `%fake5`, which can be used in the usual flat manner. We further claim that x86 has floating point instructions very similar to SPARC and Alpha, that is, a simple 3-operand register-register arrangement. Code generation and register allocation proceed on this basis.</p>
<p>When we come to print out the final assembly, our convenient fiction is converted to dismal reality. Each fake instruction is independently converted to a series of real x86 instructions. `%fake0` .. `%fake5` are mapped to `%st(0)` .. `%st(5)`. To do reg-reg arithmetic operations, the two operands are pushed onto the top of the FP stack, the operation done, and the result copied back into the relevant register. When one of the operands is also the destination, we emit a slightly less scummy translation. There are only six `%fake` registers because 2 are needed for the translation, and x86 has 8 in total.</p>
<p>The translation is inefficient but is simple and it works. A cleverer translation would handle a sequence of insns, simulating the FP stack contents, would not impose a fixed mapping from `%fake` to `%st` regs, and hopefully could avoid most of the redundant reg-reg moves of the current translation.</p>
<p>There are, however, two unforeseen bad side effects:</p>
<p><code>*Thisdoesn'tworkproperly,becauseitdoesn'tobservethenormalconventionsforx86FPcodegeneration.Itturnsoutthateachofthe8elementsinthex86FPregisterstackhasatagbitwhichindicateswhetherornotthatregisterisnotionallyinuseornot.IfyoudoaFPUoperationwhichhappenstoreadatagged-as-emptyregister,yougetanx87FPU(stackinvalid)exception,whichisnormallyhandledbytheFPUwithoutpassingittotheOS:theprogramkeepsgoing,buttheresultingFPvaluesaregarbage.TheOScanaskfortheFPUtopassitFPstack-invalidexceptions,butitusuallydoesn't.</code></p>
<p><code>Anyways:insideNCGcreatedx86FPcodethisallworksfine.However,theNCG'sfictionofaflatregistersetdoesnotoperatethex87registerstackintherequiredstack-likeway.Whencontrolreturnstoagcc-generatedworld,thestacktagbitssooncausestackexceptions,andthusgarbageresults.</code></p>
<p><code>TheonlyfixIcouldthinkof--anditishorrible--istoclearallthetagbitsjustbeforethenextSTG-levelentry,inchunksofcodewhichuseFPinsns.`i386_insert_ffrees`insertstherelevant`ffree`insnsintosuchcodeblocks.Itdependscriticallyon`is_G_instr`todetectsuchblocks.</code></p>
<p><code>*It'sverydifficulttoreadthegeneratedassemblyandreasonaboutitwhendebugging,becausethere'ssomuchclutter.Weprintthefakeinsnsascommentsintheoutput,andthathelpsabit.</code></p>
<h2 id="generating-code-for-ccalls">Generating code for ccalls</h2>
<p>For reasons I don't really understand, the instruction selectors for generating calls to C (genCCall) have proven surprisingly difficult to get right, and soaked up a lot of debugging time. As a result, I have once again opted for schemes which are simple and not too difficult to argue as correct, even if they don't generate excellent code.</p>
<p>The sparc ccall generator in particular forces all arguments into temporary virtual registers before moving them to the final out-registers (`%o0` .. `%o5`). This creates some unnecessary reg-reg moves. The reason is explained in a comment in the code.</p>
<h2 id="duplicate-implementation-for-many-stg-macros">Duplicate implementation for many STG macros</h2>
<p>This has been discussed at length already. It has caused a couple of nasty bugs due to subtle untracked divergence in the macro translations. The macro-expander really should be pushed up into the Abstract C phase, so the problem can't happen.</p>
<p>Doing so would have the added benefit that the NCG could be used to compile more &quot;ways&quot; -- well, at least the 'p' profiling way.</p>
<h2 id="how-to-debug-the-ncg-without-losing-your-sanityhaircool">How to debug the NCG without losing your sanity/hair/cool</h2>
<p>Last, but definitely not least ...</p>
<p>The usual syndrome is that some program, when compiled via C, works, but not when compiled via the NCG. Usually the problem is fairly simple to fix, once you find the specific code block which has been mistranslated. But the latter can be nearly impossible, since most modules generate at least hundreds and often thousands of them.</p>
<p>My solution: cheat.</p>
<p>Because the via-C and native routes diverge only late in the day, it is not difficult to construct a 1-1 correspondence between basic blocks on the two routes. So, if the program works via C but not on the NCG, do the following:</p>
<p><code>*Recompile`AsmCodeGen.lhs`intheafflictedcompilerwith`-DDEBUG_NCG`,sothatitinserts`___ncg_debug_markers`intotheassemblyitemits.</code><br />
<code>*Usingabinarysearchonmodules,findthemodulewhichiscausingtheproblem.</code><br />
<code>*Compilethatmoduletoassemblycode,withidenticalflags,twice,onceviaCandonceviaNCG.Calltheoutputs`ModuleName.s-gcc`and`ModuleName.s-nat`.Checkthatthelatterdoesindeedhave`___ncg_debug_markers`init;otherwisethenextstepsfail.</code><br />
<code>*Build(withaworkingcompiler)theprogram`utils/debugNCG/diff_gcc_nat`.</code><br />
<code>*Run:`diff_gcc_natModuleName.s`.Thiswillconstructthe1-1correspondence,andemitsonstdoutacppableassemblyoutput.Placethisinafile--Ialwayscallitsynth.S.Note,thecapitalSisimportant;otherwiseitwon'tgetcpp'd.Youcanfeedthisfiledirectlytoghcanditwillautomaticallygetcpp'd;youdon'thavetodosoyourself.</code><br />
<code>*Bymessingwiththe`#define`satthetopof`synth.S`,doabinarysearchtofindtheincorrectblock.Keepacarefulrecordofwhereyouareinthesearch;itiseasytogetconfused.Rememberalsothatmultipleblocksmaybewrong,whichalsoconfusesmatters.Finally,Iusuallystartoffbyre-checkingthatIcanbuildtheexecutablewithallthe`#define`ssetto0andthenallto1.Thisensuresyouwon'tgethalfwaythroughthesearchandthengetstuckduetosomesnafuwithgcc-specificliterals.UsuallyIset`UNMATCHED_GCC`to1allthetime,andthisbitshouldcontainonlyliteraldata.`UNMATCHED_NAT`shouldbeempty.</code></p>
<p>`diff_gcc_nat` was known to work correctly last time I used it, in December 01, for both x86 and sparc. If it doesn't work, due to changes in assembly syntax, or whatever, make it work. The investment is well worth it. Searching for the incorrect block(s) any other way is a total time waster.</p>
<h2 id="historical-page-1">Historical page</h2>
<p>This page describes state of the new code generator sometime back in 2008. It is completely outdated and is here only for historical reasons. See [wiki:Commentary/Compiler/CodeGen Code Generator] page for a description of current code generator.</p>
<h1 id="overview-of-modules-in-the-new-code-generator">Overview of modules in the new code generator</h1>
<p>This page gives an overview of the new code generator, including discussion of:</p>
<p><code>*the[wiki:Commentary/Compiler/NewCodeGenModules#ThenewCmmdatatypenewCmmtype]</code><br />
<code>*the[wiki:Commentary/Compiler/NewCodeGenModules#Modulestructureofthenewcodegeneratormodulestructureofthenewcodegenerator]</code></p>
<p>See also [wiki:Commentary/Compiler/NewCodeGenPipeline the description of the new code generation pipeline].</p>
<h2 id="the-new-cmm-data-type">The new Cmm data type</h2>
<p>There is a new Cmm data type:</p>
<p><code>*</code><a href="GhcFile(compiler/cmm/ZipCfg.hs)" title="wikilink"><code>GhcFile(compiler/cmm/ZipCfg.hs)</code></a><code>containsagenericzipper-basedcontrol-flowgraphdatatype.Itisgenericinthesensethatit'spolymorphicinthetypeof</code><strong><code>middle</code> <code>nodes</code></strong><code>and</code><strong><code>last</code> <code>nodes</code></strong><code>ofablock.(Middlenodesdon'tdocontroltransfers;lastnodesonlydocontroltransfers.)Thereareextensivenotesatthestartofthemodule.</code><a href="BR" title="wikilink"><code>BR</code></a><a href="BR" title="wikilink"><code>BR</code></a><br />
<code>Thekeytypesitdefinesare:</code><br />
<code>*Blockidentifiers:`BlockId`,`BlockEnv`,`BlockSet`</code><br />
<code>*Control-flowblocks:`Block`</code><br />
<code>*Control-flowgraphs:`Graph`</code><a href="BR" title="wikilink"><code>BR</code></a><a href="BR" title="wikilink"><code>BR</code></a><br />
<code>*</code><strong><code>`ZipDataFlow`</code></strong><code>containsagenericframeworkforsolvingdataflowproblemsover`ZipCfg`.Itallowsyoutodefineanewoptimizationsimplybydefiningalatticeofdataflowfacts(akintoaspecializedlogic)andthenwritingthedataflow-transferfunctionsfoundincompilertextbooks.Handingthesefunctionstothedataflowengineproducesanewoptimizationthatisnotonlyusefulonitsown,butthatcaneasilybecomposedwithotheroptimizationstocreateanintegrated&quot;superoptimization&quot;thatisstrictlymorepowerfulthananysequenceofindividualoptimizations,nomatterhowmanytimestheyarere-run.Thedataflowengineisbasedon</code><a href="http://citeseer.ist.psu.edu/old/lerner01composing.html"><code>(Lerner,</code> <code>Grove,</code> <code>and</code> <code>Chambers</code> <code>2002)</code></a><code>;youcanfindafunctionalimplementationofthedataflowenginepresentedin</code><a href="http://www.cs.tufts.edu/~nr/pubs/zipcfg-abstract.html"><code>(Ramsey</code> <code>and</code> <code>Dias</code> <code>2005)</code></a><code>.</code><a href="BR" title="wikilink"><code>BR</code></a><a href="BR" title="wikilink"><code>BR</code></a><br />
<code>*</code><strong><a href="GhcFile(compiler/cmm/ZipCfgCmmRep.hs)" title="wikilink"><code>GhcFile(compiler/cmm/ZipCfgCmmRep.hs)</code></a></strong><code>instantiates`ZipCfg`forCmm,bydefiningtypes`Middle`and`Last`andusingthesetoinstantiatethepolymorphicfieldsof`ZipCfg`.Italsodefinesabunchofsmartconstructor(`mkJump`,`mkAssign`,`mkCmmIfThenElse`etc)whichmakeiteasytobuild`CmmGraph`.</code><a href="BR" title="wikilink"><code>BR</code></a><a href="BR" title="wikilink"><code>BR</code></a><br />
<code>*</code><strong><code>`CmmExpr`</code></strong><code>containsthedatatypesforCmmexpressions,registers,andthelike.Hereisafullerdescriptionofthesetypesisat[wiki:Commentary/Compiler/BackEndTypes].Itdoesnotdependonthedataflowframeworkatall.</code></p>
<h2 id="module-structure-of-the-new-code-generator">Module structure of the new code generator</h2>
<p>The new code generator has a fair number of modules, which can be split into three groups:</p>
<p><code>*basicdatatypesandinfrastructure</code><br />
<code>*analysesandtransformations</code><br />
<code>*linkingthepipeline</code></p>
<p>All the modules mentioned are in the `cmm/` directory, unless otherwise indicated.</p>
<h3 id="basic-datatypes-and-infrastructure">Basic datatypes and infrastructure</h3>
<p>Ubiquitous types:</p>
<p><code>*`CLabel`(`CLabel`):Allsortsofgooformakingandmanipulatinglabels.</code></p>
<p><code>*`BlockId`(`BlockId`,`BlockEnv`,`BlockSet`):</code><br />
<code>Thetypeofabasic-blockid,alongwithsetsandfinitemaps.</code></p>
<p><code>*`CmmExpr`(`CmmType`,`LocalReg`,`GlobalReg`,`Area`,`CmmExpr`):</code><br />
<code>Lotsoftypedefinitions:forCmmtypes(bitwidth,GCptr,float,etc),</code><br />
<code>registers,stackareas,andCmmexpressions.</code></p>
<p><code>*`Cmm`(`GenCmm`,`CmmInfo`,`CmmInfoTable`):</code><br />
<code>Moretypedefinitions:theparameterizedtop-levelCmmtype(`GenCmm`),</code><br />
<code>alongwiththetypedefinitionsforinfotables.</code></p>
<p>Control-flow graphs:</p>
<p><code>*`ZipCfg`(`Graph`,`LGraph`,`Block`):</code><br />
<code>Describesazipper-likerepresentationfortruebasic-block</code><br />
<code>control-flowgraphs.Ablockhasasingleentrypoint,</code><br />
<code>whichisaalwaysalabel,followedbyzeroormode'middle</code><br />
<code>nodes',eachofwhichrepresentsanuninterruptible</code><br />
<code>single-entry,single-exitcomputation,thenfinallya'last</code><br />
<code>node',whichmayhavezeroormoresuccessors.</code><br />
<code>`ZipCFG`ispolymorphicinthetypeofmiddleandlastnodes.</code><br />
<code>*`ZipCfgCmmRep`(`Middle`,`Last`,`CmmGraph`)</code><br />
<code>Typestoinstantiate`ZipCfg`forC--:middleandlastnodes,</code><br />
<code>andabunchofabbreviationsoftypesin`ZipCfg`and`Cmm`.</code></p>
<p><code>*`MkZipCfg`(`AGraph`,`mkLabel`,`mkMiddle`,`mkBranch`)</code><br />
<code>Smartconstructorsforcontrol-flowgraphs(andtheconstructorshave</code><br />
<code>non-monadictypes).</code><br />
<code>Like`ZipCfg`,`MkZipCfg`ispolymorphicinthetypesofmiddleandlastnodes.</code><br />
<code>*`MkZipCfgCmm`(`mkNop`,`mkAssign`,`mkStore`,`mkCall`,...)</code><br />
<code>Smartconstructorsforcreatingmiddleandlastnodesin</code><br />
<code>control-flowgraphs(andtheconstructorshavenon-monadictypes).</code></p>
<p>Calling conventions:</p>
<p><code>*`CmmInfo`(`cmmToRawCmm`,`mkBareInfoTable`):</code><br />
<code>ConvertsCmmcodeto&quot;raw&quot;Cmm.Whatthismeansis:converta`CmmInfo`datastructuredescribingtheinfotableforeach`CmmProc`toa`[CmmStatic]`.</code><br />
<code>`mkBareInfoTable`istheworkhorsethatproducesthe`[CmmStatic]`.Itisalsousedtoproducetheinfotablerequiredforsafeforeigncalls(amiddlenode).</code><br />
<code>*`CmmCallConv`(`ArgumentFormat`,`assignArgumentsPos`):</code><br />
<code>ImplementsCmmcallingconventions:givenargumentsandacallingconvention,</code><br />
<code>thismoduledecideswheretoputthearguments.</code><br />
<code>(JD:Crufty.Lotsofoldcodeinhere,needscleanup.)</code></p>
<p>Dataflow analysis:</p>
<p><code>*`CmmTx`(`Tx`,`TxRes`):</code><br />
<code>Asimplemonadfortrackingwhenatransformationhas</code><br />
<code>occurred(somethinghaschanged).</code><br />
<code>Usedbythedataflowanalysistokeeptrackofwhenthegraphisrewritten.</code></p>
<p><code>*`OptimizationFuel`(`OptimizationFuel`,`FuelMonad`,`maybeRewriteWithFuel`)</code><br />
<code>Wecanuseameasureof&quot;fuel&quot;tolimitthenumberofrewritesperformed</code><br />
<code>byatransformation.Thismoduledefinesamonadfortracking(andlimiting)</code><br />
<code>fueluse.</code><br />
<code>(JD:Largelyuntested.)</code></p>
<p><code>*`DFMonad`(`DataflowLattice`,`DataflowAnalysis`,`runDFM`):</code><br />
<code>Definesthetypeofadataflowlatticeandananalysis.</code><br />
<code>Definesthemonadusedbythedataflowframework.</code><br />
<code>Themonadkeepstrackofdataflowfacts,alongwithfuel,</code><br />
<code>anditcanprovideuniqueid's.</code><br />
<code>Allinsupportofthedataflowmodule.</code></p>
<p><code>*`ZipDataflow`(`ForwardTransfers`,`BackwardTransfers`,`ForwardRewrites`,`BackwardRewrites`,</code><br />
<code>`zdfSolveFrom`,`zdfRewriteFrom`,etc)</code><br />
<code>ThismoduleimplementstheLerner/Grove/Chambersdataflowanalysisframeword.</code><br />
<code>Giventhedefinitionsofalatticeanddataflowtransfer/rewritefunctions,</code><br />
<code>thismoduleprovidesalltheworkofrunningthedataflowanalysisandtransformation.</code><br />
<code>Anumberofthephasesofthebackendrelyonthiscode,</code><br />
<code>andhopefullymoreoptimizationswilltargetitinthefuture.</code></p>
<p>And a few basic utilities:</p>
<p><code>*`CmmZipUtil`:(JD:Unused,Ibelieve,butprobablyshouldbeusedinafewplaces.)</code><br />
<code>Afewutilityfunctionsformanipulatingazipcfg.</code><br />
<code>*`PprC`:PrettyprintingtogenerateCcode.</code><br />
<code>*`PprCmm`:PrettyprintingtheC--code.</code><br />
<code>*`PprCmmZ`:(JD:Unused,Ibelieve.)</code><br />
<code>Prettyprintingfunctionsrelatedto`ZipCfg`and`ZipCfgCmm`.</code></p>
<h3 id="analyses-and-transformations">Analyses and transformations</h3>
<p><code>*`CmmLint`(`cmmLint`,`cmmLintTop`):</code><br />
<code>SomesanitycheckingontheoldCmmgraphs.</code><br />
<code>Notsurehoweffectivethisis.</code><br />
<code>*`CmmLiveZ`(`CmmLive`,`livelattice`,`cmmLivenessZ`):</code><br />
<code>Livenessanalysisforregisters(usesdataflowframework).</code><br />
<code>*`CmmProcPointZ`(`ProcPointSet`,`callProcPoints`,`minimalProcPointSet`,</code><br />
<code>`procPointAnalysis`,`splitAtProcPoints`)</code><br />
<code>Aprocpointisablockinacontrol-flowgraphthatmustbethe</code><br />
<code>entrypointofanewprocedurewhenwegenerateCcode.</code><br />
<code>Forexample,successorsofcallsandjoinpointsthatfollowcalls</code><br />
<code>areprocpoints.</code><br />
<code>Thismoduleprovidestheanalysestofindprocpoints,aswellas</code><br />
<code>thetransformationtosplittheprocedureintopieces.</code><br />
<code>Theprocpointanalysisdoesn'tusethedataflowframework,</code><br />
<code>butitreallyshould-dominatorsarethewayforward.</code><br />
<code>*`CmmSpillReload`(`DualLive`,`dualLiveLattice`,`dualLiveness`,</code><br />
<code>`dualLivenessWithInsertion`,`insertLateReloads`,</code><br />
<code>`removeDeadAssignmentsAndReloads`):</code><br />
<code>Insertsspillsandreloadstoestablishtheinvariantthat</code><br />
<code>atasafecall,therearenolivevariablesinregisters.</code><br />
<code>*`CmmCommonBlockElimZ`(`elimCommonBlocks`):</code><br />
<code>FindblocksintheCFGthatareidentical;mergethem.</code><br />
<code>*`CmmContFlowOpt`(`branchChainElimZ`,`removeUnreachableBlocksZ`,</code><br />
<code>`runCmmOpts`):</code><br />
<code>Branch-chaineliminationandeliminationofunreachablecode.</code><br />
<code>*`CmmStackLayout`(`SlotEnv`,`liveSlotAnal`,`manifestSP`,`stubSlotsOnDeath`):</code><br />
<code>Thelive-slotanalysisdiscoverswhichstackslotsarelive</code><br />
<code>ateachbasicblock.</code><br />
<code>Weusetheresultsfortwopurposes:</code><br />
<code>stacklayout(manifestSP)andinfotables(in!CmmBuildInfoTables).</code><br />
<code>Thefunction`stubSlotsOnDeath'isusedasadebuggingpass:</code><br />
<code>itstubseachstackslotwhenitdies,hopefullycausingbad</code><br />
<code>programstofailfaster.</code><br />
<code>*`CmmBuildInfoTables`(`CAFEnv`,`cafAnal`,`lowerSafeForeignCalls`,</code><br />
<code>`setInfoTableSRT`,`setInfoTableStackMap`):</code><br />
<code>Thismoduleisresponsibleforbuildinginfotables.</code><br />
<code>Specifically,itbuildsthemapsoflivevariables(stackmaps)</code><br />
<code>andSRTs.</code><br />
<code>Italsohascodetolowersafeforeigncallsintoasequence</code><br />
<code>thatmakesthemsafe(butsuspendingandresumingthreadsverycarefully).</code><br />
<code>(JD:Thelatterfunctionprobablyshouldn'tbehere.)</code></p>
<h3 id="linking-the-pipeline">Linking the pipeline</h3>
<p><code>*`CmmCvt`:Convertsbetween`Cmm`and`ZipCfgCmm`representations.</code><br />
<code>(JD:TheZip-&gt;Cmmpathdefinitelyworks;haven'ttriedthe</code><br />
<code>otherinalongtime--there'snoreasontouseitwith</code><br />
<code>thenewStg-&gt;Cmmpath).</code><br />
<code>*`CmmCPSZ`:Linksthephasesofthebackendinsequence,alongwith</code><br />
<code>somepossibledebuggingoutput.</code></p>
<h3 id="dead-code">Dead code</h3>
<p><code>*`CmmCPSGen`,`CmmCPS`(MichaelAdams),`CmmBrokenBlock`,`CmmLive`,`CmmPprCmmZ`,`StackColor`,`StackPlacements`</code></p>
<h2 id="historical-page-2">Historical page</h2>
<p>This page stores historical information about Cmm Pipeline in the new code generator. This description has been updated and is maintained on the [wiki:Commentary/Compiler/CodeGen Code Generator] page. This page has also historical notes about Adams optimisation. That optimisation is also described in Note [sharing continuations] in <a href="GhcFile(compiler/codeGen/StgCmmMonad.hs)" class="uri" title="wikilink">GhcFile(compiler/codeGen/StgCmmMonad.hs)</a> and probably deserves its own wiki page.</p>
<h1 id="design-of-the-new-code-generator">Design of the new code generator</h1>
<p>This page contains notes about the design of the new code generator. See also: [wiki:Commentary/Compiler/NewCodeGenModules overview of the module structure in the new code generator].</p>
<h2 id="overview-4">Overview</h2>
<p>Code generation now has three stages:</p>
<p><code>1.ConvertSTGtoCmm,withimplicitstackimplicit,andnativeCmmcalls.</code><br />
<code>2.OptimisetheCmm,andCPS-convertittohaveanexplicitstack,andnonativecalls.</code><br />
<code>Thispartofthepipelineisstitchedtogetherin`cmm/CmmPipeline.hs`.</code><br />
<code>3.FeedtheCPS-convertedCmmtotheexisting,unmodifiednativecodegenerators.</code></p>
<p>Ultimately our plan is to expand the capability of the new pipeline so that it does native code generation too, and we can ultimately discard the existing code generators. The design of this stage is here: [wiki:Commentary/Compiler/IntegratedCodeGen]</p>
<h2 id="the-cmm-pipeline">The Cmm pipeline</h2>
<p>The first two steps are described in more detail here:</p>
<p><code>*</code><strong><code>Code</code> <code>generator</code></strong><code>convertsSTGto`CmmGraph`.Implementedin`StgCmm*`modules(indirectory`codeGen`).</code><br />
<code>*`Cmm.CmmGraph`isprettymuchaHooplgraphof`CmmNode.CmmNode`nodes.Controltransferinstructionsarealwaysthelastnodeofabasicblock.</code><br />
<code>*Parameterpassingismadeexplicit;thecallingconventiondependsonthetargetarchitecture.Thekeyfunctionis`CmmCallConv.assignArgumentsPos`.</code><br />
<code>*ParametersarepassedinvirtualregistersR1,R2etc.[Thesemap1-1torealregisters.]</code><br />
<code>*Overflowparametersarepassedonthestackusingexplicitmemorystores,tolocationsdescribedabstractlyusingthe[wiki:Commentary/Compiler/StackAreas</code><em><code>Stack</code> <code>Area</code></em><code>abstraction.].</code><br />
<code>*Makingthecallingconventionexplicitincludesanexplicitstoreinstructionofthereturnaddress,whichisstoredexplicitlyonthestackinthesamewayasoverflowparameters.Thisisdone(obscurely)in`MkGraph.mkCall`.</code></p>
<p><code>*</code><strong><code>Simple</code> <code>control</code> <code>flow</code> <code>optimisation</code></strong><code>,implementedin`CmmContFlowOpt`.It'scalledbothatthebeginningandendofthepipeline.</code><br />
<code>*Branchchainelimination.</code><br />
<code>*Removeunreachableblocks.</code><br />
<code>*Blockconcatenation.branchtoK;andthisistheonlyuseofK.</code></p>
<p><code>*</code><strong><code>More</code> <code>control</code> <code>flow</code> <code>optimisations</code></strong><code>.</code><br />
<code>*CommonBlockElimination(likeCSE).ThisessentiallyimplementstheAdamsoptimisation,webelieve.</code><br />
<code>*Consider(sometime):blockduplication.branchtoK;andKisashortblock.Branchchaineliminationisjustaspecialcaseofthis.</code></p>
<p><code>*</code><strong><code>Proc-point</code> <code>analysis</code></strong><code>and</code><strong><code>transformation</code></strong><code>,implementedin`CmmProcPoint`.Thetransformationpartaddsafunctionprologuetothefrontofeachproc-point,followingastandardentryconvention.</code><br />
<code>*Theanalysisproducesasetof`BlockId`thatshouldbecomeproc-points</code><br />
<code>*Thetransformationinsertsafunctionprologueatthestartofeachproc-point,andafunctionepiloguejustbeforeeachbranchtoaproc-point.</code></p>
<p><code>*</code><strong><code>(OUTDATED</code> <code>-</code> <code>!CmmSpillReload</code> <code>does</code> <code>not</code> <code>exist</code> <code>any</code> <code>more)</code></strong><code></code><strong><code>Add</code> <code>spill/reload</code></strong><code>,implementedin`CmmSpillReload`,tospillliveC--variablesbeforeacallandreloadthemafterwards.Thespillandreloadinstructionsaresimplymemorystoresandloadsrespectively,usingsymbolicstackoffsets(see[wiki:Commentary/Compiler/StackAreas#Layingoutthestackstacklayout]).Forexample,aspillofvariable'x'wouldlooklike`Ptr32[SS(x)]=x`.</code><br />
<code>*`dualLivenessWithInsertion`doestwothings:</code><br />
<code>*Spillsatthedefinitionofanyvariablethatissubequentlyliveacrossacall(usesabackwardanalysis)</code><br />
<code>*Addsareloadateachreturn(orproc)point</code><br />
<code>Atthispoint,no(`LocalReg`)variablesareliveacrossacall.</code><br />
<code>*TODO:avoid`f();g()`turninginto`spillx;f();reloadx;spillx;g();reloadx`.</code></p>
<p><code>*</code><strong><code>(OUTDATED</code> <code>-</code> <code>!CmmRewriteAssignments</code> <code>is</code> <code>not</code> <code>used</code> <code>any</code> <code>more)</code></strong><code></code><strong><code>Rewrite</code> <code>assignments</code></strong><code>(assignmentstolocalregs,thatis,notstores).</code><br />
<code>*Convertgraphtoannotatedgraphwhosenodesare`CmmRewriteAssignments.WithRegUsage`.Specifically,`CmmAssign`isdecoratedwithaflag`RegUsage`sayingwhetheritisusedonceormanytimes.</code><br />
<code>*Sinkorinlineassignmentsnearertheirusepoints</code><br />
<code>*Doconstantmach-opfolding.Thisisdoneinthisphase,becausefoldedmach-opscanbeinlined,andinliningexposesopportunitiesformach-opfolding.</code></p>
<p><code>*</code><strong><code>Remove</code> <code>dead</code> <code>assignments</code> <code>and</code> <code>stores</code></strong><code>,implementedin`CmmLive`,removesassignmentstodeadvariablesandthingslike``a=a``or``I32[Hp]=I32[Hp]``.Thelattermaymoreappropriatelybedoneinageneraloptimizationpass,asitdoesn'ttakeadvantageoflivenessinformation.</code></p>
<p><code>*</code><strong><code>Figure</code> <code>out</code> <code>the</code> <code>stack</code> <code>layout</code></strong><code>,implementedin`CmmStackLayout`.</code><br />
<code>*Eachvariable'x',andeachproc-pointlabel'K',hasanassociated</code><em><code>Area</code></em><code>,writtenSS(x)andSS(k)resp,thatnamesacontiguousportionofthestackframe.</code><br />
<code>*Thestacklayoutpassproducesamappingof:</code><em><code>(`Area`</code> <code>-&gt;</code> <code>`StackOffset`)</code></em><code>.Formoredetail,see[wiki:Commentary/Compiler/StackAreas#Layingoutthestackthedescriptionofstacklayout.]</code><br />
<code>*A`StackOffset`isthebyteoffsetofastackslotfromtheoldend(highaddress)oftheframe.Itdoesn'tvaryasthephysicalstackpointermoves.</code></p>
<p><code>*</code><strong><code>Manifest</code> <code>the</code> <code>stack</code> <code>pointer</code></strong><code>,implementedin`CmmStackLayout`.Oncethestacklayoutmappinghasbeendetermined,asecondpasswalksoverthegraph,makingthestackpointer,`Sp`explicit.Beforethispass,thereisno`Sp`atall.Afterthis,`Sp`iscompletelymanifest.</code><br />
<code>*replacingreferencesto`Areas`withoffsetsfrom`Sp`.</code><br />
<code>*addingadjustmentsto`Sp`.</code><br />
<br />
<code>*</code><strong><code>Split</code> <code>into</code> <code>multiple</code> <code>!CmmProcs</code></strong><code>,implementedin`CmmProcPointZ`.Atthispointwebuildaninfo-tableforeachofthe!CmmProcs,includingSRTs.Doneonthebasisofthelivelocalvariables(bynowmappedtostackslots)andliveCAFstatics.</code><br />
<code>*`LastCall`and`LastReturn`nodesarereplacedby`Jump`s.</code></p>
<p><code>*</code><strong><code>Build</code> <code>info</code> <code>tables</code></strong><code>,implementedin`CmmBuildInfoTables`..</code><br />
<code>*Findeachsafe`MidForeignCall`node,&quot;lowers&quot;itintothesuspend/call/resumesequence(see`Note[Foreigncalls]`in`CmmNode.hs`.),andbuildaninfotableforthem.</code><br />
<code>*Convertthe`CmmInfo`foreach`CmmProc`intoa`[CmmStatic]`,usingthelivevariableinformationcomputedjustbefore&quot;Figureoutstacklayout&quot;.</code></p>
<h3 id="branches-to-continuations-and-the-adams-optimisation">Branches to continuations and the &quot;Adams optimisation&quot;</h3>
<p>A GC block for a heap check after a call should only take one or two instructions. However the natural code:  The label M is the head of the call-gc-and-try-again loop. If we do this, we'll generate two info tables, one for L and one for K.</p>
<p>We can do better like this: </p>
<p>Now the  call has the same return signature as  and can use the same continuation, thus:  Now we can coalesce the uniquely-used block M into L, thus:  (A call followed by a  thus gets optimized down to just the call.)</p>
<p>Now things are good. Simple common block elimination (CBE) will common up K and L, so both calls share the same info table.</p>
<h2 id="runtime-system">Runtime system</h2>
<p><code>*</code><strong><code>Garbage</code> <code>collector</code> <code>entry</code> <code>points</code></strong><code>:see`Note[Heapchecks]`in`StgCmmHeapery`.</code></p>
<p><code>*</code><strong><code>PAPs</code></strong><br />
<br />
<code>*</code><strong><code>Update</code> <code>frames</code></strong><code>and</code><strong><code>exception</code> <code>handling</code></strong><code>.AlsoSTMframes.</code></p>
<p><code>*</code><strong><code>Primitives</code></strong><code>canberewritten:</code><br />
<code>*Useparameters</code><br />
<code>*Inafewcases,usenativecalls(notablyeval)</code></p>
<h1 id="note-historical-page">NOTE: Historical page</h1>
<p>This page is here for historical reasons. Most of the issues described here are now fixed (2 Aug 2012), and the new code generator produces code approximately as good as the old code generator. Any remaining issues will be made into tickets as necessary. See [wiki:Commentary/Compiler/CodeGen Code Generator] page for an up-to-date description of the current code generator.</p>
<h1 id="stupidity-in-the-new-code-generator">Stupidity in the New Code Generator</h1>
<p>Presently compiling using the new code generator results in a fairly sizable performance hit, because the new code generator produces sub-optimal (and sometimes absolutely terrible code.) There are <a href="http://darcs.haskell.org/ghc/compiler/cmm/cmm-notes">a lot of ideas for how to make things better</a>; the idea for this wiki page is to document all of the stupid things the new code generator is doing, to later be correlated with specific refactorings and fixes that will hopefully eliminate classes of these stupid things. The hope here is to develop a sense for what the most endemic problems with the newly generated code is.</p>
<h2 id="cantankerous-comparisons">Cantankerous Comparisons</h2>
<p>FIXED in newcg branch, 15/2/2012</p>
<p>In `cgrun065` we have</p>
<p></p>
<p>Which compiles to the nice STG code</p>
<p></p>
<p>But the comparison is compiled into stupid code:</p>
<p></p>
<p>etc.</p>
<p>We're actually converting to a `Bool` and then doing an algebraic case! This is a StgCmm issue, not a pipeline issue.</p>
<h2 id="dead-stackheap-checks">Dead stack/heap checks</h2>
<p>FIXED in newcg branch, but in an ad-hoc way (the stack allocator does it). We probably want to do this as part of a more general optimisation pass.</p>
<p>See in `cgrun065`</p>
<p></p>
<h2 id="instruction-reordering">Instruction reordering</h2>
<p>NEW. We should be able to reorder instructions in order to decrease register pressure. Here's an example from 3586.hs</p>
<p></p>
<p>R1 and Sp probably don't clobber each other, so we ought to use _cPY twice in quick succession. Fortunately stg_IND_STATIC_info is a constant so in this case the optimization doesn't help to much, but in other cases it might make sense. TODO Find better example</p>
<h2 id="stack-space-overuse">Stack space overuse</h2>
<p>FIXED in the newcg branch. (stack layout algorithm redesigned)</p>
<p>CONFIRMED. `T1969.hs` demonstrates this:</p>
<p></p>
<p>The call area for the jump in cbG is using an extra word on the stack, but in fact Sp + 0 at the entry of the function immediately becomes dead after the assignment, so we ought to be able to save some space in our layout. Simon Marlow suggests we distinguish between the return address and the old call area; however, since this can also happen for the return parameters from call areas, we need a more general scheme.</p>
<p>After I discussed this with SPJ, we've decided that we need to teach the stack layout how to handle partial conflicts. There is a complication here, in that if we do this naively, the interference graph will blow up (since, rather than conflicting call areas, we now have conflicting words of call areas.) Simon suggested that we bound the amount of conflicts we track: either up to 3 or conflict with everything (in which case we just place the area as far down as necessary rather than try to be clever.) I plan on doing this once I understand the current layout code...</p>
<h2 id="double-temp-use-means-no-inlinining">Double temp-use means no inlinining?</h2>
<p>CONFIRMED. Here's a curious piece of code that fails to get inlined (from `cc004`):</p>
<p></p>
<p>Why is that? Because the temp gets reused later on:</p>
<p></p>
<p>In this case, we want more aggressive inlining because there are too many temps and they're going to have to get spilled to the stack anyway. IS THAT TRUE? For comparison's sake, the old codegen doesn't appear to do any rewriting, because it just reuses the call area.</p>
<h2 id="stupid-spills">Stupid spills</h2>
<p>CONFIRMED. If something is already in memory, why do we have to spill it again?</p>
<p></p>
<p>Well, it's because the spiller isn't clever enough:</p>
<p></p>
<p>Ick! The old codegen was much better...</p>
<p></p>
<p>The trouble is that the spiller doesn't know that the old call area is also valid game for locations that variables can live in. So, the solution is to rewrite the spiller to know about existing incoming memory locations. Make sure that this information gets to the stack layout engine when we do partial layouts (it should automatically notice, but double check!)</p>
<h2 id="noppy-proc-points">Noppy proc-points</h2>
<p>CONFIRMED. Consider</p>
<p></p>
<p></p>
<p>We generate an extra proc-point for ``cmM``, where in theory we ought to be able to stick the subsequent ``stg_ap_pp_fast`` onto the stack as another return point.</p>
<h2 id="lots-of-temporary-variables">Lots of temporary variables</h2>
<p>WONTFIX. Lots of temporary variables (these can tickle other issues when the temporaries are long-lived, but otherwise would be optimized away). You can at least eliminate some of them by looking at the output of `-ddump-opt-cmm`, which utilizes some basic temporary inlining when used with the native backend `-fasm`, but this doesn't currently apply to the GCC or LLVM backends.</p>
<p>~~At least one major culprit for this is `allocDynClosure`, described in Note `Return a LocalReg`; this pins down the value of the `CmmExpr` to be something for one particular time, but for a vast majority of use-cases the expression is used immediately afterwards. Actually, this is mostly my patches fault, because the extra rewrite means that the inline pass is broken.~~ Fixed in latest version of the pass; we don't quite manage to inline enough but there's only one extra temporary.</p>
<p>Another cause of all of these temporary variables is that the new code generator immediately assigns any variables that were on the stack to temporaries immediately upon entry to a function. This is on purpose. The idea is we optimize these temporary variables away.</p>
<h2 id="double-proc-points">Double proc points</h2>
<p>FIXED in newcg branch.</p>
<p>Given a simple case expression</p>
<p></p>
<p>we generate *two* proc points, not one.</p>
<p></p>
<p>Both `cbE` and `cbW` are going to become proc points.</p>
<p>To avoid it we should generate code that re-uses `cbE` as the destination for the first `if`; that is, we need to load up the registers as if we were returning from the call. This needs some refactoring in the code generator.</p>
<h2 id="rewriting-stacks">Rewriting stacks</h2>
<p>FIXED. `3586.hs` emits the following code:</p>
<p></p>
<p>We see that these temporary variables are being repeatedly rewritten to the stack, even when there are no changes.</p>
<p>Since these areas on the stack are all old call areas, one way to fix this is to inline all of the memory references. However, this has certain undesirable properties for other code, so we need to be a little more clever. The key thing to notice is that these accesses are only used once per control flow path, in which case sinking the loads down and then inlining them should be OK (it will increase code size but not execution time.) However, the other difficulty is that the CmmOpt inliner, as it stands, won't inline things that look like this because although the variable is only used once in different branches, the same name is used, so it can't distinguish between the temporaries with mutually exclusive live ranges. Building a more clever inliner with Hoopl is also a bit tricky, because inlining is a forward analysis/transformation, but usage counting is a backwards analysis.</p>
<p>This looks fixed with the patch from April 14.</p>
<h2 id="spilling-hpsp">Spilling Hp/Sp</h2>
<p>FIXED. `3586.hs` emits the following code:</p>
<p></p>
<p>We see `Hp - 4` being allocated to a temp, and then consequently being spilled to the stack even though `newCAF` definitely will not change `Hp`, so we could have floated the expression down.</p>
<p>This seems to happen whenever there's a `newCAF` ccall.</p>
<p>We also seem to reload these values multiple times.</p>
<p></p>
<p>~~We need to not spill across certain foreign calls, but for which calls this is OK for is unclear.~~ Variables stay live across all unsafe foreign calls (foreign calls in the middle), except for the obvious cases (the return registers), so no spilling should happen at all. The liveness analysis is too conservative.</p>
<p>This is not fixed in the April 14 version of the patch... we still need to fix the liveness analysis? I thought I fixed that... that's because the transform did extra spilling for CmmUnsafeForeignCalls. Removed that code, and now it's fixed.</p>
<h2 id="up-and-down">Up and Down</h2>
<p>FIXED. A frequent pattern is the stack pointer being bumped up and then back down again, for no particular reason.</p>
<p></p>
<p>This is mentioned at the very top of `cmm-notes`. This was a bug in the stack layout code that I have fixed.</p>
<h2 id="sp-is-generally-stupid">Sp is generally stupid</h2>
<p>FIXED. Here is an optimized C-- sample from `arr016.hs`.</p>
<p></p>
<p>Compare with the old code:</p>
<p></p>
<p>You can see the up and down behavior here, but that's been fixed, so ignore it for now. (Update the C--!) The unfixed problem is this (some of the other problems were already addressed): we do an unnecessary stack check on entry to this function. We should eliminate the stack check (and by dead code analysis, the GC call) in such cases.</p>
<p>This pattern essentially happens for every function, since we always assign incoming parameters to temporary variables before doing anything.</p>
<h2 id="heap-and-r1-aliasing">Heap and R1 aliasing</h2>
<p>FIXED. Values on the heap and values from R1 don't necessarily clobber each other. allocDynClosure seems like a pretty safe bet they don't. But is this true in general? ANSWER: Memory writes with Hp are always new allocations, so they don't clobber anything.</p>
<p></p>
<h2 id="historical-page-3">Historical page</h2>
<p>This page stores notes about progress of work on the &quot;new&quot; code generator. This page is here for historical reasons. See [wiki:Commentary/Compiler/CodeGen Code Generator] page for an up-to-date description of the current code generator.</p>
<h1 id="ghcs-glorious-new-code-generator">GHC's glorious new code generator</h1>
<p>This page summarises work that Norman Ramsey, Simon M, Simon PJ, and John Dias are doing on re-architecting GHC's back end. Here is the state of play; see also [wiki:Commentary/Compiler/Backends/LLVM work on the LLVM back end].</p>
<p><code>*Buglist(code-genrelatedbugsthatwemaybeabletofix):</code><br />
<code>*#1498(avoidredundantheapcheckonthefastpath)</code><br />
<code>*#3552(unreachablecode)</code><br />
<code>*#3462(afeature)</code><br />
<code>*#2249</code><br />
<code>*#2253</code><br />
<code>*#2289</code><br />
<code>*#7219(reinstateconstant-prop)</code><br />
<code>*#7213(massivearray)</code></p>
<p><code>*(Sept12)Newcodegeneratorislive.Here'sthe[wiki:Commentary/Compiler/NewCodeGen/Cleanuppagelistingclean-uptasks]thatwecannowdo.</code></p>
<p><code>*SimonMaddeda[blog:newcg-updateBlogPost]aboutthenewcodegeneratorstatus</code></p>
<p><code>*Linkto</code><a href="http://research.microsoft.com/en-us/um/people/simonpj/tmp/wos-diss-draft.pdf"><code>Krzysztof</code> <code>Wos's</code> <code>project</code></a><code>,inwhichhereportsgreatperformanceimprovementsbyturningtailrecursionintoloopsinC--.</code></p>
<p><code>*Normanaddeda[wiki:Commentary/Compiler/HooplPerformanceHooplperformancepage]</code></p>
<p><code>*EdwardYanghasawikipagethatdescribesshortcomingsofthecodegeneratedbythenewpipeline:[wiki:Commentary/Compiler/NewCodeGenStupidity]</code></p>
<p><code>*JohnDhasbuiltacompletenewcodegenpipeline,runningalongsidetheoldone,enabledby`-fuse-new-codegen`.Itisdescribedhere:[wiki:Commentary/Compiler/NewCodeGenPipeline].Itusesanewrepresentationfor`Cmm`,mostlywith&quot;Z&quot;inthename.(Let'scalltheoriginalCmm`OldCmm`andthisnewone`CmmZ`.)IthasanewconversionSTG-&gt;CmmZ,andthensequenceofpassesthatoptimiseandcps-converttheCmm.Finally,itisconvertedbacktotheoldCmmsothatitcanflowtotheoldcodegenerators.</code></p>
<p><code>*CompilingthroughthenewpipelinepassesalltestsandGHCisbootstrappable.</code></p>
<p><code>*Separately,wehavedevelopedyetanother,andstillbetter,Cmmrepresentation,thesubjectofanupcomingICFP2010submission.ItusesphantomtypesandGADTstoaddveryusefulopen/closedinvariants.Thisisn'tinGHCatallyet.I'llcallit`CmmGADT`foreasyreference.</code></p>
<p>Generally we want to keep old and new pipelines working simultaneously, so that we can switch only when we are sure the new stuff works. Next steps in this grand plan are:</p>
<p><code>*Checktheimpactoncompilationtimeofthenewroute.</code></p>
<p><code>*Finalise`CmmGADT`andmakethenewpipelineuseit.</code></p>
<p><code>*MaketheCmmparser(whichparses`.cmm`filesfromtheRTS)produce`CmmGADT`,andpushthatdownthenewpipeline.</code></p>
<p><code>*Implementthemanyrefactoringsandimprovementstothenewpipelinedescribedin</code><a href="http://darcs.haskell.org/ghc/compiler/cmm/cmm-notes"><code>http://darcs.haskell.org/ghc/compiler/cmm/cmm-notes</code></a><code>.Seealso:[wiki:Commentary/Compiler/NewCodeGenStupidity]</code></p>
<p><code>*InsteadofconvertingnewCmmtooldCmm,makethedownstreamcodegeneratorsconsume`CmmGADT`,andconvertoldCmmto`CmmGADT`.</code></p>
<p>Longer term</p>
<p><code>*Expandthecapabilityofthenewpipelinesothatitdoesnativecodegenerationtoo,andwecanultimatelydiscardtheexistingcodegenerators.Thedesignofthisstageishere:[wiki:Commentary/Compiler/IntegratedCodeGen]</code></p>
<h2 id="workflow-for-the-new-code-generator-and-hoopl">Workflow for the new code generator and Hoopl</h2>
<p>We have the following repositories:</p>
<p><code>*HEAD:themainGHCgitrepo.`http://darcs.haskell.org/ghc.git`</code></p>
<p><code>*!HooplMaster:themasterHooplGitrepository.</code><br />
<code></code><a href="BR" title="wikilink"><code>BR</code></a><code></code><strong><code>Location</code></strong><code>:`http://ghc.cs.tufts.edu/hoopl/hoopl.git/`</code><br />
<code></code><a href="BR" title="wikilink"><code>BR</code></a><code>(Physicallocation:`linux.cs.tufts.edu:/r/ghc/www/hoopl/hoopl.git`)</code></p>
<p><code>*!HooplLag:aGitrepothatisguaranteedtoworkwithGHCHEAD.Itis</code><br />
<code>notautomaticallyupdatedbypushesto!HooplMaster.Insteadamanual</code><br />
<code>process(below)updatesit;hence&quot;lag&quot;.</code><br />
<code></code><a href="BR" title="wikilink"><code>BR</code></a><code></code><strong><code>Location</code></strong><code>:`http://darcs.haskell.org/packages/hoopl.git`.</code></p>
<p>Normal GHC developers, who are uninterested in Hoopl, ignore all this. If they download HEAD including all submodules, they'll get !HooplLag, which is always guaranteed to work with HEAD.</p>
<p>Developers who work on GHC and also need to modify Hoopl need to ensure their changes end up in both repositories.</p>
<p><code>*Inyourhoopldirectoryinyourdevelopmenttree,add!HooplMasterasaremoteandupdateyourreferencethere.</code><br />
<code>*Hackawayinthedevelopmenttree.</code><br />
<code>*RecordHooplcommits.</code><br />
<code>*Runvalidateinthedevelopmenttree</code><br />
<code>*Pushthecommitsinhoopltothe!HooplMasterGitrepo</code><br />
<code>*Waitforthemirrorstoupdate(theimpatientcanrun`/srv/darcs/do_mirrors`ondarcs.haskell.org)</code><br />
<code>*Pushthecommitsinhoopltothe!HooplLagGitrepo(probablytheoriginremote)</code></p>
<h2 id="status-report-april-2011">Status report April 2011</h2>
<p>Term</p>
<h1 id="old-code-generator-prior-to-ghc-7.8">Old Code Generator (prior to GHC 7.8)</h1>
<p>Material below describes old code generator that was used up to GHC 7.6 and was retired in 2012. This page is not maintained and is here only for historical purposes. See [wiki:Commentary/Compiler/CodeGen Code generator] page for an up to date description of the current code generator.</p>
<h2 id="storage-manager-representations">Storage manager representations</h2>
<p>See [wiki:Commentary/Rts/Storage The Storage Manager] for the [wiki:Commentary/Rts/Storage/Stack Layout of the stack].</p>
<p>The code generator needs to know the layout of heap objects, because it generates code that accesses and constructs those heap objects. The runtime also needs to know about the layout of heap objects, because it contains the garbage collector. How can we share the definition of storage layout such that the code generator and the runtime both have access to it, and so that we don't have to keep two independent definitions in sync?</p>
<p>Currently we solve the problem this way:</p>
<p><code>*CtypesrepresentingheapobjectsaredefinedintheCheaderfiles,seeforexample</code><a href="GhcFile(includes/rts/storage/Closures.h)" title="wikilink"><code>GhcFile(includes/rts/storage/Closures.h)</code></a><code>.</code></p>
<p><code>*ACprogram,</code><a href="GhcFile(includes/mkDerivedConstants.c)" title="wikilink"><code>GhcFile(includes/mkDerivedConstants.c)</code></a><code>,`#includes`theruntimeheaders.</code><br />
<code>Thisprogramisbuiltandrunwhenyoutype`make`or`makeboot`in`includes/`.Itis</code><br />
<code>runtwice:oncetogenerate`includes/DerivedConstants.h`,andagaintogenerate</code><br />
<code>`includes/GHCConstants.h`.</code></p>
<p><code>*Thefile`DerivedConstants.h`containslotsof`#defines`likethis:</code></p>
<p></p>
<p><code>whichsaysthattheoffsettothewhy_blockedfieldofan`StgTSO`is18bytes.Thisfile</code><br />
<code>is`#included`into</code><a href="GhcFile(includes/Cmm.h)" title="wikilink"><code>GhcFile(includes/Cmm.h)</code></a><code>,sotheseoffestsareavailabletothe</code><br />
<code>[wiki:Commentary/Rts/Cmmhand-written.cmmfiles].</code></p>
<p><code>*Thefile`GHCConstants.h`containssimilardefinitions:</code></p>
<p></p>
<p><code>ThistimethedefinitionsareinHaskellsyntax,andthisfileis`#included`directlyinto</code><br />
<code></code><a href="GhcFile(compiler/main/Constants.lhs)" title="wikilink"><code>GhcFile(compiler/main/Constants.lhs)</code></a><code>.Thisisthewaythattheseoffsetsaremade</code><br />
<code>availabletoGHC'scodegenerator.</code></p>
<h2 id="generated-cmm-naming-convention">Generated Cmm Naming Convention</h2>
<p>See <a href="GhcFile(compiler/cmm/CLabel.hs)" class="uri" title="wikilink">GhcFile(compiler/cmm/CLabel.hs)</a></p>
<p>Labels generated by the code generator are of the form  where  is  for external names and  for internal names.  is one of the following:</p>
<p><code>info::Infotable</code><br />
<code>srt::Staticreferencetable</code><br />
<code>srtd::Staticreferencetabledescriptor</code><br />
<code>entry::Entrycode(function,closure)</code><br />
<code>slow::Slowentrycode(ifany)</code><br />
<code>ret::Directreturnaddress</code><br />
<code>vtbl::Vectortable</code><br />
<code></code><em><code>n</code></em><code>_alt::Casealternative(tag</code><em><code>n</code></em><code>)</code><br />
<code>dflt::Defaultcasealternative</code><br />
<code>btm::Largebitmapvector</code><br />
<code>closure::Staticclosure</code><br />
<code>con_entry::DynamicConstructorentrycode</code><br />
<code>con_info::DynamicConstructorinfotable</code><br />
<code>static_entry::StaticConstructorentrycode</code><br />
<code>static_info::StaticConstructorinfotable</code><br />
<code>sel_info::Selectorinfotable</code><br />
<code>sel_entry::Selectorentrycode</code><br />
<code>cc::Costcentre</code><br />
<code>ccs::Costcentrestack</code></p>
<p>Many of these distinctions are only for documentation reasons. For example, _ret is only distinguished from _entry to make it easy to tell whether a code fragment is a return point or a closure/function entry.</p>
<h2 id="modules">Modules</h2>
<h3 id="section-6"></h3>
<p>Top level, only exports .</p>
<p>Called from  for each module that needs to be converted from Stg to Cmm.</p>
<p>For each such module  does three things:</p>
<p><code>*</code><code>forthe</code><br />
<code>*</code><code>forthe</code><code>(Theseareconstructorsnotconstructorcalls).</code><br />
<code>*</code><code>forthemodule</code></p>
<p> generates several boilerplate initialization functions that:</p>
<p><code>*regiserthemodule,</code><br />
<code>*createsanHpctable,</code><br />
<code>*setupitsprofilinginfo(</code><code>,codecoverageinfo</code><code>),and</code><br />
<code>*callstheinitializationfunctionsofthemodulesitimports.</code></p>
<p>If neither SCC profiling or HPC are used, then the initialization code short circuits to return.</p>
<p>If the module has already been initialized, the initialization function just returns.</p>
<p>The  and  modules get special treatment.</p>
<p> is a small wrapper around  which in turn disptaches to:</p>
<p><code>*</code><code>for</code><br />
<code>(thesearebindingsofconstructorapplicationsnotconstructorsthemselves)and</code><br />
<code>*</code><code>for</code><code>.</code></p>
<p> and  are located in  and  which are the primary modules called by .</p>
<h3 id="section-7"></h3>
<p>TODO</p>
<h3 id="section-8"></h3>
<p>TODO</p>
<h3 id="section-9"></h3>
<p>The monad that most of codeGen operates inside</p>
<p><code>*Reader</code><br />
<code>*State</code><br />
<code>*(couldbeWriter?)</code><br />
<code>*fork</code><br />
<code>*flatten</code></p>
<h3 id="section-10"></h3>
<p>Called by  and .</p>
<p>Since everything in STG is an expression, almost everything branches off from here.</p>
<p>This module exports only one function , which for the most part just dispatches to other functions to handle each specific constructor in .</p>
<p>Here are the core functions that each constructor is disptached to (though some may have little helper functions called in addition to the core function):</p>
<p><code>::Callsto</code><code>in</code><br />
<code>::Callsto</code><code>in</code><br />
<code>::</code><br />
<code>Callsto</code><code>in</code><br />
<code>and</code><code>in</code><br />
<code>::</code><br />
<code>Isabitmorecomplicatedseebelow.</code><br />
<code>::Callsto</code><code>in</code><br />
<code>::Callsto</code><code>in</code><br />
<code>::</code><br />
<code>Callsto</code><code>in</code><code>,butwithalittlebitofwrapping</code><br />
<code>by</code><code>and</code><code>.</code><br />
<code>::Callsto</code><code>in</code><br />
<code>::Callsto</code><code>in</code><br />
<code>::</code><br />
<code>Doesnothaveacasebecauseitisonlyfor</code><code>'swork.</code></p>
<p>Some of these cases call to functions defined in . This is because they need a little bit of wrapping and processing before calling out to their main worker function.</p>
<p><code>::</code><br />
<code>*For</code><code>callsoutto</code><code>in</code><code>.</code><br />
<code>*For</code><code>callsoutto</code><code>.</code><br />
<code>Inturn,</code><code>callsoutto</code><code>forselectorsandthunks,</code><br />
<code>andcallsoutto</code><code>inthedefaultcase.</code><br />
<code>Boththesearedefinedin</code><code>.</code></p>
<p><code>::</code><br />
<code>*Wrapsacallto</code><code>with</code><br />
<code>dependingonwhetheritiscalledonarecursiveoranon-recursivebinding.</code><br />
<code>Inturn</code><code>wraps</code><br />
<code>definedin</code><code>.</code></p>
<p> has a number of sub-cases.</p>
<p><code>*</code><br />
<code>*</code><code>ofa!TagToEnumOp</code><br />
<code>*</code><code>thatisprimOpOutOfLine</code><br />
<code>*</code><code>thatreturnsVoid</code><br />
<code>*</code><code>thatreturnsasingleprimitive</code><br />
<code>*</code><code>thatreturnsanunboxedtuple</code><br />
<code>*</code><code>thatreturnsanenumerationtype</code></p>
<p>(It appears that non-foreign-call, inline [wiki:Commentary/PrimOps PrimOps] are not allowed to return complex data types (e.g. a |Maybe|), but this fact needs to be verified.)</p>
<p>Each of these cases centers around one of these three core calls:</p>
<p><code>*</code><code>in</code><br />
<code>*</code><code>in</code><br />
<code>*</code><code>in</code></p>
<p>There is also a little bit of argument and return marshelling with the following functions</p>
<p><code>Argumentmarshelling::</code><br />
<code></code><code>,</code><br />
<code>Returnmarshelling::</code><br />
<code></code><code>,</code><code>,</code><br />
<code>Performingthereturn::</code><br />
<code></code><code>,</code><code>,</code><br />
<code></code><code>,</code></p>
<p>In summary the modules that get called in order to handle a specific expression case are:</p>
<h4 id="also-called-for-top-level-bindings-by">Also called for top level bindings by </h4>
<p><code>::for</code><code>andthe</code><code>partof</code><br />
<code>::forthe</code><code>partof</code></p>
<h4 id="core-code-generation">Core code generation</h4>
<p><code>::for</code><code>,</code><code>,and</code><br />
<code>::for</code><br />
<code>::for</code><br />
<code>::for</code></p>
<h4 id="profiling-and-code-coverage-related">Profiling and Code coverage related</h4>
<p><code>::for</code><br />
<code>::for</code></p>
<h4 id="utility-modules-that-happen-to-have-the-functions-for-code-generation">Utility modules that happen to have the functions for code generation</h4>
<p><code>::for</code><br />
<code>::for</code></p>
<p>Note that the first two are the same modules that are called for top level bindings by , and the last two are really utility modules, but they happen to have the functions needed for those code generation cases.</p>
<h3 id="memory-and-register-management">Memory and Register Management</h3>
<p><code>::</code><br />
<code>Modulefor</code><code>whichmapsvariablenames</code><br />
<code>toallthevolitileorstablelocationswheretheyarestored</code><br />
<code>(e.g.register,stackslot,computedfromotherexpressions,etc.)</code><br />
<code>Providesthe</code><code>,</code><code>and</code><code>functions</code><br />
<code>foradding,modifyingandlookingupbindings.</code></p>
<p><code>::</code><br />
<code>Mostlyutilityfunctionsforallocatingandfreeingstackslots.</code><br />
<code>Butalsohasthingsonsettingupupdateframes.</code></p>
<p><code>::</code><br />
<code>Functionsforallocatingobjectsthatappearontheheapsuchasclosuresandconstructors.</code><br />
<code>Alsoincludescodeforstackandheapchecksand</code><code>.</code></p>
<h3 id="function-calls-and-parameter-passing">Function Calls and Parameter Passing</h3>
<p>(Note: these will largely go away once CPS conversion is fully implemented.)</p>
<p><code>,</code><code>,</code><code>::</code><br />
<code>Handledifferenttypesofcalls.</code><br />
<code>::</code><br />
<code>Usebytheothersinthiscategorytodeterminelivenessand</code><br />
<code>toselectinwhatregistersandstacklocationsargumentsandreturn</code><br />
<code>valuesgetstored.</code></p>
<h3 id="misc-utilities">Misc utilities</h3>
<p><code>::</code><br />
<code>Utilityfunctionsformakingbitmaps(e.g.</code><code>withtype</code><code>)</code><br />
<code>::</code><br />
<code>Storesinfoaboutclosuresandbindings.</code><br />
<code>Includesinformationaboutmemorylayout,howtocallabinding(</code><code>)</code><br />
<code>andinformationusedtobuildtheinfotable(</code><code>).</code><br />
<code>::</code><br />
<code>Storagemanagerrepresentationofclosures.</code><br />
<code>Partof!ClosureInfobutkeptseparateto&quot;keepnhchappy.&quot;</code><br />
<code>::TODO</code><br />
<code>::TODO</code></p>
<h3 id="special-runtime-support">Special runtime support</h3>
<p><code>::Ticky-tickyprofiling</code><br />
<code>::Cost-centreprofiling</code><br />
<code>::SupportfortheHaskellProgramCoverage(hpc)toolkit,insideGHC.</code><br />
<code>::</code><br />
<code>Codegenerationfor!GranSim(GRAN)andparallel(PAR).</code><br />
<code>Allthefunctionsaredeadstubsexcept</code><code>and</code><code>.</code></p>
<h1 id="ordering-the-core-to-core-optimisation-passes">Ordering the Core-to-Core optimisation passes</h1>
<p>This page has notes about the ordering of optimisation phases. An overview of the whole Core-to-Core optimisation pipeline can be found [wiki:Commentary/Compiler/Core2CorePipeline here].</p>
<p><strong>NOTE:</strong> This is old documentation and may not be very relevant any more!</p>
<h2 id="this-ordering-obeys-all-the-constraints-except-5">This ordering obeys all the constraints except (5)</h2>
<p><code>*fulllaziness</code><br />
<code>*simplifywithfoldr/build</code><br />
<code>*float-in</code><br />
<code>*simplify</code><br />
<code>*strictness</code><br />
<code>*float-in</code></p>
<p>[check FFT2 still gets benefits with this ordering]</p>
<h2 id="constraints-1">Constraints</h2>
<h3 id="float-in-before-strictness">1. float-in before strictness</h3>
<p>Reason: floating inwards moves definitions inwards to a site at which the binding might well be strict.  The strictness analyser will do a better job of the latter than the former.</p>
<h3 id="dont-simplify-between-float-in-and-strictness">2. Don't simplify between float-in and strictness</h3>
<p>...unless you disable float-let-out-of-let, otherwise the simiplifier's local floating might undo some useful floating-in.  This is a bad move, because now y isn't strict. In the pre-float case, the binding for y is strict. Mind you, this isn't a very common case, and it's easy to disable float-let-from-let.</p>
<h3 id="want-full-laziness-before-foldrbuild">3. Want full-laziness before foldr/build</h3>
<p>Reason: Give priority to sharing rather than deforestation.  In the post-full-laziness case, xs is shared between all applications of the function. If we did foldr/build first, we'd have got  and now we can't share xs.</p>
<h3 id="want-strictness-after-foldrbuild">4. Want strictness after foldr/build</h3>
<p>Reason: foldr/build makes new function definitions which can benefit from strictness analysis.  Here we clearly want to get strictness analysis on g.</p>
<h3 id="want-full-laziness-after-strictness">5. Want full laziness after strictness</h3>
<p>Reason: absence may allow something to be floated out which would not otherwise be.  TOO BAD. This doesn't look a common case to me.</p>
<h3 id="want-float-in-after-foldrbuild">6. Want float-in after foldr/build</h3>
<p>Reason: Desugaring list comprehensions + foldr/build gives rise to new float-in opportunities.  Now v could usefully be floated into the second branch.</p>
<h3 id="want-simplify-after-float-inwards">7. Want simplify after float-inwards</h3>
<p>(Occurred in the prelude, compiling `ITup2.hs`, function `dfun.Ord.(*,*)`) This is due to the following (that happens with dictionaries):  floating inwards will push the definition of a1 into m1 (supposing it is only used there):  if we do strictness analysis now we will not get a worker-wrapper for m1, because of the &quot;let a1 ...&quot; (notice that a1 is not strict in its body).</p>
<p>Not having this worker wrapper might be very bad, because it might mean that we will have to rebox arguments to m1 if they are already unboxed, generating extra allocations, as occurs with m2 (cc) above.</p>
<p>To solve this problem we have decided to run the simplifier after float-inwards, so that lets whose body is a HNF are floated out, undoing the float-inwards transformation in these cases. We are then back to the original code, which would have a worker-wrapper for m1 after strictness analysis and would avoid the extra let in m2.</p>
<p>What we lose in this case are the opportunities for case-floating that could be presented if, for example, a1 would indeed be demanded (strict) after the floating inwards.</p>
<p>The only way of having the best of both is if we have the worker/wrapper pass explicitly called, and then we could do with</p>
<p><code>*float-in</code><br />
<code>*strictnessanalysis</code><br />
<code>*simplify</code><br />
<code>*strictnessanalysis</code><br />
<code>*worker-wrappergeneration</code></p>
<p>as we would</p>
<p><code>*beabletodetectthestrictnessofm1afterthefirstcalltothestrictnessanalyser,andexploititwiththesimplifier(incaseitwasstrict).</code><br />
<code>*afterthecalltothesimplifier(ifm1wasnotdemanded)itwouldbefloatedoutjustlikewecurrentlydo,beforestricnessanalysisIIandworker/wrapperisation.</code></p>
<p>The reason to not do worker/wrapperisation twice is to avoid generating wrappers for wrappers which could happen.</p>
<h3 id="if-full-laziness-is-ever-done-after-strictness">8. If full laziness is ever done after strictness</h3>
<p>...remember to switch off demandedness flags on floated bindings! This isn't done at the moment.</p>
<h3 id="ignore-inline-pragmas-flag-for-final-simplification">9. Ignore-inline-pragmas flag for final simplification</h3>
<p>[Occurred in the prelude, compiling ITup2.hs, function dfun.Ord.(*,*)] Sometimes (e.g. in dictionary methods) we generate worker/wrappers for functions but the wrappers are never inlined. In dictionaries we often have  and if we create worker/wrappers for f1,...,fn the wrappers will not be inlined anywhere, and we will have ended up with extra closures (one for the worker and one for the wrapper) and extra function calls, as when we access the dictionary we will be acessing the wrapper, which will call the worker. The simplifier never inlines workers into wrappers, as the wrappers themselves have INLINE pragmas attached to them (so that they are always inlined, and we do not know in advance how many times they will be inlined).</p>
<p>To solve this problem, in the last call to the simplifier we will ignore these inline pragmas and handle the workers and the wrappers as normal definitions. This will allow a worker to be inlined into the wrapper if it satisfies all the criteria for inlining (e.g. it is the only occurrence of the worker etc.).</p>
<h3 id="run-float-inwards-once-more-after-strictness-simplify">10. Run Float Inwards once more after strictness-simplify</h3>
<p>[Occurred in the prelude, compiling `IInt.hs`, function `const.Int.index.wrk`] When workers are generated after strictness analysis (worker/wrapper), we generate them with &quot;reboxing&quot; lets, that simply reboxes the unboxed arguments, as it may be the case that the worker will need the original boxed value:  in this case the simplifier will remove the binding for y as it is not used (we expected this to happen very often, but we do not know how many &quot;reboxers&quot; are eventually removed and how many are kept), and will keep the binding for x. But notice that x is only used in *one* of the branches in the case, but is always being allocated! The floating inwards pass would push its definition into the True branch. A similar benefit occurs if it is only used inside a let definition. These are basically the advantages of floating inwards, but they are only exposed after the S.A./worker-wrapperisation of the code! As we also have reasons to float inwards before S.A. we have to run it twice.</p>
<h1 id="overall-organisation-of-ghc">Overall organisation of GHC</h1>
<p>Start at the <a href="http://haskell.org/ghc">GHC home page</a>. The most important links are in the left-hand column:</p>
<p><code>*</code><a href="http://haskell.org/haskellwiki/GHC"><code>Documentation</code></a><code>.Thisisthe</code><em><code>user</code></em><code>documentation,aimedatpeoplewhouseGHC,butdon'tcarehowitworks.It'sontheHaskellWiki(poweredbyMediaWiki),andwestronglyencouragepeopletoeditandimproveit.</code></p>
<p><code>*</code><a href="http://hackage.haskell.org/trac/ghc"><code>Developers</code></a><code>.Thislinktakesyoutothehomepagefor</code><em><code>developers</code></em><code>;thatis,peopleinterestedinhackingonGHCitself(i.e.you).It'saWikitoo,butpoweredbyTrac,andincludesbug-trackingetc.ThereisabigsectioncalledDeveloperDocumentation:</code><strong><code>please</code> <code>help</code> <code>us</code> <code>to</code> <code>improve</code> <code>it</code></strong><code>.</code></p>
<p><code>*</code><a href="http://www.haskell.org/ghc/download.html"><code>Download</code></a><code>.Atanymoment,GHChasa</code><strong><code>STABLE</code> <code>branch</code></strong><code>andthe</code><strong><code>HEAD</code></strong><code>,bothofwhichyoucandownloadfromthispage.</code><a href="BR" title="wikilink"><code>BR</code></a><a href="BR" title="wikilink"><code>BR</code></a><br />
<code>*TheSTABLEbranchisthecurrentreleasedversion.Ithasanevenversionnumber(e.g.6.4,6.6),withanextrasuffixforpatch-levelrelease(e.g.6.4.2).Patch-levelrelesesfixbugs;theydonotchangeanyAPIs.</code><a href="BR" title="wikilink"><code>BR</code></a><a href="BR" title="wikilink"><code>BR</code></a><br />
<code>*TheHEADissimplythelatest,greatestversionthatweareworkingon;itmaybebrokenonanygivenday,althoughyouareencouragednottobreakitgratuitiously.TheHEADhasanoddversionnumbers(e.g6.5,6.7).EverynightwebuildtheHEAD,anddumptheresultonthedownloadsiteunder&quot;Developmentsnapshots&quot;,withaversionnumberthatencodesthedate(e..g6.5.20060831).</code></p>
<p><code>Averyusefullinkonthedownloadpageisthe</code><a href="http://www.haskell.org/ghc/dist/current/docs/"><code>documentation</code> <code>for</code> <code>the</code> <code>HEAD</code></a><code>(underDevelopmentsnapshots).UsefulbecausetypesettingthedocumentationusesDocBook,whicheasytoinstalloneveryplatform.</code></p>
<h1 id="ghc-source-code">GHC source code</h1>
<p>GHC's source code is several Darcs repositories. The important ones are:</p>
<p><a href="http://darcs.haskell.org/ghc" class="uri">http://darcs.haskell.org/ghc</a>:: All of GHC: compiler, run-time system, support utilities.</p>
<p><a href="http://darcs.hasekll.org/packages/pkg" class="uri">http://darcs.hasekll.org/packages/pkg</a>:: A library package <em>pkg</em>. A certain number of packages are essential to build GHC. They are listed in  and currently comprise: , , , , , , , , , , , .</p>
<p><a href="http://darcs.haskell.org/testsuite" class="uri">http://darcs.haskell.org/testsuite</a>:: GHC's test suite.</p>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<p><code></code><meta http-equiv="Content-Type" content="text/html; charset=utf-8" /><br />
<code></code><meta http-equiv="Content-Style-Type" content="text/css" /><br />
<code></code><meta name="generator" content="pandoc" /><br />
<code></code></p>
<title>
</title>
<style type="text/css">
<p>code{white-space: pre;}</p>
</style>
</head>
<body>
<div id="TOC">
<ul>
<li><a href="#the-ghc-commentary-checking-types">The GHC Commentary: Checking Types</a>
<ul>
<li><a href="#the-overall-flow-of-things">The Overall Flow of Things</a>
<ul>
<li><a href="#entry-points-into-the-type-checker">Entry Points Into the Type Checker</a></li>
<li><a href="#renaming-and-type-checking-a-module">Renaming and Type Checking a Module</a></li>
</ul></li>
<li><a href="#type-checking-a-declaration-group">Type Checking a Declaration Group</a></li>
<li><a href="#type-checking-type-and-class-declarations">Type checking Type and Class Declarations</a></li>
<li><a href="#more-details">More Details</a>
<ul>
<li><a href="#types-variables-and-zonking">Types Variables and Zonking</a></li>
<li><a href="#type-representation">Type Representation</a></li>
<li><a href="#type-checking-environment">Type Checking Environment</a></li>
<li><a href="#expressions">Expressions</a></li>
<li><a href="#handling-of-dictionaries-and-method-instances">Handling of Dictionaries and Method Instances</a></li>
</ul></li>
<li><a href="#connection-with-ghcs-constraint-solver">Connection with GHC's Constraint Solver</a></li>
<li><a href="#generating-evidence">Generating Evidence</a></li>
<li><a href="#the-solver">The Solver</a>
<ul>
<li><a href="#given-constraints">Given Constraints</a></li>
<li><a href="#derived-constraints">Derived Constraints</a></li>
<li><a href="#wanted-constraints">Wanted Constraints</a></li>
</ul></li>
</ul></li>
</ul>
</div>
<h1 id="the-ghc-commentary-checking-types">
<p>The GHC Commentary: Checking Types</p>
</h1>
<p>Probably the most important phase in the frontend is the type checker, which is located at <a href="GhcFile(compiler/typecheck/)" class="uri" title="wikilink">GhcFile(compiler/typecheck/)</a>. GHC type checks programs in their original Haskell form before the desugarer converts them into Core code. This complicates the type checker as it has to handle the much more verbose Haskell AST, but it improves error messages, as those message are based on the same structure that the user sees.</p>
<p>GHC defines the abstract syntax of Haskell programs in <a href="GhcModule(compiler/hsSyn/HsSyn.lhs)" class="uri" title="wikilink">GhcModule(compiler/hsSyn/HsSyn.lhs)</a> using a structure that abstracts over the concrete representation of bound occurences of identifiers and patterns. The module <a href="GhcModule(compiler/typecheck/TcHsSyn.lhs)" class="uri" title="wikilink">GhcModule(compiler/typecheck/TcHsSyn.lhs)</a> defines a number of helper function required by the type checker. Note that the type <a href="GhcModule(compiler/typecheck/TcRnTypes.lhs)" class="uri" title="wikilink">GhcModule(compiler/typecheck/TcRnTypes.lhs)</a>.`TcId` used to represent identifiers in some signatures during type checking is, in fact, nothing but a synonym for a [wiki:Commentary/Compiler/EntityTypes#Typevariablesandtermvariables plain Id].</p>
<p>It is also noteworthy, that the representations of types changes during type checking from `HsType` to `TypeRep.Type`. The latter is a [wiki:Commentary/Compiler/TypeType hybrid type] representation that is used to type Core, but still contains sufficient information to recover source types. In particular, the type checker maintains and compares types in their `Type` form.</p>
<h2 id="the-overall-flow-of-things">
<p>The Overall Flow of Things</p>
</h2>
<p><code>*</p>
<h1 id="updates">Updates</h1>
<p>Source files: <br /><span class="math display">$$\[GhcFile(rts/Updates.h)$$</span><br />\], <br /><span class="math display">$$\[GhcFile(rts/Updates.cmm)$$</span><br />\]</p>
<p>----CategoryStub</p>
<p>.. contents::</p>
<p><code>:depth:3</code></p>
<p>..</p>
<h2 id="unique">Unique</h2>
<p>``Unique``\ s provide a fast comparison mechanism for more complex things. Every ``RdrName``, ``Name``, ``Var``, ``TyCon``, ``TyVar``, etc. has a ``Unique``. When these more complex structures are collected (in ``UniqFM``\ s or other types of collection), their ``Unique`` typically provides the key by which the collection is indexed.</p>
<p>+----------------------------+ | == Current design == | +----------------------------+ | A ``Unique`` consists of | | the <em>domain</em> of the | | thing it identifies and a | | unique integer value | | 'within' that domain. The | | two are packed into a | | single ``Int#``, with the | | <em>domain</em> being the top 8 | | bits. | +----------------------------+ | The domain is never | | inspected (SLPJ believes). | | The sole reason for its | | existence is to provide a | | number of different ranges | | of ``Unique`` values that | | are guaranteed not to | | conflict. | +----------------------------+ | === Lifetime | +----------------------------+ | The lifetime of a | | ``Unique`` is a single | | invocation of GHC, i.e. | | they must not 'leak' to | | compiler output, the | | reason being that | | ``Unique``\ s may be | | generated/assigned | | non-deterministically. | | When compiler output is | | non-deterministic, it | | becomes significantly | | harder to, for example, | | [wiki:Commentary/Compiler/ | | RecompilationAvoidance | | avoid recompilation]. | | Uniques do not get | | serialised into .hi files, | | for example. | +----------------------------+ | Note, that &quot;one compiler | | invocation&quot; is not the | | same as the compilation of | | a single ``Module``. | | Invocations such as | | ``ghc --make`` or | | ``ghc --interactive`` give | | rise to longer invocation | | life-times. | +----------------------------+ | This is also the reasons | | why ``OccName``\ s are | | <em>not</em> ordered based on | | the ``Unique``\ s of their | | underlying | | ``FastString``\ s, but | | rather | | <em>lexicographically</em> (see | | <a href="GhcFile(compiler/basicTy" title="wikilink"> | pes/OccName.lhs)</a> | | for details). &gt; &gt; | | <strong>SLPJ:</strong> I am far from | | sure that the Ord instance | | for ``OccName`` is ever | | used, so this remark is | | probably misleading. Try | | deleting it and see where | | it is used (if at all). &gt; | | <strong>PKFH:</strong> At least | | ``Name`` and ``RdrName`` | | (partially) define their | | own ``Ord`` instances in | | terms of the instance of | | ``OccName``. Maybe these | | ``Ord`` instances are also | | redundant, but for now it | | seems wise to keep them | | in. When everything has | | ``Data`` instances (after | | this and many other | | redesigns), I'm sure it | | will be easier to find | | such dependency relations. | +----------------------------+ | === Known-key things === | +----------------------------+ | A hundred or two library | | entities (types, classes, | | functions) are so-called | | &quot;known-key things&quot;. See | | [wiki:Commentary/Compiler/ | | WiredIn | | this page]. A known-key | | thing has a fixed | | ``Unique`` that is fixed | | when the compiler is | | built, and thus lives | | across all invocations of | | that compiler. These | | known-key ``Unique``\ s | | <em>are</em> written into .hi | | files. But that's ok | | because they are fully | | deterministic and never | | change. | +----------------------------+ | &gt; <strong>PKFH</strong> That's fine | | then; we also know for | | sure these things fit in | | the 30 bits used in the | | ``hi``-files. I'll comment | | appropriately. | +----------------------------+ | === Interface files === | +----------------------------+ | Entities in a interface | | file (.hi file) are, for | | the most part, stored in a | | symbol table, and referred | | to (from elsewhere in the | | same interface file) by an | | index into that table. | | Here are the details from | | <a href="GhcFile(compiler/iface/B" title="wikilink"> | inIface.lhs)</a>: | | </p>
<hr />
<h2 id="redesign-2014">Redesign (2014)</h2>
<p>=== TL;DR The redesign is to accomplish the following: \* Allow derivation of type class instances for ``Unique`` \* Restore invariants from the original design; hide representation details \* Eliminate violations of invariants and design-violations in other places of the compiler (e.g. ``Unique``\ s shouldn't be written to ``hi``-files, but are). &gt; &gt; <strong>SLPJ</strong> I don't think this is a design violation; see above. Do you have any other examples in mind? &gt; <strong>PKFH</strong> Not really of design-violations (and no other compiler-output stuff) other than the invariants mentioned above it, just yet. The key point, though, is that there are a lot of comments in ``Unique`` about not exporting things so that we know X, Y and Z, but then those things <em>are</em> exported, so we don't know them to be true. Case in point is the export of ``mkUnique``, but also ``mkUniqueGrimily``. The latter has a comment 'only for ``UniqSupply``' but is also used in other places (like Template Haskell). One redesign is to put this restriction in the name, so there still is the facility offered by ``mkUniqueGrimily``, but now it's called ``mkUniqueOnlyForUniqSupply`` (and ``mkUniqueOnlyForTemplateHaskell``), the ugliness of which should help, over time, to get rid of them.</p>
<p>=== Longer</p>
<p>In an attempt to give more of GHC's innards well-behaved instances of ``Typeable``, ``Data``, ``Foldable``, ``Traversable``, etc. the implementation of ``Unique``\ s was a bit of a sore spot. They were implemented (20+ years earlier) using custom boxing, viz.  making automatic derivation of such type class instances hard. There was already a comment asking why it wasn't simply a ``newtype`` around a normal (boxed) ``Int``. Independently, there was some discussion on the mailinglists about the use of (signed) ``Int``\ s in places where ``Word``\ s would be more appropriate. Further inspection of the ``Unique`` implementation made clear that a lot of invariants mentioned in comments had been violated by incremental edits. This is discussed in more detail below, but these things together (the desire for automatic derivation and the restoration of some important invariants) motivated a moderate redesign.</p>
<p>=== Status Quo (pre redesign)</p>
<p>A ``Unique`` has a domain (``TyCon``, ``DataCon``, ``PrelName``, ``Builtin``, etc.) that was codified by a character. The remainder of the ``Unique`` was an integer that should be unique for said domain. This <strong>was</strong> once guaranteed through the export list of <a href="GhcFile(compiler/basicTypes/Unique.lhs)" class="uri" title="wikilink">GhcFile(compiler/basicTypes/Unique.lhs)</a>, where direct access to the domain-character was hidden, i.e.  were not exported. This should have guaranteed that every domain was assigned its own unique character, because only in <a href="GhcFile(compiler/basicTypes/Unique.lhs)" class="uri" title="wikilink">GhcFile(compiler/basicTypes/Unique.lhs)</a> could those ``Char``\ s be assigned. However, through  this separation of concerns leaked out to <a href="GhcFile(compiler/basicTypes/UniqSupply.lhs)" class="uri" title="wikilink">GhcFile(compiler/basicTypes/UniqSupply.lhs)</a>, because its ``Int`` argument is the <em>entire</em> ``Unique`` and not just the integer part 'under' the domain character. &gt; &gt; <strong>SLPJ</strong> OK, but to eliminate ``mkUniqueGrimily`` you need to examine the calls, decide how to do it better, and document the new design. &gt; <strong>PKFH</strong> See above; the solution for now is ``mkUniqueOnlyForUniqSupply``. A separate patch will deal with trying to refactor/redesign ``UniqSupply`` if this is necessary.</p>
<p>The function ``mkSplitUniqSupply`` made the domain-character accessible to all the other modules, by having a wholly separate implementation of the functionality of ``mkUnique``.</p>
<p>Where the intention was still to have a clean interface, the (would-be) hidden ``mkUnique`` is only called by functions defined in the ``Unique`` module with the corresponding character, e.g. </p>
<p>=== New plan</p>
<p>In the new design, the domains are explicitly encoded in a sum-type ``UniqueDomain``. At the very least, this should help make the code a little more self-documenting <em>and</em> prevent accidental overlap in the choice of bits to identify the domain. Since the purpose of ``Unique``\ s is to provide <em>fast</em> comparison for different types of things, the redesign should remain performance concious. With this in mind, keeping the ``UniqueDomain`` and the integer-part explicitly in the type  seems unwise, but by choosing  we win the ability to automatically derive things and should also be able to test how far optimisation has come in the past 20+ years; does default boxing with ``newtype``-style wrapping have (nearly) the same performance as manual unboxing? This should follow from the tests.</p>
<p>The encoding is kept the same, i.e. the ``Word`` is still built up with the domain encoded in the most significant bits and the integer-part in the remaining bits. However, instead encoding the domain as a ``Char`` in the (internal <em>and</em> external interface), we now create an ADT (sum-type) that encodes the domain. This has two advantages. First, it prevents people from picking domain-tags ad hoc an possibly overlapping. Second, encoding in the ``Word`` does not rely on the assumption that the domain requires and/or fits in 8 bits. Since Haskell ``Char``\ s are unicode, the 8-bit assumption is wrong for the old design. In other words, the above examples are changed to:</p>
<p></p>
<p>Ideal world scenario, the entire external interface would be:  and the instances for ``Eq``, ``Ord``, ``Data``, etc. For now, though, it will also have </p>
<p><code></code><strong><code>SLPJ</code></strong><code>Iagreethata``newtype``arounda``Word``is</code><br />
<code>betterthana``data``typearound``Int#``.Thatisasmall,</code><br />
<code>simplechange.ButIthinkyouplantodomorethanthis,and</code><br />
<code>that&quot;more&quot;isnotdocumentedhere.E.g.whatisthenewAPIto</code><br />
<code>``Unique``?</code><strong><code>PKFH</code></strong><code>Added.Seeabove.</code></p>
<p><a href="PageOutline" class="uri" title="wikilink">PageOutline</a></p>
<h1 id="the-data-type-and-its-friends">The data type  and its friends</h1>
<p>GHC compiles a typed programming language, and GHC's intermediate language is explicitly typed. So the data type that GHC uses to represent types is of central importance.</p>
<p>The single data type  is used to represent \* Types (possibly of higher kind); e.g. ``[Int]``, ``Maybe`` \* Kinds (which classify types and coercions); e.g. ``(* -&gt; *)``, ``T :=: [Int]``. See [wiki:Commentary/Compiler/Kinds] \* Sorts (which classify types); e.g. ``TY``, ``CO``</p>
<p>GHC's use of [wiki:Commentary/Compiler/FC coercions and equality constraints] is important enough to deserve its own page.</p>
<p>The module  exposes the representation because a few other modules (, , , etc) work directly on its representation. However, you should not lightly pattern-match on ; it is meant to be an abstract type. Instead, try to use functions defined by ,  etc.</p>
<h2 id="views-of-types">Views of types</h2>
<p>Even when considering only types (not kinds, sorts, coercions) you need to know that GHC uses a <em>single</em> data type for types. You can look at the same type in different ways:</p>
<p>- The &quot;typechecker view&quot; regards the type as a Haskell type, complete</p>
<p><code>withimplicitparameters,classconstraints,andthelike.For</code><br />
<code>example:</code><code>Functionsin</code><br />
<code>``TcType``takethisviewoftypes;e.g.``tcSplitSigmaTy``splitsup</code><br />
<code>atypeintoitsforall'dtypevariables,itsconstraints,andthe</code><br />
<code>rest.</code></p>
<p>- The &quot;core view&quot; regards the type as a Core-language type, where class</p>
<p><code>andimplicitparameterconstraintsaretreatedasfunctionarguments:</code><br />
<code></code><code>Functionsin``Type``take</code><br />
<code>thisview.</code></p>
<p>The data type ``Type`` represents type synonym applications in un-expanded form. E.g.  Here ``f``'s type doesn't look like a function type, but it really is. The function ``Type.coreView :: Type -&gt; Maybe Type`` takes a type and, if it's a type synonym application, it expands the synonym and returns ``Just <expanded-type>``. Otherwise it returns ``Nothing``.</p>
<p>Now, other functions use ``coreView`` to expand where necessary, thus:  Notice the first line, which uses the view, and recurses when the view 'fires'. Since ``coreView`` is non-recursive, GHC will inline it, and the optimiser will ultimately produce something like: </p>
<h2 id="the-representation-of">The representation of </h2>
<p>Here, then is the representation of types (see <a href="GhcFile(compiler/types/TypeRep.hs)" class="uri" title="wikilink">GhcFile(compiler/types/TypeRep.hs)</a> for more details): </p>
<p>Invariant: if the head of a type application is a , GHC <em>always</em> uses the  constructor, not . This invariant is maintained internally by 'smart constructors'. A similar invariant applies to ;  is never used with an arrow type.</p>
<p>Type variables are represented by the ``TyVar`` constructor of the [wiki:Commentary/Compiler/EntityTypes data type Var].</p>
<h2 id="overloaded-types">Overloaded types</h2>
<p>In Haskell we write  but in Core the ``=&gt;`` is represented by an ordinary ``FunTy``. So f's type looks like this:  Nevertheless, we can tell when a function argument is actually a predicate (and hence should be displayed with ``=&gt;``, etc), using  The various forms of predicate can be extracted thus:  These functions are defined in module ``Type``.</p>
<h2 id="classifying-types">Classifying types</h2>
<p>GHC uses the following nomenclature for types:</p>
<p><strong>Unboxed</strong>:: A type is unboxed iff its representation is other than a pointer. Unboxed types are also unlifted.</p>
<p><strong>Lifted</strong>:: A type is lifted iff it has bottom as an element. Closures always have lifted types: i.e. any let-bound identifier in Core must have a lifted type. Operationally, a lifted object is one that can be entered. Only lifted types may be unified with a type variable.</p>
<p><strong>Data</strong>:: A type declared with <strong></strong>. Also boxed tuples.</p>
<p><strong>Algebraic</strong>:: An algebraic data type is a data type with one or more constructors, whether declared with  or . An algebraic type is one that can be deconstructed with a case expression. &quot;Algebraic&quot; is <strong>NOT</strong> the same as &quot;lifted&quot;, because unboxed (and thus unlifted) tuples count as &quot;algebraic&quot;.</p>
<p><strong>Primitive</strong>:: a type is primitive iff it is a built-in type that can't be expressed in Haskell.</p>
<p>Currently, all primitive types are unlifted, but that's not necessarily the case. (E.g. Int could be primitive.)</p>
<p>Some primitive types are unboxed, such as Int#, whereas some are boxed but unlifted (such as ``ByteArray#``). The only primitive types that we classify as algebraic are the unboxed tuples.</p>
<p>Examples of type classifications:</p>
<p>\|\| \|\| <strong>Primitive</strong> \|\| <strong>Boxed</strong> \|\| <strong>Lifted</strong> \|\| <strong>Algebraic</strong> \|\| \|\| ``Int#`` \|\| Yes \|\| No \|\| No \|\| No \|\| \|\| ``ByteArray#`` \|\| Yes \|\| Yes \|\| No \|\| No \|\| \|\| ``(# a, b #)`` \|\| Yes \|\| No \|\| No \|\| Yes \|\| \|\| ``( a, b )`` \|\| No \|\| Yes \|\| Yes \|\| Yes \|\| \|\| ``[a]`` \|\| No \|\| Yes \|\| Yes \|\| Yes \|\|</p>
<h1 id="package-compatibility">Package Compatibility</h1>
<p>In GHC 6.8.1 we reorganised some of the contents of the packages we ship with GHC, see #710. The idea was to lessen the problem caused by the base package being essentially static between GHC major releases. By separating modules out of base and putting them into separate packages, it is possible to updgrade these modules independently of GHC.</p>
<p>The reorganisations unfortunately exposed some problems with our package infrastructure, in particular most packages that compiled with 6.6 do not compile with 6.8.1 because they don't depend on the new packages. Some instructions for upgrading packages are here: <a href="http://haskell.org/haskellwiki/Upgrading_packages">Upgrading packages</a>.</p>
<p>We anticipated the problem to some extent, adding &quot;configurations&quot; to Cabal to make it possible to write conditional package specifications that work with multiple sets of dependencies. We are still left with the problem that the `.cabal` files for all packages need to be updated for GHC 6.8.1. This seems like the wrong way around: the change we made to a few packages has to be propagated everywhere, when there should be a way to confine it locally, at least for the purposes of continued compatibility with existing source code. In many cases, the underlying APIs are still available, just from a different place. (in general this may not be true - modifications to packages may make changes to APIs which require real changes to dependent packages).</p>
<p>Some of the problems that contributed to this situation can be addressed. We wrote the <a href="http://haskell.org/haskellwiki/Package_versioning_policy">Package Versioning Policy</a> so that packages can start using versions that reflect API changes, and so that dependencies can start being precise about which dependencies they work with. If we follow these guidelines, then</p>
<p><code>*failureswillbemorepredictable</code><br />
<code>*failureswillbemoreinformative</code></p>
<p>because dependencies and API changes are better documented. However, we have no fewer failures than before, in fact we have more because packages cannot now &quot;accidentally work&quot; by specifying loose dependency ranges.</p>
<p>So the big question is, what changes do we need to make in the future to either prevent this happening, or to reduce the pain when it does happen? Below are collected various proposals. If the proposals get too long we can separate them out into new pages.</p>
<h2 id="dont-reorganise-packages">1. Don't reorganise packages</h2>
<p>We could do this, but that just hides the problem and we're still left with a monolithic base package. We still have to contend with API changes causing breakage.</p>
<h2 id="provide-older-versions-of-base-with-a-new-ghc-release">2. Provide older version(s) of base with a new GHC release</h2>
<p>We could fork the base package for each new release, and keep compiling the old one(s). Unfortunately we would then have to compile every other package two (or more) times, once against each version of base. And if we were to give the same treatment to any other library, we end up with exponential blowup in the number of copies.</p>
<p>The GHC build gets slower, and the testing surface increases for each release.</p>
<p>Furthermore, the package database cannot currently understand multiple packages compiled against different versions of dependencies. One workaround is to have multiple package databases, but that's not too convenient.</p>
<h2 id="allow-packages-to-re-export-modules">4. Allow packages to re-export modules</h2>
<p>Packages currently cannot re-export modules from other packages. Well, that's not strictly true, it is possible to do this but it currently requires an extra package and two stub modules per module to be re-exported (see <a href="http://www.haskell.org/pipermail/haskell-cafe/2007-October/033141.html">7</a>).</p>
<p>This could be made easier. Suppose you could write this:</p>
<p></p>
<p>to construct a module called `Data.Maybe` that re-exports the module `Data.Maybe` from package `base-2.0`. This extension to the import syntax was proposed in PackageImports.</p>
<p>Using this extension, we can construct packages that re-export modules using only one stub module per re-exported module, and Cabal could generate the stubs for us given a suitable addition to the `.cabal` file syntax.</p>
<p>Package re-exports are useful for</p>
<p><code>*Constructingpackagesthatarebackwards-compatiblewitholdpackagesbyre-exportingpartsofthenewAPI.</code><br />
<code>*Providingasinglewrapperforchoosingoneofseveralunderlyingproviders</code></p>
<h2 id="provide-backwards-compatible-versions-of-base">4.1 Provide backwards-compatible versions of base</h2>
<p>So using re-exports we can construct a backwards-compatible version of base (`base-2.0` that re-exports `base-3.0` and the other packages that were split from it). We can do this for other packages that have changed, too. This is good because:</p>
<p><code>*Codeissharedbetweenthetwoversionsofthepackage</code><br />
<code>*Multipleversionsofeachpackagecancoexistinthesameprogrameasily(unlikeinproposal2)</code></p>
<p>However, this approach runs into problems when types or classes, rather than just functions, change. Suppose in `base-3.0` we changed a type somewhere; for example, we remove a constructor from the `Exception` type. Now `base-2.0` has to provide the old `Exception` type. It can do this, but the `Exception` type in `base-2.0` is now incompatible with the `Exception` type in `base-3.0`, so every function that refers to `Exception` must be copied into `base-2.0`. At this point we start to need to recompile other packages against `base-2.0` too, and before long we're back in the state of proposal (2) above.</p>
<p>This approach therefore doesn't scale to API changes that include types and classes, but it can cope with changes to functions only.</p>
<h2 id="rename-base-and-provide-a-compatibility-wrapper">4.2 Rename base, and provide a compatibility wrapper</h2>
<p>This requires the re-exporting functionality described above. When splitting base, we would rename the base package, creating several new packages. e.g. `base-3.0` would be replaced by `newbase-1.0`, `concurrent-1.0`, `generics-1.0`, etc. Additionally, we would provide a wrapper called `base-4.0` that re-exports all of the new packages.</p>
<p>Advantages:</p>
<p><code>*Updatestoexistingpackagesaremucheasier(noconfigurationsrequired)</code><br />
<code>*Doesn'tfallintothetrapoftryingtomaintainacompletelybackwards-compatibleversionoftheoldAPI,asin4.1</code></p>
<p>Disadvantages:</p>
<p><code>*AllpackagesstillbreakwhenthebaseAPIchanges(iftheyareusingprecisedependenciesonbase,whichtheyshouldbe)</code><br />
<code>*Backwardscompatibilitycruftintheformofthe`base`wrapperwillbehardtogetridof;there'sno</code><br />
<code>incentiveforpackagestostopusingit.Perhapsweneedadeprecationmarkeronpackages.</code><br />
<code>*Eachtimewesplitbasewehavetoinventanewnameforit,andweaccumulateanewcompatibilitywrapper</code><br />
<code>fortheoldone.</code></p>
<h2 id="dont-rename-base">4.3 Don't rename base</h2>
<p>This is a slight variation on 4.2, in which instead of renaming `base` to `newbase`, we simply provide two versions of `base` after the split. Take the example of splitting `base-3.0` into `base + concurrent + generics` again:</p>
<p><code>*`base-4.0`istheremainingcontentsof`base-3.0`afterthesplit</code><br />
<code>*`base-3.1`isacompatibilitywrapper,re-exporting`base-4.0+concurrent-1.0+generics-1.0`.</code></p>
<p>The idea is that all existing packages that worked with `base-3.0` will have  or similar. To make these work after the split, all that is needed is to modify the upper bound:  which is better than requiring a conditional dependency, as was the case with the `base-3.0` split. In due course, these packages can be updated to use the new `base-4.0`.</p>
<p>Advantages: the same as 4.2, plus there's no need to rename `base` for each split. Disadvantages: multiple versions of `base` could get confusing. The upgrade path is still not completely smooth (existing packages all need to be modified manually).</p>
<h2 id="do-some-kind-of-providesrequires-interface-in-cabal">5. Do some kind of provides/requires interface in Cabal</h2>
<p>Currently, Cabal's idea of API is asymmetric and very coarse: the client depends on a package by name and version only, the provider implements a single package name and version by exposing a list of modules. That has several disadvantages:</p>
<p><code>*Cabalcannotensurebuildsafety:mosterrorswillnotshowupbeforebuild-time(contrastthatwithHaskell'susualmodelofstatictypesafety).</code><br />
<code>*Cabalhasnoideawhatadependencyconsistsofunlessitisinstalled.evenifitisinstalled,itonlyknowsthemodulesexposed.TheactualAPImightbedefinedinHaddockcomments,butisnotformallyspecifiedorverified.</code></p>
<h3 id="make-api-specifications-more-symmetric">5.1 Make API specifications more symmetric</h3>
<p>Just as a provider lists the modules it exposes, clients should list the modules they import (this field should be inferred by a 'ghc -M'-style dependency analysis). Advantages:</p>
<p><code>*Cabalwouldhaveanideawhichpartsofapackageaclientdependsoninsteadofdefaultingto&quot;everyclientneedseverything&quot;(example:clientsusingonlypartsoftheoldbasenotsplitoffshouldbehappywiththenewbase)</code><br />
<code>*Cabalwouldhaveanideawhatamissingdependencywasmeanttoprovide(example:clientsusingpartsoftheoldbasethathavebeensplitoffcouldbeofferedthesplit-offpackagesasalternativeprovidersofthemodulesimported)</code></p>
<h3 id="make-api-specifications-explicit">5.2 Make API specifications explicit</h3>
<p>Currently, the name and version of a package are synonymous with its API. That is like modules depending on concrete data type representations instead of abstract types. It should not really matter that the functionality needed by package P was only available in package Q-2.3.42 at the time P was written. What should matter is which parts of Q are needed for P, and which packages are able to provide those parts when P is built.</p>
<p>Section 5.1 above suggests to make this specification at least at the level of modules, in both providers and clients. But even if one wanted to stay at the coarser level of API names and versions, one should distinguish between an API and one of its implementing packages. Each client should list the APIs it depends on, each provider should list the APIs it can be called upon to provide.</p>
<p>One can achieve some of this in current Cabal by introducing intermediate packages that represent named APIs to clients while re-exporting implementations of those APIs by providers. Apart from needing re-export functionality, this is more complicated than it should be.</p>
<h3 id="make-api-specifications-more-specific">5.3 Make API specifications more specific</h3>
<p>If one compares Cabal's ideas of packages and APIs with Standard ML's module language, with its structures, functors, and interfaces forming part of a statically typed functional program composition language, one can see a lot of room for development.</p>
<h2 id="distributions-at-the-hackage-level">6. Distributions at the Hackage level</h2>
<p>The idea here is to group packages into &quot;distributions&quot; in Hackage, with the property that all packages within a distribution are mutually compatible. Todo... expand.</p>
<h2 id="allow-package-overlaps">7. Allow package overlaps</h2>
<p>This is not a solution to the problem of splitting a package but helps in the case that we want to use a new package that provides an updated version of some modules in an existing package. An example of this is the bytestring and base package. The base-2.0 package included Data.ByteString but it was split off into a bytestring package and not included in base-3.0. At the moment ghc allows local .hs files to provide modules that can shadow modules from a package but does not packages to shadow each other.</p>
<p>So an extension that would help this case would be to let packages shadow each other. The user would need to specify an ordering on packages so ghc knows which way round the shadowing should go. This could be specified by the order of the -package flags on the command line, which is equivalent to the order in which they are listed in the build-depends field in a .cabal file. This would be a relatively easy extension to implement.</p>
<p>Note that it only solves the problem of backporting packages to be used on top of older versions of the package they were split from. It also provides a way for people to experiment with packages that provide alternative implementations of standard modules.</p>
<p>There is potential for confusion if this is used too heavily however. For example two packages built against standard and replacement modules may not be able to be used together because they will re-export different types.</p>
<h2 id="the-problem-of-lax-version-dependencies">The problem of lax version dependencies</h2>
<p>Supposing that we used solution 2 above and had a base-2.x and a base-3.x. If we take an old package and build it against base-2.x then it will work and if we build it against base-3.x then it'll fail because it uses modules from the split out packages like directory, bytestring etc. So obviously Cabal should select base-2.x, but how is this decision actually supposed to be made automatically? From a quick survey of the packages on hackage we find that 85% specify unversioned dependencies on the base package and none of them specify upper bounds for the version of base. So presented with a package that says:</p>
<p></p>
<p>how are we to know if we should use base-2.x or base-3.x. It may be that this package has been updated to work with base-3.x or that it only ever used the parts of base-2.x that were not split off. This dependency does not provide us with enough information to know which to choose. So we are still left with the situation that every package must be updated to specify an api version of base.</p>
<p>One possible remedy would be to call version 3 something other than base. Any dependency on 'base' would then refer to the set of modules that comprise base-2.x (this is (4.2) above, incedentally).</p>
<h1 id="note-about-this-page">Note about this page</h1>
<p><code></code><em><code>Apparently,</code> <code>this</code> <code>page</code> <code>is</code> <code>out</code> <code>of</code> <code>date</code> <code>and</code> <code>the</code> <code>issue</code> <code>has</code> <code>been</code> <code>settled</code> <code>in</code> <code>favour</code> <code>of</code> <code>the</code> <code>syntax:</code></em><br />
<code></code><br />
<code>Seealso:</code><br />
<code></code><a href="http://haskell.org/ghc/docs/latest/html/users_guide/syntax-extns.html#package-imports"><code>8</code></a></p>
<h1 id="explicit-package-imports">Explicit package imports</h1>
<p>This proposal is one possibility for addressing the question of identifying which package is meant in an import declaration. For the context, read the [wiki:Commentary/Packages/GhcPackagesProposal GHC packages summary page] first.</p>
<p>The main idea of this proposal is to allow the programmer to specify the source package in the import line, something like this:  That would presumably get the most recent installed incarnation of the  package. If you want a particular version of the package, we could allow  The exact syntax is unimportant. The important thing is that the programmer can specify the package in the source text. Note that this fundamentally conflicts with the second assumption we started with. We were trying to avoid specifying &quot;provenance&quot; at the same time as &quot;purpose&quot;, on the grounds that we wanted to avoid editing lots of source text when the provenance changed. (And so it begs the question, if we need to edit the source anyway, why separate the syntax of packages from modules at all?)</p>
<p>If we adopt the idea that an import statement can specify the source package, several design choices arise:</p>
<h2 id="is-the-from-compulsory">Is the 'from <package>' compulsory?</h2>
<p>If you want to import A.B.C, a module exported by package &quot;foo&quot;, can you say just , or must you say ?</p>
<p>We think of this as rather like the question &quot;If you import f from module M, can you refer to it as plain &quot;f&quot;, or must you refer to it as &quot;M.f&quot;? The answer in Haskell 98 is that you can refer to it as plain &quot;f&quot; so long as plain &quot;f&quot; is umambiguous; otherwise you can use a qualified reference &quot;M.f&quot; to disambiguate.</p>
<p>We propose to adopt the same principle for imports. That is, an import with no package specified, such as &quot;&quot;, means:</p>
<p><code>FindallmodulesA.B.Cexportedbyallexposedpackages,orthepackageorprogrambeingcompiled.Ifthereisexactlyonesuchmodule,that'stheonetoimport.Otherwisereport&quot;ambiguousimport&quot;.</code></p>
<p>If the reference to A.B.C is ambiguous, you can qualify the import by adding &quot;&quot;.</p>
<h2 id="package-versions">Package versions</h2>
<p>We probably want some special treatment for multiple versions of the same package. What if you have both &quot;foo-3.9&quot; and &quot;foo-4.0&quot; installed, both exporting A.B.C? This is jolly useful when you want to install new packages, but keep old ones around so you can try your program with the older one. So we propose that this is not regarded as ambiguous: importing A.B.C gets the latest version, unless some compiler flag (-hide-package) takes it of the running.</p>
<p>In short, an installed package can be of two kinds:</p>
<p><code>*</code><strong><code>Exposed</code></strong><code>:thepackage'smodulespopulatetheglobalmodulenamespace,andcanbeimportedwithoutmentioningthepacckagenameexplicitly(</code><code>).Explicit&quot;from&quot;importsmaybeusedtoresolveambiguity.</code><br />
<code>*</code><strong><code>Available</code></strong><code>,butnotexposed:thepackagecanbeusedonlybyanexplicit&quot;from&quot;import.Thisisratherlike&quot;</code><code>,exceptatthepackagelevel.</code></p>
<p>Typically, if multiple versions of the same package are installed, then all will be available, but only one will be exposed.</p>
<p>GHC's command-line flags (, ) can be used to manipulate which packages are exposed, but typically an entire package or program will be compiled with a single set of such flags. GHC does not curretly support in-module control, thus , and we do not propose to change that.</p>
<p>Simon suggested that an installed package might be hidden (so that it cannot be used at all) but I'm not sure why we need that.</p>
<h2 id="importing-from-the-home-package">Importing from the home package</h2>
<p>If A.B.C is in the package being compiled (which we call &quot;the home package&quot;), and in an exposed package, and you say , do you get an &quot;ambiguous import&quot; error , or does the current package override. And if the former, how can you say &quot;import A.B.C from the current package&quot;?</p>
<p>One possibility is to reuqire the code to know its own package name, and mention that in the import. For exmaple, in a module that is being compiled as part package &quot;foo&quot;, you'd say . What about modules that are part of the main program (not a package at all). Perhaps you could then say .</p>
<p>Another way is to have a special package name meaning &quot;the home package&quot;. The special name could be</p>
<p><code>*&quot;&quot;</code><br />
<code>*&quot;home&quot;</code><br />
<code>*&quot;this&quot;</code><br />
<code>*this(withnoquotes)</code></p>
<h2 id="the-as-p-alias">The 'as P' alias</h2>
<p>We propose to maintain the local, within-module &quot;as P&quot; alias mechanism unchanged. Thus:  Here, the qualified name &quot;M.T&quot; refers to the T imported from A.B.C in package &quot;foo&quot;.</p>
<h2 id="qualified-names">Qualified names</h2>
<p>We propose that the default qualified name of an entity within a module is just the module name plus the entity name. Thus  If you want to import multiple A.B.C's (from different packages) then perhaps they define different entities, in which case there is no problem:  But if they both export entities with the same name, there is no alternative to using the 'as M' mechanism: </p>
<h2 id="exporting-modules-from-other-packages">Exporting modules from other packages</h2>
<p>It is perfectly OK to export entities, or whole modules, imported from other packages: </p>
<h2 id="syntax">Syntax</h2>
<p>Should package names be in quotes? Probably yes, because they have a different lexcal syntax to the rest of Haskell. (&quot;foo-2.3&quot; would parse as three tokens, &quot;foo&quot;, &quot;-&quot;, and &quot;2.3&quot;.</p>
<p>It's been suggested that one might want to import several modules from one package in one go:  What we don't like about that is that it needs a new keyword &quot;&quot;. Perhaps all imports can start with the keyword , and then we are free to use extra (context-specific) keywords. (Haskell already has several of these, such as . Something like this:</p>
<p> Here the layout is explicit, but the braces and semicolons could be avoided by making use of the layout rule as usual.</p>
<p>Indeed, we could allow this multiple form even for ordinary imports: </p>
<p>It is clear from the above examples that the keyword  is redundant - the presence of a string literal (or special keyword to denote the home package) after the keyword  is sufficient to distinguish per-package imports from the ordinary shared-namespace imports, so the above could instead be written as </p>
<h3 id="syntax-formalised-and-summarised">Syntax formalised and summarised</h3>
<p>A possible syntax which covers everything in this proposal is therefore:</p>
<p><code></code><strong><code>import</code></strong><code>[</code><em><code>package-name</code></em><code>]</code><strong><code>{</code></strong><code></code><em><code>import-specifier</code></em><code>[</code><strong><code>;</code></strong><code></code><em><code>import-specifier</code></em><code>]</code><strong><code>}</code></strong></p>
<p>where <em>package-name</em> is a string literal or the keyword , the <em>import-specifier</em> corresponds to everything that is currently allowed after the keyword , and the braces and semicolons would be added by the layout rule. </p>
<h3 id="proposal-for-package-mounting">Proposal for Package Mounting</h3>
<p>It may help to refer to [wiki:Commentary/Packages/GhcPackagesProposal] for an introduction to some of the issues mentioned here.</p>
<p>A message by Frederik Eaton to the Haskell mailing list describing the present proposal is archived: <a href="http://www.haskell.org/pipermail/libraries/2005-June/004009.html">9</a>. (Also, see note at the end of this document regarding an earlier proposal by Simon Marlow)</p>
<p>This document will go over Frederik's proposal again in brief. The proposal doesn't involve any changes to syntax, only an extra command line option to , etc., and a small change to Cabal syntax.</p>
<p>In this proposal, during compilation of a module, every package would have a &quot;mount point&quot; with respect to which its particular module namespace would be resolved. Each package should have a default &quot;mount point&quot;, but this default would be overridable with an option to , etc.</p>
<p>For example, the  library currently has module namespace:</p>
<p></p>
<p>In this proposal, it might instead have default mount point  and (internal) module namespace:</p>
<p></p>
<p>To most users of the X11 package, there would be no change - because of the mounting, modules in that package would still appear with the same names in places where the X11 package is imported: , etc. However, if someone wanted to specify a different the mount point, he could use a special compiler option, for instance :</p>
<p></p>
<p>(so the imported namespace would appear as , , etc.) Note that the intention is for each  option to refer to the package specified in the preceding  option, so to give package  a mount point of  we use the syntax</p>
<p></p>
<p>Ideally one would also be able to link to two different versions of the same package, at different mount points:</p>
<p></p>
<p>(yielding , , ...; , , ...)</p>
<p>However, usually the default mount point would be sufficient, so most users wouldn't have to learn about .</p>
<p>Additionally, Cabal syntax should be extended to support mounting. I would suggest that the optional mount point should appear after a package in the Build-Depends clause of a Cabal file:</p>
<p></p>
<p>And in the package Cabal file, a new clause to specify the default mount point:</p>
<p></p>
<h3 id="evaluation">Evaluation</h3>
<p>This proposal has several advantages over the [wiki:Commentary/Packages/PackageImportsProposal] proposal.</p>
<p><code>*</code><em><code>No</code> <code>package</code> <code>names</code> <code>in</code> <code>code</code></em><code>.Inthisproposal,packagenameswouldbedecoupledfromcode.Thisisveryimportant.Itshouldbepossibletorenameapackage(orcreateanewversionofapackagewithanewname),anduseitinaproject,withouteditingeverysinglemoduleoftheprojectand/orpackage.Eveniftheeditscouldbedoneautomatically,theywouldstillcauserevisioncontrolheadaches.AnyproposalwhichputspackagenamesinHaskellsourcecodeshouldbeconsideredunacceptable.</code></p>
<p><code>*</code><em><code>No</code> <code>syntax</code> <code>changes</code></em><code>.The[wiki:Commentary/Packages/PackageImportsProposal]proposalrequiresnewsyntax,butthisproposaldoesnot.Ofcourse,inthisproposalitwouldbeslightlymoredifficultfortheprogrammertofindoutwhichpackageamoduleiscomingfrom.Hewouldhavetolookatthecommandlinethatcompilesthecodehe'sreading.However,Ithinkthatthatisappropriate.Provenanceshouldnotbespecifiedincode,sinceitchangesallthetime.(AndtherecouldbeasimpledebuggingoptiontoGHCwhichoutputsadescriptionofthenamespaceusedwhencompilingeachfile)</code></p>
<p><code>*</code><em><code>Simpler</code> <code>module</code> <code>names</code></em><code>.Thisproposalwouldallowlibraryauthorstousesimplermodulenamesintheirpackages,whichwouldinturnmakelibrarycodemorereadable,andmoreportablebetweenprojects.Forinstance,imaginethatIwantedtoimportsomeofthecodefromthe</code><code>libraryintomyownproject.Currently,Iwouldhavetodeleteeveryoccurrenceof</code><code>inthosemodules.Mergingfuturechangesaftersuchanextensivemodificationwouldbecomedifficult.Thisisarealproblem,whichIhaveencounteredwhileusingJohnMeacham'scurseslibrary.Thereareseveraldifferentversionsofthatlibrarybeingusedbydifferentpeopleindifferentprojects,anditisdifficulttoconsolidatethembecausetheyallhavedifferentmodulenames.Thereasontheyhavedifferentmodulenamesisthatpackagemountinghasn'tbeenimplementedyet.The[wiki:Commentary/Packages/PackageImportsProposal]proposalwouldnotfixtheproblem.</code></p>
<p><code>*</code><em><code>Development</code> <code>decoupled</code> <code>from</code> <code>naming</code></em><code>.(thereisabitofoverlapwithpreviouspointshere)Inthepresentproposal,programmerswouldbeabletostartwritingalibrarybeforedecidingonanameforthelibrary.Forinstance,everymoduleinthe</code><code>librarycontainstheprefix</code><code>.Thismeansthateithertheauthorofthelibraryhadtochoosethename</code><code>attheverybeginning,orhehadtomakeseveralchangestothetextofeachmoduleafterdecidingonthename.Underthepresentproposal,hewouldsimplycallhismodules</code><code>,</code><code>,</code><code>,etc.;the</code><code>prefixwouldbespecifiedinthebuildsystem,forinstanceintheCabalfile.</code></p>
<p>Frederik's mailing list message discusses some other minor advantages, but the above points are the important ones. In summary, it is argued that the above proposal should be preferred to [wiki:Commentary/Packages/PackageImportsProposal] because it is both easier to implement (using command line options rather than syntax), and more advantageous for the programmer.</p>
<h3 id="note-on-package-grafting">Note on Package Grafting</h3>
<p>A proposal by Simon Marlow for &quot;package grafting&quot; predates this one: <a href="http://www.haskell.org/pipermail/libraries/2003-August/001310.html">10</a>. However, the &quot;package grafting&quot; proposal is different in that it suggests selecting a &quot;mount point&quot; at library installation time, where in the present proposal, the &quot;mount point&quot; is selected each time a module using the library in question is compiled. The difference is important, as one doesn't really want to have to install a new copy of a library just to use it with a different name. Also, Simon Marlow's proposal puts package versions in the module namespace and therefore source code, where we argue for decoupling source code from anything to do with provenance - be it package names or version numbers.</p>
<p><a href="PageOutline" class="uri" title="wikilink">PageOutline</a></p>
<h2 id="alternative-proposal-for-packages-with-explicit-namespaces">Alternative Proposal for Packages (with explicit namespaces)</h2>
<p>This proposal is an alternative to [wiki:Commentary/Packages/GhcPackagesProposal]. Large parts overlap with that proposal. To motivate this new proposal, let's consider another proposed and desirable feature of the import/export language, which may interact in interesting ways with packages.</p>
<h2 id="a-different-but-related-problem">A different, but related, problem</h2>
<p>A problem that has been mentioned several times on mailing lists, is grafting part of a directory hierarchy into an arbitrary location elsewhere in the hierarchy. (See <a href="http://www.haskell.org/pipermail/libraries/2005-June/004009.html">11</a>)</p>
<p>Another way of expressing a similar wish is the ability to re-export imports with a different qualified name, as in the scenario suggested by the developers of the package gtk2hs: <a href="http://www.haskell.org/pipermail/libraries/2004-December/002800.html">12</a></p>
<p>There are several desires in play here:</p>
<p><code>*adesiretominimisetypingoflongqualifiednames</code><br />
<code>*adesiretoreferto&quot;leaf&quot;nodesofthehierarchyinawaythatmakesiteasytorelocatethosemodulesinthehierarchy,withoutneedingtoediteveryimportdeclarationthatusesthem</code><br />
<code>*adesiretopartially-qualifynamesfordisambiguation</code></p>
<h2 id="proposal">Proposal</h2>
<p>We introduce the new concept of <em>namespace</em> as something that can be declared in source code. A namespace can contain only module names. (The specification of what module names are contained in a namespace is rather like our current concept of a package, i.e. not declared in the source code, but rather by some external mechanism e.g. grouping of files in a filesystem hierarchy.)</p>
<p>There are now two separate kinds of .</p>
<p><code>*</code><br />
<code>*</code></p>
<p>The new semi-reserved word  is introduced, having special meaning only directly after the  keyword. There is a <em>level</em> difference in what this new form of import means. The declaration  brings into availability the subset of the hierarchy of <em>module</em> names rooted in the package , at the position . That is, if the package  version  contains the modules</p>
<p><code>*Data.Foo.Bar</code><br />
<code>*Data.Foo.Baz</code><br />
<code>*Data.Bar</code></p>
<p>then the namespace import brings into the &quot;importable&quot; namespace only the modules</p>
<p><code>*Data.Foo.Bar</code><br />
<code>*Data.Foo.Baz</code></p>
<p>However, for the program to use those modules, it is still necessary to go ahead and actually  them in the normal way, although the names used to import them will now be <em>relative</em> to the available namespaces, rather than absolute. So the declaration  brings into scope all the entities defined in . Like any normal import, these can be qualified or hidden.</p>
<p>Thus,</p>
<p><code>*</code><code>bringsintoscopeabunchofnamesformodules</code><br />
<code>fromthegivenprovenance.</code><br />
<code>*</code><code>bringsintoscopeabunchofentitiesfromthegiven</code><br />
<code>module.</code></p>
<h3 id="naming-a-namespace">Naming a namespace</h3>
<p>Are namespaces first class? Can we give them a name? Indeed, why not?</p>
<p><code>*</code><br />
<code>*</code></p>
<p>Here, we have declared that we want to be able to refer to the namespace as , and so, a subsequent  specifically asks for the  from the package , just in case there might be a  module also available from another namespace.</p>
<h3 id="what-namespaces-are-available-by-default">What namespaces are available by default?</h3>
<p>If no namespaces are explicitly brought into scope, what modules are implicitly available?</p>
<p><code>*Anythinginthe</code><em><code>current</code></em><code>package,i.e.theexecutableorlibrary</code><br />
<code>whosemodulesareallphysicallyrootedatthesamelocationinthe</code><br />
<code>filesystemasthismodule.</code></p>
<p><code>*Isthereanimplicit</code><code>,justasthereisan</code><br />
<code>implicit</code><code>?</code></p>
<h3 id="namespace-resolution">Namespace resolution</h3>
<p>In essence, namespaces take over the role formerly played by commandline arguments like  and . The search path used by the compiler for finding modules is now partially declared in the source code itself. (Note however that that the search path is declared symbolically, involving package names, not directories. This is a very important separation of the thing itself from where it is stored.)</p>
<p>Resolution of which module is referred to by an import statement (taking into account the namespaces) is just like the current process of resolving which entity is referred to by program text (taking into account the imported modules). The source text may import multiple namespaces. If any module import is ambiguous (i.e. the module exists in more than one namespace), it is a static error. Resolution is lazy, in the sense that there is no error if namespaces contain the same module name, only if the program tries to import that module name.</p>
<p>So when you say &quot;import A.B.C&quot;, from what package does A.B.C come?</p>
<p>There must be a single namespace in scope containing a module called . (Sidenote: or in fact a namespace called , containing a module named )</p>
<h3 id="syntax-1">Syntax</h3>
<p>The precise syntax can be debated. New keywords like  or  could be substituted for . The key important features however are the inclusion of:</p>
<p><code>*thepackagename(mandatory)</code><br />
<code>*anoptionalpackageversion,ifseveralareavailable</code><br />
<code>*anoptionalpathtouseastherootoftheavailablenamespace</code><br />
<code>*anoptionalrenaming</code></p>
<h3 id="exports-1">Exports</h3>
<p>One might wonder whether it is now either necessary or desirable to permit <em>namespaces</em> to be re-exported in the same way that <em>modules</em> can be? For instance:</p>
<p></p>
<p>The idea is that any module saying  would thereby implicitly open the namespace of package  at the root , in addition to having access to entities defined in  itself.</p>
<p>Note that, just as with a current module re-export it is no longer possible for the importing location to use the original module name as a qualifier; so with a namespace re-export, there is no way to refer to the namespace in the importing location either. It is purely a signal to the compiler telling it where to look for modules when resolving imports.</p>
<p>I argue that namespace export <em>is</em> desirable, because it allows (but does not require) all package (namespace) dependencies to be gathered together in a single module for an entire project. With such an organising principle, when dependencies change, there is only one source file to update. But without namespace re-exports, it would be impossible to localise those dependencies to a single file.</p>
<p>Note how this feature addresses several of the initial stated desires, of reducing the verbosity of imports, and of referring to leaf modules conveniently. For instance:</p>
<p></p>
<h3 id="implicit-imports">Implicit imports</h3>
<p>One could go further. If I write a qualified name  in the source text, must I also write  at the top? The qualified entity is unambiguous, whether or not there is an explicit import for it, because the module qualification  must be unambiguous within the current namespaces. In the Gtk example above, this would eliminate the need for , and who knows how many other imports, leaving a single  to bring all of the qualified entities into scope.</p>
<h3 id="exposed-vs-hidden-packages">Exposed vs Hidden packages</h3>
<p>GHC's scheme of exposed vs hidden packages can now be replaced with full source-code control of namespace visibility. To setup a default set of exposed packages, you just write a module to export their namespaces:</p>
<p></p>
<p>and import it in every module of your project. Or if importing it everywhere sounds too painful, one can even imagine that a compiler might provide a command-line option (or use a configuration file) to specify one distinguished module to be implicitly imported everywhere:</p>
<p></p>
<h3 id="what-if-you-wanted-to-import-a.b.c-from-p1-and-a.b.c-from-p2-into-the-same-module">What if you wanted to import A.B.C from P1 and A.B.C from P2 into the <em>same</em> module?</h3>
<p></p>
<p><a href="PageOutline" class="uri" title="wikilink">PageOutline</a></p>
<h1 id="package-reorg">Package Reorg</h1>
<p>In this page we collect proposals and design discussion for reorganising the packages that come with compilers, and the contents of those packages.</p>
<p>None of the ideas herein are claimed to belong to any particular person, many of the ideas have been extracted from mailing list discussions, eg.</p>
<p><a href="http://www.haskell.org/pipermail/libraries/2006-November/006396.html"><code>13</code></a></p>
<p>Some of the points are GHC-specific. Please feel free to insert points specific to other compilers.</p>
<h2 id="goals-1">Goals</h2>
<p><code>*Itwouldbegoodtohavesetof'core'packagesthatisinstalledwith</code><br />
<code>everyHaskellimplementation.MoreonthisatPackageReorg/Rationalepage</code><br />
<code>*Forwardscompatibility.Userswouldliketheirprogramswrittenagainstthe'core'packagestocontinuetowork,without</code><br />
<code>modificationtosourcetextorbuildsystem,afterupgradingthe</code><br />
<code>compiler,oritspackages,orswitchingtoadifferentcompiler.</code><br />
<code>*Backwardscompatibility.Userswouldliketobeabletotakea</code><br />
<code>programwrittenagainstsomeversionofthe'core'packages,and</code><br />
<code>builditwithanoldercompiler,acceptingthattheymayhaveto</code><br />
<code>installnewerversionsofthe'core'packagesinordertodoso.</code></p>
<p>It may not be possible to fully achieve these goals (in particular, backwards compatibility), but that does not mean we should not aim for them.</p>
<h2 id="proposal-1">Proposal</h2>
<p>Here's a straw-man proposal</p>
<p><code>*ThereisasetofpackagesthatcomewitheveryconformingHaskell</code><br />
<code>implementation.Let'scallthesethe</code><strong><code>Core</code> <code>Packages</code></strong><code>to</code><br />
<code>avoidconfusion(Bulatcalledthesethe&quot;basepackages&quot;,butthat'san</code><br />
<code>over-usedtermgiventhatthereisapackagecalled`base`).</code><br />
<code>ThegoodthingabouttheCorePackagesisthat</code><br />
<code>usersknowthattheywillbethere,andtheyareconsistentwith</code><br />
<code>eachother.</code></p>
<p><code>*Anyparticularimplementationmayinstallmorepackagesbydefault;</code><br />
<code>forexampleGHCwillinstallthe`template-haskell`and`stm`</code><br />
<code>packages.Let'scallthesethe</code><strong><code>GHC</code> <code>Install</code> <code>Packages</code></strong><code>,'''Hugs</code><br />
<code>InstallPackages'''etc;theInstallPackagesareasupersetofthe</code><br />
<code>CorePackages.</code></p>
<h3 id="what-is-in-the-core-packages">What is in the Core Packages?</h3>
<p>The Core Packages are installed with every conforming Haskell implementation. What should be in the Core? There is a tension:</p>
<p><code>1.</code><strong><code>As</code> <code>much</code> <code>as</code> <code>possible</code></strong><code>;whichmeansinpracticewidely-usedandreasonablystablepackages.Itisconvenientforprogrammerstohaveasmuchaspossibleinaconsistent,bundlethatis(a)knowntoworktogetherbundle,and(b)knowntoworkonallimplementations.</code><a href="BR" title="wikilink"><code>BR</code></a><a href="BR" title="wikilink"><code>BR</code></a><br />
<code>2.</code><strong><code>As</code> <code>little</code> <code>as</code> <code>possible</code></strong><code>;whichinpracticemeansenoughtorunCabalsothatyoucanruntheSetupfilesthatcomewhendownloadingnewpackages.AsIanputsit:thelessweforcetheimplementationstocomewith,thequickercompilationwillbewhendeveloping,thesmallerDebianpackages(forexample)canbe,thelowerthediskspacerequirementstobuildGHC,thelowerthetimewastedwhenaDebianpackage(forexample)buildfailsandthefewerpackageswearetanglingupwithcompilerreleaseschedules.</code></p>
<p>There's a real choice here: Bulat wants (1) and Ian wants (2).</p>
<p>Initial stab at (1):</p>
<p><code>*`base`</code><br />
<code>*`Cabal`</code><br />
<code>*`haskell98`</code><br />
<code>*Some`regex`packages(preciselywhich?)</code><br />
<code>*`unix`or`Win32`.Questionable,partlybecauseitmeanstheCoreinterfacebecomesplatform-dependent;andpartlybecause`Win32`woulddoublethesizeoftheHugsdistribution.</code><br />
<code>*`parsec`</code><br />
<code>*`mtl`</code><br />
<code>*`time`</code><br />
<code>*`network`</code><br />
<code>*`QuickCheck`(questionable)</code><br />
<code>*`HUnit`(questionable)</code></p>
<p>Initial stab at (2):</p>
<p><code>*`base`</code><br />
<code>*`haskell98`</code><br />
<code>*`Cabal`</code><br />
<code>*`filepath`(?)</code></p>
<p>Bulat: i think that all regex packages should be included and of course libs that helps testing. overall, it should be any general-purpose lib that porters accept (enlarging this set makes users live easier, and porters live harder)</p>
<p>about unix/win32 - these libs provide access to OS internals, not some everywhere-portable API. moreover, other world-interfacing libs (i/o, networking) should use APIs provided by these libs with a conditional compilation (CPPery) tricks in order to provide portable APIs! current situation where such libs use FFI isn't ideal. WinHugs size problem is rather technical - it includes a lot of DLLs which contains almost the same code</p>
<p>i agree to start with minimal stub, and then proceed with discussing inclusion of each library. what we need now is requirements to include library in this set and lifetime support procedure. so:</p>
<h3 id="requirements-to-libraries-to-be-included-in-core-set">Requirements to libraries to be included in core set</h3>
<p><code>*BSD-licensed,andevenbelongstoHaskellcommunity?</code><br />
<code>*portable(issenseofcompilerandOS),maybejustHaskell'compatible?</code><br />
<code>*alreadywidelyused</code><br />
<code>*shouldn'tduplicateexistingcorelibsfunctionality(?)</code></p>
<p>Exact inclusion, support and exclusion processes?</p>
<h3 id="the-base-package">The base package</h3>
<p>The base package is a bit special</p>
<p><code>*Package`base`isratherbigatthemoment.</code></p>
<p><code>*Fromauser'spointofviewitwouldbenicertogiveita</code><br />
<code>compiler-independentAPI.(Amodulelike`GHC.Exts`wouldmoveto</code><br />
<code>anewpackage`ghc-base`.)</code></p>
<p>Thinking of GHC alone for a moment, we could have a package `ghc-base` (which is pretty much the current `base`) and a thin wrapper package `base` that re-exposes some, but not all, of what `ghc-base` exposes. To support this re-exposing, we need a small fix to both GHC and Cabal, but one that is independently desirable.</p>
<p>Similarly, Hugs could build `hugs-base` from the same souce code, by using CPP-ery, exactly as now. The thin `base` wrapper package would not change.</p>
<p>To make `base` smaller, we could remove stuff, and put it into separate packages. But be careful: packages cannot be cyclic, so anything that is moved out can't be used in `base`. Some chunks that would currently be easy to split off are:</p>
<p><code>*Data.!ByteString.*(plusfuturepackedCharstrings)</code><br />
<code>*Control.Applicative(?),Data.Foldable,Data.Monoid(?),Data.Traversable,Data.Graph,Data.!IntMap,Data.!IntSet,Data.Map,Data.Sequence,Data.Set,Data.Tree</code><br />
<code>*System.Console.!GetOpt</code><br />
<code>*Text.!PrettyPrint.*</code><br />
<code>*Text.Printf</code></p>
<p>Some other things, such as arrays and concurrency, have nothing else depending on them, but are so closely coupled with GHC's internals that extracting them would require exposing these internals in the interface of `base`.</p>
<p>Bulat: my ArrayRef library contains portable implementation of arrays. there is only thin ghc/hugs-specific layer which should be provided by ghcbase/hugsbase libs. except for MPTC problem (IArray/MArray classes has multiple parameters), this library should be easily portable to any other haskell compiler</p>
<p>See also BaseSplit.</p>
<h3 id="other-packages">Other packages</h3>
<p>Other non-core packages would probably have their own existence. That is, they don't come with an implementation; instead you use `cabal-get`, or some other mechanism, such as your OS's package manager. Some of these currently come with GHC, and would no longer do so</p>
<p><code>*`GLUT`</code><br />
<code>*`ALUT`</code><br />
<code>*`OpenAL`</code><br />
<code>*`OpenGL`</code><br />
<code>*`HGL`</code><br />
<code>*`HUnit`</code><br />
<code>*`ObjectIO`</code><br />
<code>*`X11`</code><br />
<code>*`arrows`</code><br />
<code>*`cgi`</code><br />
<code>*`fgl`</code><br />
<code>*`html`</code><br />
<code>*`xhtml`</code></p>
<p>Bulat: i propose to unbundle only graphics/sound libs because these solves particular problems and tends to be large, non-portable (?) and some are just legacy ones - like ObjectIO. we should keep everything small &amp; general purpose, including HUnit, arrows, fgl, html and xhtml, and include even more: ByteString, regex-*, Edison, Filepath, MissingH, NewBinary, QuickCheck, monads</p>
<h2 id="testing-1">Testing</h2>
<p>We should separate out package-specifc tests, which should be part of the repository for each package. Currently they are all squashed together into the testsuite repository.</p>
<h2 id="implementation-specific-notes">Implementation-specific notes</h2>
<h3 id="notes-about-ghc">Notes about GHC</h3>
<p>Currently GHC installs a set of packages by default, the so-called <strong>GHC Boot Packages</strong>. They are graphed here, with arrows representing dependencies between them: <a href="Image(packagegraph.png,_800)" title="wikilink">Image(packagegraph.png, 800)</a></p>
<p>These are exactly the libraries required to build GHC. That shouldn't be the criterion for the core packages.</p>
<p>One reason we do this is because it means that every GHC installation can build GHC. Less configure-script hacking. (NB: even today if you upgrade any of these packages, and then build GHC, the build might fail because the CPP-ery in GHC's sources uses only the version number of GHC, not the version number of the package.)</p>
<p>Still, for convenience we'd probably arrange that the GHC Install Packages included all the GHC Boot Packages.</p>
<p>Every GHC installation must include packages: `base`, `ghc-prim`, `integer` and `template-haskell`, else GHC itself will not work. (In fact `haskell98` is also required, but only because it is linked by default.)</p>
<p>So GHC's Install Packages would be the Core Packages plus</p>
<p><code>*`template-haskell`</code><br />
<code>*`editline`</code><br />
<code>*`integer`</code><br />
<code>*`ghc-prim`</code></p>
<p>You can upgrade any package, including `base` after installing GHC. However, you need to take care. You must not change a number of things that GHC &quot;knows about&quot;. In particular, these things must not change</p>
<p><code>*Name</code><br />
<code>*Definingmodule</code></p>
<p>GHC knows even more about some things, where you must not change</p>
<p><code>*Typesignature</code><br />
<code>*Fordatatypes,thenames,types,andorderoftheconstructors</code></p>
<p>The latter group are confined to packages base and template-haskell.</p>
<p>(Note: a few other packages are used by tests in GHC's test suite, currently: `mtl`, `QuickCheck`. We should probably eliminate the mtl dependency; but `QuickCheck` is used as part of the test infrastructure itself, so we'll make it a GHC Boot Package.)</p>
<h3 id="notes-about-hugs">Notes about Hugs</h3>
<p>Recent distributions of Hugs come in two sizes, jumbo and minimal. Minimal distributions include only the packages `base`, `haskell98` and `Cabal`. (Hugs includes another package `hugsbase` containing interfaces to Hugs primitives.) The requirements for this set are to</p>
<p><code>*runHaskell98programs</code><br />
<code>*allowpackagestobeaddedandupgradedusingCabal</code></p>
<p>(Currently `cpphs` is a Haskell 98 program, so the latter implies the former.)</p>
<p>It should be possible to upgrade even the core packages using Cabal.</p>
<h1 id="commentary-the-package-system">Commentary: The Package System</h1>
<p>See also: [wiki:Commentary/Compiler/Packages Packages], where we describe how this is implemented in GHC.</p>
<h2 id="architecture">Architecture</h2>
<p>GHC maintains a package database, that is basically a list of `InstalledPackageInfo`. The `InstalledPackageInfo` type is defined in `Distribution.InstalledPackageInfo` in Cabal, and both `ghc-pkg` and GHC itself import it directly from there.</p>
<p>There are four main components of the package system:</p>
<p><code>Cabal::</code><br />
<code>CabalisaHaskelllibrary,whichprovidesbasicdatatypesforthepackagesystem,andsupportforbuilding,</code><br />
<code>configuring,andinstallingpackages.</code></p>
<p><code>GHCitself::</code><br />
<code>GHCreadsthepackagedatabase(s),understandstheflags`-package`,`-hide-package`,etc.,andusesthepackagedatabase</code><br />
<code>tofind`.hi`filesandlibraryfilesforpackages.GHCimportsmodulesfromCabal.</code></p>
<p><code>`ghc-pkg`::</code><br />
<code>The`ghc-pkg`toolmanagesthepackagedatabase,includingregistering/unregisteringpackages,queries,and</code><br />
<code>checkingconsistency.`ghc-pkg`alsoimportsmodulesfromCabal.</code></p>
<p><code>`cabal-install`::</code><br />
<code>AtoolbuiltontopofCabal,whichaddssupportfordownloadingpackagesfromHackage,andbuildingandinstalling</code><br />
<code>multiplepackageswithasinglecommand.</code></p>
<p>For the purposes of this commentary, we are mostly concerned with GHC and `ghc-pkg`.</p>
<h2 id="identifying-packages">Identifying Packages</h2>
<p><code>`Cabal.PackageName`(&quot;base&quot;)::</code><br />
<code>Astring.Definedin`Distribution.Package`.Doesnotuniquelyidentifyapackage:thepackage</code><br />
<code>databasecancontainseveralpackageswiththesamename.</code></p>
<p><code>`Cabal.PackageId`(&quot;base-4.1.0.0&quot;)::</code><br />
<code>A`PackageName`plusa`Version`.A`PackageId`namesanAPI.Iftwo`PackageId`sare</code><br />
<code>thesame,theyareassumedtohavethesameAPI.</code><br />
<code></code><a href="BR" title="wikilink"><code>BR</code></a><a href="BR" title="wikilink"><code>BR</code></a><br />
<code>`InstalledPackageInfo`containsthefield`sourcePackageId::PackageId`.</code><br />
<code></code><a href="BR" title="wikilink"><code>BR</code></a><a href="BR" title="wikilink"><code>BR</code></a><br />
<code>InGHC6.11,the`PackageId`alsouniquelyidentifiesapackageinstanceinthepackagedatabase,but</code><br />
<code>onlybyconvention(wemayliftthisrestrictioninthefuture,andallowthedatabasetocontain</code><br />
<code>multiplepackageinstanceswiththesame`PackageId`(anddifferent`InstalledPackageId`s).</code></p>
<p><code>`Cabal.InstalledPackageId`(&quot;base-4.1.0.0-1mpgjN&quot;)::</code><br />
<code>(introducedinGHC6.12/Cabal1.7.2)Astringthatuniquelyidentifiesapackageinstanceinthedatabase.</code><br />
<code>An`InstalledPackageId`identifiesanABI:iftwo`InstalledPackageIds`arethesame,theyhavethe</code><br />
<code>sameABI.</code><br />
<code></code><a href="BR" title="wikilink"><code>BR</code></a><a href="BR" title="wikilink"><code>BR</code></a><br />
<code>`InstalledPackageInfo`containsthefield`installedPackageId::InstalledPackageId`.</code><br />
<code></code><a href="BR" title="wikilink"><code>BR</code></a><a href="BR" title="wikilink"><code>BR</code></a><br />
<code>Dependenciesbetweeninstalledpackagesareidentifiedbythe`InstalledPackageId`.An`InstalledPackageId`is</code><br />
<code>chosenwhenapackageisregistered.Itischosenbycalling`ghc--abi-hash`onthecompiledmodulesandappending</code><br />
<code>thehashasasuffixtothestringrepresentingthe`PackageIdentifier`.</code></p>
<p><code>`GHC.PackageId`(thesecurrentlylooklike&quot;base-4.1.0.0&quot;inGHC6.12)::</code><br />
<code>InsideGHC,weusethetype`PackageId`,whichisa`FastString`.The(Z-encodingof)`PackageId`prefixeseach</code><br />
<code>externalsymbolinthegeneratedcode,sothatthemodulesofonepackagedonotclashwiththoseofanotherpackage,</code><br />
<code>evenwhenthemodulenamesoverlap.</code></p>
<h2 id="design-constraints">Design constraints</h2>
<p><code>1.Wewant[wiki:Commentary/Compiler/RecompilationAvoidancerecompilationavoidance]towork.Thismeansthatsymbolnamesshouldnotcontainanyinformationthatvariestoooften,suchastheABIhashofthemoduleorpackage.TheABIofanentityshoulddependonlyonitsdefinition,andthedefinitionsofthethingsitdependson.</code></p>
<p><code>2.WewanttobeabletodetectABIincompatibility.Ifapackageisrecompiledandinstalledoverthetopoftheoldone,andthenewversionisABI-incompatiblewiththeoldone,thenpackagesthatdependedontheoldversionshouldbedetectablybrokenusingthetools.</code></p>
<p><code>3.ABIcompatibility:</code><br />
<code>*Wewantrepeatablecompilations.Compilingapackagewiththesameinputsshouldyieldthesameoutputs.</code><br />
<code>*Furthermore,wewanttobeabletomakecompiledpackagesthatexposeanABIthatiscompatible(e.g.asuperset)</code><br />
<code>ofanexistingcompiledpackage.</code><br />
<code>*Modularupgrades:wewanttobeabletoupgradeanexistingpackagewithoutrecompilingeverythingthatdepends</code><br />
<code>onit,byensuringthatthereplacementisABI-compatible.</code><br />
<code>*Sharedlibraryupgrades.WewanttobeabletosubstituteanewABI-compatiblesharedlibraryforanoldone,andalltheexistingbinarieslinkedagainsttheoldversioncontinuetowork.</code><br />
<code>*ABIcompatibilityisdependentonGHCtoo;changestothecompilerandRTScanintroduceABIincompatibilities.We</code><br />
<code>guaranteetoonlymakeABIincompatiblechangesinamajorreleaseofGHC.Betweenmajorreleases,ABIcompatibility</code><br />
<code>isensured;soforexampleitshouldbepossibletouseGHC6.12.2withthepackagesthatcamewithGHC6.12.1.</code></p>
<p>Right now, we do not have repeatable compilations, so while we cannot do (3), we keep it in mind.</p>
<h2 id="the-plan-1">The Plan</h2>
<p>We need to talk about some more package Ids:</p>
<p><code>*`PackageSymbolId`:thesymbolprefixusedincompiledcode.</code><br />
<code>*`PackageLibId`:thepackageIdinthenameofacompiledlibraryfile(staticandshared).</code></p>
<h3 id="detecting-abi-incompatibility">Detecting ABI incompatibility</h3>
<p><code>*inthepackagedatabase,dependenciesspecifythe`InstalledPackageId`.</code></p>
<p><code>*Thepackagedatabasewillcontainatmostoneinstanceofagivenpackage/versioncombination.Thetools</code><br />
<code>arenotcurrentlyabletocopewithmultipleinstances(e.g.GHC's-packageflagselectsbyname/version).</code></p>
<p><code>*If,say,packageP-1.0isrecompiledandre-installed,thenewinstanceofthepackagewillalmost</code><br />
<code>certainlyhaveanincompatibleABIfromthepreviousversion.Wegivethenewpackageadistinct</code><br />
<code>`InstalledPackageId`,sothatpackagesthatdependontheoldP-1.0willnowbedetectablybroken.</code></p>
<p><code>*`PackageSymbolId`:Wedonotusethe`InstalledPackageId`asthesymbolprefixinthecompiledcode,because</code><br />
<code>thatinteractsbadlywith[wiki:Commentary/Compiler/RecompilationAvoidancerecompilationavoidance].Everytimewepicka</code><br />
<code>newunique`InstalledPackageId`(e.g.whenreconfiguringthepackage),wewouldhavetorecompile</code><br />
<code>theentirepackage.Hence,the`PackageSymbolId`ispickeddeterministicallyforthepackage,e.g.</code><br />
<code>itcanbethe`PackageIdentifier`.</code></p>
<p><code>*`PackageLibId`:wedowanttoputthe`InstalledPackageId`inthenameofalibraryfile,however.Thisallows</code><br />
<code>ABIincompatibilitytobedetectedbythelinker.Thisisimportantforsharedlibrariestoo:we</code><br />
<code>wantanABI-incompatiblesharedlibraryupgradetobedetectedbythedynamiclinker.Hence,</code><br />
<code>`PackageLibId`==`InstalledPackageId`.</code></p>
<h3 id="allowing-abi-compatibilty">Allowing ABI compatibilty</h3>
<p><code>*ThesimplestschemeistohaveanidentifierforeachdistinctABI,e.g.apairofthepackagenameandaninteger</code><br />
<code>thatisincrementedeachtimeanABIchangeofanykindismadetothepackage.TheABIidentifier</code><br />
<code>isdeclaredbythepackage,andisusedasthe`PackageSymbolId`.SincepackageswiththesameABIidentifier</code><br />
<code>areABI-compatible,the`PackageLibId`canbethesameasthe`PackageSymbolId`.</code></p>
<p><code>*ThepreviousschemedoesnotallowABI-compatiblechanges(e.g.ABIextension)tobemade.Hence,wecould</code><br />
<code>generaliseittoamajor/minorversioningscheme.</code><br />
<code>*theABImajorversionisasbefore,thepackagename+aninteger.Thisisalsothe`PackageSymbolId`.</code><br />
<code>*theABIminorversionisanintegerthatisincrementedeachtimetheABIisextendedinacompatibleway.</code><br />
<code>*packagedependenciesinthedatabasespecifythemajor+minorABIversiontheyrequire,inadditiontothe</code><br />
<code>`InstalledPackageId`.Theymaybesatisfiedbyagreaterminorversion;whenupgradingapackagewithan</code><br />
<code>ABI-compatiblereplacement,ghc-pkgupdatesdependenciestopointtothenew`InstalledPackageId`.</code><br />
<code>*`PackageLibId`isthemajorversion.Inthecaseofsharedlibraries,wemaynamethelibraryusingthe</code><br />
<code>major+minorversions,withasymboliclinkfromthemajorversiontomajor+minor.</code><br />
<code>*thesharedlibrary`SONAME`isthemajorversion.</code></p>
<p><code>*ThepreviousschemeonlyallowsABI-compatiblechangestobemadeinalinearsequence.Ifwewantatree-shaped</code><br />
<code>compatibilitystructure,thensomethingmorecomplexisneeded(ToDo).</code></p>
<p><code>*ThepreviousschemesonlyallowcompatibleABIchangestobemade.Ifwewanttoallowincompatiblechangestobe</code><br />
<code>made,thenweneedsomethinglikeELF'ssymbolversioning.Thisisprobablyoverkill,sincewewillbemaking</code><br />
<code>incompatibleABIchangesinthecompilerandRTSatregularintervalsanyway,solong-termABIcompatibilityis</code><br />
<code>impracticalatthisstage.</code></p>
<p><a href="PageOutline" class="uri" title="wikilink">PageOutline</a></p>
<h1 id="the-parser">The Parser</h1>
<p>[Very incomplete. Please extend as you learn more.]</p>
<p>The parser is written using</p>
<p><code>*</code><a href="http://www.haskell.org/alex/"><code>Alex</code></a><code>,forlexicalanalysis.Sourcefile</code><a href="GhcFile(compiler/parser/Lexer.x)" title="wikilink"><code>GhcFile(compiler/parser/Lexer.x)</code></a><br />
<code>*</code><a href="http://www.haskell.org/happy/"><code>Happy</code></a><code>,fortheparseritself.Sourcefile</code><a href="GhcFile(compiler/parser/Parser.y)" title="wikilink"><code>GhcFile(compiler/parser/Parser.y)</code></a><code>.</code><br />
<code>*`RdrHsSyn`,forHaskellsupportfunctions.Sourcefile</code><a href="GhcFile(compiler/parser/RdrHsSyn.lhs)" title="wikilink"><code>GhcFile(compiler/parser/RdrHsSyn.lhs)</code></a></p>
<h2 id="principles">Principles</h2>
<p>Making a parser parse <em>precisely</em> the right language is hard. So GHC's parser follows the following principle:</p>
<p><code>*</code><strong><code>We</code> <code>often</code> <code>parse</code> <code>&quot;over-generously&quot;,</code> <code>and</code> <code>filter</code> <code>out</code> <code>the</code> <code>bad</code> <code>cases</code> <code>later.</code></strong></p>
<p>Here are some examples:</p>
<p><code>*Patternsareparsedasexpressions,andtransformedfrom`HsExpr.HsExp`into`HsPat.HsPat`in`RdrHsSyn.checkPattern`.Anexpressionlike`[x|x&lt;-xs]`thatdoesn'tlooklikeapatternisrejectedby`checkPattern`.</code></p>
<p><code>*Thecontextofatypeisparsedasatype,andthenconvertedintoacontextby`RdrHsSyn.checkContext`.Forexample,whenparsing</code></p>
<p></p>
<p><code>theparsercanonlydiscoverthat`(Reada,Numa)`isacontext,ratherthanatype,whenitmeetsthe`=&gt;`.Thatrequiresinfinitelookahead.Soinsteadweparse`(Reada,Numa)`asatupletype,andthenconvertittoacontextwhenweseethe`=&gt;`.</code></p>
<p>Sometimes the over-generous parsing is only dealt with by the renamer. For example:</p>
<p><code>*Infixoperatorsareparsedasiftheywereallleft-associative.Therenamerusesthefixitydeclarationstore-associatethesyntaxtree.</code></p>
<p>There are plenty more examples. A good feature of this approach is that the error messages later in compilation tend to produce much more helpful error messages. Errors generated by the parser itself tend to say &quot;Parse error on line X&quot; and not much more.</p>
<p>The main point is this. If you are changing the parser, feel free to make it accept more programs than it does at the moment, provided you also add a later test that rejects the bad programs. Typically you need this flexibility if some new thing you want to add makes the pars ambiguous, and you need more context to disambiguate. Delicate hacking of the LR grammar is to be discouraged. It's very hard to maintain and debug.</p>
<h2 id="avoiding-right-recursion">Avoiding right-recursion</h2>
<p>Be sure to read <a href="https://www.haskell.org/happy/doc/html/sec-sequences.html">this section</a> of the Happy manual for tips on avoiding right recursion. In GHC, the preferred method is using a left-recursive `OrdList`, as below:</p>
<p></p>
<p>`OrdList` operationally works the same way as building a list in reverse (as in the Happy manual), but it makes it less likely you'll forget to call `reverse` when you need to get the `final` list out.</p>
<p>One interesting, non-obvious fact, is that if you *do* use a right-recursive parser, the &quot;extra semi-colons&quot; production should NOT be pluralized:</p>
<p></p>
<h2 id="indentation">Indentation</h2>
<p>Probably the most complicated interaction between the lexer and parser is with regards to //whitespace-sensitive layout.// The most important thing to know is that the lexer understands layout, and will output virtual open/close curlies (productions `vocurly` and `vccurly`) as well as semicolons, which can then be used as part of productions in `Parser.y`. So for example, if you are writing a rule that will make use of indentation, you should accept both virtual and literal curlies:</p>
<p></p>
<p>Notice the use of `close` rather than `vccurly`: `close` is a production that accepts both `vccurly` and a Happy `error`; that is, if we encounter an error in parsing, we try exiting an indentation context and trying again. This ensures, for example, that the top-level context can be closed even if no virtual curly was output.</p>
<p>The top-level of a Haskell file does not automatically have a layout context; when there is no `module` keyword, a context is implicitly pushed using `missing_module_keyword`.</p>
<p>When writing grammars that accept semicolon-separated sequences, be sure to include a rule allowing for trailing semicolons (see the previous section), otherwise, you will reject layout.</p>
<h2 id="syntax-extensions">Syntax extensions</h2>
<p>Many syntactic features must be enabled with a `LANGUAGE` flag, since they could cause existing Haskell programs to stop compiling, as turn some identifiers into keywords. We primarily affect this change of behavior in the lexer, by turning on/off certain tokens. This is done using predicates, which let Alex turn token rules on and off depending on what extensions are enabled:</p>
<p></p>
<p>To add a new syntax extension, add a constructor to `ExtBits` and set the bit appropriately in `mkPState`.</p>
<h1 id="pinned-objects">Pinned Objects</h1>
<p>The GC does not support pinning arbitrary objects. Only objects that have no pointer fields can be pinned. Nevertheless, this is a useful case, because we often want to allocate garbage-collectable memory that can be passed to foreign functions via the FFI, and we want to be able to run the GC while the foreign function is still executing (for a `safe` foreign call). Hence, the memory we allocated must not move.</p>
<p>Bytestrings are currently allocated as pinned memory, so that the bytestring contents can be passed to FFI calls if necessary.</p>
<p>The RTS provides an API for allocating pinned memory, in <a href="GhcFile(includes/rts/storage/GC.h)" class="uri" title="wikilink">GhcFile(includes/rts/storage/GC.h)</a>:</p>
<p></p>
<p>This allocates memory from the given Capability's nursery.</p>
<p>Pinned objects work in the GC as follows:</p>
<p><code>*Pinnedobjectsareallocatedintoablockoftheirown,notmixedupwithunpinnedobjects.</code><br />
<code>*Theblockcontainingpinnedobjectsismarkedasa</code><em><code>large</code> <code>block</code></em><code>,i.e.the`BF_LARGE`bitissetin`bd-&gt;flags`.</code><br />
<code>*Whenencounteringaliveobjectina`BF_LARGE`block,theGCnevercopiestheobject,insteaditjustre-linksthewholeblockontothe`large_objects`listofthedestinationgeneration.</code><br />
<code>*TheGCdoesn'thavetoscavengethepinnedobject,sinceitdoesnotcontainanypointers.Thisisjustaswell,becausewecannotscanblocksforlivepinnedobjects,dueto[wiki:Commentary/Rts/Storage/Slopslop].Hencetherestrictionthatpinnedobjectsdonotcontainpointers.</code></p>
<p>This means that using pinned objects may lead to memory fragmentation, since a single pinned object keeps alive the whole block in which it resides. If we were to implement a non-moving collector such as [wiki:Commentary/Rts/Storage/GC/Sweeping mark-region], then we would be able to reduce the impact of fragmentation due to pinned objects.</p>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>
<p>Commentary/Rts/Storage/GC/Pinned</p>
<h1 id="overview-5">Overview</h1>
<p>GHC is structured into two parts:</p>
<p><code>*The`ghc`package(insubdirectory`compiler`),whichimplementsalmostallGHC'sfunctionality.ItisanordinaryHaskelllibrary,andcanbeimportedintoaHaskellprogrambysaying`importGHC`.</code><br />
<code>*The`ghc`binary(insubdirectory`ghc`)whichimportsthe`ghc`package,andimplementstheI/Oforthe`ghci`interactiveloop.</code></p>
<p>Here's an overview of the module structure of the top levels of GHC library. (Note: more precisly, this is the plan. Currently the module `Make` below is glommed into the giant module `GHC`.) </p>
<h1 id="the-driver-pipeline">The driver pipeline</h1>
<p>The driver pipeline consist of a couple of phases that call other programs and generate a series of intermediate files. Code responsible for managing the order of phases is in <a href="GhcFile(compiler/main/DriverPhases.hs)" class="uri" title="wikilink">GhcFile(compiler/main/DriverPhases.hs)</a>, while managing the driver pipeline as a whole is coded in <a href="GhcFile(compiler/main/DriverPipeline.hs)" class="uri" title="wikilink">GhcFile(compiler/main/DriverPipeline.hs)</a>. Note that driver pipeline is not the same thing as compilation pipeline: the latter is part of the former.</p>
<p>Let's take a look at the overall structure of the driver pipeline. When we compile  or  (&quot;lhs&quot; extension means that Literate Haskell is being used) the following phases are being called (some of them depending on additional conditions like file extensions or enabled flags):</p>
<p><code>*Runthe</code><strong><code>unlit</code> <code>pre-processor</code></strong><code>,</code><code>,toremovetheliteratemarkup,generating</code><code>.The</code><code>processorisaCprogramkeptin</code><a href="GhcFile(utils/unlit)" title="wikilink"><code>GhcFile(utils/unlit)</code></a><code>.</code></p>
<p><code>*Runthe</code><strong><code>C</code> <code>preprocessor</code></strong><code>,`cpp`,(if</code><code>isspecified),generating</code><code>.</code></p>
<p><code>*Run</code><strong><code>the</code> <code>compiler</code> <code>itself</code></strong><code>.Thisdoesnotstartaseparateprocess;it'sjustacalltoaHaskellfunction.Thisstepalwaysgeneratesan[wiki:Commentary/Compiler/IfaceFiles</code><strong><code>interface</code> <code>file</code></strong><code>]</code><code>,anddependingonwhatflagsyougive,italsogeneratesacompiledfile.AsGHCsupportsthreebackendcodegeneratorscurrently(anativecodegenerator,aCcodegeneratorandanllvmcodegenerator)thepossiblerangeofoutputsdependsonthebackendused.Allthreesupportassemblyoutput:</code><br />
<code>*Objectcode:noflagsrequired,file</code><code>(supportedbyallthreebackends)</code><br />
<code>*Assemblycode:flag</code><code>,file</code><code>(supportedbyallthreebackends)</code><br />
<code>*Ccode:flags</code><code>,file</code><code>(onlysupportedbyCbackend)</code></p>
<p><code>*Inthe</code><code>case:</code><br />
<code>*Runthe</code><strong><code>C</code> <code>compiler</code></strong><code>on`Foo.hc`,togenerate`Foo.s`.</code></p>
<p><code>*If`-split-objs`isinforce,runthe</code><strong><code>splitter</code></strong><code>on`Foo.s`.Thissplits`Foo.s`intolotsofsmallfiles.Theideaisthatthestaticlinkerwilltherebyavoidlinkingdeadcode.</code></p>
<p><code>*Runtheassembleron`Foo.s`,orif`-split-objs`isinforce,oneachindividualassemblyfile.</code></p>
<h1 id="the-compiler-pipeline">The compiler pipeline</h1>
<p>The <strong>compiler itself</strong>, independent of the external tools, is also structured as a pipeline. For details (and a diagram), see [wiki:Commentary/Compiler/HscMain]</p>
<h1 id="video">Video</h1>
<p>Video of compilation pipeline explanation from 2006: <a href="http://www.youtube.com/watch?v=dzSc8ACz_mw&amp;list=PLBkRCigjPwyeCSD_DFxpd246YIF7_RDDI">Compilation Pipeline</a> and interface files (17'30&quot;)</p>
<h1 id="platforms">Platforms</h1>
<p>Please read [wiki:CrossCompilation this wiki page] on cross compilation for a better understanding of the situation here. There are three platforms of interest to GHC when compiling and running:</p>
<p><code>*The</code><strong><code>Build</code></strong><code>platform.ThisistheplatformonwhichwearebuildingGHC.</code><br />
<code>*The</code><strong><code>Host</code></strong><code>platform.ThisistheplatformonwhichwearegoingtorunthisGHCbinary,andassociatedtools.</code><br />
<code>*The</code><strong><code>Target</code></strong><code>platform.ThisistheplatformforwhichthisGHCbinarywillgeneratecode.</code></p>
<h2 id="limitations">Limitations</h2>
<p>At the moment, there is limited support for having different values for build, host, and target. Please refer to the [wiki:CrossCompilation cross compilation] page for more details. In particular:</p>
<p>The build platform is currently always the same as the host platform. The build process needs to use some of the tools in the source tree, for example ghc-pkg and hsc2hs.</p>
<p>If the target platform differs from the host platform, then this is generally for the purpose of building .hc files from Haskell source for porting GHC to the target platform. Full cross-compilation isn't supported (yet).</p>
<h2 id="macros">Macros</h2>
<p>In the compiler's source code, you may make use of the following CPP symbols:</p>
<p><code>*</code><em><code>xxx</code></em><code>`_TARGET_ARCH`</code><br />
<code>*</code><em><code>xxx</code></em><code>`_TARGET_VENDOR`</code><br />
<code>*</code><em><code>xxx</code></em><code>`_TARGET_OS`</code><br />
<code>*</code><em><code>xxx</code></em><code>`_HOST_ARCH`</code><br />
<code>*</code><em><code>xxx</code></em><code>`_HOST_VENDOR`</code><br />
<code>*</code><em><code>xxx</code></em><code>`_HOST_OS`</code></p>
<p>where <em>xxx</em> is the appropriate value: eg. `i386_TARGET_ARCH`. However <strong>GHC is moving away from using CPP for this purpose</strong> in many cases due to the problems it creates with supporting cross compilation.</p>
<p>So instead of it the new plan is to always build GHC as a cross compiler and select the appropriate values and backend code generator to run and runtime. For this purpose there is the Platform module (<a href="GhcFile(compiler/utils/Platform.hs)" class="uri" title="wikilink">GhcFile(compiler/utils/Platform.hs)</a>). That contains various methods for querying the !DynFlags (<a href="GhcFile(compiler/main/DynFlags.hs)" class="uri" title="wikilink">GhcFile(compiler/main/DynFlags.hs)</a>) value for what platform GHC is currently compiling for. You should use these when appropriate over the CPP methods.</p>
<h1 id="pointer-tagging-1">Pointer Tagging</h1>
<p>Paper: <a href="http://research.microsoft.com/pubs/67969/ptr-tagging.pdf">Faster laziness using dynamic pointer tagging</a></p>
<p>In GHC we &quot;tag&quot; pointers to heap objects with information about the object they point to. The tag goes in the low 2 bits (3 bits on a 64-bit platform) of the pointer, which would normally be zero since heap objects are always [wiki:Commentary/Rts/Word word]-aligned.</p>
<h2 id="meaning-of-the-tag-bits">Meaning of the tag bits</h2>
<p>The way the tag bits are used depends on the type of object pointed to:</p>
<p><code>*Iftheobjectisa</code><strong><code>constructor</code></strong><code>,thetagbitscontainthe</code><em><code>constructor</code> <code>tag</code></em><code>,ifthenumberof</code><br />
<code>constructorsinthedatatypeislessthan4(lessthan8ona64-bitplatform).Ifthenumberof</code><br />
<code>constructorsinthedatatypeisequaltoormorethan4(resp8),thenthetagbitshavethevalue1,andtheconstructortag</code><br />
<code>isextractedfromtheconstructor'sinfotableinstead.</code></p>
<p><code>*Iftheobjectisa</code><strong><code>function</code></strong><code>,thetagbitscontainthe</code><em><code>arity</code></em><code>ofthefunction,ifthearityfits</code><br />
<code>inthetagbits.</code></p>
<p><code>*Forapointertoanyotherobject,thetagbitsarealwayszero.</code></p>
<h2 id="optimisations-enabled-by-tag-bits">Optimisations enabled by tag bits</h2>
<p>The presence of tag bits enables certain optimisations:</p>
<p><code>*Inacase-expression,ifthevariablebeingscrutinisedhasnon-zerotagbits,thenweknow</code><br />
<code>thatitpointsdirectlytoaconstructorandwecanavoid</code><em><code>entering</code></em><code>ittoevaluateit.</code><br />
<code>Furthermore,fordatatypeswithonlyafewconstructors,thetagbitswilltellus</code><em><code>which</code></em><br />
<code>constructoritis,eliminatingafurthermemoryloadtoextracttheconstructortagfromthe</code><br />
<code>infotable.</code></p>
<p><code>*Ina[wiki:Commentary/Rts/HaskellExecution/FunctionCalls#Genericapplygenericapply],ifthefunctionbeingappliedhasatagvaluethatindicatesithasexactlythe</code><br />
<code>rightarityforthenumberofargumentsbeingapplied,wecanjumpdirectlytothefunction,insteadof</code><br />
<code>inspectingitsinfotablefirst.</code></p>
<p>Pointer-tagging is a fairly significant optimisation: we measured 10-14% depending on platform. A large proportion of this comes from eliminating the indirect jumps in a case expression, which are hard to predict by branch-prediction. The paper has full results and analysis.</p>
<h2 id="garbage-collection-with-tagged-pointers">Garbage collection with tagged pointers</h2>
<p>The [wiki:Commentary/Rts/Storage/GC garbage collector] maintains tag bits on the pointers it traverses. This is easier, it turns out, than <em>reconstructing</em> tag bits. Reconstructing tag bits would require that the GC knows not only the tag of the constructor (which is in the info table), but also the family size (which is currently not in the info table), since a constructor from a large family should always have tag 1. To make this practical we would probably need different closure types for &quot;small family&quot; and &quot;large family&quot; constructors, and we already subdivide the constructor closures types by their layout.</p>
<p>Additionally, when the GC eliminates an indirection it takes the tag bits from the pointer inside the indirection. Pointers to indirections always have zero tag bits.</p>
<h2 id="invariants">Invariants</h2>
<p>Pointer tagging is <em>not</em> optional, contrary to what the paper says. We originally planned that it would be: if the GC threw away all the tags, then everything would continue to work albeit more slowly. However, it turned out that in fact we really want to assume tag bits in some places:</p>
<p><code>*Inthecontinuationofanalgebraiccase,R1isassumedtagged</code><br />
<code>*Onentrytoanon-top-levelfunction,R1isassumedtagged</code></p>
<p>If we don't assume the value of the tag bits in these places, then extra code is needed to untag the pointer. If we can assume the value of the tag bits, then we just take this into account when indexing off R1.</p>
<p>This means that everywhere that enters either a case continuation or a non-top-level function must ensure that R1 is correctly tagged. For a case continuation, the possibilities are:</p>
<p><code>*thescrutineeofthecasejumpsdirectlytothealternativeifR1isalreadytagged.</code><br />
<code>*theconstructorentrycodereturnstoanalternative.Thiscodeaddsthecorrecttag.</code><br />
<code>*ifthecasealternativefailsaheaporstackcheck,thentheRTSwillre-enterthealternativeafter</code><br />
<code>GC.Inthiscase,ourre-entryarrangestoentertheconstructor,sowegetthecorrecttagby</code><br />
<code>virtueofgoingthroughtheconstructorentrycode.</code></p>
<p>For a non-top-level function, the cases are:</p>
<p><code>*unknownfunctionapplicationgoesvia`stg_ap_XXX`(see[wiki:Commentary/Rts/HaskellExecution/FunctionCalls#GenericapplyGenericApply]).</code><br />
<code>ThegenericapplyfunctionsmustthereforearrangetocorrectlytagR1beforeenteringthefunction.</code><br />
<code>*Aknownfunctioncanbeentereddirectly,ifthecallismadewithexactlytherightnumberofarguments.</code><br />
<code>*Ifafunctionfailsitsheapcheckandreturnstotheruntimetogarbagecollect,onre-entrytheclosure</code><br />
<code>pointermustbestilltagged.</code><br />
<code>*thePAPentrycodejumpstothefunction'sentrycode,soitmusthaveataggedpointertothefunction</code><br />
<code>closureinR1.WethereforeassumethataPAPalwayscontainsataggedpointertothefunctionclosure.</code></p>
<p>In the second case, calling a known non-top-level function must pass the function closure in R1, and this pointer <em>must</em> be correctly tagged. The code generator does not arrange to tag the pointer before calling the function; it assumes the pointer is already tagged. Since we arrange to tag the pointer when the closure is created, this assumption is normally safe. However, if the pointer has to be saved on the stack, say across a call, then when the pointer is retrieved again we must either retag it, or be sure that it is still tagged. Currently we do the latter, but this imposes an invariant on the garbage collector: all tags must be retained on non-top-level function pointers.</p>
<p>Pointers to top-level functions are not necessarily tagged, because we don't always know the arity of a function that resides in another module. When optimisation is on, we do know the arities of external functions, and this information is indeed used to tag pointers to imported functions, but when optimisation is off we do not have this information. For constructors, the interface doesn't contain information about the constructor tag, except that there may be an unfolding, but the unfolding is not necessarily reliable (the unfolding may be a constructor application, but in reality the closure may be a CAF, e.g. if any of the fields are references outside the current shared library).</p>
<h2 id="compacting-gc">Compacting GC</h2>
<p>Compacting GC also uses tag bits, because it needs to distinguish between a heap pointer and an info pointer quickly. The compacting GC has a complicated scheme to ensure that pointer tags are retained, see the comments in <a href="GhcFile(rts/sm/Compact.c)" class="uri" title="wikilink">GhcFile(rts/sm/Compact.c)</a>.</p>
<h2 id="dealing-with-tags-in-the-code">Dealing with tags in the code</h2>
<p>Every time we dereference a pointer to a heap object, we must first zero the tag bits. In the RTS, this is done with the inline function (previously: macro) `UNTAG_CLOSURE()`; in `.cmm` code this is done with the `UNTAG()` macro. Surprisingly few places needed untagging to be added.</p>
<h1 id="position-independent-code-and-dynamic-linking">Position-Independent Code and Dynamic Linking</h1>
<p>We need to generate position-independent code on most platforms when we want our code to go into dynamic libraries (also referred to as shared libraries or DLLs). On some platforms (AIX, powerpc64-linux, x86_64-darwin), PIC is required for all code.</p>
<p>To access things defined in a dynamic library, we might need to do special things, such as look up the address of the imported thing in a table of pointers, depending on what platform we are on.</p>
<h2 id="how-to-access-symbols">How to access symbols</h2>
<p>A C compiler is in an unfortunate position when generating PIC code, as it does not have any hints, whether an accessed symbol ends up in the same dynamic library or if it is truely an external symbol (from the dynamic library point of view). It can only generate non-PIC access for symbols generated within the same object file. In Haskell, we can do better as we assume all package code to end up in a single dynamic library. Hence, all intra-package symbol accesses can be generated as code that does direct access. For all inter-package accesses (package haskell98 accessing symbols in package base, e.g.), we have to generate PIC code. For the following we establish the following:</p>
<p><code>*</code><em><code>object-local</code> <code>symbols</code></em><code>,symbolswithinthesameobjectfile.Alwaysgeneratedirectaccess.</code><br />
<code>*</code><em><code>package-local</code> <code>symbols</code></em><code>,symbolswithinthesameHaskellpackage.TheNCGcangeneratedirectaccesscode,Ccompilerscan't.</code><br />
<code>*</code><em><code>local</code> <code>symbols</code></em><code>,eitherobject-localorpackage-local.</code><br />
<code>*</code><em><code>global</code> <code>symbols</code></em><code>,symbolindifferentlibraries/packages.AlwaysgeneratePIC.</code></p>
<h2 id="clabel.labeldynamic">CLabel.labelDynamic</h2>
<p>On most platforms, we can access any global symbol as if it was imported from a dynamic library; this usually means a small performance hit (an extra pointer dereference), but it is otherwise harmless. On some platforms, we have to access all global symbols this way. On Windows, we must know exactly which symbols are DLL-imported and which aren't.</p>
<p>Module `CLabel` contains a function `labelDynamic :: CLabel -&gt; Bool` which is supposed to know whether a `CLabel` is imported from a dynamic library. On Windows, this function needs to be exact; everywhere else, we don't mind the occasional false positive.</p>
<h2 id="info-tables-1">Info Tables</h2>
<p>Info tables are in the text segment, which is supposed to be read-only and position-independent. Therefore, an info table <em>must not</em> contain any absolute address; instead, all addresses in info tables are instead encoded as relative offsets from the info label.</p>
<p>Note that this is done even when we are generating code that is otherwise position-dependent, in order to preserve binary compatibility between PIC and non-PIC.</p>
<p>It is not possible to generate those relative references from C code, so for the via-C compilation route, we pretty-print these relative references (`CmmLabelDiffOff` in cmm) as absolute references and have the mangler convert them to relative references again.</p>
<h2 id="imported-labels-in-srts-windows">Imported labels in SRTs (Windows)</h2>
<p>Windows doesn't support references to imported labels in the data segment; on other platforms, the dynamic linker will just relocate the pointers in the SRTs to point to the right symbols. There is a hack in the code that tries to work around it; it might be bitrotted, and it might have been made unnecessary by the GNU linker's new auto-import on Windows.</p>
<h2 id="pic-and-dynamic-linking-support-in-the-ncg">PIC and dynamic linking support in the NCG</h2>
<p>The module `PositionIndependentCode` lies at the heart of PIC and dynamic linking support in the native code generator.</p>
<p>The basic idea is to call a function `cmmMakeDynamicReference` for all labels accessed from the code during the cmm-to-cmm transformation phase. This function will decide on the appropriate way to access the given label for the current platform and the current combination of -fPIC and -dynamic flags.</p>
<p>We extend Cmm and the `CLabel` module by a few things to allow us to express all the different things that occur on different platforms:</p>
<p>The `Cmm.GlobalReg` datatype has a constructor `PicBaseReg`. This PIC base register is the register relative to which position-independent references are calculated. This can be a general-purpose register that is allocated on a per-!CmmProc basis, or it can be a dedicated register, like the instruction pointer `%rip` on x86_64.</p>
<h2 id="how-things-are-done-on-different-platforms">How things are done on different platforms</h2>
<p>This section is a survey of how PIC and dynamic linking works on different platforms. There are small snippets of assembly code for several platforms, platforms that are similar to other platforms are left out (e.g. powerpc-darwin is left out, because the logic is the same as for i386-darwin). I hope the reader will not be too confused by irrelevant differences between the platforms, such as the fact that Darwin and Windows prefix all symbols with an underscore, and Linux doesn't.</p>
<h3 id="position-dependent-code">Position dependent code</h3>
<p>In the absence of PIC and dynamic linking, things are simple; when we use a label in assembly code, the linker will make sure it points to the right place.</p>
<p></p>
<p>Now, to access a symbol `xfoo` that has been imported from a dynamic library, we do not want to mention the address of `xfoo` in the text section, because it would need to be modified at load-time.</p>
<p>One solution is to allocate a pointer to the imported symbol in a writable section and have the dynamic linker fill in this pointer table. The pointer table itself resides at a statically known address. The __imp__* symbols on Windows are automatically generated by the linker.</p>
<p></p>
<p>On Mac OS X, the same system is used for data imports, but this time we have to define the symbol pointers ourselves. For references to code, there is an additional mechanism available; we can jump to a small piece of stub code that will resolve the symbol the first time it is used, in order to reduce application load times. Unfortunately, everything on Mac OS X requires 16-byte stack alignment, even the dynamic linker, so we cannot use this for a tail call.</p>
<p></p>
<p>In theory, dynamic linking is transparent to position-dependent code on Linux, i.e. the code for accessing imported labels should look exactly the same as for non-imported labels. Unfortunately, things just don't work as they should for strange stuff like info tables.</p>
<p>When the ELF static linker finds a jump or call to an imported symbol, it automatically redirects the jump or call to a linker generated code stub (in the so-called procedure linkage table, or PLT). The linker then considers the label to be a code label and redirects all further references to the label to the code stub, even if they are data references. If this ever happens to an info label, our program will crash, as there is no info table in front of the code stub.</p>
<p>When the ELF static linker finds a data reference to an imported symbol (that it doesn't consider a code label), it allocates space for that symbol in the executable's data section and issues an `R_COPY` relocation, which instructs the dynamic linker to copy the (initial) contents of the symbol to its new place in the executable's image. All references to the symbol from the dynamic library are relocated to point to the symbol's new location, instead.</p>
<p>If `R_COPY` is ever used for an info label, our program will also crash, because the data we're interested in is *before* the info label and is not copied to the symbol's new home.</p>
<p>Fortunately, if the static linker finds a pointer to an imported symbol in a writable section, it just instructs the dynamic linker to update that pointer to the symbols address, without doing anything &quot;funny&quot;. We can therefore work around these problems.</p>
<p>The workaround is inspired by the position-independent code that GCC generates for powerpc-linux, a platform that is amazingly broken.</p>
<p></p>
<p>Things look pretty much the same on x86_64-linux, powerpc-linux and powerpc-darwin; PowerPC has the added handicap that it takes two instructions to load a 32 bit quantity into a register. On x86_64-darwin, powerpc64-linux and all versions of AIX, PIC is <em>required</em>.</p>
<h3 id="position-independent-code">Position independent code</h3>
<p>First, let it be said that there is no such thing as position-independent code on Windows. The dynamic linker will just patiently relocate all dynamic libraries that are not loaded at their preferred base address. On all other platforms, PIC is at least strongly recommended for dynamic libraries.</p>
<p>In an ideal world, there would be assembler instructions for referring to things via an offset from the current instruction pointer. Jump instructions are ip-relative on all platforms that GHC runs on, but for data accesses, only x86_64 is this ideal world.</p>
<p>On x86_64, on both Linux and Mac OS X, we can use `foo(%rip)` to encode an instruction pointer relative data reference to `foo`, and `foo@GOTPCREL(%rip)` to encode an instruction pointer relative referece to a linker-generated symbol pointer for symbol `foo`. A linker-generated code stub for imported code can be accessed by appending `@PLT` to the label on Linux, and is used implicitly when necessary on Mac OS X.</p>
<p>Again, we have to avoid the code stubs for tail-calls and use the symbol pointer instead, because there is a stack alignment requirement.</p>
<p></p>
<p>Other platforms are not nearly as nice; i386 and powerpc[64] do not have a way of accessing the current instruction pointer or referring to data relative to it. The *only* way to get at the current instruction pointer is to issue a call instruction. To generate PIC code, we have to do just that at the beginning of each function.</p>
<p>On Darwin, things are relatively straightforward: </p>
<p>There is one more small additional complication on Darwin. The assembler doesn't support label difference expressions involving labels not defined in the same source file, so we have to treat all symbols not defined in the same source file as dynamically imported.</p>
<p>On Linux, we need to first calculate the address of the Global Offset Table (GOT) and then use `bar@GOT` to refer to symbol pointers and `bar@GOTOFF` to refer to a local symbol relative to the GOT. Also, the linker-generated code-stubs (`xfoo@PLT`) require the address of the GOT to be in register `%ebx` when they are invoked. The NCG currently doesn't do this, so we avoid code stubs altogether on i386.</p>
<p></p>
<p><strong>To be done:</strong> powerpc-linux, AIX/powerpc64-linux</p>
<h2 id="linking-on-elf">Linking on ELF</h2>
<p>To generate a DSO on ELF platform, we use GNU ld. Except for `-Bsymbolic`, ld is invoked regularly with the `-shared` option, and `-o` pointing to the output DSO file followed objects that in its sum compose an entire package. In Haskell, we assume that there is a one-to-one mapping from packages to DSOs. So, all parts of the base package will end up in a libHSbase.so. As intra-package references are not generated as PIC code, we have to supply all objects that make up a package, so that ld is able to resolve these references before writing a (.text) relocation free DSO library file. To enable these cross-object relocations GNU ld needs `-Bsymbolic`.</p>
<h2 id="mangling-dynamic-library-names">Mangling dynamic library names</h2>
<p>As Haskell DSOs might end up in standard library paths, and as they might not be compatible among compilers and compiler version, we need to mangle their names to include the compiler and its version.</p>
<p>The scheme is libHS<em><package></em>-<em><package-version></em>-<em><compiler><compilerversion></em>.so. E.g. libHSbase-2.1-ghc6.6.so</p>
<h1 id="ghc-commentary-the-c-code-generator">GHC Commentary: The C code generator</h1>
<p>Source: <a href="GhcFile(compiler/cmm/PprC.hs)" class="uri" title="wikilink">GhcFile(compiler/cmm/PprC.hs)</a></p>
<p>This phase takes [wiki:Commentary/Compiler/CmmType Cmm] and generates plain C code. The C code generator is very simple these days, in fact it can almost be considered pretty-printing. It is only used for unregisterised compilers.</p>
<h2 id="header-files">Header files</h2>
<p>GHC was changed (from version 6.10) so that the C backend no longer uses header files specified by the user in any way. The `c-includes` field of a `.cabal` file is ignored, as is the `-#include` flag on the command-line. There were several reasons for making this change:</p>
<p>This has several advantages:</p>
<p><code>*ViaCcompilationisconsistentwiththeotherbackendwithrespecttoFFIdeclarations:</code><br />
<code>allbindtotheABI,nottheAPI.</code><br />
<code></code><br />
<code>*foreigncallscannowbeinlinedfreelyacrossmoduleboundaries,since</code><br />
<code>aheaderfileisnotrequiredwhencompilingthecall.</code><br />
<code></code><br />
<code>*bootstrappingviaCwillbemorereliable,becausethisdifference</code><br />
<code>inbehaviorbetweenthetwobackendshasbeenremoved.</code><br />
<code></code></p>
<p>There are some disadvantages:</p>
<p><code>*wegetnocheckingbytheCcompilerthattheFFIdeclaration</code><br />
<code>iscorrect.</code></p>
<p><code>*wecan'tbenefitfrominlinedefinitionsinheaderfiles.</code><br />
<code></code></p>
<h2 id="prototypes">Prototypes</h2>
<p>When a label is referenced by an expression, the compiler needs to know whether to declare the label first, and if so, at what type.</p>
<p>C only lets us declare an external label at one type in any given source file, even if the scopes of the declarations don't overlap. So we either have to scan the whole code to figure out what the type of each label should be, or we opt for declaring all labels at the same type and then casting later. Currently we do the latter.</p>
<p><code>*alllabelsreferencedasaresultofanFFIdeclaration</code><br />
<code>aredeclaredas`externStgWord[]`,includingfunctionlabels.</code><br />
<code>Ifthelabeliscalled,itisfirstcasttothecorrect</code><br />
<code>functiontype.Thisisbecausethesamelabelmightbe</code><br />
<code>referredtobothasafunctionandanuntypeddatalabelin</code><br />
<code>thesamemodule(e.g.Foreign.Marsal.Allocrefersto&quot;free&quot;</code><br />
<code>thisway).</code></p>
<p><code>*Anexceptionismadetotheaboveforfunctionsdeclaredwith</code><br />
<code>the`stdcall`callingconventiononWindows.Thesefunctionsmust</code><br />
<code>bedeclaredwiththe`stdcall`attributeandafunctiontype,</code><br />
<code>otherwisetheCcompilerwon'taddthe`@n`suffixtothesymbol.</code><br />
<code>Wecan'taddthe`@n`suffixourselves,becauseitisillegal</code><br />
<code>syntaxinC.However,wealwaysdeclaretheselabelswiththe</code><br />
<code>type`void(*)(void)`,toavoidconflictsifthesamefunction</code><br />
<code>iscalledatdifferenttypesinonemodule(see`Graphics.Win32.GDI.HDC.SelectObject`).</code></p>
<p><code>*Anotherexceptionismadeforfunctionsthataremarked`neverreturns`inC--.We</code><br />
<code>havetoputan`__attribute__((noreturn))`onthedeclarationforthesefunctions,</code><br />
<code>anditonlyworksifthefunctionisdeclaredwithaproperfunctiontypeand</code><br />
<code>calledwithoutcastingitto/fromapointer.Soonlythecorrectprototype</code><br />
<code>willdohere.</code></p>
<p><code>*allRTSsymbolsalreadyhavedeclarations(mostlywiththecorrect</code><br />
<code>type)in</code><a href="GhcFile(includes/StgMiscClosures.h)" title="wikilink"><code>GhcFile(includes/StgMiscClosures.h)</code></a><code>,sonodeclarationsaregenerated.</code></p>
<p><code>*certainlabelsareknowntohavebeendefinedearlierinthesamefile,</code><br />
<code>soadeclarationcanbeomitted(e.g.SRTlabels)</code></p>
<p><code>*certainmathfunctions(`sin()`,`cos()`etc.)arealreadydeclaredbecause</code><br />
<code>we#includemath.h,sowedon'temitdeclarationsforthese.Weneed</code><br />
<code>to#includemath.hbecausesomeofthesefunctionshaveinline</code><br />
<code>definitions,andwegetterriblecodeotherwise.</code></p>
<p>When compiling the RTS cmm code, we have almost no information about labels referenced in the code. The only information we have is whether the label is defined in the RTS or in another package: a label that is declared with an import statement in the .cmm file is assumed to be defined in another package (this is for dynamic linking, where we need to emit special code to reference these labels).</p>
<p>For all other labels referenced by RTS .cmm code, we assume they are RTS labels, and hence already declared in <a href="GhcFile(includes/StgMiscClosures.h)" class="uri" title="wikilink">GhcFile(includes/StgMiscClosures.h)</a>. This is the only choice here: since we don't know the type of the label (info, entry etc.), we can't generate a correct declaration.</p>
<p><a href="PageOutline" class="uri" title="wikilink">PageOutline</a></p>
<h1 id="primitive-operations-primops">Primitive Operations (!PrimOps)</h1>
<p>!PrimOps are functions that cannot be implemented in Haskell, and are provided natively by GHC. For example, adding two  values is provided as the !PrimOp , and allocating a new mutable array is the !PrimOp .</p>
<p>!PrimOps are made available to Haskell code through the virtual module . This module has no implementation, and its interface never resides on disk: if  is imported, we use a built-in  value - see  in <a href="GhcFile(compiler/iface/LoadIface.hs)" class="uri" title="wikilink">GhcFile(compiler/iface/LoadIface.hs)</a>.</p>
<p>It would also be useful to look at the [wiki:Commentary/Compiler/WiredIn Wired-in and known-key things] wiki page to understand this topic.</p>
<h2 id="the-primops.txt.pp-file">The primops.txt.pp file</h2>
<p>The file <a href="GhcFile(compiler/prelude/primops.txt.pp)" class="uri" title="wikilink">GhcFile(compiler/prelude/primops.txt.pp)</a> includes all the information the compiler needs to know about a !PrimOp, bar its actual implementation. For each !PrimOp,  lists:</p>
<p><code>*Itsname,asitappearsinHaskellcode(eg.int2Integer#)</code><br />
<code>*Itstype</code><br />
<code>*ThenameofitsconstructorinGHC's</code><code>datatype.</code><br />
<code>*Variousproperties,suchaswhethertheoperationiscommutable,orhassideeffects.</code></p>
<p>For example, here's the integer multiplication !PrimOp:</p>
<p></p>
<p>The  file is processed first by CPP, and then by the  program (see <a href="GhcFile(utils/genprimopcode)" class="uri" title="wikilink">GhcFile(utils/genprimopcode)</a>).  generates the following bits from :</p>
<p><code>*Variousfilesthatare</code><code>dinto</code><a href="GhcFile(compiler/prelude/PrimOp.hs)" title="wikilink"><code>GhcFile(compiler/prelude/PrimOp.hs)</code></a><code>,</code><br />
<code>containingdeclarationsofdatatypesandfunctionsdescribingthe!PrimOps.See</code><br />
<code></code><a href="GhcFile(compiler/Makefile)" title="wikilink"><code>GhcFile(compiler/Makefile)</code></a><code>.</code></p>
<p><code>*</code><code>,afilethatcontains(curried)wrapper</code><br />
<code>functionsforeachofthe!PrimOps,sothattheyareaccessiblefrombyte-code,and</code><br />
<code>sothatthe[wiki:Commentary/Rts/Interpreterbyte-codeinterpreter]doesn'tneedtoimplementany!PrimOpsatall:it</code><br />
<code>justinvokesthecompiledonesfrom</code><code>.</code></p>
<p><code>*</code><code>,asourcefilecontainingdummydeclarationsfor</code><br />
<code>allthe!PrimOps,solelysothatHaddockcanincludedocumentationfor</code><br />
<code>initsdocumentationforthe</code><code>package.Thefile</code><code>isnever</code><br />
<code>actuallycompiled,onlyprocessedbyHaddock.</code></p>
<p>Note that if you want to create a polymorphic primop, you need to return , not .</p>
<h2 id="implementation-of-primops">Implementation of !PrimOps</h2>
<p>!PrimOps are divided into two categories for the purposes of implementation: inline and out-of-line.</p>
<h3 id="inline-primops">Inline !PrimOps</h3>
<p>Inline !PrimOps are operations that can be compiled into a short sequence of code that never needs to allocate, block, or return to the scheduler for any reason. An inline !PrimOp is compiled directly into [wiki:Commentary/Rts/Cmm Cmm] by the [wiki:Commentary/Compiler/CodeGen code generator]. The code for doing this is in <a href="GhcFile(compiler/codeGen/StgCmmPrim.hs)" class="uri" title="wikilink">GhcFile(compiler/codeGen/StgCmmPrim.hs)</a>.</p>
<h3 id="out-of-line-primops">Out-of-line !PrimOps</h3>
<p>All other !PrimOps are classified as out-of-line, and are implemented by hand-written C-- code in the file <a href="GhcFile(rts/PrimOps.cmm)" class="uri" title="wikilink">GhcFile(rts/PrimOps.cmm)</a>. An out-of-line !PrimOp is like a Haskell function, except that</p>
<p><code>*!PrimOpscannotbepartiallyapplied.Callstoall!PrimOpsaremadeatthecorrectarity;thisisensuredby</code><br />
<code>the[wiki:Commentary/Compiler/HscMainCorePrep]pass.</code></p>
<p><code>*Out-of-line!PrimOpshaveaspecial,fixed,[wiki:Commentary/Rts/HaskellExecution#CallingConventioncallingconvention]:</code><br />
<code>allarguments</code><br />
<code>areinthe[wiki:Commentary/Rts/HaskellExecution#Registersregisters]R1-R8.Thisistomakeiteasytowritethe</code><br />
<code>C--codeforthese!PrimOps:wedon'thavetowritecodeformultiplecallingconventions.</code></p>
<p>It's possible to provide inline versions of out-of-line !PimOps. This is useful when we have enough static information to generated a short, more efficient inline version. For example, a call to  can be implemented more efficiently as an inline !PrimOp as the heap check for the array allocation can be combined with the heap check for the surrounding code. See `shouldInlinePrimOp` in <a href="GhcFile(compiler/codeGen/StgCmmPrim.hs)" class="uri" title="wikilink">GhcFile(compiler/codeGen/StgCmmPrim.hs)</a>.</p>
<h3 id="foreign-out-of-line-primops-and-foreign-import-prim">Foreign out-of-line !PrimOps and `foreign import prim`</h3>
<p>A new and somewhat more flexible form of out-of-line !PrimOp is the foreign out-of-line !PrimOp. These are essentially the same but instead of their Cmm code being included in the RTS, they can be defined in Cmm code in any package and instead of knowledge of the !PrimOp being baked into the compiler, they can be imported using special FFI syntax:</p>
<p></p>
<p>The string (e.g. &quot;int2Integerzh&quot;) is the linker name of the Cmm function. Using this syntax requires the extensions `ForeignFunctionInterface`, `GHCForeignImportPrim`, `MagicHash`, `UnboxedTuples` and `UnliftedFFITypes`. The current type restriction is that all arguments and results must be unlifted types, with two additional possibilities: An argument may (since GHC 7.5) be of type `Any` (in which case the called function will receive a pointer to the heap), and the result type is allowed to be an unboxed tuple. The calling convention is exactly the same as for ordinary out-of-line primops. Currently it is not possible to specify any of the !PrimOp attributes.</p>
<p>The `integer-gmp` package now uses this method for all the primops that deal with GMP big integer values. The advantage of using this technique is that it is a bit more modular. The RTS does not need to include all the primops. For example in the integer case the RTS no longer needs to link against the GMP C library.</p>
<p>The future direction is to extend this syntax to allow !PrimOp attributes to be specified. The calling convention for primops and ordinary compiled Haskell functions may be unified in future and at that time it the restriction on using only unlifted types may be lifted.</p>
<p>It has been suggested that we extend this !PrimOp definition and import method to cover all !PrimOps, even inline ones. This would replace the current `primops.txt.pp` system of builtin !PrimOps. The inline !PrimOps would still be defined in the compiler but they would be imported in any module via `foreign import prim` rather than appearing magically to be exported from the `GHC.Prim` module. Hugs has used a similar system for years (with the syntax `primitive seq :: a -&gt; b -&gt; b`).</p>
<h2 id="adding-a-new-primop">Adding a new !PrimOp</h2>
<p>To add a new primop, you currently need to update the following files:</p>
<p><code>*</code><a href="GhcFile(compiler/prelude/primops.txt.pp)" title="wikilink"><code>GhcFile(compiler/prelude/primops.txt.pp)</code></a><code>,whichincludesthe</code><br />
<code>typeoftheprimop,andvariousotherproperties.Syntaxand</code><br />
<code>examplesareinthefile.</code></p>
<p><code>*iftheprimopisinline,then:</code><br />
<code></code><a href="GhcFile(compiler/codeGen/StgCmmPrim.hs)" title="wikilink"><code>GhcFile(compiler/codeGen/StgCmmPrim.hs)</code></a><code>definesthetranslationof</code><br />
<code>theprimopinto</code><code>.</code><br />
<code></code><br />
<code>*foranout-of-lineprimop:</code><br />
<code>*</code><a href="GhcFile(includes/stg/MiscClosures.h)" title="wikilink"><code>GhcFile(includes/stg/MiscClosures.h)</code></a><code>(justaddthedeclaration),</code><br />
<code>*</code><a href="GhcFile(rts/PrimOps.cmm)" title="wikilink"><code>GhcFile(rts/PrimOps.cmm)</code></a><code>(implementithere)</code><br />
<code>*</code><a href="GhcFile(rts/Linker.c)" title="wikilink"><code>GhcFile(rts/Linker.c)</code></a><code>(declarethesymbolforGHCi)</code></p>
<p><code>*foraforeignout-of-lineprimopYoudonotneedtomodifythertsorcompileratall.</code><br />
<code>*`yourpackage/cbits/primops.cmm`:implementyourprimopshere.Youhavetoarrangeforthe.cmmfiletobecompiledandlinkedintothepackage.TheGHCbuildsystemhassupportforthis.Cabaldoesnotyet.</code><br />
<code>*`yourpackage/TheCode.hs`:use`foreignimportprim`toimporttheprimops.</code></p>
<p>In addition, if new primtypes are being added, the following files need to be updated:</p>
<p><code>*</code><a href="GhcFile(utils/genprimopcode/Main.hs)" title="wikilink"><code>GhcFile(utils/genprimopcode/Main.hs)</code></a><code>--extendppType::Type-&gt;Stringfunction</code><br />
<code></code><br />
<code>*</code><a href="GhcFile(compiler/prelude/PrelNames.hs)" title="wikilink"><code>GhcFile(compiler/prelude/PrelNames.hs)</code></a><code>--addanewuniqueidusingmkPreludeTyConUnique</code></p>
<p><code>*</code><a href="GhcFile(compiler/prelude/TysPrim.hs)" title="wikilink"><code>GhcFile(compiler/prelude/TysPrim.hs)</code></a><code>--therearearaftofchangeshere;youneedtocreate</code><code>,</code><code>and</code><code>variables.ThemostimportantthingtomakesureyougetrightiswhenyoumakeaPrimTyCon,youpickthecorrect</code><code>foryourtype.Forexample,ifyou</code></p>
<h1 id="profiling">Profiling</h1>
<p>GHC includes two types of profiling: cost-centre profiling and ticky-ticky profiling. Additionally, HPC code coverage is not &quot;technically&quot; profiling, but it uses a lot of the same mechanisms as cost-centre profiling (you can read more about it at [wiki:Commentary/Hpc]).</p>
<p>Cost-centre profiling operates at something close to the source level, and ticky-ticky profiling operates at something much closer to the machine level. This means that the two types of profiling are useful for different tasks. Ticky-ticky profiling is mainly meant for compiler implementors, and cost-centre profiling for mortals. However, because cost-centre profiling operates at a high level, it can be difficult (if not impossible) to use it to profile optimized code. Personally, I (Kirsten) have had a lot of success using cost-centre profiling to find problems that were due to my own bad algorithms, but less success once I was fairly sure that I wasn't doing anything obviously stupid and was trying to figure out why my code didn't get optimized as well as it could have been.</p>
<p>You can't use cost-centre profiling and ticky-ticky profiling at the same time; in the past, this was because ticky-ticky profiling relied on a different closure layout, but now that's no longer the case. You probably can't use both at the same time as it is unless you wanted to modify the build system to allow using way=p and way=t at the same time to build the RTS. I haven't thought about whether it would make sense to use both at the same time.</p>
<h2 id="cost-centre-profiling">Cost-centre profiling</h2>
<p>Cost-center profiling in GHC, e.g. of SCCs, consists of the following components:</p>
<p><code>*Data-structuresforrepresentingcost-centresin</code><a href="GhcFile(compiler/profiling/CostCentre.lhs)" title="wikilink"><code>GhcFile(compiler/profiling/CostCentre.lhs)</code></a><code>.</code><br />
<code>*Front-endsupportin</code><a href="GhcFile(compiler/deSugar/DsExpr.lhs)" title="wikilink"><code>GhcFile(compiler/deSugar/DsExpr.lhs)</code></a><code>,forconverting</code><code>pragmaintothe</code><code>constructorinCore.</code><br />
<code>*Modificationstooptimizationbehaviorin</code><a href="GhcFile(compiler/coreSyn/CoreUtils.lhs)" title="wikilink"><code>GhcFile(compiler/coreSyn/CoreUtils.lhs)</code></a><code>and</code><a href="GhcFile(compiler/coreSyn/CorePrep.lhs)" title="wikilink"><code>GhcFile(compiler/coreSyn/CorePrep.lhs)</code></a><code>topreventoptimizationswhichwouldresultinmisleadingprofileinformation.MostofthisistohandlethefactthatSCCsalsocountentries(tickishCounts,alsoappliesto[wiki:Commentary/Hpc]);otherwisetheonlyrelevantoptimizationisavoidingfloatingexpressionsoutofSCCs.Notethatthesimplifieralsohas&quot;ticks&quot;(soitcandecidewhentostopoptimizing);thesearenotthesamethingatall.</code><br />
<code>*The</code><code>constructorinSTG,andcodegenerationforit</code><a href="GhcFile(compiler/codeGen/StgCmmProf.hs)" title="wikilink"><code>GhcFile(compiler/codeGen/StgCmmProf.hs)</code></a><br />
<code>*ApassoverSTGin</code><a href="GhcFile(compiler/profiling/SCCfinal.lhs)" title="wikilink"><code>GhcFile(compiler/profiling/SCCfinal.lhs)</code></a><code>tocollectcostcentressothattheycanbestaticallydeclaredby</code><a href="GhcFile(compiler/profiling/ProfInit.hs)" title="wikilink"><code>GhcFile(compiler/profiling/ProfInit.hs)</code></a><code>,andaddextraSCCsinthecaseof</code><code>;seealso</code><a href="GhcFile(compiler/profiling/NOTES)" title="wikilink"><code>GhcFile(compiler/profiling/NOTES)</code></a><br />
<code>*Code-generationforsettinglabelsfoundin</code><a href="GhcFile(compiler/codeGen/StgCmmProf.hs)" title="wikilink"><code>GhcFile(compiler/codeGen/StgCmmProf.hs)</code></a><code>,inparticularsavingandrestoringCClabelsandwellascountingticks;notethatcost-centresevengettheirownconstructorinC--asCC_Labels(cost-centrelabels).</code><br />
<code>*Runtimesupportforinitializingandmanipulatingtheactualruntime</code><code>structswhichstoreinformation,in</code><a href="GhcFile(rts/Profiling.c)" title="wikilink"><code>GhcFile(rts/Profiling.c)</code></a><code>;headersarelocatedin</code><a href="GhcFile(includes/rts/prof/CCS.h)" title="wikilink"><code>GhcFile(includes/rts/prof/CCS.h)</code></a></p>
<h2 id="ticky-ticky-profiling">Ticky-ticky profiling</h2>
<p>Ticky-ticky profiling is very simple (conceptually): instrument the C code generated by GHC with a lot of extra code that updates counters when various (supposedly) interesting things happen, and generate a report giving the values of the counters when your program terminates. GHC does this instrumentation for you when you compile your program with a special flag. Then, you use another flag to tell the RTS to generate the profiling report.</p>
<p>You might want to use ticky-ticky profiling for one of the following two reasons:</p>
<ul>
<li>You are an implementor trying to understand the effect of an optimization in GHC more precisely.</li>
</ul>
<ul>
<li>You are a user trying to observe the behavior of your programs with optimization turned on. GHC doesn't do certain transformations in the presence of cost centres, so cost-centre profiling can be less than accurate if you're trying to understand what really happens when you're compiling with .</li>
</ul>
<p>I won't necessarily try to argue that ticky-ticky is useful at all for the second group of people, but it's better than nothing, and perhaps the ticky-ticky data could be used to build a better profiler.</p>
<p>For more info, including HOWTO details, see [wiki:Debugging/TickyTicky]. like &quot;computer is a net&quot;, nowadays language is a library. there is nothing exceptional in C++ and Java languages except for their huge library codebase that makes them so widely appreciated</p>
<p>while it's impossible for Haskell to have the same level of libraries maturity, we can try to do our best. Libraries was considered so important, that in H98 report libs required more pages than language itself. But, really, all libraries described there together is appropriate only for learning and small programs - to do real work, we need even much, much more</p>
<p>fortunately, now we have large enough set of libs. moreover, this set grows each year. but these libs don't have official/recommended status. now we have two languages - H98 as reported with its bare libs, which is appropriate only for teaching, and real Haskell language with many extensions and rich set of libs, used to develop real programs</p>
<p>with a language itself, now we go to standardize current practice and include into language definition all popular extensions. this will close the gap between standard and practice. Haskell' committee also plan to define new version of standard Haskell library. but what a library can be defined in this way? slightly extended version of standard Haskell98 lib? or, if it will be significantly extended - how much time this work will require and isn't that a duplication of work done at libraries list?</p>
<p>i propose not to try to define reality, but accept existing one and join committee's work on new library definition with a current discussion of core libraries, which should define a set of libs available on any Haskell compiler on any platform - aren't goals the same?</p>
<p>instead of providing rather small and meaningless standard Haskell library, now we can just include in Report docs existing and widely used libs, such as Network, mtl and so on. This will mean that language, defined in Haskell standard, can be used to write real programs, which will be guaranteed to run in any Haskell environment.</p>
<p>of course, this mind game can't change anything in one moment. but it will change *accents*</p>
<p>first, Haskell with its libraries will become language for a real work. such extended language isn't small nor easy to master in full, but it is normal for any mature programming environment. people learning Haskell should select in which area they need to specialize - be it gaming or web service development, and study appropriate subset of libs. people teaching Haskell now can show how *standard* Haskell may be used to solve real world problems, and this should change treatment of Haskell as academic language. also, we may expect that books teaching Haskell will start to teach on using standard libs, while their authors now don't consider teaching for non-standard libs</p>
<p>second, by declaring these libs as standard ones we create sort of lingua franca, common language spoken by all Haskell users. for example, now there are about 10 serialization libs. by declaring one of them as standard, we will make choice simpler for most of users (who don't need very specific features) and allow them to speak in common language. in other words, number of Haskell libs is so large now that we should define some core subset in order to escape syndrome of Babel tower. defining core libraries set is just sharing knowledge that some libraries are more portable, easier to use, faster and so on, so they become more popular than alternatives in this area</p>
<p>third. now we have Cabal that automates installation of any lib. next year we will got Hackage that automates downloading and checking dependencies. but these tools still can't replace a rich set of standard libs shipped with compiler. there are still many places and social situations where Internet downloading isn't available. Compiler can be sold on CD, transferred on USB stick. and separate Haskell libs probably will be not included here. Standard libraries bundled with compiler will ensure that at least this set of libs will be available for any haskell installation. Internet access shouldn't be a precondition for Haskell usage! :)</p>
<p>fourth. now there is tendency to write ghc-specific libs. by defining requirements to the standard libs we may facilitate development of more portable, well documented and quick-checked ones. or may be some good enough libraries will be passed to society which will &quot;polish&quot; them in order to include in the set. anyway, i hope that *extensible* set of standard libraries with a published requirements to such libs would facilitate &quot;polishing&quot; of all Haskell libs just because ;)</p>
<p>and this leads us to other question - whether this set and API of each library should be fixed in language standard or it can evolve during the time?...</p>
<p><a href="PageOutline" class="uri" title="wikilink">PageOutline</a></p>
<h1 id="and">, , and </h1>
<p>When the parser parses an identifier, it generates a . A  is pretty much just a string, or a pair of strings, for a qualified name, such as . Here's the data type declaration, from <a href="GhcFile(compiler/basicTypes/RdrName.hs)" class="uri" title="wikilink">GhcFile(compiler/basicTypes/RdrName.hs)</a>: </p>
<p>User-written code never gets translated into the last two alternatives. They are used only internally by the compiler. For example, code generated by  might use an  to refer to , ignoring whatever  might happen to be in scope (dammit).</p>
<h2 id="the-module-and-modulename-types">The `Module` and `ModuleName` types</h2>
<p>In GHC, a <em>module</em> is uniquely defined by a pair of the module name and the package where the module is defined. The details are in <a href="GhcFile(compiler/basicTypes/Module.hs)" class="uri" title="wikilink">GhcFile(compiler/basicTypes/Module.hs)</a> and <a href="GhcFile(compiler/main/PackageConfig.hs)" class="uri" title="wikilink">GhcFile(compiler/main/PackageConfig.hs)</a>, but here are the key definitions:  You'll notice that a `Qual` `RdrName` contains a `ModuleName`; which module is referred to depends on the import declarations in that module. In contrast, a `Orig` `RdrName` refers to a unique `Module`.</p>
<h2 id="the-type-2">The  type</h2>
<p>An  is more-or-less just a string, like &quot;foo&quot; or &quot;Tree&quot;, giving the (unqualified) name of an entity. Well, not quite just a string, because in Haskell a name like &quot;C&quot; could mean a type constructor or data constructor, depending on context. So GHC defines a type `OccName` that is a pair of a  and a  indicating which name space the name is drawn from. The data type is defined (abstractly) in <a href="GhcFile(compiler/basicTypes/OccName.hs)" class="uri" title="wikilink">GhcFile(compiler/basicTypes/OccName.hs)</a>:  The name spaces are: </p>
<p>Attaching the names to their name spaces makes it very convenient to build mappings from names to things; where such a mapping might contain two strings that are identical, they can be distinguished by the name space, so when mapping s, a single map suffices.</p>
<p><a href="PageOutline" class="uri" title="wikilink">PageOutline</a></p>
<h1 id="recompilation-avoidance">Recompilation Avoidance</h1>
<h2 id="what-is-recompilation-avoidance">What is recompilation avoidance?</h2>
<p>When GHC is compiling a module, it tries to determine early on whether</p>
<p><code>*Theobjectfile(orbyte-codeinthecaseofGHCi)and[wiki:Commentary/Compiler/IfaceFilesinterfacefile]existfromapreviouscompilation</code><br />
<code>*Recompilationissuretoproduceexactlythesameresults,soit</code><br />
<code>isnotnecessary.</code></p>
<p>If both of these hold, GHC stops compilation early, because the existing object code and interface are still valid. In GHCi and `--make`, we must generate the `ModDetails` from the `ModIface`, but this is easily done by calling `MkIface.typecheckIface`.</p>
<h2 id="example-2">Example</h2>
<p>Let's use a running example to demonstrate the issues. We'll have four modules with dependencies like this:</p>
<p></p>
<p>`A.hs`:</p>
<p></p>
<p>`B.hs`:</p>
<p></p>
<p>`C.hs`:</p>
<p></p>
<p>`D.hs`: </p>
<h2 id="why-do-we-need-recompilation-avoidance">Why do we need recompilation avoidance?</h2>
<h3 id="ghci-and---make">GHCi and `--make`</h3>
<p>The simple fact is that when you make a small change to a large program, it is often not necessary to recompile every module that depends directly or indirectly on something that changed. In GHCi and `--make`, GHC considers every module in the program in dependency order, and decides whether it needs to be recompiled, or whether the existing object code and interface will do.</p>
<h3 id="make">`make`</h3>
<p>`make` works by checking the timestamps on dependencies and recompiling things when the dependencies are newer. Dependency lists for `make` look like this (generated by `ghc -M`):</p>
<p></p>
<p>Only the `.hi` files of the <em>direct imports</em> of a module are listed. For example, `A.o` depends on `C.hi` and `B.hi`, but not `D.hi`. Nevertheless, if D is modified, we might need to recompile A. How does this happen?</p>
<p><code>*first,makewillrecompileDbecauseitssourcefilehaschanged,</code><br />
<code>generatinganew`D.o`and`D.hi`.</code></p>
<p><code>*IfafterrecompilingD,wenoticethatitsinterfaceisthesame</code><br />
<code>asbefore,thereisnoneedtomodifythe`.hi`file.Ifthe`.hi`</code><br />
<code>fileisnotmodifiedbythecompilation,then`make`willnotice</code><br />
<code>andnotrecompile`B`or`C`,orindeed`A`.Thisisanimportant</code><br />
<code>optimisation.</code></p>
<p><code>*Supposethechangeto`D`didcauseachangeintheinterface</code><br />
<code>(e.g.thetypeof`f`changed).Now,`make`willrecompileboth</code><br />
<code>`B`and`C`.Supposethattheinterfacesto`B`and`C`</code><br />
<code>remainthesame:B'sinterfacesaysonlythatitre-exports`D.f`,</code><br />
<code>sothefactthat`f`hasanewtypedoesnotaffect`B`'s</code><br />
<code>interface.</code></p>
<p><code>*Now,`A`'sdependenciesareunchanged,so`A`willnotbe</code><br />
<code>recompiled.Butthisiswrong:`A`mightdependonsomethingfrom</code><br />
<code>`D`thatwasre-exportedvia`B`or`C`,andthereforeneed</code><br />
<code>recompiling.</code></p>
<p>To ensure that `A` is recompiled, we therefore have two options:</p>
<p><code>1.arrangethatmakeknowsaboutthedependencyofAonD.</code></p>
<p><code>2.arrangetotouch`B.hi`and`C.hi`eveniftheyhaven'tchanged.</code></p>
<p>GHC currently does (2), more about that in a minute.</p>
<p>Why not do (1)? Well, then <em>every</em> time `D.hi` changed, GHC would be invoked on `A` again. But `A` doesn't depend directly on `D`: it imports `B`, and it might be therefore be insensitive to changes in `D`. By telling make only about direct dependencies, we gain the ability to avoid recompiling modules further up the dependency graph, by not touching interface files when they don't change.</p>
<p>Back to (2). In addition to correctness (recompile when necessary), we also want to avoid unnecessary recompilation as far as possible. Make only knows about very coarse-grained dependencies. For example, it doesn't know that changing the type of `D.f` can have no effect on `C`, so `C` does not in fact need to be recompiled, because to do so would generate exactly the same `.o` and `.hi` files as last time. GHC does have enough information to figure this out, so when GHC is asked to recompile a module it invokes the <em>recompilation checker</em> to determine whether recompilation can be avoided in this case.</p>
<h2 id="how-does-it-work">How does it work?</h2>
<p>We use <a href="http://en.wikipedia.org/wiki/Fingerprint_%28computing%29">fingerprints</a> to uniquely identify the interface exposed by a module, and to detect when it changes. In particular, we currently use 128-bit hashes produced by the MD5 algorithm (see <a href="GhcFile(compiler/utils/Fingerprint.hsc)" class="uri" title="wikilink">GhcFile(compiler/utils/Fingerprint.hsc)</a>).</p>
<p>An [wiki:Commentary/Compiler/IfaceFiles interface file] contains:</p>
<p><code>*Variousfingerprints:</code><br />
<code>*The</code><em><code>interface</code> <code>hash</code></em><code>,whichdependsontheentirecontentsofthe</code><br />
<code>interfacefile.Thisisusedtodetectwhetherweshould</code><br />
<code>updatetheinterfaceondiskafterrecompilingthemodule.Ifthe</code><br />
<code>interfacedidn'tchangeatall,thenwedon'twanttotouchthe</code><br />
<code>on-diskversionbecausethatwouldcause`make`toperformmore</code><br />
<code>compilations.</code><br />
<code>*The</code><em><code>ABI</code> <code>hash</code></em><code>,whichdependsoneverythingthatthemodule</code><br />
<code>exposesaboutitsimplementation:thinkofthisasahashof</code><br />
<code></code><em><code>export-list</code> <code>hash</code></em><code>and</code><em><code>decls</code></em><code>.</code><br />
<code>*The</code><em><code>export-list</code> <code>hash</code></em><code>,whichdependson</code><br />
<code>*Theexportlistitself.Theexport-listhashonlydependsonthe</code><em><code>names</code></em><code>oftheexportsforthemodules.The</code><em><code>types</code></em><code>oftheseexportsareignoredincalculatingthehash.Onlyachangeofnameorremovaloradditionofanexportwillchangethehash.Notatypechangeofdefinitionchange.</code><br />
<code>*the</code><em><code>orphan</code> <code>hash</code></em><code>,whichdependsonalltheorphaninstances/rulesinthe,andtheorphanhashesofallorphanmodulesbelowthismoduleinthedependencytree(see[#OrphansOrphans]).</code><br />
<code>*thepackagedependencies(see[#PackageversionchangesPackageVersionChanges]).</code><br />
<code>*</code><em><code>exports</code></em><code>:whatthemoduleexports</code><br />
<code>*</code><em><code>dependencies</code></em><code>:modulesandpackagesthatthismoduledependson</code><br />
<code>*</code><em><code>usages</code></em><code>:whatspecificentitiesthemoduledependson</code><br />
<code>*</code><em><code>decls</code></em><code>:whatthemoduledefines</code><br />
<code>*variousotherstuff,buttheabovearetheimportantbits</code></p>
<p>To look at the contents of an interface, use `ghc --show-iface`. For example, here's the output of `ghc --show-iface D.hi` for the module `D` in our example:</p>
<p></p>
<p>Lines beginning `import` are the <em>usages</em>, and after the usages are the decls.</p>
<h3 id="deciding-whether-to-recompile">Deciding whether to recompile</h3>
<p>If we already have an object file and interface file for a module, we might not have to recompile it, if we can be sure the results will be the same as last time.</p>
<p><code>*Ifthesourcefilehaschangedsincetheobjectfilewascreated,</code><br />
<code>webetterrecompile.</code></p>
<p><code>*Ifanythingelsehaschangedinawaythatwouldaffecttheresults</code><br />
<code>ofcompilingthismodule,wemustrecompile.</code></p>
<p>In order to determine the second point, we look at the <em>dependencies</em> and <em>usages</em> fields of the old interface file. The dependencies contains:</p>
<p><code>*</code><em><code>dep_mods</code></em><code>:Transitiveclosureofhome-packagemodulesthatare</code><br />
<code>importedbythismodule.Thatis,allmodulesbelowthecurrent</code><br />
<code>oneinthedependencygraph.</code></p>
<p><code>*</code><em><code>dep_pkgs</code></em><code>:Transitiveclosureofpackagesdependedonbythis</code><br />
<code>module,orbyanymodulein</code><em><code>dep_mods</code></em><code>.</code></p>
<p><code>*otherlessimportantstuff.</code></p>
<p>First, the direct imports of the current module are resolved to `Module`s using `Finder.findModule` (a `Module` contains a module name and a package identifier). If any of those `Module`s are not listed amongst the dependencies of the old interface file, then either:</p>
<p><code>*anexposedpackagehasbeenupgraded</code><br />
<code>*wearecompilingwithdifferentpackageflags</code><br />
<code>*ahomemodulethatwasshadowingapackagemodulehasbeenremoved</code><br />
<code>*anewhomemodulehasbeenaddedthatshadowsapackagemodule</code></p>
<p>and we must recompile.</p>
<p>Second, the <em>usages</em> of the module are checked. The usages contains two types of information:</p>
<p><code>*foramodulethatwasimported,theexport-listfingerprintofthe</code><br />
<code>importedmoduleisrecorded.Ifanyofthemodulesweimportednow</code><br />
<code>hasadifferentexportlistwemustrecompile,sowecheckthe</code><br />
<code>currentexport-listfingerprintsagainstthoserecordedinthe</code><br />
<code>usages.</code></p>
<p><code>*foreveryexternalnamementionedinthesourcecode,the</code><br />
<code>fingerprintofthatnameisrecordedintheusages.Thisisso</code><br />
<code>thatifwementionforexampleanexternalfunction`M.f`,we'll</code><br />
<code>recompileif`M.f`'stypehaschanged,oranythingreferredto</code><br />
<code>by`M.f`'stypehaschanged,or`M.f`'sunfoldinghaschanged</code><br />
<code>(when-Oison),andsoon.</code></p>
<p>The interface files for everything in the usages are read (they'll already be in memory if we're doing `--make`), and the current versions for each of these entities checked against the usages from the old interface file. If any of these versions has changed, the module must be recompiled.</p>
<h3 id="example-3">Example</h3>
<p>There are some tricky cases to consider.</p>
<p>Suppose we change the definition of `D.f` in the example, and make it  Now, ultimately we need to recompile `A`, because it might be using an inlined copy of the old `D.f`, which it got via `B`.</p>
<p>It works like this:</p>
<p><code>*`D`isrecompiled;thefingerprintof`D.f`changes</code><br />
<code>*`B`isconsidered;itrecordedausageontheold`D.f`,so</code><br />
<code>getsrecompiled,andnowitsinterfacerecordsausageonthenew`D.f`</code><br />
<code>*`C`isconsidered;itdoesn'tneedtoberecompiled.</code><br />
<code>*`A`isconsidered(ifwe'reusingmake,thisisbecause`B.hi`</code><br />
<code>changed);itrecordedausageontheold`D.f`,andsogets</code><br />
<code>recompiled.</code></p>
<p>Now a slightly more tricky case: suppose we add an INLINE pragma to `D.f` (this is a trick to prevent GHC from inlining `D.h`, so that we can demonstrate dependencies between unfoldings). The code for D.hs is now</p>
<p></p>
<p>Looking at the interface file we can see what happened (snipped slightly):</p>
<p></p>
<p>Note that the unfolding of `D.f` mentions `D.h`.</p>
<p>Now, let's modify `D.h`, and look at the interface file again:</p>
<p></p>
<p>The fingerprint for `D.h` has changed, because we changed its definition. The fingerprint for `D.f` has also changed, because it depends on `D.h`. And consequently, the ABI hash has changed, and so has the interface hash (although the export hash and orphan hash are still the same). Note that it is significant that we used '-O' here. If we hadn't used '-O' then a change of a definition doesn't change any of the hashes because of the lack of inlining.</p>
<p>Why did the fingerprint for `D.f` have to change? This is vital, because anything that referred to `D.f` must be recompiled, because it may now see the new unfolding for `D.h`.</p>
<p>So the fingerprint of an entity represents not just the definition of the entity itself, but also the definitions of all the entities reachable from it - its transitive closure. The consequence of this is that when recording usages we only have to record the fingerprints of entities that were referred to directly in the source code, because the transitive nature of the fingerprint means that we'll recompile if anything reachable from these entities changes.</p>
<h3 id="how-does-fingerprinting-work">How does fingerprinting work?</h3>
<p>We calculate fingerprints by serialising the data to be fingerprinted using the `Binary` module, and then running the md5 algorithm over the serlialised data. When the data contains external `Name`s, the serialiser emits the fingerprint of the `Name`; this is the way that the fingerprint of a declaration can be made to depend on the fingerprints of the things it mentions.</p>
<h3 id="mutually-recursive-groups-of-entities">Mutually recursive groups of entities</h3>
<p>When fingerprinting a recursive group of entities, we fingerprint the group as a whole. If any of the definitions changes, the fingerprint of every entity in the group changes.</p>
<h3 id="fixities">Fixities</h3>
<p>We include the fixity of an entity when computing its fingerprint.</p>
<h3 id="instances">Instances</h3>
<p>Instances are tricky in Haskell, because they aren't imported or exported explicitly. Haskell requires that any instance defined in a module directly or indirectly imported by the current module is visible. So how do we track instances for recompilation, such that if a relevant instance is changed, added, or removed anywhere beneath the current module we will trigger a recompilation?</p>
<p>Here's how it works. For each instance we pick a distinguished entity to attach the instance to - possibly the class itself, or a type constructor mentioned in the instance. The entity we pick must be defined in the current module; if there are none to pick, then the instance is an orphan (more about those in the section on Orphans, below).</p>
<p>Having picked the distinguished entity, when fingerprinting that entity we include the instances. For example, consider an instance for class C at type T. Any module that could use this instance must depend (directly or indirectly) on both C and T, so it doesn't matter whether we attach the instance to C or T - either way it will be included in the fingerprint of something that the module depends on. In this way we can be sure that if someone adds a new instance, or removes an existing instance, if the instance is relevant to a module then it will affect the fingerprint of something that the module depends on, and hence will trigger recompilation.</p>
<p>In fact, we don't need to include the instance itself when fingerprinting C or T, it is enough to include the DFun (dictionary function) Id, since the type of this Id includes the form of the instance. Furthermore, we <em>must</em> include the DFun anway, because we must have a dependency on the dictionary and its methods, just in case they are inlined in a client module. A DFun looks something like this:</p>
<p></p>
<p>Making a type or class depend on its instances can cause a lot of recompilation when an instance changes. For example:</p>
<p></p>
<p>now the DFun for the instance `C T` will be attached to `T`, and so `T`'s fingerprint will change when anything about the instance changes, including `C` itself. So there is now have a dependency of `T` on `C`, which can cause a lot of recompilation whenever `C` changes. Modules using `T` who do not care about `C` will still be recompiled.</p>
<p>This seems like it would cause a lot of unnecessary recompilation. Indeed, in GHC 7.0.1 and earlier we tried to optimise this case, by breaking the dependency of `T` on `C` and tracking usages of DFuns directly - whenever a DFun was used, the typechecker would record the fact, and a usage on the DFun would be recorded in the interface file. Unfortunately, there's a bug in this plan (see #4469). When we're using `make`, we only recompile a module when any of the interfaces that it directly imports have changed; but a DFun dependency can refer to any module, not just the directly imported ones. Instead, we have to ensure that if an instance related to a particular type or class has changed, then the fingerprint on either the type or class changes, which is what the current plan does. It would be nice to optimise this in a safe way, and maybe in the future we will be able to do that.</p>
<h3 id="orphans">Orphans</h3>
<p>What if we have no declaration to attach the instance to? Instances with no obvious parent are called <em>orphans</em>, and GHC must read the interface for any module that contains orphan instances below the current module, just in case those instances are relevant when compiling the current module.</p>
<p>Orphans require special treatment in the recompilation checker.</p>
<p><code>*Everymodulehasan</code><em><code>orphan</code> <code>hash</code></em><code>,whichisafingerprintofall</code><br />
<code>theorphaninstances(andrules)inthecurrentmodule.</code></p>
<p><code>*The</code><em><code>export</code> <code>hash</code></em><code>dependsonthe</code><em><code>orphan</code> <code>hash</code></em><code>ofthecurrent</code><br />
<code>module,andallmodulesbelowthecurrentmoduleinthedependency</code><br />
<code>tree.Thismodelsthefactthatallinstancesdefinedinmodules</code><br />
<code>belowthecurrentmoduleareavailabletoimportersofthismodule.</code></p>
<p>So if we add, delete, or modify an orphan instance, the orphan hash of the current module will change, and so will the export hash of the current module. This will trigger recompilation of modules that import the current module, which will cause their export hashes to change, and so on up the dependency tree.</p>
<p>This means a lot of recompilation, but it is at least safe. The trick is to avoid orphan instances as far as possible, which is why GHC has the warning flag `-fwarn-orphans`.</p>
<h3 id="rules">Rules</h3>
<p>RULEs are treated very much like instances: they are attached to one particular parent declaration, and if a suitable parent cannot be found, they become orphans and are handled in the same way as orphan instances.</p>
<h3 id="on-ordering">On ordering</h3>
<p>When fingerprinting a collection of things, for example the export list, we must be careful to use a canonical ordering for the collection. Otherwise, if we recompile the module without making any changes, we might get a different fingerprint due to accidental reordering of the elements.</p>
<p>Why would we get accidental reordering? GHC relies heavily on &quot;uniques&quot; internally (see <a href="GhcFile(compiler/basicTypes/Unique.lhs)" class="uri" title="wikilink">GhcFile(compiler/basicTypes/Unique.lhs)</a>): every entity has a unique, and uniques are assigned semi-randomly. Asking for the contents of a `UniqSet` or `UniqFM` will return the elements in order of their uniques, which may vary from run to run of the compiler.</p>
<p>The solution is to sort the elements using a stable ordering, such as lexicographic ordering.</p>
<h3 id="packages">Packages</h3>
<p>We need to record usage information about package modules too, so that we can correctly trigger recompilation if we depend on a package that has changed. But packages change rarely, so it would be wasteful to record detailed usage information for every entity that we use from an external package (imagine recording the fingerprints for `Bool`, `Int`, etc.). Instead, we simply record the ABI fingerprint for every package module that was imported by the current module. That way, if anything about the ABI of that package module has changed, then we can trigger a recompilation.</p>
<p>(Correctly triggering recompilation when packages change was one of the things we fixed when implementing fingerprints, see #1372).</p>
<h3 id="package-version-changes">Package version changes</h3>
<p>If the version of a package is bumped, what forces recompilation of the things that depend on it?</p>
<p><code>1.Ifamodulefromthepackageisimporteddirectly,thenwewillnoticethattheimportedmoduleisnotamongstthedependenciesofthemodulewhenitwascompiledlast,andforcearecompilation(see[#DecidingwhethertorecompileDecidingwhethertorecompile]).</code></p>
<p><code>2.Ifamodulefromtheoldpackageisimportedindirectly,thentheoldpackagewillbeamongstthepackagedependencies(`dep_pkgs.mi_deps`),sowemustrecompileotherwisethesedependencieswillbeinconsistent.Thewaywehandlethiscaseisbyincludingthepackagedependenciesinthe</code><em><code>export</code> <code>hash</code></em><code>ofamodule,sothatothermoduleswhichimportthismodulewillautomaticallyberecompiledwhenoneofthepackagedependencieschanges.Therecompiledmodulewillhavenewpackagedependencies,whichwillforcerecompilationofitsimporters,andsoon.Thereforeifapackageversionchanges,thechangewillbepropagatedthroughoutthemoduledependencygraph.</code></p>
<h2 id="interface-stability">Interface stability</h2>
<p>For recompilation avoidance to be really effective, we need to ensure that fingerprints do not change unnecessarily. That is, if a module is modified, it should be the case that the only fingerprints that change are related to the parts of the module that were modified. This may seem obvious, but it's surprisingly easy to get wrong. Here are some of the ways we got it wrong in the past, and some ways we still get it wrong.</p>
<p><code>*PriortoGHC6.12,dictionaryfunctionswerenamedsomethinglike`M.$f23`,where`M`isthemoduledefiningtheinstance,andthenumber`23`wasgeneratedbysimplyassigningnumberstothedictionaryfunctionsdefinedby`M`sequentially.Thisisaproblemforrecompilationavoidance,becausenowremovingoraddinganinstancein`M`willchangethenumbering,andforcerecompilationofanythingthatdependsonanyinstancein`M`.Worse,thenumbersareassignednon-deterministically,sosimplyrecompiling`M`withoutchangingitscodecouldchangethefingerprints.InGHC6.12wechangeditsothatdictionaryfunctionsarenamedaftertheclassandtype(s)oftheinstance,e.g.`M.$fOrdInteger`.</code></p>
<p><code>*compiler-generatedbindingsusedtobenumberedinthesameway,non-deterministically.Thenon-determinismarisesbecauseUniquesareassignedbythecompilernon-deterministically.Well,theyaredeterministicbutnotinawaythatyoucansensiblycontrol,becauseitdependsontheorderinwhichinterfacebindingsareread,etc.InternalmappingsuseUniquesasthekey,soaskingfortheelementsofamappinggivesanon-deterministicordering.Thelistofbindingsemittedbythesimplifier,althoughindependencyorder,canvarynon-deterministicallywithintheconstraintsofthedependencies.Soifwenumberthecompiler-generatedbindingssequentially,theresultwillbeanon-deterministicABI.</code><br />
<code></code><a href="BR" title="wikilink"><code>BR</code></a><a href="BR" title="wikilink"><code>BR</code></a><br />
<code>InGHC6.12wechangedthissothatcompiler-generatedbindingsaregivennamesoftheform`f_x`,where`f`isthenameoftheexportedIdthatreferstothebinding.Iftherearemultiple`f_x`s,thentheyaredisambiguatedwithanintegersuffix,butthenumbersareassigneddeterministically,bytraversingthedefinitionof`f`indepth-firstleft-to-rightordertofindreferences.See`TidyPgm.chooseExternalIds`.</code></p>
<p><code>*Therearestillsomecaseswhereaninterfacecanchangewithoutchangingthesourcecode.Theonesweknowaboutarelistedin#4012</code></p>
<h1 id="the-register-allocator-1">The Register Allocator</h1>
<h2 id="overview-6">Overview</h2>
<p>The register allocator is responsible for assigning real/hardware regs (hregs) to each of the virtual regs (vregs) present in the code emitted by the native code generator. It also inserts spill/reload instructions to save vregs to the stack in situations where not enough hregs are available.</p>
<p>GHC currently provides three register allocation algorithms, one which does simple linear scan and two version of graph coloring. Support for linear scan is likely to be removed in a subequent version.</p>
<p><code>*</code><strong><code>Linear</code> <code>scan</code></strong><a href="BR" title="wikilink"><code>BR</code></a><br />
<code>Thelinearallocatoristurnedonbydefault.Thisiswhatyougetwhenyoucompilewith</code><code>.Thelinearallocatordoesasinglepassthroughthecode,allocatingregistersonafirst-come-first-servedbasis.Itisquick,anddoesareasonablejobforcodewithlittleregisterpressure.</code></p>
<p><code>Thisalgorithmhasnolook-ahead.Ifsay,aparticularhregwillbeclobberedbyafunctioncall,itdoesnotknowtoavoidallocatingtoitinthecodebeforethecall,andsubsequentlyinsertsmorespill/reloadinstructionsthanstrictlyneeded.</code></p>
<p><code>*</code><strong><code>Graph</code> <code>coloring</code></strong><code>(enabledwith</code><code>)</code><a href="BR" title="wikilink"><code>BR</code></a><br />
<code>Thegraphcoloringalgorithmoperatesonthecodeforawholefunctionatatime.Fromeachfunctionitextractsaregisterconflictgraphwhichhasanodeforeveryvregandanedgebetweentwovregsiftheyareinuseatthesametimeandthuscannotsharethesamehreg.Thealgorithmtriestoassignhregs(imaginedascolors)tothenodessothatnotwoadjacentnodessharethesamecolor,ifitcan'tthenitinsertsspillcode,rebuildsthegraphandtriesagain.</code></p>
<p><code>Graphcoloringtendstodobetterthanthelinearallocatorbecausetheconflictgraphhelpsitavoidthelook-aheadproblem.Thecoloringallocatoralsotrieshardertoallocatethesourceanddestinationofreg-to-regmoveinstructionstothesamehreg.Thisisdonebycoalescing(merging)move-relatednodes.Ifthissucceedsthentheassociatedmovescanbeerased.</code></p>
<p><code>*</code><strong><code>Graph</code> <code>coloring</code> <code>with</code> <code>iterative</code> <code>coalescing</code></strong><code>(enabledwith</code><code>)</code><a href="BR" title="wikilink"><code>BR</code></a><br />
<code>Iterativecoalescingisanimprovementoverregulargraphcoloringwherebycoalescingpassesareinterleavedwithcoloringpasses.Iterativecoalescingdoesabetterjobthanregulargraphcoloring,butisslowerbecauseitmustalternatebetweenthecoloringandcoalescingofnodes.</code></p>
<h2 id="code-map">Code map</h2>
<p>For an outline of the code see [wiki:Commentary/Compiler/Backends/NCG/RegisterAllocator/Code]</p>
<h2 id="references-2">References</h2>
<p>If you decide to do some hacking on the register allocator then take a look at (at least) these papers first:</p>
<p><strong>Iterated Register Coalescing</strong><a href="BR" class="uri" title="wikilink">BR</a> <em>George, Appel, 1996</em><a href="BR" class="uri" title="wikilink">BR</a> Decribes the core graph coloring algorithm used.</p>
<p><strong>A Generalised Algorithm for Graph-Coloring Register Allocation</strong><a href="BR" class="uri" title="wikilink">BR</a> <em>Smith, Ramsey, Holloway, 2004</em><a href="BR" class="uri" title="wikilink">BR</a> For a decription of how to deal with overlapping register sets, which aren't fully implemented. Explains what the ,  and  functions are for.</p>
<p><strong>Design and Implementation of a Graph Coloring Register Allocator for GCC</strong><a href="BR" class="uri" title="wikilink">BR</a> <em>Matz, 2003</em><a href="BR" class="uri" title="wikilink">BR</a> For an overview of techniques for inserting spill code.</p>
<h2 id="register-pressure-in-haskell-code">Register pressure in Haskell code</h2>
<p>Present GHC compiled code places very little pressure on the register set. Even on x86 with only 3 allocable registers, most modules do not need spill/reloads. This is a mixed blessing - on one hand the conflict graphs are small so we can avoid performance problems related to how the graph is represented, on the other hand it can be hard to find code to test against. Register pressure is expected to increase as the Stg-&gt;Cmm transform improves.</p>
<p>In the meantime, here are some good sources for test code:</p>
<p><code>*</code><strong><code>Nofib</code></strong><a href="BR" title="wikilink"><code>BR</code></a><br />
<code>Onlyafewnofibbenchmarkscreatespillswith</code><code>,twoare</code><code>and</code><code>.</code></p>
<p><code>*</code><strong><code>Turn</code> <code>on</code> <code>profiling</code></strong><a href="BR" title="wikilink"><code>BR</code></a><br />
<code>Registerpressureincreasessignificantlywhenthemoduleiscompiledwithprofiling.</code><a href="attachment:checkSpills.report"><code>14</code></a><code>givestuplesof</code><code>presentinoutputcodegeneratedbythethreealgorithmswhencompiledwith</code><code>.Lefttorightarethestatsforthelinear,graphcoloringanditerativecoalescingalgorithms.Notethatmostmodulescompilewithnospill/reloadsinserted,butafew(notably</code><code>)needseveralhundred.</code></p>
<p><code>I'vefounditusefultomaintainthreedarcsreposwhenworkingontheallocator.</code><code>compiledwith</code><code>forfastcompilationduringhacking,</code><code>fortestingwithprofilingturnedon,and</code><code>forrunningthevalidatescript.Patchesarecreatedin</code><code>,pushedinto</code><code>where</code><code>isusedtocompilethenofibbenchmarkswiththemostregisterpressure.Oncewe'rehappythattheperformanceisok,thepatchisthenpushedinto</code><code>forvalidationbeforepushingtothemainrepoon</code></p>
<p><code>*</code><strong><code>SHA</code> <code>from</code> <code>darcs</code></strong><a href="BR" title="wikilink"><code>BR</code></a><br />
<code>The</code><code>modulefromthedarcssource,compiledwith</code><code>createsthemostregisterpressureoutofanyHaskellcodethatI'mawareof.WhencompilingSHA1,GHCinlinesseveralworkerfunctionsandthenativecodeblockthatcomputesthehashendsupbeingaround1700instructionslong.vregsthatliveinthemiddleoftheblockhaveintheorderof30conflictneighbors.(evidently,theconflictgraphistoolargeformostofthegraphvizlayoutalgorithmstocopewith)</code></p>
<p><code>Forthesereasons,</code><code>canbetreatedasagoodworst-caseinputtotheallocator.Infact,thecurrentlinearallocatorcannotcompileitwith</code><code>onx86asitrunsoutofstackslots,whichareallocatedfromastaticpool.Makesuretotestanychangestotheallocatoragainstthismodule.</code></p>
<h2 id="hackingdebugging">Hacking/Debugging</h2>
<p><code>*</code><strong><code>Turn</code> <code>on</code> </strong><a href="BR" title="wikilink"><code>BR</code></a><br />
<code>Breakingtheallocatorcanresultincompiledprogramscrashingrandomly(ifyou'relucky)orproducingthewrongoutput.Makesuretoalwaysturnon</code><code>.Doingthismakestheallocatorcall</code><code>aftereveryspill/colorstage.</code><code>checksthatalltheedgespointtovalidnodes,thatnoconflictingnodeshavethesamecolor,andifthegraphissupposedtobecoloredthenallnodesarereallycolored.</code></p>
<p><code>*</code><strong><code>Some</code> <code>useful</code> <code>dump</code> <code>flags</code></strong></p>
<p><code></code><a href="BR" title="wikilink"><code>BR</code></a><br />
<code>Showsthecodeandconflictgraphaftereverspill/colorstage.Alsoshowsspillcosts,andwhatregisterswerecoalesced.</code></p>
<p><code></code><a href="BR" title="wikilink"><code>BR</code></a><br />
<code>Givesstatisticsabouthowmanyspills/reloads/reg-reg-movesareintheoutputprogram.</code></p>
<p><code></code><a href="BR" title="wikilink"><code>BR</code></a><br />
<code>Givesthefinaloutputcode.</code></p>
<p><code></code><a href="BR" title="wikilink"><code>BR</code></a><br />
<code>Divertsdumpoutputtofiles.Thiscanbeusedtogetdumpsfromeachmoduleinanofibbenchmark.</code><br />
<br />
<code></code></p>
<p><code>*</code><strong><code>Visualisation</code> <code>of</code> <code>conflict</code> <code>graphs</code></strong><a href="BR" title="wikilink"><code>BR</code></a><br />
<code>Graphviz,availablefrom</code><a href="http://www.graphviz.org"><code>15</code></a><code>canbeusedtomakenicevisualisationsoftheregisterconflictgraphs.Use</code><code>,andcopyoneofthegraphdescriptionsintoanewfile</code></p>
<p><code></code><br />
<code>Here'stwofrom</code><code>compiledwith</code><code>:</code></p>
<p><code></code><a href="attachment:graph.dot"><code>16</code></a><code>-&gt;</code><a href="attachment:graph.png"><code>17</code></a></p>
<p><code></code><a href="attachment:graph-colored.dot"><code>18</code></a><code>-&gt;</code><a href="attachment:graph-colored.png"><code>19</code></a></p>
<p><code>*</code><strong><code>checkSpills</code></strong><a href="BR" title="wikilink"><code>BR</code></a><br />
<code></code><a href="attachment:checkSpills.hs"><code>20</code></a><code>isanasty,throwawayscriptwhichcanbeusedtoautomatethecomparisonofallocationalgorithms.Copyitandalistoftestlike</code><a href="attachment:checkSpills.tests"><code>21</code></a><code>tothetoplevelnofibdirectory,compileandrun.Itwillbuildthenofibbenchmarksinthelist6timeseach,onceeachwitheachoftheallocatorstoextractspillcounts,andthenonceagaintogetcompiletimingswhichareunperterbedbythespaceleaksintroducedbycompilingwithdebuggingturnedon.It'sonlyneededifyou'rehackingontheallocator,parsesthenofibmakeoutputdirectly,andislikelytorot-whichiswhyitisn'tincludedinthemainsourcetree.</code></p>
<h2 id="runtime-performance">Runtime performance</h2>
<p>Runtime performance of the graph coloring allocator is proportional to the size of the conflict graph and the number of build/spill cycles needed to obtain a coloring. Most functions have graphs &lt; 100 nodes and generate no spills, so register allocation is a small fraction of overall compile time.</p>
<h2 id="possible-improvements">Possible Improvements</h2>
<p>These are some ideas for improving the current allocator, most potentially useful first.</p>
<p><code>*</code><strong><code>Work</code> <code>lists</code> <code>for</code> <code>iterative</code> <code>coalescing.</code></strong><a href="BR" title="wikilink"><code>BR</code></a><br />
<code>Theiterativecoalescingalternatesbetweenscanningthegraphfortriviallycolorable(triv)nodesandperforingcoalescing.Whentwonodesarecoalesced,othernodesthatarenotadjacenttothecoalescednodesdonotchangeanddonotneedtoberescannedstraightaway.Runtimeperformanceoftheiterativecoalescercouldprobablybeimprovedbykeepingawork-listof&quot;nodesthatmighthavebecometriviallycolorable&quot;,tohelpfindnodesthatwon'thavechanged.</code></p>
<p><code>*</code><strong><code>Improve</code> <code>spill</code> <code>code</code> <code>generator/cleaner.</code></strong><a href="BR" title="wikilink"><code>BR</code></a><br />
<code>Whenspillingaparticularvreg,thecurrentspillcodegeneratorsimplyinsertsaspillaftereachdefandareloadbeforeeachuse.Thisquicklyreducesthedensityofconflictsinthegraph,butproducesinefficientcodebecausemorespill/reloadsareinsertedthanstrictlynessesary.Goodcodeisrecoveredbythespillcleanerwhichrunsafterallocationandremovesspill/reloadinstructionsthataren'tnessesary.Somethingstotry:</code><br />
<code>*</code><strong><code>Spill</code> <code>coalescing</code></strong><a href="BR" title="wikilink"><code>BR</code></a><code></code><br />
<code>Noattemptiscurrentlymadetosharespillslotsbetweendifferentvregs.EachnamedvregisspilledtoitsownstaticspillslotontheCstack.Theamountofstackspaceneededcouldbereducedbysharingspillslotsbetweenvregssolongastheirliverangesdonotoverlap.</code><br />
<code>*</code><strong><code>Try</code> <code>to</code> <code>split</code> <code>live</code> <code>ranges</code> <code>before</code> <code>spilling</code></strong><a href="BR" title="wikilink"><code>BR</code></a><br />
<code>Ifaliverangehasseveraluse/defsthenwecouldinsertfreshreg-regmovestobreakitupintoseveralsmallerliveranges.Wethenmightgetawaywithspillingjustonesectioninsteadofthewholerange.Notsureifthiswouldbeawinoverthecurrentsituation.Wewouldneedspill-coalescingtobeimplementedbeforethissothatwedon'trequireanextraslotforeachnewliverange.</code><br />
<code>*</code><strong><code>Rematerialization</code></strong><a href="BR" title="wikilink"><code>BR</code></a><br />
<code>Asthespillcleanerwalksthroughthecodeitbuildsamappingofwhichslotsandregistersholdthesamevalue.Oneachreloadinstruction,iftheslotandregareknowntoalreadyhavethesamevaluethenthereloadcanbeerased.Thismappingcouldbeextendedwithconstants,sothatifavregholdingaconstantvaluecannotbeallocatedahreg,theconstantvaluecanberematerializedinsteadofbeingspilled/reloadedtoastackslot.</code></p>
<p><code>*</code><strong><code>Revisit</code> <code>choosing</code> <code>of</code> <code>spill</code> <code>candidates</code></strong><a href="BR" title="wikilink"><code>BR</code></a><br />
<code>Ifthegraphcannotbecoloredthenanode/vregmustbechosentobepotentiallyspilled.Chaitin'sforumulasaystocalculatethespillcostbyaddingupthenumberofusesanddefsofthatvreganddividebythedegreeofthenode.InthecodethatI'vetestedagainst,it'sbeenbettertojustchoosetheliverangethatlivesthelongest.Perhapsthisisbecausethe'real'spillcostwoulddependonthespills/reloadsactuallyinserted,notasimplecountofuse/defs.PerhapschoosingthelongestliverangeisjustbetterfortheparticularkindofcodethatGHCgenerates.</code></p>
<p><code>*</code><strong><code>Revisit</code> <code>trivColorable</code> <code>/</code> <code>aliasing</code> <code>of</code> <code>register</code> <code>sets</code></strong><a href="BR" title="wikilink"><code>BR</code></a><br />
<code>Forthearchitecturescurrentlysupported,x86,x86_64andppc,thenativecodegeneratorcurrentlyemitscodeusingonlytworegisterclasses</code><code>and</code><code>.Astheseclassesaredisjoint(ie,noneoftheregsfromoneclassaliaswithwithregsfromanother),checkingwhetheranodeofacertainclassistriviallycolorablereducestocountingupthenumberofneighboursofthatclass.</code></p>
<p><code>IftheNCGstartstousealiasingregisterclasseseg:both32bit</code><code>sand64bit</code><code>sonsparc;combinationsof8,16,and32bitintegersonx86/x86_x6orusageofsse/altivecregsindifferentmodes,thenthiscanbesupportedviathemethoddescribedin[Smithetal].Theallocatorwasdesignedwiththisinmind-ie,bypassingafunctiontotestifanodeistriviallycolorableasaparametertothecoloringfunction-andthereisalreadyadescriptionoftheregistersetforx86in</code><a href="GhcFile(compiler/nativeGen/RegArchX86.hs)" title="wikilink"><code>GhcFile(compiler/nativeGen/RegArchX86.hs)</code></a><code>,butthenativecodegeneratordoesn'tcurrentlyemitcodetotestitagainst.</code></p>
<h1 id="haskell-excecution-registers">Haskell Excecution: Registers</h1>
<p>Source files: <a href="GhcFile(includes/stg/Regs.h)" class="uri" title="wikilink">GhcFile(includes/stg/Regs.h)</a>, <a href="GhcFile(includes/stg/MachRegs.h)" class="uri" title="wikilink">GhcFile(includes/stg/MachRegs.h)</a></p>
<p>During execution of Haskell code the following (virtual) registers are always valid:</p>
<p><code>*`Hp`pointstothebytebeforethefirstfreebyteinthe(contiguous)allocationspace.</code></p>
<p><code>*`HpLim`pointstothelastavailablebyteinthecurrentchunkofallocationspace.</code></p>
<p><code>*`Sp`pointstotheyoungestallocatedbyteofstack.Thestackgrowsdownwards.Why?Becausethatmeansareturnaddressisataloweraddressthanthestackframeit&quot;knowsabout&quot;,andthatinturnmeansthatwecantreatastackframeverylikeaheapobject,withaninfopointer(returnaddress)asitsfirstword.</code></p>
<p><code>*`SpLim`pointstothelast(youngest)availablebyteinthecurrentstack.</code></p>
<p>There are bunch of other virtual registers, used for temporary argument passing, for words, floats and doubles: `R1` .. `R10`, `F1` .. `F4`, `D1` .. `D4`, `L1` .. `L2`.</p>
<p>In a register-rich machine, many of these virtual registers will be mapped to real registers. In a register-poor machine, they are instead allocated in a static memory record, pointed to by a real register, `BaseReg`.</p>
<p>The code generator knows how many real registers there are, and tries to avoid using virtual registers that are not mapped to real registers. So, for example, it does not use `R5` if the latter is memory-mapped; instead, it passes arguments on the stack.</p>
<h1 id="relevant-ghc-parts-for-demand-analysis-results">Relevant GHC parts for Demand Analysis results</h1>
<p><code>*`compiler/basicTypes/Demand.lhs`--containsallinformationaboutdemandsandoperationsonthem,aswellasaboutserialization/deserializationofdemandsignatures.Thismoduleissupposedtobechangedwheneverthedemandnatureshouldbeenhanced;</code></p>
<p><code>*`compiler/stranal/DmdAnal.lhs`--thedemandanalysisitself.Checkmultiplecommentstofigureoutmainprinciplesofthealgorithm.</code></p>
<p><code>*`compiler/stranal/WorkWrap.lhs`--aworker-wrappertransform,mainclientofthedemandanalysis.Thefunctionsplitisperformedin`worthSplittingFun`basingondemandannotationsofafunction'sparameters.</code></p>
<p><code>*`compiler/stranal/WwLib.lhs`--ahelpermodulefortheworker-wrappermachinery.The&quot;deep&quot;splittingofaproducttypeargumentmakesuseofthestrictnessinfoandisimplementedbythefunction`mkWWstr_one`.Thefunction`mkWWcpr`makesuseoftheCPRinfo.</code></p>
<p><code>*`compiler/basicTypes/Id.lhs`--implementationofidentifierscontainsanumberofutilityfunctionstocheck/setdemandannotationsofbinders.Allofthemarejustdelegatingtoappropriatefunctions/fieldsofthe`IdInfo`record;</code></p>
<p><code>*`compiler/basicTypes/IdInfo.lhs`--`IdInfo`recordcontainsallinformationaboutdemandandstrictnessannotationsofanidentifier.`strictnessInfo`containsarepresentationofanabstracttwo-pointdemandtransformerofabinder,consideredasareferencetoavalue.`demandInfo`indicates,whichdemandisputtotheidentifier,whichisafunctionparameter,ifthefunctioniscalledinastrict/usedcontext.`seq*`-functionsareinvokedtoavoidmemoryleakscausedbytransformingnewASTsbyeachofthecompilerpasses(i.e.,nothunkspointingtothepartsoftheprocessedtreesareleft).</code></p>
<p><code>*`compiler/basicTypes/MkId.lhs`--Amachinery,responsibleforgenerationofworker-wrappersmakesuseofdemands.Forinstance,whenasignatureforaworkerisgenerated,thefollowingstrictnesssignatureiscreated:</code></p>
<p></p>
<p><code>Inwords,anon-bottomingdemandtypewith`N`lazy/usedarguments(`top`)iscreatedforaworker,where`N`isjustaworker'spre-computedarity.Also,particulardemandsareusedwhencreatingsignaturesfordictionaryselectors(see`mkDictSelId`).</code></p>
<p><code>*`compiler/prelude/primops.txt.pp`--thisfiledefinesdemandsignaturesforprimitiveoperations,whichareinsertedby`cpp`passonthemodule`compiler/basicTypes/MkId.lhs`;</code></p>
<p><code>*`compiler/coreSyn/CoreArity.lhs`--demandsignaturesareusedinordertocomputetheunfoldinginfoofafunction:bottomingfunctionsshouldnobeunfolded.See`exprBotStrictness_maybe`and`arityType`.</code></p>
<p><code>*`compiler/coreSyn/CoreLint.lhs`--thechecksareperformed(in`lintSingleBinding`):</code><br />
<code>*whetherarityanddemandtypeareconsistent(onlyifdemandanalysisalreadyhappened);</code><br />
<code>*ifthebinderistop-levelorrecursive,it'snotdemanded(i.e.,itsdemandisnotstrict).</code></p>
<p><code>*`compiler/coreSyn/CorePrep.lhs`--strictnesssignaturesareexaminingbeforeconvertingexpressiontoA-normalform.</code></p>
<p><code>*`compiler/coreSyn/MkCore.lhs`--abottomingstrictnesssignaturecreatedfor`error`-likefunctions(see`pc_bottoming_Id`).</code></p>
<p><code>*`compiler/coreSyn/PprCore.lhs`--standardpretty-printingmachinery,shouldbemodifiedtochangePPofdemands.</code></p>
<p><code>*`compiler/iface/IfaceSyn.lhs`--serialization,grepfor`HsStrictness`constructors.</code></p>
<p><code>*`compiler/iface/MkIface.lhs`--aclientof`IfaceSyn`,seeusagesof`HsStrictness`.</code></p>
<p><code>*`compiler/iface/TcIface.lhs`--thefunction`tcUnfolding`checksifanidentifierbindsabottomingfunctioninordertodecideifitshouldbeunfoldedornot</code></p>
<p><code>*`compiler/main/TidyPgm.lhs`--Multiplechecksofanidentifiertobindabottomingexpression,runningacheap-an-cheerfulbottomanalyser.See`addExternal`andoccurrencesof`exprBotStrictness_maybe`.</code></p>
<p><code>*`compiler/simplCore/SetLevels.lhs`--Itisimportanttozapdemandinformation,whenanidentifierismovedtoatop-level(duetolet-floating),hencelookforoccurrencesof`zapDemandIdInfo`.</code></p>
<p><code>*`compiler/simplCore/SimplCore.lhs`--thismoduleisresponsibleforrunningthedemandanalyserandthesubsequentworker-wrappersplitpasses.</code></p>
<p><code>*`compiler/simplCore/SimplUtils.lhs`--isanewarityislessthanthearityofthedemandtype,awarningisemitted;check`tryEtaExpand`.</code></p>
<p><code>*`compiler/specialise/SpecConstr.lhs`--strictnessinfoisusedwhencreatingaspecializedcopyofafunction,see`spec_one`and`calcSpecStrictness`.</code></p>
<p><a href="PageOutline" class="uri" title="wikilink">PageOutline</a></p>
<h1 id="remembered-sets">Remembered Sets</h1>
<p>Since in generational GC we may need to find all the live objects in a young generation without traversing the older generation(s), we need a record of the pointers from those old generations into the young generations. This is termed the &quot;remembered set&quot;.</p>
<p>In GHC each `generation` structure contains a field `mut_list`, which points to a chain of blocks. Each block in the chain contains a list of pointers to objects in that generation which contain pointers to objects in younger generations. There are alternative schemes, e.g.</p>
<p><code>*Keepingtrackofeach</code><em><code>pointer</code></em><code>,ratherthan</code><em><code>object</code></em><code>thatpointstoayoungergeneration.Therememberedsetwould</code><br />
<code>belarger(possiblyverymuchlarger,inthecaseofarrays),butitwouldbemoreaccurate,andtraversingthe</code><br />
<code>rememberedsetatGCtimewouldbefaster.</code></p>
<p><code>*SomeGCsuse&quot;card-marking&quot;schemeswherebytheheapisdividedinto&quot;cards&quot;ofafixedsize,andeachcardhasabitto</code><br />
<code>indicatewhetherthatcardcontainspointerstoayoungergeneration.Thisismuchlessaccuratethanarememberedset,</code><br />
<code>butitisfasteratruntimeifalotofmutationistakingplace,andittakeslessspacethanarememberedset.InGHC</code><br />
<code>wetypicallydonothavemuchmutationtoworryabout,socardmarkingwouldbeapoorcompromiseinourcase.</code></p>
<p>The remembered set may contain duplicates, or it may contain pointers to objects that don't really point to young generations.</p>
<h2 id="remembered-set-maintenance-during-mutation">Remembered set maintenance during mutation</h2>
<p>While the mutator is running, we have to add any old-to-new generation pointers that are created. Old-to-new pointers are created by mutating (writing to) an object in the old generation, and catching these writes is called a &quot;write barrier&quot;.</p>
<p>A pointer can be added to a remembered set using</p>
<p></p>
<p>This adds the pointer `p` to the remembered set for generation `gen`, using Capability `cap`. Each Capability has its own remembered set for each generation, so that when running in parallel we can update remembered sets without taking a lock, and also so that we can take advantage of locality in the GC, by traversing a remembered set on the same CPU that created it.</p>
<p>Here are the cases where we need a write barrier in GHC:</p>
<h3 id="thunk-updates">Thunk Updates</h3>
<p>Updating a thunk in an old generation. This is taken care of by the update code, see <a href="GhcFile(rts/Updates.h)" class="uri" title="wikilink">GhcFile(rts/Updates.h)</a>.</p>
<h3 id="mutable-objects-mut_var-mvar">Mutable objects: MUT_VAR, MVAR</h3>
<p>For `MUT_VAR`, the writer must call `dirty_MUT_VAR`:</p>
<p></p>
<p>(in <a href="GhcFile(rts/sm/Storage.c)" class="uri" title="wikilink">GhcFile(rts/sm/Storage.c)</a>). The code generator inserts calls to `dirty_MUT_VAR` when it compiles a call to the primitive `writeMutVar#`.</p>
<p>`dirty_MUT_VAR` does the following: if the object's header is `MUT_VAR_CLEAN`, then the header is set to `MUT_VAR_DIRTY`, and the object is added to the remembered set if it resides in an old generation. If the header was already `MUT_VAR_DIRTY`, no action is taken.</p>
<p>`MVAR` is handled in the same way, with </p>
<h3 id="arrays-mut_arr_ptrs">Arrays: MUT_ARR_PTRS</h3>
<p>Unlike mutable variables and MVARs, mutable arrays are kept in the remembered set permanently. This reflects the fact that mutable arrays are likely to be written to more often, and there are likely to be fewer of them. However, we still mark arrays according to whether the array is dirty or not, using `MUT_ARR_PTRS_DIRTY` and `MUT_ARR_PTRS_CLEAN`.</p>
<p>There are also `MUT_ARR_PTRS_FROZEN` and `MUT_ARR_PTRS_FROZEN0`, which are used to indicate arrays that have been frozen using `unsafeFreezeArray#`. A frozen array is different from a mutable array in the sense that while it may have old-to-new pointers, it is not going to be mutated any further, and so we probably want to use [wiki:Commentary/Rts/Storage/GC/EagerPromotion eager promotion] on it.</p>
<h3 id="threads-tso">Threads: TSO</h3>
<p>Threads (TSOs) have stacks, which are by definition mutable. Running a thread is therefore an act of mutation, and if the thread resides in an old generation, it must be placed in the remembered set. Threads have two dirty bits: `tso-&gt;dirty` is set to non-zero if the thread's stack or any part of the TSO structure may be dirty, and also there is a bit `TSO_LINK_DIRTY` in `tso-&gt;flags` which is set if the TSO's link field may be dirty. If the thread is executed, then `dirty_TSO()` must be called in order to set the `tso-&gt;dirty` bit and add the TSO to the appropriate remembered set.</p>
<p></p>
<p>To set the TSO's link field, use `setTSOLink()` (from <a href="GhcFile(rts/sm/Storage.c)" class="uri" title="wikilink">GhcFile(rts/sm/Storage.c)</a>) which arranges to add the TSO to the remembered set if necessary.</p>
<p></p>
<p>there are a few exceptions where `setTSOLink()` does not need to be called; see <a href="GhcFile(rts/sm/Storage.c)" class="uri" title="wikilink">GhcFile(rts/sm/Storage.c)</a> for details.</p>
<h2 id="remembered-set-maintenance-during-gc">Remembered set maintenance during GC</h2>
<p>During GC, the principle of write barriers is quite similar: whenever we create an old-to-new pointer, we have to record it in the remembered set. The GC achieves this as follows:</p>
<p><code>*TheGCthreadstructurehasafield`gct-&gt;evac_gen`whichspecifiesthedesireddestinationgeneration.</code><br />
<code>*thereisaflag`gct-&gt;failed_to_evac`,whichissettotrueby`evacuate`ifitdidnotmanagetoevacuate</code><br />
<code>theobjectintothedesiredgeneration.</code><br />
<code>*afterscavenginganobject,`scavenge_block`checksthe`failed_to_evac`flag,andifitisset,addstheobjecttotherememberedset,using`recordMutableGen_GC()`(theequivalentof`recordMutableCap`forcallingwithintheGC).</code></p>
<h1 id="the-renamer">The renamer</h1>
<p>The renamer's Number One task is to replace [wiki:Commentary/Compiler/RdrNameType RdrNames] with [wiki:Commentary/Compiler/NameType Names]. For example, consider  (where all the variables are s). The result of renaming module M is:  where all these names are now s.</p>
<p><code>*Thetop-levelunqualifed</code><code>&quot;</code><code>&quot;hasbecomethe</code><code></code><code></code><code>.</code><br />
<code>*Theoccurrences&quot;</code><code>&quot;and&quot;</code><code>&quot;arebothboundtothis</code><code>.</code><br />
<code>*Thequalified</code><code>&quot;</code><code>&quot;becomesthe</code><code></code><code>,becausethefunctionisdefinedinmoduleK.</code><br />
<code>*Thelambda-bound&quot;</code><code>&quot;becomesan</code><code>name,herewritten</code><code>.(Allthe</code><code>nameshaveuniquestoo,butweoftendonotprintthem.)</code></p>
<p>In addition, the renamer does the following things:</p>
<p><code>*Sortoutfixities.Theparserparsesallinfixapplicationsas</code><strong><code>left-associative</code></strong><code>,regardlessoffixity.Forexample&quot;</code><code>&quot;isparsedas&quot;</code><code>&quot;.Therenamerre-associatessuchnestedoperatorapplications,usingthefixitiesdeclaredinthemodule.</code></p>
<p><code>*Dependencyanalysisformutually-recursivegroupsofdeclarations.Thisdividesthedeclarationsintostrongly-connectedcomponents.</code></p>
<p><code>*Lotsoflexicalerrorchecking:variablesoutofscope,unusedbindings,unusedimports,patternsthatusethesamebindermanytimes,etc.</code></p>
<p>The renamer sits between the parser and the typechecker. However, its operation is quite tightly interwoven with the typechecker. This is mainly due to support for Template Haskell, where spliced code has to be renamed and type checked. In particular, top-level splices lead to multiple rounds of renaming and type checking. It uses the [wiki:Commentary/Compiler/TcRnMonad same monad as the typechecker].</p>
<h2 id="the-global-renamer-environment">The global renamer environment, </h2>
<p>A big part of the renamer's task is to build the <strong>global rdr-env</strong> for the module, of type . This environment allows us to take a qualified or un-qualified  and figure out which  it means. The global rdr-env is built by looking at all the imports, and the top-level declarations of the module.</p>
<p>You might think that the global rdr-env would be a mapping from  to , but it isn't. Here is what it looks like, after at least three iterations (all in <a href="GhcFile(compiler/basicTypes/RdrName.hs)" class="uri" title="wikilink">GhcFile(compiler/basicTypes/RdrName.hs)</a>):  Here is how to understand these types:</p>
<p><code>*Theenvironment(`GlobalRdrEnv`)mapsan</code><code>toalistofallentitieswiththatoccurrencenamethatareinscope(inanyway).</code></p>
<p><code>*Eachoftheseisrepresentedbya</code><code>,whichgivestheentity's</code><code>plusaspecificationofhowitisinscope,its</code><code>.</code></p>
<p><code>*The</code><code>hasoneoftwoforms.Eitheritisinscopebecauseitisdefinedinthismodule(</code><code>),orbecauseitisimported.Inthelattercase,the</code><code>describesalltheimportstatementsthatbringitintoscope.</code></p>
<p><code>*An</code><code>hastwocomponents:</code><br />
<code>*An</code><code>thatdescribestheentireimportdeclaration.Thisissharedbetweenallentitiesbroughtintoscopebyaparticularimportdeclaration.</code><br />
<code>*An</code><code>thatdescribestheimportitemthatbroughttheentityintoscope.</code><br />
<code>Forexample,given</code></p>
<p></p>
<p><code>the</code><code>woulddescribethe</code><code>and</code><code>part,whilethe</code><code>describesthe</code><code>part.Youcanlookin</code><code>toseewhatan</code><code>and</code><code>arelike!</code><br />
<code>*The</code><code>ofanentityisthe</code><code>underwhichitisgroupedwhentheforms`T(..)`or`T(C,D)`areusedinanexportorimportlist.Inthe`T(..)`form,allthethingswhose</code><code>is`T`arechosen.Inthe`T(C,D)`form,itisrequiredthat`C`and`D`have`T`asparents.</code><br />
<code>Forexample,</code><br />
<code>*The`Parent`ofadataconstructorisitsdatatype</code><br />
<code>*The`Parent`ofarecordfieldselectorisitsdatatype</code><br />
<code>*The`Parent`ofaclassoperationisitsclass</code></p>
<p>With all that information, we can give good error messages, especially in the case where an occurrence &quot;f&quot; is ambiguous (i.e. different entities, both called &quot;f&quot;, were imported by different import statements).</p>
<p>The global rdr-env is created by <a href="GhcFile(compiler/rename/RnNames.hs)" class="uri" title="wikilink">GhcFile(compiler/rename/RnNames.hs)</a>.</p>
<p>It is important to note that the global rdr-env is created <em>before</em> the renamer actually descends into the top-level bindings of a module. In other words, before  performs the renaming of a module by way of , it uses  to set up the global rdr-env environment, which contains  for all imported and all locally defined toplevel binders. Hence, when the helpers of  come across the defining occurences of a toplevel , they don't rename it by generating a new name, but they simply look up its name in the global rdr-env.</p>
<h2 id="unused-imports">Unused imports</h2>
<p>See [wiki:Commentary/Compiler/UnusedImports how the renamer reports unused imports]</p>
<h2 id="name-space-management">Name Space Management</h2>
<p>(too much detail?)</p>
<p>As anticipated by the variants  and  of , some names should not change during renaming, whereas others need to be turned into unique names. In this context, the two functions  and  are important:  The two functions introduces new toplevel and new local names, respectively, where the first two arguments to newTopSrcBinder determine the currently compiled module and the parent construct of the newly defined name. Both functions create new names only for [wiki:Commentary/Compiler/RdrNameType RdrNames] that are neither exact nor original.</p>
<h2 id="rebindable-syntax">Rebindable syntax</h2>
<p>(!ToDo: Not fully proof-read.)</p>
<p>In Haskell when one writes &quot;3&quot; one gets &quot;fromInteger 3&quot;, where &quot;fromInteger&quot; comes from the Prelude (regardless of whether the Prelude is in scope). If you want to completely redefine numbers, that becomes inconvenient. So GHC lets you say &quot;-fno-implicit-prelude&quot;; in that case, the &quot;fromInteger&quot; comes from whatever is in scope. (This is documented in the User Guide.)</p>
<p>This feature is implemented as follows (I always forget).</p>
<p><code>*NamesthatareimplicitlyboundbythePrelude,aremarkedbythetype</code><code>.Moreover,theassociationlist</code><code>issetupbytherenamertomaprebindablenamestothevaluetheyareboundto.</code><br />
<code>*Currently,fiveconstructsrelatedtonumerals(</code><code>,</code><code>,</code><code>,</code><code>,and</code><code>)andtwoconstructsrelatedtodo-expressions(</code><code>and</code><code>)haverebindablesyntax.</code><br />
<code>*Whentheparserbuildstheseconstructs,itputsinthebuilt-inPreludeName(e.g.</code><code>).</code><br />
<code>*Whentherenamerencounterstheseconstructs,itcalls</code><code>.Thischecksfor</code><code>;ifnot,itjustreturnsthesameName;otherwiseittakestheoccurrencenameoftheName,turnsitintoanunqualified</code><code>,andlooksitupintheenvironment.Thereturnednameispluggedbackintotheconstruct.</code><br />
<code>*Thetypecheckerusesthe</code><code>togeneratetheappropriatetypingconstraints.</code></p>
<h1 id="replacing-the-native-code-generator">Replacing the Native Code Generator</h1>
<p>The existence of LLVM is definitely an argument not to put any more effort into backend optimisation in GHC, at least for those optimisations that LLVM can already do. There's also the question of whether it's worth extending the NCG to support SIMD primops. At the moment only the LLVM backend supports these, but current processor architectures will rely more and more on wide vector SIMD instructions for performance. Given that the LLVM project is now stable and widely used, it may be better to drop the NCG entirely (and delete the code).</p>
<p>However, there are a few ways that the LLVM backend needs to be improved before it can be considered to be a complete replacement for the existing NCG:</p>
<p>1. Compilation speed. LLVM approximately doubles compilation time. Avoiding going via the textual intermediate syntax would probably help here.</p>
<p>2. Shared library support (#4210, #5786). It works (or worked?) on a couple of platforms. But even on those platforms it generated worse code than the NCG due to using dynamic references for *all* symbols, whereas the NCG knows which symbols live in a separate package and need to use dynamic references.</p>
<p>3. Some low-level optimisation problems (#4308, #5567). The LLVM backend generates bad code for certain critical bits of the runtime, perhaps due to lack of good aliasing information. This hasn't been revisited in the light of the new codegen, so perhaps it's better now.</p>
<p>Someone should benchmark the LLVM backend against the NCG with new codegen in GHC 7.8. It's possible that the new codegen is getting a slight boost because it doesn't have to split up proc points, so it can do better code generation for let-no-escapes. It's also possible that LLVM is being penalised a bit for the same reason.</p>
<p>Other considerations:</p>
<p>1. The GHC distribution would need to start shipping with its own copy of LLVM. The LLVM code that GHC produces typically lags the current version of LLVM, so we'd need to ensure there was a usable version.</p>
<p>2. If we did ship our own version of LLVM, we could add custom plugins to improve the GHC generated code. At one stage Max Bolingbroke wrote an LLVM alias analysis plugin, but making it work against an arbitrary existing LLVM version would be infeasible.</p>
<p>note (carter): If we're very thoughtful about the changes / extensions to llvm needed for GHC, I'm somewhat confident that we could get any such patches upstreamed to llvm proper. The down side of this is that any such features would be subject to the llvm release cycle, plus we'd want to make sure that we're not just completely changing what we'd like upstreamed every ghc release cycle. The upside is that we'd get a lot more scrutiny / feedback / checking by llvm devs than we'd get with our own patched variant</p>
<h1 id="resource-limits">Resource Limits</h1>
<p>This page describes a proposed resource limits capabilities for GHC. The idea is to give users the ability to create and utilize resource containers inside programs, and then provide in-program access to heap census and other information. The semantics of resource containers are quite similar to cost centers used in profiling, except that they do not have &quot;stack&quot; semantics (more on this later). The end result is the ability to impose resource limits on space usage.</p>
<h2 id="code-generation-changes">Code generation changes</h2>
<p>Resource limits is a new way (similar to profiled and dynamic). Here are the relevant changes:</p>
<h3 id="dynamic-closure-allocation">Dynamic closure allocation</h3>
<p><a href="GhcFile(compiler/codeGen/StgCmmHeap.hs)" class="uri" title="wikilink">GhcFile(compiler/codeGen/StgCmmHeap.hs)</a>:allocDynClosureCmm (via StgCmmCon, also handles StgCmmBind:mkRhsClosure/cgRhsStdThunk. link_caf needs special treatment.)</p>
<p></p>
<p>Changes to:</p>
<p></p>
<p>I.e. no change from un-profiled.</p>
<h3 id="caf-allocation">CAF Allocation</h3>
<p><a href="GhcFile(compiler/codeGen/StgCmmBind.hs)" class="uri" title="wikilink">GhcFile(compiler/codeGen/StgCmmBind.hs)</a>:thunkCode</p>
<p>Here is an interesting bugger:</p>
<p></p>
<p>Notice the heap check serves for the later branch too. On the other hand, the CCCS coincides with the later change. This seems to be the general pattern. So we might be able to handle this CAF by special-casing CAFs.</p>
<p></p>
<p>We also hit the slow function application path.</p>
<h3 id="thunk-code">Thunk code</h3>
<p><a href="GhcFile(compiler/codeGen/StgCmmBind.hs)" class="uri" title="wikilink">GhcFile(compiler/codeGen/StgCmmBind.hs)</a>:thunkCode</p>
<p></p>
<p>Changes to:</p>
<p></p>
<h3 id="foreign-calls">Foreign calls</h3>
<p></p>
<p>Changes to:</p>
<p></p>
<p>No change from unprofiled</p>
<h2 id="case-split">Case split</h2>
<p>Do a nursery swap.</p>
<ul>
<li><ul>
<li>Warning:** The rest of this document describes an old iteration of the system, which directly used</li>
</ul></li>
</ul>
<h2 id="front-end-changes">Front-end changes</h2>
<p>The basic idea behind this patch is that data collected during **profiling** can also be used at runtime to enforce limits. So most of the API involves (1) dynamically setting cost-centres, which GHC uses to do profiling, and (2) querying and receiving callbacks when certain events happen during profiling. Costs can be collected anywhere you could have placed an  annotation statically.</p>
<p></p>
<p>The general usage of this API goes like:</p>
<p></p>
<p>Another use-case is more fine-grained SCCs based on runtime properties, not source-level features.</p>
<p>I am planning on providing semantics, based on GHC</p>
<h1 id="garbage-collection-roots">Garbage Collection Roots</h1>
<p>The &quot;roots&quot; are the set of pointers that the GC starts traversing from, i.e. the roots of the live object graph.</p>
<p>Most roots belong to a particular Capability. Traversing the roots of a capbility is done by `markSomeCapabilities()` in <a href="GhcFile(rts/Capability.c)" class="uri" title="wikilink">GhcFile(rts/Capability.c)</a>. The roots of a Capability are:</p>
<p><code>*Therunqueue(headandtail)</code><br />
<code>*Thewakeupqueue(headandtail)</code><br />
<code>*ForeachTaskonthe`suspended_ccalling_tasks`list,theTSOforthatTask</code><br />
<code>*TheSparkPool</code><br />
<code>*Onlyforthenon-threadedRTS:Theblockedqueue(headandtail),andthesleepingqueue</code></p>
<p>In addition, each Capability has a [wiki:Commentary/Rts/Storage/GC/RememberedSets remembered set] for each generation. A remembered set is a source of roots if that generation is <em>not</em> being collected during this cycle; otherwise the remembered set is discarded. During GC, all remembered sets are discarded and new ones will be constructed for each generation and Capability; see `scavenge_capability_mut_lists()` in <a href="GhcFile(rts/sm/Scav.c)" class="uri" title="wikilink">GhcFile(rts/sm/Scav.c)</a>.</p>
<p>There are also roots from other parts of the system:</p>
<p><code>*Signalhandlers(onlyinthenon-threadedRTS;inthethreadedRTSsignalhandlersaremaintainedbytheIOmanagerin`GHC.Conc`ratherthantheRTS).</code><br />
<code>*[wiki:Commentary/Rts/Storage/GC/WeakWeakpointers]</code><br />
<code>*[wiki:Commentary/Rts/StableStablepointers]</code></p>
<p><a href="PageOutline" class="uri" title="wikilink">PageOutline</a></p>
<h1 id="ghc-source-tree-roadmap-rts">GHC Source Tree Roadmap: rts/</h1>
<p>This directory contains the source code for the runtime system.</p>
<p>There are three types of files:</p>
<p><code>::</code><br />
<code>Headerfilesthatare</code><em><code>private</code> <code>to</code> <code>the</code> <code>RTS</code></em><code>.Thatis,headerfilesinthisdirectoryare</code><br />
<code>notshippedwithGHC,andAPIstheydefinearethereforeintendedtobeprivateandnot</code><br />
<code>usablebyclientcode(inpractice,wedonotandprobablycannotenforcethis).Header</code><br />
<code>filesthatwe</code><em><code>do</code></em><code>shipwithGHCareinthe[wiki:Commentary/SourceTree/Includesincludes]</code><br />
<code>directory.</code></p>
<p><code>::</code><br />
<code>Csourcecodefortheruntimesystem.Conventionsusedinthiscodearedescribedin</code><br />
<code>[wiki:Commentary/Rts/Conventions].</code></p>
<p><code>::</code><br />
<code>C--codeforpartsoftheruntimethatarepartoftheHaskellexecutionenvironment:for</code><br />
<code>example,theimplementationofprimitives,exceptions,andsoon.A</code><code>fileis</code><br />
<code>pseudoC--:moreorlessC--syntaxwithsomeomissionsandsomeadditionalmacro-like</code><br />
<code>extensionsimplementedbyGHC.The</code><code>filesarecompiledusingGHCitself:see</code><br />
<code>[wiki:Commentary/Rts/Cmm].</code></p>
<h3 id="subdirectories-of-rts">Subdirectories of rts/</h3>
<p><code>::</code><br />
<code>::</code><br />
<code>POSIXandWin32-specificpartsoftheruntimerespectively.Wetrytoputplatform-specificstuffinthesedirectories,</code><br />
<code>howevernotalloftheRTSfollowsthisconventionrightnow.</code></p>
<p><code>::</code><br />
<code>HooksforchangingtheRTSbehaviourfromclientcode,eg.changingthedefaultheapsize.</code><br />
<code>(see</code><a href="https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/runtime-control.html#rts-hooks"><code>User's</code> <code>Guide</code> <code>for</code> <code>more</code> <code>about</code> <code>hooks</code></a><code>).</code></p>
<p><code>::</code><br />
<code>The[wiki:Commentary/Rts/StorageStorageManager].</code></p>
<h3 id="haskell-execution">Haskell Execution</h3>
<p>All this code runs on the Haskell side of the Haskell/C divide;  is the interface between the two layers.</p>
<p><a href="http://darcs.haskell.org/ghc/rts/Apply.cmm"><code>Apply.cmm</code></a><code>,</code><a href="http://darcs.haskell.org/ghc/rts/AutoApply.h"><code>AutoApply.h</code></a><code>,</code><code>,</code><a href="http://darcs.haskell.org/ghc/rts/Apply.h"><code>Apply.h</code></a><code>::</code><br />
<code>Theeval/applymachinery.Note:</code><code>isthefamily</code><br />
<code>offunctionsforperforminggenericapplicationofunknown</code><br />
<code>functions,thiscodedependsonthenumberofregistersavailable</code><br />
<code>forargumentpassing,soitisgeneratedautomaticallybytheprogram</code><br />
<code></code><code>in</code><code>.</code></p>
<p><a href="http://darcs.haskell.org/ghc/rts/Exception.cmm"><code>Exception.cmm</code></a><code>::</code><br />
<code>Supportforexecptions.</code></p>
<p><a href="http://darcs.haskell.org/ghc/rts/HeapStackCheck.cmm"><code>HeapStackCheck.cmm</code></a><code>::</code><br />
<code>CodeforpreparingthestackwhenthecurrentHaskellthreadneeds</code><br />
<code>toreturntotheRTS,becauseweeitherranoutofheaporstack,or</code><br />
<code>needtoblock(eg.</code><code>),oryield.</code></p>
<p><a href="http://darcs.haskell.org/ghc/rts/PrimOps.cmm"><code>PrimOps.cmm</code></a><code>::</code><br />
<code>Implementationofout-of-lineprimitives(see[wiki:Commentary/PrimOps]).</code></p>
<p><a href="http://darcs.haskell.org/ghc/rts/StgMiscClosures.cmm"><code>StgMiscClosures.cmm</code></a><code>::</code><br />
<code>Somebuilt-inclosures,suchasthefamilyofsmall</code><code>sand</code><br />
<code></code><code>,andsomebuilt-ininfotablessuchas</code><br />
<code>and</code><code>.</code></p>
<p><a href="http://darcs.haskell.org/ghc/rts/StgStartup.cmm"><code>StgStartup.cmm</code></a><code>::</code><br />
<code>CodethatexecuteswhenaHaskellthreadbeginsandends.</code></p>
<p><a href="http://darcs.haskell.org/ghc/rts/StgStdThunks.cmm"><code>StgStdThunks.cmm</code></a><code>::</code><br />
<code>Somebuilt-inthunks:[wiki:Commentary/Rts/Storage/HeapObjects#Selectorthunksselectorthunks]and&quot;apply&quot;thunks.</code></p>
<p><a href="http://darcs.haskell.org/ghc/rts/Updates.cmm"><code>Updates.cmm</code></a><code>,</code><a href="http://darcs.haskell.org/ghc/rts/Updates.h"><code>Updates.h</code></a><code>::</code><br />
<code>[wiki:CommentaryUpdates].</code></p>
<p><a href="http://darcs.haskell.org/ghc/rts/HCIncludes.h"><code>HCIncludes.h</code></a><code>::</code><br />
<code>Headerfileincludedwhencompiling</code><code>filesviaC.</code></p>
<p><a href="http://darcs.haskell.org/ghc/rts/StgCRun.c"><code>StgCRun.c</code></a><code>,</code><a href="http://darcs.haskell.org/ghc/rts/StgRun.h"><code>StgRun.h</code></a><code>::</code><br />
<code>TheinterfacebetweentheCexecutionlayerandtheHaskell</code><br />
<code>executionlayer.</code></p>
<p><a href="http://darcs.haskell.org/ghc/rts/StgPrimFloat.c"><code>StgPrimFloat.c</code></a><code>::</code><br />
<code>Floating-pointstuff.</code></p>
<p><a href="http://darcs.haskell.org/ghc/rts/STM.c"><code>STM.c</code></a><code>::</code><br />
<code>ImplementationofSoftwareTransactionalMemory.</code></p>
<h3 id="the-wikicommentaryrtsstorage-storage-manager">The [wiki:Commentary/Rts/Storage Storage Manager]</h3>
<p><a href="http://darcs.haskell.org/ghc/rts/sm/Storage.c"><code>sm/Storage.c</code></a><code>::</code><br />
<code>Top-levelofthestoragemanager.</code></p>
<p><a href="http://darcs.haskell.org/ghc/rts/sm/MBlock.c"><code>sm/MBlock.c</code></a><code>,</code><a href="http://darcs.haskell.org/ghc/rts/sm/MBlock.h"><code>sm/MBlock.h</code></a><code>,</code><a href="http://darcs.haskell.org/ghc/rts/sm/OSMem.h"><code>sm/OSMem.h</code></a><code>::</code><br />
<code>The&quot;megablock&quot;allocator;thisisthethinlayerbetweentheRTSand</code><br />
<code>theoperatingsystemforallocatingmemory.</code></p>
<p><a href="http://darcs.haskell.org/ghc/rts/sm/BlockAlloc.c"><code>sm/BlockAlloc.c</code></a><code>,</code><a href="http://darcs.haskell.org/ghc/rts/sm/BlockAlloc.h"><code>sm/BlockAlloc.h</code></a><code>::</code><br />
<code>Thelow-levelblockallocator,requiresonly</code><code>.</code></p>
<p><a href="http://darcs.haskell.org/ghc/rts/sm/GC.c"><code>sm/GC.c</code></a><code>,</code><a href="http://darcs.haskell.org/ghc/rts/sm/Scav.c"><code>sm/Scav.c</code></a><code>,</code><a href="http://darcs.haskell.org/ghc/rts/sm/Evac.c"><code>sm/Evac.c</code></a><code>,</code><a href="http://darcs.haskell.org/ghc/rts/sm/GCUtils.c"><code>sm/GCUtils.c</code></a><code>,</code><a href="http://darcs.haskell.org/ghc/rts/sm/MarkWeak.c"><code>sm/MarkWeak.c</code></a><code>::</code><br />
<code>Thegenerationalcopyinggarbagecollector.</code></p>
<p><a href="http://darcs.haskell.org/ghc/rts/sm/Compact.c"><code>sm/Compact.c</code></a><code>,</code><a href="http://darcs.haskell.org/ghc/rts/sm/Compact.h"><code>sm/Compact.h</code></a><code>::</code><br />
<code>Thecompactinggarbagecollector.</code></p>
<p><a href="http://darcs.haskell.org/ghc/rts/ClosureFlags.c"><code>ClosureFlags.c</code></a><code>::</code><br />
<code>Determiningpropertiesofvarioustypesofclosures.</code></p>
<p><a href="http://darcs.haskell.org/ghc/rts/Sanity.c"><code>Sanity.c</code></a><code>,</code><a href="http://darcs.haskell.org/ghc/rts/Sanity.h"><code>Sanity.h</code></a><code>::</code><br />
<code>Asanity-checkerfortheheapandrelateddatastructures.</code></p>
<p><a href="http://darcs.haskell.org/ghc/rts/Stats.c"><code>Stats.c</code></a><code>,</code><a href="http://darcs.haskell.org/ghc/rts/Stats.h"><code>Stats.h</code></a><code>::</code><br />
<code>Statisticsforthegarbagecollectorandstoragemanager.</code></p>
<p><a href="http://darcs.haskell.org/ghc/rts/Stable.c"><code>Stable.c</code></a><code>::</code><br />
<code>Stablenamesandstablepointers.</code></p>
<p><a href="http://darcs.haskell.org/ghc/rts/Weak.c"><code>Weak.c</code></a><code>,</code><a href="http://darcs.haskell.org/ghc/rts/Weak.h"><code>Weak.h</code></a><code>::</code><br />
<code>Weakpointers.</code></p>
<h3 id="data-structures">Data Structures</h3>
<p>Data structure abstractions for use in the RTS:</p>
<p><a href="http://darcs.haskell.org/ghc/rts/Arena.c"><code>Arena.c</code></a><code>,</code><a href="http://darcs.haskell.org/ghc/rts/Arena.h"><code>Arena.h</code></a><code>::</code><br />
<code>Anarenaallocator</code></p>
<p><a href="http://darcs.haskell.org/ghc/rts/Hash.c"><code>Hash.c</code></a><code>,</code><a href="http://darcs.haskell.org/ghc/rts/Hash.h"><code>Hash.h</code></a><code>::</code><br />
<code>Agenerichashtableimplementation.</code></p>
<h3 id="the-wikicommentaryrtsscheduler-scheduler">The [wiki:Commentary/Rts/Scheduler Scheduler]</h3>
<p><a href="http://darcs.haskell.org/ghc/rts/Capability.c"><code>Capability.c</code></a><code>,</code><a href="http://darcs.haskell.org/ghc/rts/Capability.h"><code>Capability.h</code></a><code>::</code><br />
<code>Capabilities:virtualCPUsforexecutingHaskellcode.</code></p>
<p><a href="http://darcs.haskell.org/ghc/rts/RaiseAsync.c"><code>RaiseAsync.c</code></a><code>,</code><a href="http://darcs.haskell.org/ghc/rts/RaiseAsync.h"><code>RaiseAsync.h</code></a><code>::</code><br />
<code>Asynchronousexceptions.</code></p>
<p><a href="http://darcs.haskell.org/ghc/rts/Schedule.c"><code>Schedule.c</code></a><code>,</code><a href="http://darcs.haskell.org/ghc/rts/Schedule.h"><code>Schedule.h</code></a><code>::</code><br />
<code>Thescheduleritself.</code></p>
<p><a href="http://darcs.haskell.org/ghc/rts/Sparks.c"><code>Sparks.c</code></a><code>,</code><a href="http://darcs.haskell.org/ghc/rts/Sparks.h"><code>Sparks.h</code></a><code>::</code><br />
<code>Sparks:theimplementationof</code><code>.</code></p>
<p><a href="http://darcs.haskell.org/ghc/rts/ThreadLabels.c"><code>ThreadLabels.c</code></a><code>,</code><a href="http://darcs.haskell.org/ghc/rts/ThreadLabels.h"><code>ThreadLabels.h</code></a><code>::</code><br />
<code>Labellingthreads.</code></p>
<p><a href="http://darcs.haskell.org/ghc/rts/Threads.c"><code>Threads.c</code></a><code>,</code><a href="http://darcs.haskell.org/ghc/rts/Threads.h"><code>Threads.h</code></a><code>::</code><br />
<code>Variousthread-relatedfunctionality.</code></p>
<p><a href="http://darcs.haskell.org/ghc/rts/ThreadPaused.c"><code>ThreadPaused.c</code></a><code>::</code><br />
<code>SuspendingathreadbeforeitreturnstotheRTS.</code></p>
<p><a href="http://darcs.haskell.org/ghc/rts/Task.c"><code>Task.c</code></a><code>,</code><a href="http://darcs.haskell.org/ghc/rts/Task.h"><code>Task.h</code></a><code>::</code><br />
<code>Task:anOS-threadabstraction.</code></p>
<p><a href="http://darcs.haskell.org/ghc/rts/AwaitEvent.h"><code>AwaitEvent.h</code></a><code>::</code><br />
<code>Waitingforevents(non-threadedRTSonly).</code></p>
<p><a href="http://darcs.haskell.org/ghc/rts/Timer.c"><code>Timer.c</code></a><code>,</code><a href="http://darcs.haskell.org/ghc/rts/Timer.h"><code>Timer.h</code></a><code>,</code><a href="http://darcs.haskell.org/ghc/rts/Ticker.h"><code>Ticker.h</code></a><code>::</code><br />
<code>Theruntime'sintervaltimer,usedforcontextswitchingandprofiling.</code></p>
<h3 id="c-files-the-wikicommentaryrtsffi-ffi">C files: the [wiki:Commentary/Rts/FFI FFI]</h3>
<p><a href="http://darcs.haskell.org/ghc/rts/Adjustor.c"><code>Adjustor.c</code></a><code>::</code><br />
<code>Veryhairysupportfor</code><code>.</code></p>
<p><a href="http://darcs.haskell.org/ghc/rts/HsFFI.c"><code>HsFFI.c</code></a><code>,</code><a href="http://darcs.haskell.org/ghc/rts/RtsAPI.c"><code>RtsAPI.c</code></a><code>::</code><br />
<code>ImplementationoftheHaskellFFICinterface:</code><code>,</code><br />
<code></code><code>,etc.</code><br />
<code></code></p>
<h3 id="the-wikicommentaryrtsinterpreter-byte-code-interpreter">The [wiki:Commentary/Rts/Interpreter Byte-code Interpreter]</h3>
<p><a href="http://darcs.haskell.org/ghc/rts/Disassembler.c"><code>Disassembler.c</code></a><code>,</code><a href="http://darcs.haskell.org/ghc/rts/Disassembler.h"><code>Disassembler.h</code></a><code>::</code><br />
<a href="http://darcs.haskell.org/ghc/rts/Interpreter.c"><code>Interpreter.c</code></a><code>,</code><a href="http://darcs.haskell.org/ghc/rts/Interpreter.h"><code>Interpreter.h</code></a><code>::</code><br />
<code>The[wiki:Commentary/Rts/Interpreterbyte-codeinterpreter]anddisassembler.</code></p>
<p><a href="http://darcs.haskell.org/ghc/rts/Linker.c"><code>Linker.c</code></a><code>::</code><br />
<a href="http://darcs.haskell.org/ghc/rts/LinkerInternals.h"><code>LinkerInternals.h</code></a><br />
<code>The[wiki:Commentary/Rts/Linkerdynamicobject-codelinker].</code></p>
<h3 id="wikicommentaryprofiling-profiling">[wiki:Commentary/Profiling Profiling]</h3>
<p><a href="http://darcs.haskell.org/ghc/rts/LdvProfile.c"><code>LdvProfile.c</code></a><code>,</code><a href="http://darcs.haskell.org/ghc/rts/LdvProfile.h"><code>LdvProfile.h</code></a><code>::</code><br />
<code>Lag-drag-voidprofiling(alsoknownasBiographicalProfiling).</code></p>
<p><a href="http://darcs.haskell.org/ghc/rts/ProfHeap.c"><code>ProfHeap.c</code></a><code>,</code><a href="http://darcs.haskell.org/ghc/rts/ProfHeap.h"><code>ProfHeap.h</code></a><code>::</code><br />
<code>Genericheap-profilngsupport.</code></p>
<p><a href="http://darcs.haskell.org/ghc/rts/Profiling.c"><code>Profiling.c</code></a><code>,</code><a href="http://darcs.haskell.org/ghc/rts/Profiling.h"><code>Profiling.h</code></a><code>::</code><br />
<code>Genericprofilngsupport.</code></p>
<p><a href="http://darcs.haskell.org/ghc/rts/Proftimer.c"><code>Proftimer.c</code></a><code>,</code><a href="http://darcs.haskell.org/ghc/rts/Proftimer.h"><code>Proftimer.h</code></a><code>::</code><br />
<code>Theprofilingtimer.</code></p>
<p><a href="http://darcs.haskell.org/ghc/rts/RetainerProfile.c"><code>RetainerProfile.c</code></a><code>,</code><a href="http://darcs.haskell.org/ghc/rts/RetainerProfile.h"><code>RetainerProfile.h</code></a><code>::</code><br />
<a href="http://darcs.haskell.org/ghc/rts/RetainerSet.c"><code>RetainerSet.c</code></a><code>,</code><a href="http://darcs.haskell.org/ghc/rts/RetainerSet.h"><code>RetainerSet.h</code></a><code>::</code><br />
<code>Retainerprofiling.</code></p>
<p><a href="http://darcs.haskell.org/ghc/rts/Ticky.c"><code>Ticky.c</code></a><code>,</code><a href="http://darcs.haskell.org/ghc/rts/Ticky.h"><code>Ticky.h</code></a><code>::</code><br />
<code>Ticky-tickyprofiling(currentlydefunct;needsreviving).</code></p>
<h3 id="rts-debugging">RTS Debugging</h3>
<p><a href="http://darcs.haskell.org/ghc/rts/Printer.c"><code>Printer.c</code></a><code>,</code><a href="http://darcs.haskell.org/ghc/rts/Printer.h"><code>Printer.h</code></a><code>::</code><br />
<code>Genericprintingforheapobjectsandstacks(notusedmuch).</code></p>
<p><a href="http://darcs.haskell.org/ghc/rts/Trace.c"><code>Trace.c</code></a><code>,</code><a href="http://darcs.haskell.org/ghc/rts/Trace.h"><code>Trace.h</code></a><code>::</code><br />
<code>Genericsupportforvariouskindsoftraceanddebuggingmessages.</code></p>
<h3 id="the-front-panel">The Front Panel</h3>
<p>The front panel is currently defunct. It offers a graphical view of the running Haskell program in real time, and was pretty cool when it worked.</p>
<p><a href="http://darcs.haskell.org/ghc/rts/FrontPanel.c"><code>FrontPanel.c</code></a><code>,</code><a href="http://darcs.haskell.org/ghc/rts/FrontPanel.h"><code>FrontPanel.h</code></a><code>::</code><br />
<a href="http://darcs.haskell.org/ghc/rts/VisCallbacks.c"><code>VisCallbacks.c</code></a><code>,</code><a href="http://darcs.haskell.org/ghc/rts/VisCallbacks.h"><code>VisCallbacks.h</code></a><code>::</code><br />
<a href="http://darcs.haskell.org/ghc/rts/VisSupport.c"><code>VisSupport.c</code></a><code>,</code><a href="http://darcs.haskell.org/ghc/rts/VisSupport.h"><code>VisSupport.h</code></a><code>::</code><br />
<a href="http://darcs.haskell.org/ghc/rts/VisWindow.c"><code>VisWindow.c</code></a><code>,</code><a href="http://darcs.haskell.org/ghc/rts/VisWindow.h"><code>VisWindow.h</code></a><code>::</code></p>
<h3 id="other">Other</h3>
<p><a href="http://darcs.haskell.org/ghc/rts/Main.c"><code>Main.c</code></a><code>::</code><br />
<code>TheC</code><code>functionforastandaloneHaskellprogram;</code><br />
<code>basicallythisisjustaclientof</code><code>.</code></p>
<p><a href="http://darcs.haskell.org/ghc/rts/RtsFlags.c"><code>RtsFlags.c</code></a><code>::</code><br />
<code>Understandsthe</code><code>flags.</code></p>
<p><a href="http://darcs.haskell.org/ghc/rts/RtsMessages.c"><code>RtsMessages.c</code></a><code>::</code><br />
<code>Supportforemittingmessagesfromtheruntime.</code></p>
<p><a href="http://darcs.haskell.org/ghc/rts/RtsSignals.c"><code>RtsSignals.c</code></a><code>,</code><a href="http://darcs.haskell.org/ghc/rts/RtsSignals.h"><code>RtsSignals.h</code></a><code>::</code><br />
<code>Signal-relatedstuff.</code></p>
<p>Miscellaneous stuff:</p>
<p><a href="http://darcs.haskell.org/ghc/rts/RtsUtils.c"><code>RtsUtils.c</code></a><code>,</code><a href="http://darcs.haskell.org/ghc/rts/RtsUtils.h"><code>RtsUtils.h</code></a><code>::</code><br />
<a href="http://darcs.haskell.org/ghc/rts/GetTime.h"><code>GetTime.h</code></a><code>::</code><br />
<a href="http://darcs.haskell.org/ghc/rts/PosixSource.h"><code>PosixSource.h</code></a><code>::</code><br />
<a href="http://darcs.haskell.org/ghc/rts/Prelude.h"><code>Prelude.h</code></a><code>::</code><br />
<a href="http://darcs.haskell.org/ghc/rts/Typeable.c"><code>Typeable.c</code></a><code>::</code><br />
<a href="http://darcs.haskell.org/ghc/rts/RtsDllMain.c"><code>RtsDllMain.c</code></a><code>::</code></p>
<h3 id="old-stuff">OLD stuff</h3>
<p><code>::</code><br />
<code>CodeforGUM:parallelGHC.Thisisheavilybitrottedandcurrentlydoesn'twork(asofGHC6.6;itlastworkedaround</code><br />
<code>5.02Ibelieve).</code></p>
<p><code>::</code><br />
<code>BitrottedcodeforGHC.NET.</code></p>
<h1 id="sanity-checking">Sanity Checking</h1>
<p>Source code: <a href="GhcFile(rts/Sanity.c)" class="uri" title="wikilink">GhcFile(rts/Sanity.c)</a>, <a href="GhcFile(rts/Sanity.h)" class="uri" title="wikilink">GhcFile(rts/Sanity.h)</a>.</p>
<p>The purpose of sanity checking is to catch bugs in the RTS as early as possible; if the program is going to crash, we want it to crash as soon as possible after the error occurred. The problem with debugging the RTS is that heap corruption can go unnoticed through several GC cycles, making it particularly difficult to trace back to the erroneous code.</p>
<p>Sanity checking is turned on by the `+RTS -DS` option. We treat it like an expensive assertion: normal assertions are allowed to take a few extra percent of run time, so we don't mind having them on all the time in a `DEBUG` RTS, but sanity checking may double the run time of the program or worse. So the rule of thumb is that expensive assertions go into sanity checking, cheap assertions are on in `DEBUG`, or possibly even on all the time.</p>
<p>Sanity checking does a complete traversal of the heap after each GC to look for dangling pointers (see `checkHeap` in <a href="GhcFile(rts/Sanity.c)" class="uri" title="wikilink">GhcFile(rts/Sanity.c)</a>). For this it needs to ensure that there is no [wiki:Commentary/Rts/Storage/Slop slop], which is why we can only do this in a `DEBUG` runtime: the slop-avoiding machinery is only on with `DEBUG`.</p>
<p>Sanity checking also turns on some other expensive checks: for example in the [wiki:Commentary/Rts/HaskellExecution#Genericapply generic apply] code we check that the arguments point to valid closures.</p>
<p><a href="PageOutline" class="uri" title="wikilink">PageOutline</a></p>
<h1 id="the-scheduler">The Scheduler</h1>
<p>The scheduler is the heart of the runtime: it is the single part of the system through which all entry to the Haskell world goes, and it handles requests from outside to invoke Haskell functions (foreign export).</p>
<p>In this part of the commentary we'll discuss the <em>threaded</em> version of the runtime (see [wiki:Commentary/Rts/Config]), that is, the version of the runtime that uses multiple OS threads, because it is by far the most complex beast.</p>
<p>See also <a href="http://blog.ezyang.com/2013/01/the-ghc-scheduler/">Edward Yang's blog post</a> (2013); some of the material there has been incorporated here.</p>
<p>We begin by discussing the basic abstractions used in the scheduler.</p>
<h2 id="os-threads">OS Threads</h2>
<p>Source files: <a href="GhcFile(includes/rts/OSThreads.h)" class="uri" title="wikilink">GhcFile(includes/rts/OSThreads.h)</a>, <a href="GhcFile(rts/win32/OSThreads.c)" class="uri" title="wikilink">GhcFile(rts/win32/OSThreads.c)</a>, <a href="GhcFile(rts/posix/OSThreads.c)" class="uri" title="wikilink">GhcFile(rts/posix/OSThreads.c)</a></p>
<p>We assume that the OS provides some kind of native threads, and for SMP parallelism we assume that the OS will schedule multiple OS threads across the available CPUs.</p>
<p>OS threads are only used by the runtime for two reasons:</p>
<p><code>*Tosupportnon-blockingforeigncalls:aforeigncall</code><br />
<code>shouldnotblocktheotherHaskellthreadsinthesystemfrom</code><br />
<code>running,andusingOSthreadsistheonlywaytoensurethat.</code></p>
<p><code>*TosupportSMPparallelism.</code></p>
<p>Haskell threads are much lighter-weight (at least 100x) than OS threads.</p>
<p>When running on an SMP, we begin by creating the number of OS threads specified by the `+RTS -N` option, although during the course of running the program more OS threads might be created in order to continue running Haskell code while foreign calls execute. Spare OS threads are kept in a pool attached to each `Capability` (see [#Capabilities]).</p>
<p>The RTS provides a platform-independent abstraction layer for OS threads in <a href="GhcFile(includes/rts/OSThreads.h)" class="uri" title="wikilink">GhcFile(includes/rts/OSThreads.h)</a>.</p>
<h2 id="haskell-threads">Haskell threads</h2>
<p>A Haskell thread is represented by a Thread State Object ([wiki:Commentary/Rts/Storage/HeapObjects#ThreadStateObjects TSO]). These objects are <em>garbage-collected</em>, like other closures in Haskell. The TSO, along with the stack allocated with it (STACK), constitute the primary memory overhead of a thread. Default stack size, in particular, is controlled by the GC flag , and is 1k by default (Actually, your usable stack will be a little smaller than that because this size also includes the size of the  struct, so that a lot of allocated threads will fit nicely into a single block.) There are two kinds of Haskell thread:</p>
<p><code>*A</code><em><code>bound</code></em><code>threadiscreatedastheresultofa</code><em><code>call-in</code></em><code>from</code><br />
<code>outsideHaskell;thatis,acallto</code><code>or</code><br />
<code></code><code>.Aboundthreadistiedtothe</code><br />
<code>OSthreadthatmadethecall;allfurtherforeigncallsmadeby</code><br />
<code>thisHaskellthreadaremadeinthesameOSthread.(thisispart</code><br />
<code>ofthedesignoftheFFI,describedinthepaper</code><br />
<code></code><a href="http://www.haskell.org/~simonmar/papers/conc-ffi.pdf"><code>Extending</code> <code>the</code> <code>Haskell</code> <code>Foreign</code> <code>Function</code> <code>Inteface</code> <code>with</code> <code>Concurrency</code></a><code>).</code></p>
<p><code>*An</code><em><code>unbound</code></em><code>threadiscreatedby</code><br />
<code></code><code>.Foreigncallsmadebyanunbound</code><br />
<code>threadaremadebyanarbitraryOSthread.</code></p>
<p>Initialization of TSOs is handled in  in <a href="GhcFile(rts/Threads.c)" class="uri" title="wikilink">GhcFile(rts/Threads.c)</a>; this function is in turn invoked by ,  and  in <a href="GhcFile(rts/RtsAPI.c)" class="uri" title="wikilink">GhcFile(rts/RtsAPI.c)</a>. These functions setup the initial stack state, which controls what the thread executes when it actually gets run. These functions are the ones invoked by the  and other primops (recall entry-points for primops are located in <a href="GhcFile(rts/PrimOps.cmm)" class="uri" title="wikilink">GhcFile(rts/PrimOps.cmm)</a>).</p>
<p>Being garbage collected has two major implications for TSOs. First, TSOs are not GC roots, so they will get GC'd if there is nothing holding on to them (e.g. <a href="http://blog.ezyang.com/2011/07/blockedindefinitelyonmvar">in the case of deadlock</a>), and their space is not automatically reclaimed when they finish executing (so  can cause memory leaks}}}. Usually, a TSO will be retained by a Capability</p>
<h1 id="seq-magic">Seq magic</h1>
<p>The innocent-looking `seq` operator causes all manner of mayhem in GHC. This page summarises the issues. See also discussion in Trac #5129, #5262</p>
<h2 id="the-baseline-position">The baseline position</h2>
<p>Our initial story was that `(seq e1 e2)` meant precisely  Indeed this was `seq`'s inlining. This translation validates some important rules </p>
<p>But this approach has problems; see `Note [Deguaring seq]` in `DsUtils`.</p>
<h3 id="problem-1-trac-1031">Problem 1 (Trac #1031)</h3>
<p>Consider  The `[CoreSyn let/app invariant]` (see `CoreSyn`) means that, other things being equal, because the argument to the outer `seq` has an unlifted type, we'll use call-by-value thus:  But that is bad for two reasons:</p>
<p><code>*wenowevaluate`y`before`x`,and</code><br />
<code>*wecan'tbind`v`toanunboxedpair</code></p>
<p>Seq is very, very special! Treating it as a two-argument function, strict in both arguments, doesn't work. We &quot;fixed&quot; this by treating `seq` as a language construct, desugared by the desugarer, rather than as a function that may (or may not) be inlined by the simplifier. So the above term is desugared to: </p>
<h3 id="problem-2-trac-2273">Problem 2 (Trac #2273)</h3>
<p>Consider  Here the `seq` is designed to plug the space leak of retaining `(snd x)` for too long.</p>
<p>If we rely on the ordinary inlining of `seq`, we'll get  But since `chp` is cheap, and the case is an alluring contet, we'll inline `chp` into the case scrutinee. Now there is only one use of `chp`, so we'll inline a second copy. Alas, we've now ruined the purpose of the seq, by re-introducing the space leak:  We can try to avoid doing this by ensuring that the binder-swap in the case happens, so we get his at an early stage:  But this is fragile. The real culprit is the source program. Perhaps we should have said explicitly  But that's painful. So the desugarer does a little hack to make `seq` more robust: a saturated application of `seq` is turned <strong>directly</strong> into the case expression, thus:  So we desugar our example to:  And now all is well.</p>
<p>Be careful not to desugar  which stupidly tries to bind the datacon 'True'. This is easily avoided.</p>
<p>The whole thing is a hack though; if you define `mySeq=seq`, the hack won't work on `mySeq`.</p>
<h3 id="problem-3-trac-5262">Problem 3 (Trac #5262)</h3>
<p>Consider  With the above desugaring we get  and now ete expansion gives  Now suppose that we have  Plainly `(length xs)` should be evaluated... but it isn't because `f` has arity 2. (Without -O this doesn't happen.)</p>
<h3 id="problem-4-seq-in-the-io-monad">Problem 4: seq in the IO monad</h3>
<p>See the extensive discussion in Trac #5129.</p>
<h3 id="problem-5-the-need-for-special-rules">Problem 5: the need for special rules</h3>
<p>Roman found situations where he had  where he knew that `f` (which was strict in `n`) would terminate if n did. Notice that the result of `(f n)` is discarded. So it makes sense to transform to  Rather than attempt some general analysis to support this, I've added enough support that you can do this using a rewrite rule:  You write that rule. When GHC sees a case expression that discards its result, it mentally transforms it to a call to `seq` and looks for a RULE. (This is done in `Simplify.rebuildCase`.) As usual, the correctness of the rule is up to you.</p>
<p>To make this work, we need to be careful that `seq` is <strong>not</strong> desguared into a case expression on the LHS of a rule.</p>
<p>To increase applicability of these user-defined rules, we also have the following built-in rule for `seq`  This eliminates unnecessary casts and also allows other seq rules to match more often. Notably,  and now a user-defined rule for `seq` may fire.</p>
<h1 id="a-better-way">A better way</h1>
<p>Here's our new plan.</p>
<p><code>*Introduceanewprimop`seq#::a-&gt;State#s-&gt;(#a,State#s#)`(seebe5441799b7d94646dcd4bfea15407883537eaaa)</code><br />
<code>*Implement`seq#`byturningitintotheobviousevalinthebackend.Infact,sincethereturnconventionfor`(#State#s,a#)`isexactlythesameasfor`a`,wecanimplement`seq#sa`by`a`(evenwhenitappearsasacasescrutinee).</code><br />
<code>*Define`evaluate`thus</code></p>
<p></p>
<p>That fixes problem 4.</p>
<p>We could go on and desugar `seq` thus: </p>
<p>and if we consider `seq#` to be expensive, then we won't eta-expand around it, and that would fix problem 3.</p>
<p>However, there is a concern that this might lead to performance regressions in examples like this:</p>
<p></p>
<p>so `f` turns into</p>
<p></p>
<p>and we won't get to eta-expand the `\s` as we would normally do (this is pretty important for getting good performance from IO and ST monad code).</p>
<p>Arguably `f` should be rewritten with a bang pattern, and we should treat bang patterns as the eta-expandable seq and translate them directly into `case`, not `seq#`. But this would be a subtle difference between `seq` and bang patterns.</p>
<p>Furthermore, we already have `pseq`, which is supposed to be a &quot;strictly ordered seq&quot;, that is it preserves evaluation order. So perhaps `pseq` should be the one that more accurately implements the programmer's intentions, leaving `seq` as it currently is.</p>
<p>We are currently pondering what to do here.</p>
<h1 id="the-ghc-commentary-signals">The GHC Commentary: Signals</h1>
<p>This section describes how the RTS interacts with the OS signal facilities. Throughout we use the term &quot;signal&quot; to refer to both POSIX-style signals and Windows <em>ConsoleEvents</em>.</p>
<p>Signal handling differs between the <em>threaded</em> version of the runtime and the non-threaded version (see [wiki:Commentary/Rts/Config]). Here we discuss only the threaded version, since we expect that to become the standard version in due course.</p>
<p>Source files:</p>
<p><code>*POSIXsignalhandling:</code><br />
<code>*</code><a href="GhcFile(rts/posix/Signals.h)" title="wikilink"><code>GhcFile(rts/posix/Signals.h)</code></a><code>,</code><a href="GhcFile(rts/posix/Signals.c)" title="wikilink"><code>GhcFile(rts/posix/Signals.c)</code></a><br />
<code>*Windowsconsoleevents:</code><br />
<code>*</code><a href="GhcFile(rts/win32/ConsoleHandler.h)" title="wikilink"><code>GhcFile(rts/win32/ConsoleHandler.h)</code></a><code>,</code><a href="GhcFile(rts/win32/ConsoleHandler.c)" title="wikilink"><code>GhcFile(rts/win32/ConsoleHandler.c)</code></a></p>
<h2 id="signal-handling-in-the-rts">Signal handling in the RTS</h2>
<p>The RTS is interested in two signals: a timer signal, and an interrupt signal.</p>
<h3 id="the-timer-signal">The timer signal</h3>
<p>The timer signal is used for several things:</p>
<p><code>*Tocausethe[wiki:Commentary/Rts/Schedulerscheduler]tocontextswitch</code><br />
<code>*Samplingfor[wiki:Commentary/Profilingtimeprofiling]</code><br />
<code>*Todetectdeadlock(see[wiki:Commentary/Rts/Scheduler])</code></p>
<p>Source files:</p>
<p><code>*Thetimerinterrupthandler,andstarting/stoppingthetimer:</code><br />
<code>*</code><a href="GhcFile(rts/Timer.h)" title="wikilink"><code>GhcFile(rts/Timer.h)</code></a><code>,</code><a href="GhcFile(rts/Timer.c)" title="wikilink"><code>GhcFile(rts/Timer.c)</code></a><br />
<code>*Platform-independenttickerinterface,usedbythetimer:</code><br />
<code>*</code><a href="GhcFile(rts/Ticker.h)" title="wikilink"><code>GhcFile(rts/Ticker.h)</code></a><br />
<code>*Posiximplementationofticker:</code><br />
<code>*</code><a href="GhcFile(rts/posix/Itimer.h)" title="wikilink"><code>GhcFile(rts/posix/Itimer.h)</code></a><code>,</code><a href="GhcFile(rts/posix/Itimer.h)" title="wikilink"><code>GhcFile(rts/posix/Itimer.h)</code></a><br />
<code>*Windowsimplementationofticker:</code><br />
<code>*</code><a href="GhcFile(rts/win32/Ticker.c)" title="wikilink"><code>GhcFile(rts/win32/Ticker.c)</code></a></p>
<p>On Posix, the timer signal is implemented by calling `timer_create()` to generate regular `SIGVTALRM` signals (this was changed from SIGALRM in #850).</p>
<p>On Windows, we spawn a new thread that repeatedly sleeps for the timer interval and then executes the timer interrupt handler.</p>
<h2 id="the-interrupt-signal">The interrupt signal</h2>
<p>The interrupt signal is `SIGINT` on POSIX systems or `CTRL_C_EVENT/CTRL_BREAK_EVENT`on Windows, and is normally sent to the process when the user hits Control-C. By default, interrupts are handled by the runtime. They can be caught and handled by Haskell code instead, using `System.Posix.Signals` on POSIX systems or `GHC.ConsoleHandler` on Windows systems. For example, [wiki:Commentary/Compiler/Backends/GHCi GHCi] hooks the interrupt signal so that it can abort the current interpreted computation and return to the prompt, rather than terminating the whole GHCi process.</p>
<p>When the interrupt signal is received, the default behaviour of the runtime is to attempt to shut down the Haskell program gracefully. It does this by calling `interruptStgRts()` in <a href="GhcFile(rts/Schedule.c)" class="uri" title="wikilink">GhcFile(rts/Schedule.c)</a> (see [wiki:Commentary/Rts/Scheduler#ShuttingDown]). If a second interrupt signal is received, then we terminate the process immediately; this is just in case the normal shutdown procedure failed or hung for some reason, the user is always able to stop the process with two control-C keystrokes.</p>
<h2 id="signal-handling-in-haskell-code">Signal handling in Haskell code</h2>
<p>Source files:</p>
<p><code>*POSIX:</code><a href="GhcFile(rts/posix/Signals.h)" title="wikilink"><code>GhcFile(rts/posix/Signals.h)</code></a><code>,</code><a href="GhcFile(rts/posix/Signals.c)" title="wikilink"><code>GhcFile(rts/posix/Signals.c)</code></a><br />
<code>*Windows:</code><a href="GhcFile(rts/win32/ConsoleHandler.h)" title="wikilink"><code>GhcFile(rts/win32/ConsoleHandler.h)</code></a><code>,</code><a href="GhcFile(rts/win32/ConsoleHandler.c)" title="wikilink"><code>GhcFile(rts/win32/ConsoleHandler.c)</code></a></p>
<p>A Haskell program can ask to install signal handlers, via the `System.Posix.Signals` API, or `GHC.ConsoleHandler` on Windows. When a signal arrives that has a Haskell handler, it is the job of the runtime to create a new Haskell thread to run the signal handler and place the new thread on the run queue of a suitable [wiki:Commentary/Rts/Scheduler#Capabilities Capability].</p>
<p>When the runtime is idle, the OS threads will all be waiting inside `yieldCapability()`, waiting for some work to arrive. We want a signal to be able to create a new Haskell thread and wake up one of these OS threads to run it, but unfortunately the range of operations that can be performed inside a POSIX signal handler is extremely limited, and doesn't include any inter-thread synchronisation (because the signal handler might be running on the same stack as the OS thread it is communicating with).</p>
<p>The solution we use, on both Windows and POSIX systems, is to pass all signals that arrive to the [wiki:Commentary/Rts/IOManager IO Manager] thread. On POSIX this works by sending the signal number down a pipe, on Windows it works by storing the signal number in a buffer and signaling the IO Manager's `Event` object to wake it up. The IO Manager thread then wakes up and creates a new thread for the signal handler, before going back to sleep again.</p>
<h2 id="rts-alarm-signals-and-foreign-libraries">RTS Alarm Signals and Foreign Libraries</h2>
<p>When using foreign libraries through the Haskell FFI, it is important to ensure that the foreign code is capable of dealing with system call interrupts due to alarm signals GHC is generating.</p>
<p>For example, in this `strace` output a `select` call is interrupted, but the foreign C code interprets the interrupt as an application error and closes a critical file descriptor:</p>
<p></p>
<p>Once the C code was modified to deal with the interrupt properly, it proceeded correctly (note that foreign call is restarted 3 times before it succeeds).</p>
<p></p>
<h1 id="slop">Slop</h1>
<p>Slop is unused memory between objects in the heap.</p>
<p>|| Object1 || ... Slop ... || Object2 ||</p>
<h2 id="why-do-we-want-to-avoid-slop">Why do we want to avoid slop?</h2>
<p>Slop makes it difficult to traverse an area of memory linearly, visiting all the objects, because we can't tell where `Object2` starts in the above diagram. We need to do linear traversals for two reasons, currently:</p>
<p><code>*[wiki:Commentary/Profiling/HeapHeapprofiling]needstoperformacensusonthewholeheap.</code><br />
<code>*[wiki:Commentary/Rts/SanitySanitychecking]needstoensurethatallthepointersintheheap</code><br />
<code>pointtovalidobjects.</code></p>
<p>Additionally, linear traversals are useful for the mark phase of the [wiki:Commentary/Rts/Storage compacting garbage collector], and would be useful if we were to allow objects to be pinned arbitrarily (currently pinned objects cannot contain pointers, which means they don't need to be scavenged by the GC).</p>
<h2 id="how-does-slop-arise">How does slop arise?</h2>
<p>Slop can arise for two reasons:</p>
<p><code>*Thecompiledcodeallocatestoomuchmemory,andonlyfillspartofitwithobjects.Forexample,</code><br />
<code>whencompilingcodeforafunctionlikethis:</code></p>
<p></p>
<p><code>thecodegeneratortakesthemaximumoftheheaprequirementsofe1ande2andaggregatesitinto</code><br />
<code>theheapcheckatthebeginningofthefunction`f`(toavoiddoingtoomanyheapchecks).</code><br />
<code>Unfortunatelythatmeanseither`e1`or`e2`hastoomuchheapallocatedtoit,leavingsomeslop.</code><br />
<code>Wesolvethisproblembymovingtheheappointer</code><em><code>backwards</code></em><code>beforemakingatail-callif</code><br />
<code>thereisanyheapslop.</code></p>
<p><code>*Whenanobjectisoverwrittenwithasmallerobject.Thishappensintwoways:</code><br />
<code>[wiki:Commentary/Rts/HaskellExecution/UpdatesUpdates]and[wiki:Commentary/Rts/Storage/HeapObjects#BlackholesBlackHoles].</code></p>
<h2 id="what-do-we-do-about-it">What do we do about it?</h2>
<p>We avoid the problem for [wiki:Commentary/Profiling/Heap heap profiling] by arranging that we only ever do a census on a newly garbage-collected heap, which has no slop in it (the garbage collector never leaves slop between objects in the heap).</p>
<p>Slop does arise due to updates and black holes during normal execution, and GHC does not attempt to avoid it (because avoiding or filling slop during an update is costly). However, if we're doing [wiki:Commentary/Rts/Sanity sanity checking], then we need to arrange that slop is clearly marked: so in a `DEBUG` version of the RTS (see [wiki:Commentary/Rts/Config RTS configurations]) the update code and the blackhole code both arrange to fill slop with zeros: see the `FILL_SLOP` macro in <a href="GhcFile(rts/Updates.h)" class="uri" title="wikilink">GhcFile(rts/Updates.h)</a>. Hence sanity checking only works with a `DEBUG` version of the RTS.</p>
<p><a href="PageOutline" class="uri" title="wikilink">PageOutline</a></p>
<h1 id="layout-of-important-files-and-directories">Layout of important files and directories</h1>
<p>This page summarises the overall file and directory structure of GHC. We include both source files and generated files; the latter are always identified &quot;build-tree only&quot;.</p>
<p>Everything starts with the main GHC repository (see [wiki:Building/GettingTheSources]). The build system calls that directory `$(TOP)`. All the paths below are relative to `$(TOP)`.</p>
<h2 id="files-in-top">Files in `$(TOP)`</h2>
<p><strong><code>`packages`</code></strong><code>::</code><br />
<code>Despitethename&quot;package&quot;,thisfilecontainsthemasterlistofthe*repositories*thatmakeupGHC.Itisparsedby`./boot`.</code></p>
<p><strong><code>`tarballs`</code></strong><code>::</code><br />
<code>Liststhevarioustarballs(binarypackages)thatghcreliesonandwheretounpackthemduringabuild.</code></p>
<p><strong><code>`validate`</code></strong><code>::Run`validate`(ashellscript)beforecommitting(see[wiki:TestingPatches]).Thescriptisdocumentedinthefileitself.</code></p>
<p><strong><code>Documentation</code> <code>files</code></strong><code>::`README`,`ANNOUNCE`,`HACKING`,`LICENSE`,`new_tc_notes`</code></p>
<p><strong><code>GNU</code> <code>autoconf</code> <code>machinery</code></strong><code>::`aclocal.m4`,`config.guess`,`config.sub`,`configure.ac`,`install-sh`,`config.mk.in`,`settings.in`</code></p>
<p><strong><code>`Makefile`</code></strong><code>::Thetop-level</code><code>:see[wiki:Building/ArchitectureGHCBuildSystemArchitecture].GHCrequires</code><br />
<code></code><a href="http://www.gnu.org/software/make/"><code>GNU</code> <code>make</code></a><code>.</code></p>
<p><strong><code>Make</code> <code>system</code> <code>files</code></strong><code>::`ghc.mk`,`MAKEHELP`,`SUBMAKEHELP`</code></p>
<h2 id="libraries">`libraries/`</h2>
<p>The `libraries/` directory contains all the packages that GHC needs to build. It has one sub-directory for each package repository (e.g. `base`, `haskell98`, `random`). Usually each such repository builds just one package, but there is more than one in `dph`.</p>
<p>GHC's libraries are described in more detail on the [wiki:Commentary/Libraries libraries page].</p>
<h2 id="compiler-docs-ghc">`compiler/`, `docs/`, `ghc/`</h2>
<p>These directories contain the main GHC compiler and documentation. The `compiler/` directory contains the ghc package, which is linked into an executable in the `ghc/` directory.</p>
<p>There is [wiki:ModuleDependencies documentation of the intended module dependency structure] of the `compiler/` directory.</p>
<p><code>*</code><strong><code>`compiler/ghc.cabal.in`</code></strong><code>:theCabalfileforGHCisgeneratedfromthis.IfyouaddamoduletoGHC'ssourcecode,youmustadditinthe`ghc.cabal.in`filetoo,elseyou'llgetlinkerrors.</code></p>
<p>The following directories appear only in the build tree:</p>
<p><code>*</code><strong><code>`compiler/stage1`</code></strong><code>:generatedfilesforthestage1buildofGHC.Thereareahandfuloffiles(`ghc_boot_platform.h`etc),andadirectory`compiler/stage1/build/`thatcontainsallthe`.o`and`.hi`filesforthecompiler.</code><br />
<code>*</code><strong><code>`compiler/stage2`</code></strong><code>:similarlystage2.</code></p>
<p>You can't run a binary from here: look in the `inplace/` directory below for that.</p>
<h2 id="rts">`rts/`</h2>
<p>Sources for the runtime system; see [wiki:Commentary/SourceTree/Rts].</p>
<h2 id="includes">`includes/`</h2>
<p>Header files for the runtime system; see [wiki:Commentary/SourceTree/Includes].</p>
<h2 id="utils-libffi">`utils/`, `libffi/`</h2>
<p>The `utils` directory contains support utilities that GHC uses.</p>
<p>These utils may be built with the bootstrapping compiler, for use during the build, or with the stage1 or stage2 compiler, for installing. Some of them are built with both; we can't install the utils built with the bootstrapping compiler as they may use different versions of C libraries. The reason we use sometimes stage2 rather than stage1 is that some utils, e.g. haddock, need the GHC API package.</p>
<p><code>*</code><strong><code>`utils/ghc-cabal`</code></strong><code>isalittleprogramweuseforbuildingthelibraries.It'ssimilartocabal-install,butwithoutthedependencieson`http`etc.</code><br />
<code>*</code><strong><code>`utils/count_lines`</code></strong><code>isaprogramthatcountsthenumberofsource-codelinesinGHC'scode-base.Itdistinguishescommentsfromnon-comments.</code></p>
<h2 id="driver">`driver/`</h2>
<p>This contains some simple wrapper programs and scripts, for example the `ghci` wrapper that invokes the `ghc` binary with the `--interactive` flag. These wrappers tend to be executable programs on Windows and scripts on Unix systems.</p>
<h2 id="ghc-tarballs-windows-only">`ghc-tarballs/` (Windows only)</h2>
<p>This contains some tarball files (binary packages) that GHC relies upon. Used for easier development / deployment on windows.</p>
<h2 id="testsuite-nofib">`testsuite/`, `nofib/`</h2>
<p>The `testsuite/` and `nofib/` directories contain apparatus for testing GHC.</p>
<p><code>*[wiki:Building/RunningTests]</code><br />
<code>*[wiki:Building/RunningNoFib]</code></p>
<h2 id="mk-rules">`mk/`, `rules/`</h2>
<p>The `mk/` and `rules.mk` directories contains all the build system Makefile boilerplate; see [wiki:Building/Architecture GHC Build System Architecture]. Some particular files are interesting:</p>
<p><code>*</code><strong><code>`mk/build.mk`</code></strong><code>:containsMakefilesettingsthatcontrolyourbuild.Details[wiki:Building/Usinghere].Thefile`mk/build.mk.sample`containsastartingpointthatyoucancopyto`mk/build.mk`ifyouwant.</code><br />
<code>*</code><strong><code>`mk/are-validating.mk`</code></strong><code>:thisfilerecordsthefactthatyouaredoing[wiki:TestingPatchesvalidation],bycontainingthesingleline`Validating=YES`.Thatinturnmeansthethebuildsystemgetsitssettingsfrom`mk/validate-settings.mk`insteadoffrom`mk/build.mk`.Removethefiletostopvalidating.</code><br />
<code>*</code><strong><code>`mk/validate.mk`</code></strong><code>:justlike`build.mk`,butapplieswhenvalidating.Usethisfiletooverridethedefaultsettingsforvalidation,whicharein`mk/validate-settings.mk`.</code></p>
<h2 id="distrib">`distrib/`</h2>
<p>Miscellaneous files for building distributions.</p>
<h2 id="stuff-that-appears-only-in-a-build-tree">Stuff that appears only in a build tree</h2>
<h3 id="inplace">`inplace/`</h3>
<p>The `inplace/` directory is where we &quot;install&quot; stage1 and stage2 compilers, and other utility programs, when they are built, to be used when building other things in the build tree. The layout is exactly the same as that of an installed GHC on the host platform.</p>
<p><code>*</code><strong><code>`inplace/bin/`</code></strong><code>:executables,including</code><br />
<code>*`ghc-stage1`</code><br />
<code>*`ghc-stage2`</code><br />
<code>*`ghc-pkg`</code><br />
<code>*`hasktags`</code><br />
<code>*`hsc2hs`</code><br />
<code>*`haddock`</code><br />
<code>*`count_lines`</code><br />
<code>*`compareSizes`</code></p>
<p><code>*</code><strong><code>`inplace/lib/`</code></strong><code>:suppportinglibrariesfortheexecutables.</code></p>
<h3 id="dist">`.../dist*/`</h3>
<p>In many directories, `dist*` subdirectories appear. These are where Cabal, and the build system makefiles, put all of the files generated while building. Some particularly interesting files are:</p>
<p><code>*</code><strong><code>`docs/users_guide/users_guide/index.html`</code></strong><code>:theHTMLfortheusermanual</code><br />
<code>*</code><strong><code>`libraries/`</code><em><code>lib</code></em><code>`/dist-install/doc/html/`</code><em><code>lib</code></em></strong><code>:containstheHaddock'ddocumentationforlibrary</code><em><code>lib</code></em></p>
<p><a href="PageOutline" class="uri" title="wikilink">PageOutline</a></p>
<hr />
<h2 id="stack-layout-1">Stack Layout</h2>
<p>The stack-layout phase decides where to spill variables. The important goals are to avoid memory traffic and to minimize the size of the stack frame. Both of these goals are accomplished by reusing stack slots.</p>
<h3 id="representing-stack-slots">Representing Stack Slots</h3>
<p>For each stack slot, we introduce a new name, then treat the name as the addressing expression for the slot. At the end of the pipeline, we choose a stack layout, then replace each stack slot with its offset from the stack pointer. The benefit is that we break the phase-ordering problem: any phase of the compiler can name a stack slot.</p>
<p>For example, for a variable `x`, the expression `SS(x)` is the address of the stack slot where we can spill `x`. (I don't think we output any C-- that uses SS anymore, but the new code generator marks its stack slots prior to layout with `young<k> + 4`, etc. -- Edward) The stack is assumed to grow down, and we assume that the address `SS(x)` points to the old end of the slot. Therefore, to address the low address of a 4-byte slot, we would use the expression `SS(x + 4)`. And we would spill `x` using the following instruction: </p>
<p>where  refers to an address  in memory.</p>
<p>But what about parameter passing? We use a similar technique, but this time we describe the slot for each location as an offset within the area where the parameters are passed. For example, we lower a function call</p>
<p></p>
<p>into approximately the following C--:</p>
<p></p>
<p>We use the following types to represent stack slots and parameter-passing areas:</p>
<p></p>
<p>An `Area` represents space on the stack; it may use either the `RegSlot` constructor to represent a single stack slot for a register or the `CallArea` constructor to represent parameters passed to/from a function call/return. In a young `CallArea`, the `BlockId` is the label of the function call's continuation, and it passes parameters to the call.</p>
<p><strong>Area layout and addressing</strong></p>
<p><code>*Each`Area`growsdown,towardslowermachineaddresses.</code><br />
<code>*</code><em><code>Offsets</code></em><code>arealways-positivebytedisplacementswithinan`Area`.</code><br />
<code>*Thelow-offsetendisalsocalledthe&quot;oldend&quot;ofthearea,thehigh-offsetendisalsocalledthe&quot;youngend&quot;.</code><br />
<code>*Noticethatthelow-offset(old)endhashighermachineaddresses.</code><br />
<code>*Offset0(ifweallowedit)wouldaddressthebyteone</code><em><code>beyond</code></em><code>thehigh-addressendofthe`Area`.</code><br />
<code>*Largeroffsets(fromthebeginningofthe`Area`)correspondtolowermachineaddresses.</code><br />
<code>*Hence,toaddressa4-byteobjectattheoldendof`Area`a,weusetheoffset+4,thus`(CmmStackSlota4)`.</code></p>
<p>The `Old` call area is the initial state of the stack on entry to the function (the overflow parameters and the return address) as well as any arguments that will be passed to a tail call. (SLPJ believes that:) On entry to the function, register `Sp` contains the address of the youngest (lowest-address, highest offset) byte in the `Old` area.</p>
<p>Note that `RegSlot` areas are very small (since they only need to store a single register), while `CallArea` are contiguous chunks of arguments.</p>
<p>To name a specific location on the stack, we represent its address with a new kind of `CmmExpr`: the `CmmStackSlot`. A `CmmStackSlot` is just an integer offset into an `Area`. <a href="BR" class="uri" title="wikilink">BR</a></p>
<p>Notice that a `CmmStackSlot` is an <em>address</em>, so we can say  to make `Sp` point to a particular stack slot. Use a `CmmLoad` to load from the stack slot.</p>
<p>The following figure shows the layout of a `CallArea` for both the outgoing parameters (function call) and incoming results (continuation after returning from the function call). Note that the incoming and outgoing parameters may be different, and they may overlap.</p>
<p><a href="Image(CallArea.png)" class="uri" title="wikilink">Image(CallArea.png)</a></p>
<p>A `RegSlot` is laid out in the same fashion, with the offset 0 pointing off the high byte of the stack slot. To address an 8-byte double-word, we would use the offset 8. To address only the high word of the same stack slot, we would use the offset 4.</p>
<p>Currently, the intermediate code does not explicitly use a virtual frame pointer, but when we talk about offsets into the stack, we implicitly assume that there is a virtual frame pointer that points just off the oldest byte of the return address on entry to the procedures. Therefore, on entry to the procedure, the offset of the (4-byte) return address is 4.</p>
<h3 id="laying-out-the-stack">Laying out the stack</h3>
<p>The business of the stack-layout pass is to construct a mapping (fixed across a single procedure)  which assigns a virtual stack slot (i.e. offset in bytes, relative to the virtual frame pointer) to each `Area`.</p>
<p>A naive approach to laying out the stack would be to give each variable its own stack slot for spilling, and allocate only the ends of the stack frame for parameter-passing areas. But this approach misses two opportunities for optimization:</p>
<p><code>*Stackslotscanbereusedbyvariablesthatareneveronthestackatthesametime</code><br />
<code>*Ifafunctionreturnsavariableonthestack,wemightbeabletousethereturnlocationasthevariable'sstackslot.</code></p>
<p>As it turns out, it is quite common in GHC that the first definition of a variable comes when its value is returned from a function call. If the value is returned on the stack, then an important optimization is to avoid copying that value to some other location on the stack. How is that achieved? By making sure the location where the value is returned is also its spill slot.</p>
<h3 id="a-greedy-algorithm">A greedy algorithm</h3>
<p>We rewrite the stack slots in two passes:</p>
<p><code>1.Walkoverthegraphandchooseanoffsetforeach`Area`.</code><br />
<code>1.Walkoverthegraph,keepingtrackofthestackpointer,andrewriteeachaddressofastackslotwithanoffsetfromthestackpointer.Also,insertadjustmentstothestackpointerbeforeandafterprocpoints.</code></p>
<p>The details are in cmm/CmmProcPointZ.hs (they have not yet been committed, but will be soon - Aug 4, 2008).</p>
<h1 id="layout-of-the-stack">Layout of the stack</h1>
<p>Every [wiki:Commentary/Rts/HeapObjects#ThreadStateObjects TSO object] contains a stack. The stack of a TSO grows downwards, with the topmost (most recently pushed) word pointed to by , and the bottom of the stack given by .</p>
<p>The stack consists of a sequence of <em>stack frames</em> (also sometimes called <em>activation records</em>) where each frame has the same layout as a heap object:</p>
<p>|| Header || Payload... ||</p>
<p>There are several kinds of [wiki:Commentary/Rts/Storage/Stack#KindsofStackFrame stack frames], but the most common types are those pushed when evaluating a  expression:  The code for evaluating a  pushes a new stack frame representing the alternatives of the case, and continues by evaluating . When  completes, it returns to the stack frame pushed earlier, which inspects the value and selects the appropriate branch of the case. The stack frame for a  includes the values of all the free variables in the case alternatives.</p>
<h2 id="info-tables-for-stack-frames">Info tables for stack frames</h2>
<p>The info table for a stack frame has a couple of extra fields in addition to the [wiki:Commentary/Rts/HeapObjects#InfoTables basic info table layout]. A stack-frame info table is defined by  in <a href="GhcFile(includes/rts/storage/InfoTables.h)" class="uri" title="wikilink">GhcFile(includes/rts/storage/InfoTables.h)</a>.</p>
<p><a href="Image(ret-itbl-no-rv.png)" class="uri" title="wikilink">Image(ret-itbl-no-rv.png)</a></p>
<p>The <em>SRT</em> field points to the static reference table (SRT) for this stack frame (see [wiki:Commentary/Rts/Storage/GC/CAFs] for details of SRTs).</p>
<h2 id="layout-of-the-payload">Layout of the payload</h2>
<p>Unlike heap objects which mainly have &quot;pointers first&quot; layout, in a stack frame the pointers and non-pointers are intermingled. This is so that we can support &quot;stack stubbing&quot; whereby a live variable stored on the stack can be later marked as dead simply by pushing a new stack frame that identifies that slot as containing a non-pointer, so the GC will not follow it.</p>
<p>Stack frames therefore have [wiki:Commentary/Rts/HeapObjects#Bitmaplayout bitmap layout].</p>
<h2 id="kinds-of-stack-frame">Kinds of Stack Frame</h2>
<p>The constants for the different types of stack frame are defined in <a href="GhcFile(includes/rts/storage/ClosureTypes.h)" class="uri" title="wikilink">GhcFile(includes/rts/storage/ClosureTypes.h)</a>. More details about the layouts are available in <a href="GhcFile(includes/rts/storage/Closures.h)" class="uri" title="wikilink">GhcFile(includes/rts/storage/Closures.h)</a></p>
<p><code>*</code><br />
<code>*</code><br />
<code>*</code><br />
<code>*</code><code>-(Explainedabithere:</code><a href="https://ghc.haskell.org/trac/ghc/wiki/Commentary/Compiler/CPS#Notes"><code>https://ghc.haskell.org/trac/ghc/wiki/Commentary/Compiler/CPS#Notes</code></a><code>)</code><br />
<code>*</code><br />
<code>*</code><br />
<code>*</code><code>-Thestackischunkednow.Connectedasalinkedlist.(SinceDec2010:f30d527344db528618f64a25250a3be557d9f287,</code><a href="https://ghc.haskell.org/trac/ghc/blog/stack-chunks"><code>Blogpost</code></a><code>)</code><br />
<code>*</code><br />
<code>*</code><br />
<code>*</code><br />
<code>*</code></p>
<p>Video: <a href="http://www.youtube.com/watch?v=v0J1iZ7F7W8&amp;list=PLBkRCigjPwyeCSD_DFxpd246YIF7_RDDI">STG language</a> (17'21&quot;)</p>
<h1 id="the-stg-syntax-data-types">The STG syntax data types</h1>
<p>Before code generation, GHC converts the Core-language program into . The basic ideas are still pretty much exactly as described in the paper <a href="http://research.microsoft.com/en-us/um/people/simonpj/papers/spineless-tagless-gmachine.ps.gz">Implementing lazy functional languages on stock hardware: the Spineless Tagless G-machine</a>.</p>
<p>The best way to think of STG is as special form of [wiki:Commentary/Compiler/CoreSynType Core]. Specifically, the differences are these (see <a href="GhcFile(compiler/stgSyn/StgSyn.hs)" class="uri" title="wikilink">GhcFile(compiler/stgSyn/StgSyn.hs)</a>):</p>
<p><code>*Functionargumentsareatoms(literalsorvariables),oftype</code><code>.</code><br />
<code>*Therighthandsideofalet-binding,</code><code>,iseither</code><br />
<code>*`StgRhsCon`:aconstructorapplication,or</code><br />
<code>*`StgRhsClosure`:</code><strong><code>lambda-form</code></strong><code>(possiblywithzeroarguments,inwhichcaseit'sathunk).</code><br />
<code>*Constructorapplicationsaresaturated.</code><br />
<code>*Applicationsofprimitiveoperatorsaresaturated.</code><br />
<code>*Lambdascanonlyappeartheright-handsideofalet-binding.(Thereisanexpressionform</code><code>,butitisonlyusedduringtheCore-to-STGtransformation,notinavalidSTGprogram.)</code><br />
<code>*Typeshavelargelybeendiscarded,retainingonlyenoughtypeinformationasisneededtoguidecodegeneration.Thereisan</code><code>checker,whichmakessomeconsistencychecks,butthe!CoreLintguaranteethat&quot;iftheprogrampassesLintitcannotcrash&quot;hasbeenlost.</code></p>
<p>In addition, the STG program is decorated with the results of some analyses:</p>
<p><code>*Everylambda-form(`StgRhsClosure`)listsitsfreevariables.Thesearethevariablesthatareinthethunkoffunctionclosurethatisallocatedbythelet.</code></p>
<p><code>*Everylambda-formgivesits[wiki:Commentary/Rts/CAFs</code><strong><code>Static</code> <code>Reference</code> <code>Table</code></strong><code>]or</code><strong><code>SRT</code></strong><code>.YoushouldthinkoftheSRTasthe</code><em><code>top-level</code></em><code>freevariablesofthebody.Theydonotneedtobedynamicallyallocatedintheheapobject,buttheydoneedtobeaccessiblefromtheobject'sinfo-table,sothatthegarbagecollectorcanfindtheCAFskeptalivebytheobject.</code></p>
<p><code>*A</code><code>expressionisdecoratedwithits</code><strong><code>live</code> <code>variables</code></strong><code>;thatis,variablesreachablefromthecontinuationofthecase.Moreprecisely,twosetsoflivevariables,plustheSRTforthecontinuation.Todo:saymore.</code></p>
<p><code>*TheSTGprogramhasanewconstructcalled</code><strong><code>let-no-escape</code></strong><code>,thatencodesso-called</code><strong><code>join</code> <code>points</code></strong><code>.Variablesboundbyalet-no-escapeareguaranteedtobetail-calls,notembeddedinsideadatastructure,inwhichcasewedon</code></p>
<h1 id="ghc-commentary-software-transactional-memory-stm">GHC Commentary: Software Transactional Memory (STM)</h1>
<p>This document gives an overview of the runtime system (RTS) support for GHC's STM implementation. We will focus on the case where fine grain locking is used ().</p>
<p>Some details about the implementation can be found in the papers <a href="http://research.microsoft.com/en-us/um/people/simonpj/papers/stm/stm.pdf">&quot;Composable Memory Transactions&quot;</a> and <a href="http://research.microsoft.com/en-us/um/people/simonpj/papers/stm/stm-invariants.pdf">&quot;Transactional memory with data invariants&quot;</a>. Additional details can be found in the Harris et al book <a href="http://www.morganclaypool.com/doi/abs/10.2200/s00272ed1v01y201006cac011">&quot;Transactional memory&quot;</a>. Some analysis on performance can be found in the paper <a href="https://www.bscmsrc.eu/sites/default/files/cf-final.pdf">&quot;The Limits of Software Transactional Memory&quot;</a> though this work only looks at the coarse grain lock version. Many of the other details here are gleaned from the comments in the source code.</p>
<h1 id="background">Background</h1>
<p>This document assumes the reader is familiar with some general details of GHC's execution and memory layout. A good starting point for this information is can be found here: [wiki:Commentary/Compiler/GeneratedCode Generated Code].</p>
<h2 id="definitions">Definitions</h2>
<h3 id="useful-rts-terms">Useful RTS terms</h3>
<p></p>
<p><code>CorrespondstoaCPU.ThenumberofcapabilitiesshouldmatchthenumberofCPUs.See[wiki:Commentary/Rts/Scheduler#CapabilitiesCapabilities].</code></p>
<p>TSO</p>
<p><code>ThreadStateObject.ThestateofaHaskellthread.See[wiki:Commentary/Rts/Storage/HeapObjects#ThreadStateObjectsThreadStateObjects].</code></p>
<p>Heap object</p>
<p><code>Objectsontheheapalltaketheformofan</code><code>structurewithaheaderpointingandapayloadofdata.Theheaderpointstocodeandaninfotable.See[wiki:Commentary/Rts/Storage/HeapObjectsHeapObjects].</code></p>
<h3 id="transactional-memory-terms">Transactional Memory terms</h3>
<p>Read set</p>
<p><code>Thesetof</code><code>sthatareread,butnotwrittentoduringatransaction.</code></p>
<p>Write set</p>
<p><code>Thesetof</code><code>sthatarewrittentoduringatransaction.Inthecodeeachwritten</code><code>iscalledan&quot;updateentry&quot;inthetransactionalrecord.</code></p>
<p>Access set</p>
<p><code>All</code><code>saccessedduringthetransaction.</code></p>
<p>While GHC's STM does not have a separate read set and write set these terms are useful for discussion.</p>
<p>Retry</p>
<p><code>HerewewillusethetermretryexclusivelyfortheblockingprimitiveinGHC'sSTM.Thisshouldnotbeconfusedwiththestepstakenwhenatransactiondetectsthatithasseenaninconsistentviewofmemoryandmuststartagainfromthebeginning.</code></p>
<p>Failure</p>
<p><code>Afailedtransactionisonethathasseeninconsistentstate.Thisshouldnotbeconfusedwithasuccessfultransactionthatexecutesthe</code><code>primitive.</code></p>
<hr />
<h1 id="overview-of-features">Overview of Features</h1>
<p>At the high level, transactions are computations that read and write to s with changes only being committed atomically after seeing a consistent view of memory. Transactions can also be composed together, building new transactions out of existing transactions. In the RTS each transaction keeps a record of its interaction with the s it touches in a . A pointer to this record is stored in the TSO that is running the transaction.</p>
<h2 id="reading-and-writing">Reading and Writing</h2>
<p>The semantics of a transaction require that when a  is read in a transaction, its value will stay the same for the duration of execution. Similarly a write to a  will keep the same value for the duration of the transaction. The transaction itself, however, from the perspective of other threads can apply all of its effects in one moment. That is, other threads cannot see intermediate states of the transaction, so it is as if all the effects happen in a single moment.</p>
<p>As a simple example we can consider a transaction that transfers value between two accounts:</p>
<p></p>
<p>No other thread can observe the value  in  without also observing  in .</p>
<h2 id="blocking">Blocking</h2>
<p>Transactions can choose to block until changes are made to s that allow it to try again. This is enabled with an explicit . Note that when changes are made the transaction is restarted from the beginning.</p>
<p>Continuing the example, we can choose to block when there are insufficient funds:</p>
<p></p>
<h2 id="choice">Choice</h2>
<p>Any blocking transaction can be composed with  to choose an alternative transaction to run instead of blocking. The  primitive operation creates a nested transaction and if this first transaction executes , the effects of the nested transaction are rolled back and the alternative transaction is executed. This choice is biased towards the first parameter. A validation failure in the first branch aborts the entire transaction, not just the nested part. An explicit  is the only mechanism that gives partial rollback.</p>
<p>We now can choose the account that has enough funds for the transfer:</p>
<p></p>
<h2 id="data-invariants">Data Invariants</h2>
<p>Invariants support checking global data invariants beyond the atomicity transactions demand. For instance, a transactional linked list (written correctly) will never have an inconsistent structure due to the atomicity of updates. It is no harder to maintain this property in a concurrent setting then in a sequential one with STM. It may be desired, however, to make statements about the consistency of the <em>data</em> in a particular a sorted linked list is sorted, not because of the structure (where the s point to) but instead because of the data in the structure (the relation between the data in adjacent nodes). Global data invariant checks can be introduced with the  operation which demands that the transaction it is given results in  and that it continues to hold for every transaction that is committed globally.</p>
<p>We can use data invariants to guard against negative balances:</p>
<p></p>
<h2 id="exceptions">Exceptions</h2>
<p>Exceptions inside transactions should only propagate outside if the transaction has seen a consistent view of memory. Note that the semantics of exceptions allow the exception itself to capture the view of memory from inside the transaction, but this transaction is not committed.</p>
<hr />
<h1 id="overview-of-the-implementation">Overview of the Implementation</h1>
<p>We will start this section by considering building GHC's STM with only the features of reading and writing. Then we will add  then  and finally data invariants. Each of the subsequent features adds more complexity to the implementation. Taken all at once it can be difficult to understand the subtlety of some of the design choices.</p>
<hr />
<h2 id="transactions-that-read-and-write.">Transactions that Read and Write.</h2>
<p>With this simplified view we only support , , and  as well as all the STM type class instances except .</p>
<h3 id="transactional-record">Transactional Record</h3>
<p>The overall scheme of GHC's STM is to perform all the effects of a transaction locally in the transactional record or . Once the transaction has finished its work locally, a value based consistency check determines if the values read for the entire access set are consistent. This only needs to consider the  and the main memory view of the access set as it is assumed that main memory is always consistent. This check also obtains locks for the write set and with those locks we can update main memory and unlock. Rolling back the effects of a transaction is just forgetting the current  and starting again.</p>
<p>The transactional record itself will have an entry for each transactional variable that is accessed. Each entry has a pointer to the  heap object and a record of the value that the  held when it was first accessed.</p>
<h3 id="starting">Starting</h3>
<p>A transaction starts by initializing a new  () assigning the TSO's  pointer to the new  then executing the transaction's code.</p>
<p>(See <a href="GhcFile(rts/PrimOps.cmm)" class="uri" title="wikilink">GhcFile(rts/PrimOps.cmm)</a>  and <a href="GhcFile(rts/STM.c)" class="uri" title="wikilink">GhcFile(rts/STM.c)</a> ).</p>
<h3 id="reading">Reading</h3>
<p>When a read is attempted we first search the  for an existing entry. If it is found, we use that local view of the variable. On the first read of the variable, a new entry is allocated and the value of the variable is read and stored locally. The original  does not need to be accessed again for its value until a validation check is needed.</p>
<p>In the coarse grain version, the read is done without synchronization. With the fine grain lock, the lock variable is the  of the  structure. While reading an inconsistent value is an issue that can be resolved later, reading a value that indicates a lock and handing that value to code that expects a different type of heap object will almost certainly lead to a runtime failure. To avoid this the fine grain lock version of the code will spin if the value read is a lock, waiting to observe the lock released with an appropriate pointer to a heap object.</p>
<p>(See <a href="GhcFile(rts/STM.c)" class="uri" title="wikilink">GhcFile(rts/STM.c)</a> )</p>
<h3 id="writing">Writing</h3>
<p>Writing to a  requires that the variable first be in the . If it is not currently in the , a read of the 's value is stored in a new entry (this value will be used to validate and ensure that no updates were made concurrently to this variable).</p>
<p>In both the fine grain and coarse grain lock versions of the code no synchronization is needed to perform the write as the value is stored locally in the  until commit time.</p>
<p>(See <a href="GhcFile(rts/STM.c)" class="uri" title="wikilink">GhcFile(rts/STM.c)</a> )</p>
<h3 id="validation">Validation</h3>
<p>Before a transaction can make its effects visible to other threads it must check that it has seen a consistent view of memory while it was executing. Most of the work is done in  by checking that s hold their expected values.</p>
<p>For the coarse grain lock version the lock is held before entering  through the writing of values to s. With the fine grain lock, validation acquires locks for the write set and reads a version number consistent with the expected value for each  in the read set. After all the locks for writes have been acquired, The read set is checked again to see if each value is still the expected value and the version number still matches ().</p>
<p>(See <a href="GhcFile(rts/STM.c)" class="uri" title="wikilink">GhcFile(rts/STM.c)</a>  and )</p>
<h3 id="committing">Committing</h3>
<p>Before committing, each invariant associated with each accessed  needs to be checked by running the invariant transaction with its own . The read set for each invariant is merged into the transaction as those reads must be included in the consistency check. The  is then validated. If validation fails, the transaction must start over from the beginning after releasing all locks. In the case of the coarse grain lock validation and commit are in a critical section protected by the global STM lock. Updates to s proceeds while holding the global lock.</p>
<p>With the fine grain lock version when validation, including any read-only phase, succeeds, two properties will hold simultaneously that give the desired atomicity:</p>
<ul>
<li>Validation has witnessed all s with their expected value.</li>
<li>Locks are held for all of the s in the write set.</li>
</ul>
<p>Commit can proceed to increment each locked 's  field and unlock by writing the new value to the  field. While these updates happen one-by-one, any attempt to read from this set will spin while the lock is held. Any reads made before the lock was acquired will fail to validate as the number of updates will change.</p>
<p>(See <a href="GhcFile(rts/PrimOps.cmm)" class="uri" title="wikilink">GhcFile(rts/PrimOps.cmm)</a>  and <a href="GhcFile(rts/STM.c)" class="uri" title="wikilink">GhcFile(rts/STM.c)</a> )</p>
<h3 id="aborting">Aborting</h3>
<p>Aborting is simply throwing away changes that are stored in the .</p>
<p>(See <a href="GhcFile(rts/STM.c)" class="uri" title="wikilink">GhcFile(rts/STM.c)</a> )</p>
<h3 id="exceptions-1">Exceptions</h3>
<p>An exception in a transaction will only propagate outside of the transaction if the transaction can be validated. If validation fails, the whole transaction will abort and start again from the beginning. Nothing special needs to be done to support the semantics allowing the view <em>inside</em> the aborted transaction.</p>
<p>(See <a href="GhcFile(rts/Exception.cmm)" class="uri" title="wikilink">GhcFile(rts/Exception.cmm)</a> which calls  from <a href="GhcFile(rts/STM.c)" class="uri" title="wikilink">GhcFile(rts/STM.c)</a>).</p>
<hr />
<h2 id="blocking-with">Blocking with </h2>
<p>We will now introduce the blocking feature. To support this we will add a watch queue to each  where we can place a pointer to a blocked TSO. When a transaction commits we will now wake up the TSOs on watch queues for s that are written.</p>
<p>The mechanism for  is similar to exception handling. In the simple case of only supporting blocking and not supporting choice, an encountered retry should validate, and if valid, add the TSO to the watch queue of every accessed  (see <a href="GhcFile(rts/STM.c)" class="uri" title="wikilink">GhcFile(rts/STM.c)</a>  and ). Locks are acquired for all s when validating to control access to the watch queues and prevent missing an update to a  before the thread is sleeping. In particular if validation is successful the locks are held after the return of , through the return to the scheduler, after the thread is safely paused (see <a href="GhcFile(rts/HeapStackCheck.cmm)" class="uri" title="wikilink">GhcFile(rts/HeapStackCheck.cmm)</a> ), and until  is called. This ensures that no updates to the s are made until the TSO is ready to be woken. If validation fails, the  is discarded and the transaction is started from the beginning. (See <a href="GhcFile(rts/PrimOps.cmm)" class="uri" title="wikilink">GhcFile(rts/PrimOps.cmm)</a> )</p>
<p>When a transaction is committed, each write that it makes to a  is preceded by waking up each TSO in the watch queue. Eventually these TSOs will be run, but before restarting the transaction its  is validated again if valid then nothing has changed that will allow the transaction to proceed with a different result. If invalid, some other transaction has committed and progress may be possible (note there is the additional case that some other transaction is merely holding a lock temporarily, causing validation to fail). The TSO is not removed from the watch queues it is on until the transaction is aborted (at this point we no longer need the ) and the abort happens after the failure to validate on wakeup. (See <a href="GhcFile(rts/STM.c)" class="uri" title="wikilink">GhcFile(rts/STM.c)</a>  and )</p>
<hr />
<h2 id="choice-with">Choice with </h2>
<p>When  executes it searches the stack for either a  or the outer  (the boundary between normal execution and the transaction). The former is placed on the stack by an  (see <a href="GhcFile(rts/PrimOps.cmm)" class="uri" title="wikilink">GhcFile(rts/PrimOps.cmm)</a> ) and if executing the first branch we can partially abort and switch to the second branch, otherwise we propagate the  further. In the latter case this  represents a transaction that should block and the behavior is as above with only .</p>
<p>How do we support a &quot;partial abort&quot;? This introduces the need for a nested transaction. Our  will now have a pointer to an outer  (the  field). This allows us to isolate effects from the branch of the  that we might need to abort. Let's revisit the features that need to take this into account.</p>
<p><code>*</code><strong><code>Reading</code></strong><code>--Readsnowsearchthechainofnestedtransactionsinadditiontothelocal</code><code>.Whenanentryisfoundinaparentitiscopiedintothelocal</code><code>.Notethatthereisstillonlyasingleaccesstotheactual</code><code>throughthelifeofthetransaction(untilvalidation).</code><br />
<code>*</code><strong><code>Writing</code></strong><code>--Writes,likereads,nowsearchtheparent</code><code>sandthewriteisstoredinthelocalcopy.</code><br />
<code>*</code><strong><code>Retry</code></strong><code>--Asdescribedabove,wenowneedtosearchthestackfora</code><code>andiffound,abortingthenestedtransactionandattemptingthealternativeorpropagatingtheretryinsteadofimmediatelyworkingonblocking.</code><br />
<code>*</code><strong><code>Validation</code></strong><code>--Ifwearevalidatinginthemiddleofarunningtransactionwewillneedtovalidatethewholenestoftransactions.</code><a href="BR" title="wikilink"><code>BR</code></a><code>(See</code><a href="GhcFile(rts/STM.c)" title="wikilink"><code>GhcFile(rts/STM.c)</code></a><code></code><code>anditsusesin</code><a href="GhcFile(rts/Exception.cmm)" title="wikilink"><code>GhcFile(rts/Exception.cmm)</code></a><code>and</code><a href="GhcFile(rts/Schedule.c)" title="wikilink"><code>GhcFile(rts/Schedule.c)</code></a><code>)</code><br />
<code>*</code><strong><code>Committing</code></strong><code>--Justaswenowhaveapartialabort,weneedapartialcommitwhenwefinishabranchofan</code><code>.Thiscommitisdonewith</code><code>whichvalidatesjusttheinner</code><code>andmergesupdatesbackintoitsparent.Notethatanupdateisdistinguishedfromareadonlyentrybyvalue.Thismeansthatifanestedtransactionperformsawritethatrevertsavaluethisisachangeandmuststillpropagatetotheparent(seeticket#7493).</code><br />
<code>*</code><strong><code>Aborting</code></strong><code>--Thereisanothersubtleissuewithhowchoiceandblockinginteract.Whenweblockweneedtowakeupifthereisachangeto</code><em><code>any</code></em><code>accessed</code><code>.Consideratransaction:</code><a href="BR" title="wikilink"><code>BR</code></a><a href="BR" title="wikilink"><code>BRIf</code></a><code>both</code><code>and</code><code>execute</code><code>theneventhoughtheeffectsof</code><code>arethrownaway,itcouldbethatachangetoa</code><code>thatisonlyintheaccesssetof</code><code>willallowthewholetransactiontosucceedwhenitiswoken.</code><a href="BR" title="wikilink"><code>BRTo</code></a><code>solvethisproblem,whenabranchonanestedtransactionisabortedtheaccesssetofthenestedtransactionismergedasareadsetintotheparent</code><code>.Specificallyifthe</code><code>isin</code><em><code>any</code></em><code></code><code>upthechainofnestedtransactionsitmustbeignored,otherwiseitisenteredasanewentry(retainingjusttheread)intheparent</code><code>.</code><a href="BR" title="wikilink"><code>BR</code></a><code>(Seeagainticket#7493and</code><a href="GhcFile(rts/STM.c)" title="wikilink"><code>GhcFile(rts/STM.c)</code></a><code></code><code>)</code><br />
<code>*</code><strong><code>Exceptions</code></strong><code>--Theonlychangeneededhereeach</code><code>onthestackrepresentsanestedtransaction.Asthestackissearchedforahandler,ateachencountered</code><code>thenestedtransactionisaborted.Whenthe</code><code>isencounteredwethenknowthatthereisnonestedtransaction.</code><a href="BR" title="wikilink"><code>BR</code></a><code>(See</code><a href="GhcFile(rts/Exception.cmm)" title="wikilink"><code>GhcFile(rts/Exception.cmm)</code></a><code></code><code>)</code></p>
<p>(See <a href="GhcFile(rts/PrimOps.cmm)" class="uri" title="wikilink">GhcFile(rts/PrimOps.cmm)</a>  and )</p>
<hr />
<h2 id="invariants-1">Invariants</h2>
<p>We will start this section with an overview of some of the details then review with notes on the changes from the choice case.</p>
<h3 id="details">Details</h3>
<p>As a transaction is executing it can collect dynamically checked data invariants. These invariants are transactions that are never committed, but if they raise an exception when executed successfully that exception will propagate out of the atomic frame.</p>
<p></p>
<p><code>Primitiveoperationthataddsaninvariant(transactiontorun)tothequeueofthecurrent</code><code>bycalling</code><code>.</code></p>
<p></p>
<p><code>Awrapperfor</code><code>(togiveitthe</code><code>type).</code></p>
<p></p>
<p><code>Thisisthe</code><code>fromthe&quot;Transactionalmemorywithdatainvariants&quot;paper.Theactionimmediatelyruns,wrappedinanestedtransactionsothatitwillnevercommitbutwillhaveanopportunitytoraiseanexception.Ifsuccessful,theoriginallypassedactionisaddedtotheinvariantqueue.</code></p>
<p></p>
<p><code>Takesan</code><code>actionthatresultsina</code><code>andaddsaninvariantthatthrowsanexceptionwhentheresultofthetransactionis</code><code>.</code></p>
<p>The bookkeeping for invariants is in each s  queue and the s  field. Each invariant is in a  structure that includes the  action, the  where it was last executed, and a lock. This is added to the current s queue when  is executed.</p>
<p>When a transaction completes, execution will reach the  and the s  will be  (a nested transaction would have a  before the  to handle cases of non-empty ). The frame will then check the invariants by collecting the invariants it needs to check with , dequeuing each, executing, and when (or if) we get back to the frame, aborting the invariant action. If the invariant failed to hold, we would not get here due to an exception and if it succeeds we do not want its effects. Once all the invariants have been checked, the frame will to commit.</p>
<p>Which invariants need to be checked for a given transaction? Clearly invariants introduced in the transaction will be checked these are added to the s  queue directly when  is executed. In addition, once the transaction has finished executing, we can look at each entry in the write set and search its watch queue for any invariants.</p>
<p>Note that there is a  in the  package in  which matches the  from the <a href="http://research.microsoft.com/pubs/74063/beautiful.pdf">beauty</a> chapter of &quot;Beautiful code&quot;:</p>
<p></p>
<p>It requires no additional runtime support. If it is a transaction that produces the  argument it will be committed (when ) and it is only a one time check, not an invariant that will be checked at commits.</p>
<h3 id="changes-from-choice">Changes from Choice</h3>
<p>With the addition of data invariants we have the following changes to the implementation:</p>
<p><code>*</code><strong><code>Retrying</code></strong><code>--Aretryinaninvariantindicatesthattheinvariantcouldnotproceedandthewholetransactionshouldblock.Thisspecialcaseisdetectedwhenan</code><code>isencounteredwithanestoftransactions(i.e.whenthe</code><code>fieldisnot</code><code>).Theinvariantissimplyabortedandexecutionproceedsto</code><code>(see</code><a href="GhcFile(rts/PrimOps.cmm)" title="wikilink"><code>GhcFile(rts/PrimOps.cmm)</code></a><code></code><code>).</code><br />
<code>*</code><strong><code>Commiting</code></strong><code>--Commitnowneedsaphasewhereitrunsinvariantsafterthecodeofthetransactionhascompletedbutbeforecommit.Theimplementationrecyclesthestructurealreadyinplaceforthisphasesospecialcasesareneededinthe</code><code>thatcollectsinvariantsandworksthroughthemoneatatimethenmovesontocommitting(see</code><a href="GhcFile(rts/PrimOps.cmm)" title="wikilink"><code>GhcFile(rts/PrimOps.cmm)</code></a><code></code><code>).</code><a href="BR" title="wikilink"><code>BRTo</code></a><code>efficientlyhandleinvariantstheyneedtoonlybecheckedwhenarelevantdatadependencychanges.Thismeanswecanassociatethemwiththe</code><code>ofthelastcommitthatneededtochecktheinvariantatthecostofserializinginvarianthandlingcommits.Thisisenforcedbythelockoneachinvariant.Ifitcannotbeacquiredthewholetransactionmuststartover.</code><a href="BR" title="wikilink"><code>BRAt</code></a><code>committime,eachinvariantislockedandthereadsetforthelastcommitedtransactionofeachinvariantismergedintothe</code><code>.</code><a href="BR" title="wikilink"><code>BRValidation</code></a><code>acuqireslockforallentriesinthe</code><code>(notjustthewrites).Aftervalidation,eachinvariantisremovedfromthewatchqueueofeach</code><code>itpreviouslydependedon,thenthe</code><code>thatwasusedwhenexecutingtheinvariantcodeisupdatedtoreflectthevaluesfromthefinalexecutionofthemaintransactionandeach</code><code>,beingadatadepenencyoftheinvariant,hastheinvariantaddedtoitswatchqueue.</code><a href="BR" title="wikilink"><code>BR</code></a><code>(See</code><a href="GhcFile(rts/STM.c)" title="wikilink"><code>GhcFile(rts/STM.c)</code></a><code></code><code>,</code><code>and</code><code>)</code><br />
<code>*</code><strong><code>Exceptions</code></strong><code>--Whenanexceptionpropagatestothe</code><code>therearenowtwostatesthatitcouldencounter.Ifthereisnoenclosing</code><code>wearenotdealingwithanexceptionfromaninvariantanditproceedsasabove.Seeinganestoftransactionsindicatesthatthetransactionwascheckinganinvariantwhenitencounteredtheexception.Theeffectofafailedinvariant</code><em><code>is</code></em><code>thisexceptionsonothingspecialneedstobedoneexcepttovalidateandabortboththeoutertransactionandthenestedtransaction(see</code><a href="GhcFile(rts/Exception.cmm)" title="wikilink"><code>GhcFile(rts/Exception.cmm)</code></a><code></code><code>).</code></p>
<hr />
<h2 id="other-details">Other Details</h2>
<p>This section describes some details that can be discussed largely in isolation from the rest of the system.</p>
<h3 id="detecting-long-running-transactions">Detecting Long Running Transactions</h3>
<p>While the type system enforces STM actions to be constrained to STM side effects, pure computations in Haskell can be non-terminating. It could be that a transaction sees inconsistent data that leads to non-termination that would never happen in a program that only saw consistent data. To detect this problem, every time a thread yields it is validated. A validation failure causes the transaction to be condemned.</p>
<h3 id="transaction-state">Transaction State</h3>
<p>Each  has a  field that holds the status of the transaction. It can be one of the following:</p>
<p></p>
<p><code>Thetransactionisactivelyrunning.</code></p>
<p></p>
<p><code>Thetransactionhasseenaninconsistency.</code></p>
<p></p>
<p><code>Thetransactionhascommittedandisintheprocessofupdating</code><code>values.</code></p>
<p></p>
<p><code>Thetransactionhasabortedandisworkingtoreleaselocks.</code></p>
<p></p>
<p><code>Thetransactionhashita</code><code>andiswaitingtobewoken.</code></p>
<p>If a  state is  (some inconsistency was seen) validate does nothing. When a top-level transaction is aborted in , if the state is  it will remove the watch queue entries for the . Similarly if a waiting  is condemned via an asynchronous exception when a validation failure is observed after a thread yield, its watch queue entries are removed. Finally a  in the  state is not condemned by a validation. In this case the  is already waiting for a wake up from a  that changes and observing an inconsistency merely indicates that this will happen soon.</p>
<p>In the work of Keir Fraser a transaction state is used for cooperative efforts of transactions to give lock-free properties for STM systems. The design of GHC's STM is clearly influenced by this work and seems close to some of the algorithms in Fraser's work. It does not, however, implement what would be required to be lock-free or live-lock free (in the fine grain lock code). For instance, if two transactions  and  are committing at the same time and  has read  and written  while  has read  and written , both the transactions can fail to commit. For example, consider the interleaving:</p>
<p>||<strong>`T1`</strong> || <strong>`TVar`</strong> || <strong>`T2`</strong> ||<strong>Action</strong> || ||`A 0 0` || `A 0` || ||`T1` read A || || || `B 0` || `B 0 0` ||`T2` read B || ||`B 0 1` || || ||`T1` write B 1 || || || || `A 0 1` ||`T2` write A 1 || ||`A 0 0 0` || `A 0` || ||`T1` Validation Part 1 (read A) || || || `A T2` || ||`T2` Validation (Lock A) || || || `B 0` || `B 0 0 0` ||`T2` Validation (Read B) || || || `B T1` || ||`T1` Validation Part 2 (Lock B) ||</p>
<p>Note: the first and third columns are the local state of the s and the second column is the values of the  structures. Each  entry has the expected value followed by the new value and a number of updates field when it is read for validation.</p>
<p>At this point  and  both perform their  and both could (at least one will) discover that a  in their read set is now locked. This leads to both transactions aborting. The chances of this are narrow but not impossible (see ticket #7815). Fraser's work avoids this by using the transaction status and the fact that locks point back to the  holding the lock to detect other transactions in a read only check (read phase) and resolving conflicts so that at least one of the transactions can commit.</p>
<p>A simpler example can also cause both transactions to abort. Consider two transactions with the same write set, but the writes entered the s in a different order. Both transactions could encounter a lock from the other before they have a chance to release locks and get out of the way. Having an ordering on lock could avoid this problem but would add a little more complexity.</p>
<h3 id="gc-and-aba">GC and ABA</h3>
<p>GHC's STM does comparisons for validation by value. Since these are always pure computations these values are represented by heap objects and a simple pointer comparison is sufficient to know if the same value is in place. This presents an ABA problem however if the location of some value is recycled it could appear as though the value has not changed when, in fact, it is a different value. This is avoided by making the  fields of the  entries pointers into the heap followed by the garbage collector. As long as a  is still alive it will keep the original value it read for a  alive.</p>
<h3 id="management-of-s">Management of s</h3>
<p>The  structure is built as a list of chunks to give better locality and amortize the cost of searching and allocating entries. Additionally s are recycled to aid locality further when a transaction is aborted and started again. Both of these details add a little complexity to the implementation that is abated with some macros such as  and .</p>
<h3 id="tokens-and-version-numbers.">Tokens and Version Numbers.</h3>
<p>When validating a transaction each entry in the  is checked for consistency. Any entry that is an update (in the write set) is locked. This locking is a visible effect to the rest of the system and prevents other committing transactions from progress. Reads, however, are not going to be updated. Instead we check that a read to the value matches our expected value, then we read a version number (the  field) and check again that the expected value holds. This gives us a read of  that is consistent with the  holding the expected value. Once all the locks for the write set are acquired we know that only our transaction can have an effect on the write set. All that remains is to rule out some change to the read set while we were still acquiring locks for the writes. This is done in the read phase (with ) which checks first if the value matches the expectation then checks if the version numbers match. If this holds for each entry in the read set then there must have existed a moment, while we held the locks for all the write set, where the read set held all its values. Even if some other transaction committed a new value and yet another transaction committed the expected value back the version number will have been incremented.</p>
<p>All that remains is managing these version numbers. When a  is updated its version number is incremented before the value is updated with the lock release. There is the unlikely case that the finite version numbers wrap around to an expected value while the transaction is committing (even with a 32-bit version number this is <em>highly</em> unlikely to happen). This is, however, accounted for by allocating a batch of tokens to each capability from a global  variable. Each time a transaction is started it decrements it's batch of tokens. By sampling  at the beginning of commit and after the read phase the possibility of an overflow can be detected (when more then 32-bits worth of commits have been allocated out).</p>
<p>(See <a href="GhcFile(rts/STM.c)" class="uri" title="wikilink">GhcFile(rts/STM.c)</a> , , , , and )</p>
<h3 id="implementation-invariants">Implementation Invariants</h3>
<p>Some of the invariants of the implementation:</p>
<p><code>*Locksareonlyacquiredin</code><a href="GhcFile(rts/STM.c)" title="wikilink"><code>GhcFile(rts/STM.c)</code></a><code>andarealwaysreleasedbeforetheendofafunctioncall(withtheexceptionof</code><code>whichmustreleaselocksafterthethreadissafe).</code><br />
<code>*Whenrunningatransactioneach</code><code>isreadexactlyonceandifitisawrite,isupdatedexactlyonce.</code><br />
<code>*Mainmemory(</code><code>s)alwaysholdsconsistentvaluesorlocksofapartiallyupdatedcommit.Thatisasetofreadsatanymomentfrom</code><code>swillresultinconsistentdataifnoneofthevaluesarelocks.</code><br />
<code>*Anestof</code><code>shasamatchingnestof</code><code>sendingwithan</code><code>onthestack.Oneexceptiontothisiswhencheckingdatainvariantstheinvariant's</code><code>isnestedunderthetoplevel</code><code>withouta</code><code>.</code></p>
<h3 id="fine-grain-locking">Fine Grain Locking</h3>
<p>The locks in fine grain locking () are at the  level and are implemented by placing the locking thread's  in the s current value using a compare and swap (). The value observed when locking is returned by . To test if a  is locked the value is inspected to see if it is a  (checking that the closure's info table pointer is to ). If a  is found  will spin reading the s current value until it is not a  and then attempt again to obtain the lock. Unlocking is simply a write of the current value of the . There is also a conditional lock  which will obtain the lock if the s current value is the given expected value. If the  is already locked this will not be the case (the value would be a ) and if the  has been updated to a new (different) value then locking will fail because the value does not match the expected value. A compare and swap is used for .</p>
<p>This arrangement is useful for allowing a transaction that encounters a locked  to know which particular transaction is locked (used in algorithms in from Fraser). GHC's STM does not, however, use this information.</p>
<h2 id="bibliography">Bibliography</h2>
<p>Fraser, Keir. <em>Practical lock-freedom</em>. Diss. PhD thesis, University of Cambridge Computer Laboratory, 2004.</p>
<p>Jones, Simon Peyton. &quot;Beautiful concurrency.&quot; <em>Beautiful Code: Leading Programmers Explain How They Think</em> (2007): 385-406.</p>
<p>Harris, Tim, et al. &quot;Composable memory transactions.&quot; <em>Proceedings of the tenth ACM SIGPLAN symposium on Principles and practice of parallel programming.</em> ACM, 2005.</p>
<p>Harris, Tim, James Larus, and Ravi Rajwar. &quot;Transactional memory.&quot; <em>Synthesis Lectures on Computer Architecture</em> 5.1 (2010): 1-263.</p>
<p>Harris, Tim, and Simon Peyton Jones. &quot;Transactional memory with data invariants.&quot; <em>First ACM SIGPLAN Workshop on Languages, Compilers, and Hardware Support for Transactional Computing (TRANSACT'06), Ottowa.</em> 2006.</p>
<h1 id="ghc-commentary-storage">GHC Commentary: Storage</h1>
<p>GHC's storage manager is designed to be quite flexible: there are a large number of tunable parameters in the garbage collector, and partly the reason for this was because we wanted to experiment with tweaking these settings in the context of Haskell.</p>
<p><a href="Image(sm-top.png)" class="uri" title="wikilink">Image(sm-top.png)</a></p>
<p><code>*[wiki:Commentary/Rts/Storage/HeapObjectsLayoutofHeapObjects]</code><br />
<code>*[wiki:Commentary/Rts/Storage/StackLayoutoftheStack]</code><br />
<code>*[wiki:Commentary/Rts/Storage/SlopSlop]</code><br />
<code>*[wiki:Commentary/Rts/Storage/BlockAllocTheBlockAllocator]</code><br />
<code>*[wiki:Commentary/Rts/Storage/GCTheGarbageCollector]</code><br />
<code>*[wiki:Commentary/Rts/Storage/HeapAllocedTheHEAP_ALLOCED()macro]</code></p>
<p>See also:</p>
<p><code>*[wiki:Commentary/Rts/HaskellExecution/PointerTaggingPointertagging]</code></p>
<h1 id="general-overview">General overview</h1>
<p>GHC's approach to strictness analysis is that of &quot;demand analysis&quot;, a backwards analysis in which strictness analysis and absence analysis are done in a single pass. In the future, analysis to perform unboxing, as well as other analyses, may be implemented within this framework as well.</p>
<h1 id="important-note">IMPORTANT NOTE</h1>
<p>The rest of this commentary describes code that is not checked in to the HEAD yet.</p>
<p>Update: as of 2014-02-12, newer documentation (apparently on the same topic and apparently more up-to-date) is available at <a href="Commentary/Compiler/Demand" class="uri" title="wikilink">Commentary/Compiler/Demand</a> (I am not an expert on the GHC internals though). Also, <a href="GhcFile(compiler/basicTypes/NewDemand.lhs)" class="uri" title="wikilink">GhcFile(compiler/basicTypes/NewDemand.lhs)</a> is not any more in the sources, replaced by (or renamed to?) <a href="GhcFile(compiler/basicTypes/Demand.lhs)" class="uri" title="wikilink">GhcFile(compiler/basicTypes/Demand.lhs)</a>.</p>
<h1 id="the-demand-analyzer">The demand analyzer</h1>
<p>Most of the demand analyzer lives in two files:</p>
<p><code>*</code><a href="GhcFile(compiler/basicTypes/NewDemand.lhs)" title="wikilink"><code>GhcFile(compiler/basicTypes/NewDemand.lhs)</code></a><code>(definesthedatatypesusedbythedemandanalyzer,andsomefunctionsonthem)</code><br />
<code>*</code><a href="GhcFile(compiler/stranal/DmdAnal.lhs)" title="wikilink"><code>GhcFile(compiler/stranal/DmdAnal.lhs)</code></a><code>(thedemandanalyzeritself)</code></p>
<p>The demand analyzer does strictness analysis, absence analysis, and box-demand analysis in a single pass. (!ToDo: explain what these are.)</p>
<p>In <a href="GhcFile(compiler/stranal/DmdAnal.lhs)" class="uri" title="wikilink">GhcFile(compiler/stranal/DmdAnal.lhs)</a>,  is the function that performs demand analysis on an expression. It has the following type:  The first argument is an environment mapping variables onto demand signatures. (!ToDo: explain more.) The second argument is the demand that's being placed on the expression being analyzed, which was determined from the context already. The third argument is the expression being analyzed.  returns a pair of a new expression (possibly with demand information added to any [wiki:Commentary/Compiler/NameType Ids] in it), and a .</p>
<h2 id="important-datatypes">Important datatypes</h2>
<p> A demand consists of usage information, along with information about usage of the subcomponents of the expression it's associated with.</p>
<p> Usage information consists of a triple of three properties: strictness (or evaluation demand), usage demand, and box demand.</p>
<p> Something that is  may or may not be evaluated. Something that is  will definitely be evaluated at least to its outermost constructor. Something that is  will be fully evaluated (e.g., in ,  can be said to have strictness , because it doesn't matter how much we evaluate  -- this expression will diverge anyway.)</p>
<p> In the context of function arguments, an argument that is  is never used by its caller (e.g., syntactically, it doesn't appear in the body of the function at all). An argument that is  will be used zero or one times, but not more. Something that is  may be used zero, one, or many times -- we don't know.</p>
<p> Again in the context of function arguments, an argument that is  is a value constructed by a data constructor of a product type whose &quot;box&quot; is going to be needed. For example, we say that } &quot;uses the box&quot;, so in ,  has box-demand information . In },  doesn't &quot;use the box&quot; for its argument, so in ,  has box-demand information . When in doubt, we assume .</p>
<p> For a compound data value, the  type describes demands on its components.  means that we don't know anything about the expression's type.  says &quot;this expression has a product type, and the demands on its components consist of the demands in the following list&quot;. If the  is supplied, that means that this expression must be cast using the given coercion before it is evaluated. (!ToDo: explain this more.)</p>
<p>(!ToDo: explain why all the above information is important)</p>
<p>Though any expression can have a  associated with it, another datatype, , is associated with a function body.</p>
<p> A  consists of a  (which provides demands for all explicitly mentioned free variables in a functions body), a list of s on the function's arguments, and a , which indicates whether this function returns an explicitly constructed product:</p>
<p></p>
<p>The  function takes a strictness environment, an [wiki:Commentary/Compiler/NameType Id] corresponding to a function, and a  representing demand on the function -- in a particular context -- and returns a , representing the function's demand type in this context.  Demand analysis is implemented as a backwards analysis, so  takes the demand on a function's result (which was inferred based on how the function's result is used) and uses that to compute the demand type of this particular occurrence of the function itself.</p>
<p> has four cases, depending on whether the function being analyzed is a [wiki:Commentary/Compiler/EntityTypes data constructor] worker, an imported (global) function, a local -bound function, or &quot;anything else&quot; (e.g., a local lambda-bound function).</p>
<p>The data constructor case checks whether this particular constructor call is saturated. If not, it returns , indicating that we know nothing about the demand type. If so, it returns a  with an empty environment (since there are no free variables), a list of arg-demands based on the  that was passed in to  (that is, the demand on the result of the data constructor call), and a  taken from the constructor Id's strictness signature.</p>
<p>There are a couple of tricky things about the list of arg-demands:</p>
<p><code>*Iftheresultdemand(i.e.,thepassed-indemand)hasitsboxdemanded,thenwewanttomakesuretheboxisdemandedineachofthedemandsfortheargs.(!ToDo:thismaynotbetrue)</code><br />
<code>*Iftheresultdemandisnotstrict,wewanttouse</code><em><code>n</code></em><code>copiesof</code><code>asthelistofarg-demands,where</code><em><code>n</code></em><code>isthisdataconstructor'sarity.</code></p>
<p>(!ToDo: explain the other cases of )</p>
<p>[wiki:Commentary/Compiler/StrictnessAnalysis/KirstenNotes even more sketchy notes]</p>
<p>[wiki:Commentary/Compiler/StrictnessAnalysis/Examples]</p>
<h1 id="symbol-names">Symbol Names</h1>
<p>Since Haskell allows many symbols in constructor and variable names that C compilers or assembly might not allow (e.g. :, %, #) these have to be encoded using z-encoding. The encoding is as follows. See <a href="GhcFile(compiler/utils/Encoding.hs)" class="uri" title="wikilink">GhcFile(compiler/utils/Encoding.hs)</a>.</p>
<h2 id="tuples">Tuples</h2>
<p>|| Decoded || Encoded || Comment || || `()` || Z0T || Unit / 0-tuple || || || || There is no Z1T || || `(,)` || Z2T || 2-tuple || || `(,,)` || Z3T || 3-tuple || || ... || || And so on ||</p>
<h2 id="unboxed-tuples">Unboxed Tuples</h2>
<p>|| Decoded || Encoded || Comment || || || || There is no Z0H || || `(# #)` || Z1H || unboxed 1-tuple (note the space) || || `(#,#)` || Z2H || unboxed 2-tuple || || `(#,,#)` || Z3H || unboxed 3-tuple || || ... || || And so on ||</p>
<h2 id="alphanumeric-characters">Alphanumeric Characters</h2>
<p>|| Decoded || Encoded || Comment || || a-y, A-Y, 0-9 || a-y, A-Y, 0-9 || Regular letters don't need escape sequences || || z, Z || zz, ZZ || 'Z' and 'z' must be escaped ||</p>
<h2 id="constructor-characters">Constructor Characters</h2>
<p>|| Decoded || Encoded || Comment || || `(` || ZL || Left || || `)` || ZR || Right || || `[` || ZM || 'M' before 'N' in [] || || `]` || ZN || || || `:` || ZC || Colon ||</p>
<h2 id="variable-characters">Variable Characters</h2>
<p>|| Decoded || Encoded || Mnemonic || || `&amp;` || za || Ampersand || || `|` || zb || Bar || || `^` || zc || Caret || || `$` || zd || Dollar || || `=` || ze || Equals || || `&gt;` || zg || Greater than || || `#` || zh || Hash || || `.` || zi || The dot of the 'i' || || `&lt;` || zl || Less than || || `-` || zm || Minus || || `!` || zn || Not || || `+` || zp || Plus || || `'` || zq || Quote || || `\` || zr || Reverse slash || || `/` || zs || Slash || || `*` || zt || Times sign || || `_` || zu || Underscore || || `%` || zv || (TODO: I don't know what the mnemonic for this one is. Perhaps relatiVe or diVide?) ||</p>
<h2 id="other-1">Other</h2>
<p>Any other character is encoded as a 'z' followed by its hex code (lower case, variable length) followed by 'U'. If the hex code starts with 'a', 'b, 'c', 'd', 'e' or 'f', then an extra '0' is placed before the hex code to avoid conflicts with the other escape characters.</p>
<h2 id="examples">Examples</h2>
<p>|| Before || After || || `Trak` || `Trak` || || `foo_wib` || `foozuwib` || || `&gt;` || `zg` || || `&gt;1` || `zg1` || || `foo#` || `foozh` || || `foo##` || `foozhzh` || || `foo##1` || `foozhzh1` || || `fooZ` || `fooZZ` || || `:+` || `ZCzp` || || `()` || `Z0T` || || `(,,,,)` || `Z5T` || || `(# #)` || `Z1H` || || `(#,,,,#)` || `Z5H` ||</p>
<p>[ Up: [wiki:Commentary/Compiler/TypeChecker] ]</p>
<h1 id="the-monad-for-renaming-typechecking-desugaring">The monad for renaming, typechecking, desugaring</h1>
<p>The renamer, typechecker, interface-file typechecker, and desugarer all share a certain amount in common: they must report errors, handle environments, do I/O, etc. Furthermore, because of Template Haskell we have to interleave renaming and typechecking. So all four share a common monad, called . This infrastructure is defined by the following modules:</p>
<p><code>*</code><a href="GhcFile(compiler/utils/IOEnv.lhs)" title="wikilink"><code>GhcFile(compiler/utils/IOEnv.lhs)</code></a><code>:extendstheIOmonadwithanenvironment(justasimplereadermonad).</code><br />
<code>*</code><a href="GhcFile(compiler/typecheck/TcRnTypes)" title="wikilink"><code>GhcFile(compiler/typecheck/TcRnTypes)</code></a><code>:buildsthe</code><code>monadontopof</code><code>:</code><br />
<code>*</code><a href="GhcFile(compiler/typecheck/TcRnMonad)" title="wikilink"><code>GhcFile(compiler/typecheck/TcRnMonad)</code></a><code>:defineslotsofaccessfunctionsfortherenamer,typechecker,andinterfacetypechecker.</code><br />
<code>*</code><a href="GhcFile(compiler/typecheck/DsMonad)" title="wikilink"><code>GhcFile(compiler/typecheck/DsMonad)</code></a><code>:specialisesthe</code><code>monadforthedesugarer.</code></p>
<p>The typechecker and renamer use <em>exactly</em> the same monad, ; the desugarer and interface-file checker use different instantiations of . To give you the idea, here is how the  monad looks:  The details of the global environment type  and local environment type  are also defined in <a href="GhcFile(compiler/typecheck/TcRnTypes.lhs)" class="uri" title="wikilink">GhcFile(compiler/typecheck/TcRnTypes.lhs)</a>. Side effecting operations, such as updating the unique supply, are done with TcRefs, which are simply a synonym for IORefs.</p>
<p>(NB out-of-date, but maybe historically useful; cf [wiki:Debugging/TickyTicky])</p>
<h1 id="kirstens-sketchy-notes-on-getting-ticky-to-work">Kirsten's sketchy notes on getting ticky to work</h1>
<p>Macros for bumping ticky counters are now defined in <a href="GhcFile(includes/Cmm.h)" class="uri" title="wikilink">GhcFile(includes/Cmm.h)</a>. Currently, code compiled with the  flag fails to link because the macros rely on counter variables (things with names like  being declared, but there are actually no declarations for them. I'll add those declarations to <a href="GhcFile(includes/RtsExternal.h)" class="uri" title="wikilink">GhcFile(includes/RtsExternal.h)</a> so I can get something working. Really, there should be something that automatically generates both the macros that are in <a href="GhcFile(includes/Cmm.h)" class="uri" title="wikilink">GhcFile(includes/Cmm.h)</a> and the declarations for the corresponding variables, so that they stay in sync.</p>
<p>Actually, maybe it would make more sense to add a new file,  or something, which contains only ticky counter declarations (the same declarations that still exist in <a href="GhcFile(includes/StgTicky.h)" class="uri" title="wikilink">GhcFile(includes/StgTicky.h)</a>, which isn't used anymore), and that include that from <a href="GhcFile(includes/RtsExternal.h)" class="uri" title="wikilink">GhcFile(includes/RtsExternal.h)</a>.</p>
<p>No -- put actual declarations for counter variables in another file,  or something, and include that only from <a href="GhcFile(rts/Ticky.c)" class="uri" title="wikilink">GhcFile(rts/Ticky.c)</a>; put <em>extern</em> declarations for those counters in , still included from <a href="GhcFile(includes/RtsExternal.h)" class="uri" title="wikilink">GhcFile(includes/RtsExternal.h)</a>. Then later we can automatically generate both  and . The reason for this is that the ticky <strong>macros</strong> are all over the place and they refer to the ticky counters, so the ticky counters have to be <strong>declared</strong> someplace that everyone includes, but of course the actual initializations only need to happen in one place. (Maybe there's a better way to do this...)</p>
<p>No, there don't need to be two files; I was confused. Just .</p>
<p>Huh - we define ticky macros now in  but we can only include that in CMM files and some C files, like , use ticky macros. This makes my brain hurt a little. ''' Index by Title ''' | ''' [RecentChanges Index by Date] '''</p>
<p><a href="TitleIndex(format=group,min=4)" class="uri" title="wikilink">TitleIndex(format=group,min=4)</a></p>
<h1 id="the-ghc-commentary-checking-types">The GHC Commentary: Checking Types</h1>
<p>Probably the most important phase in the frontend is the type checker, which is located at <a href="GhcFile(compiler/typecheck/)" class="uri" title="wikilink">GhcFile(compiler/typecheck/)</a>. GHC type checks programs in their original Haskell form before the desugarer converts them into Core code. This complicates the type checker as it has to handle the much more verbose Haskell AST, but it improves error messages, as those message are based on the same structure that the user sees.</p>
<p>GHC defines the abstract syntax of Haskell programs in <a href="GhcModule(compiler/hsSyn/HsSyn.lhs)" class="uri" title="wikilink">GhcModule(compiler/hsSyn/HsSyn.lhs)</a> using a structure that abstracts over the concrete representation of bound occurences of identifiers and patterns. The module <a href="GhcModule(compiler/typecheck/TcHsSyn.lhs)" class="uri" title="wikilink">GhcModule(compiler/typecheck/TcHsSyn.lhs)</a> defines a number of helper function required by the type checker. Note that the type <a href="GhcModule(compiler/typecheck/TcRnTypes.lhs)" class="uri" title="wikilink">GhcModule(compiler/typecheck/TcRnTypes.lhs)</a>.`TcId` used to represent identifiers in some signatures during type checking is, in fact, nothing but a synonym for a [wiki:Commentary/Compiler/EntityTypes#Typevariablesandtermvariables plain Id].</p>
<p>It is also noteworthy, that the representations of types changes during type checking from `HsType` to `TypeRep.Type`. The latter is a [wiki:Commentary/Compiler/TypeType hybrid type] representation that is used to type Core, but still contains sufficient information to recover source types. In particular, the type checker maintains and compares types in their `Type` form.</p>
<h2 id="the-overall-flow-of-things">The Overall Flow of Things</h2>
<p><code>*`TcRnDriver`isthetoplevel.Itcalls</code><br />
<code>*`TcTyClsDecls`:typeandclassdeclaration</code><br />
<code>*`TcInstDcls`:instancedeclarations</code><br />
<code>*`TcBinds`:valuebindings</code><br />
<code>*`TcExpr`:expressions</code><br />
<code>*`TcMatches`:lambda,case,listcomprehensions</code><br />
<code>*`TcPat`:patterns</code><br />
<code>*`TcForeign`:FFIdeclarations</code><br />
<code>*`TcRules`:rewriterules</code><br />
<code>*`TcHsTypes`:kind-checkingtypesignatures</code><br />
<code>*`TcValidity`:asecondpassthatwalksoverthingsliketypesortypeconstructors,checkinganumberofextrasideconditions.</code></p>
<p><code>*Theconstraintsolverconsistsof:</code><br />
<code>*`TcSimplify`:topleveloftheconstraintsolver</code><br />
<code>*`TcCanonical`:canonicalisingconstraints</code><br />
<code>*`TcInteract`:solvingconstraintswheretheyinteractwitheachother</code><br />
<code>*`TcTypeNats`:solvingnatural-numberconstraints</code><br />
<code>*`TcSMonad`:themonadoftheconstraintsolver(builtontopofthemaintypecheckermonad)</code><br />
<code>*`TcEvidence`:thedatatypesusedforevidence(mostlypure)</code><br />
<code>*`TcUnify`:solvesunificationconstraints&quot;onthefly&quot;;ifitcan't,itgeneratesaconstraintfortheconstraintsolvertodealwithlater</code><br />
<code>*`TcErrors`:generatesgooderrormessagesfromtheresidual,unsolvedconstraints.</code><a href="BR" title="wikilink"><code>BR</code></a><br />
<code>Thebestplacereadingfortheconstraintsolveristhepaper</code><a href="http://www.haskell.org/haskellwiki/Simonpj/Talk:OutsideIn"><code>Modular</code> <code>type</code> <code>inference</code> <code>with</code> <code>local</code> <code>assumptions</code></a></p>
<p><code>*Underlyinginfrastructure:</code><br />
<code>*`TcRnTypes`:abigcollectionofthetypesusedduringtypechecking</code><br />
<code>*[wiki:Commentary/Compiler/TcRnMonadTcRnMonad]:themaintypecheckermonad</code><br />
<code>*`TcType`:purefunctionsovertypes,usedbythetypechecker</code><br />
<code></code></p>
<h3 id="entry-points-into-the-type-checker">Entry Points Into the Type Checker</h3>
<p>The interface of the type checker (and [wiki:Commentary/Compiler/Renamer renamer]) to the rest of the compiler is provided by <a href="GhcModule(compiler/typecheck/TcRnDriver.lhs)" class="uri" title="wikilink">GhcModule(compiler/typecheck/TcRnDriver.lhs)</a>. Entire modules are processed by calling `tcRnModule` and GHCi uses `tcRnStmt`, `tcRnExpr`, and `tcRnType` to typecheck statements and expressions, and to kind check types, respectively. Moreover, `tcTopSrcDecls` is used by Template Haskell - more specifically by `TcSplice.tc_bracket` - to type check the contents of declaration brackets.</p>
<h3 id="renaming-and-type-checking-a-module">Renaming and Type Checking a Module</h3>
<p>The functions `tcRnModule` and `tcRnModuleTcRnM` control the complete static analysis of a Haskell module. They set up the combined renamer and type checker monad, resolve all import statements, take care of hi-boot files, initiate the actual renaming and type checking process, and finally, wrap off by processing the export list.</p>
<p>The actual type checking and renaming process is initiated via `TcRnDriver.tcRnSrcDecls`, which uses a helper called `tc_rn_src_decls` to implement the iterative renaming and type checking process required by <a href="http://darcs.haskell.org/ghc/docs/comm/exts/th.html">Template Haskell</a> (TODO: Point at new commentary equivalent). After it invokes `tc_rn_src_decls`, it simplifies type constraints and zonking (see below regarding the later).</p>
<p>The function `tc_rn_src_decls` partitions static analysis of a whole module into multiple rounds, where the initial round is followed by an additional one for each toplevel splice. It collects all declarations up to the next splice into an `HsDecl.HsGroup`. To rename and type check that declaration group it calls `TcRnDriver.rnTopSrcDecls` and `TcRnDriver.tcTopSrcDecls`. Afterwards, it executes the splice (if there are any left) and proceeds to the next group, which includes the declarations produced by the splice.</p>
<p>The renamer, apart from renaming, computes the global type checking environment, of type `TcRnTypes.TcGblEnv`, which is stored in the [wiki:Commentary/Compiler/TcRnMonad type checking monad] before type checking commences.</p>
<h2 id="type-checking-a-declaration-group">Type Checking a Declaration Group</h2>
<p>The type checking of a declaration group, performed by `tcTopSrcDecls` and its helper function `tcTyClsInstDecls`, starts by processing of the type and class declarations of the current module, using the function `TcTyClsDecls.tcTyAndClassDecls`. This is followed by a first round over instance declarations using `TcInstDcls.tcInstDecls1`, which in particular generates all additional bindings due to the deriving process. Then come foreign import declarations (`TcForeign.tcForeignImports`) and default declarations (`TcDefaults.tcDefaults`).</p>
<p>Now, finally, toplevel value declarations (including derived ones) are type checked using `TcBinds.tcTopBinds`. Afterwards, `TcInstDcls.tcInstDecls2` traverses instances for the second time. Type checking concludes with processing foreign exports (`TcForeign.tcForeignExports`) and rewrite rules (`TcRules.tcRules`). Finally, the global environment is extended with the new bindings.</p>
<h2 id="type-checking-type-and-class-declarations">Type checking Type and Class Declarations</h2>
<p>Type and class declarations are type checked in a couple of phases that contain recursive dependencies - aka <em>knots</em>. The first knot encompasses almost the whole type checking of these declarations and forms the main piece of `TcTyClsDecls.tcTyAndClassDecls`.</p>
<p>Inside this big knot, the first main operation is kind checking, which again involves a knot. It is implemented by `kcTyClDecls`, which performs kind checking of potentially recursively-dependent type and class declarations using kind variables for initially unknown kinds. During processing the individual declarations some of these variables will be instantiated depending on the context; the rest gets by default kind * (during <em>zonking</em> of the kind signatures). Type synonyms are treated specially in this process, because they can have an unboxed type, but they cannot be recursive. Hence, their kinds are inferred in dependency order. Moreover, in contrast to class declarations and other type declarations, synonyms are not entered into the global environment as a global `TyThing`. (`TypeRep.TyThing` is a sum type that combines the various flavours of typish entities, such that they can be stuck into type environments and similar.)</p>
<h2 id="more-details">More Details</h2>
<h3 id="types-variables-and-zonking">Types Variables and Zonking</h3>
<p>During type checking type variables are represented by mutable variables - cf. the <a href="http://darcs.haskell.org/ghc/docs/comm/the-beast/vars.html#TyVar">variable story</a> (TODO: Point at new commentary equivalent). Consequently, unification can instantiate type variables by updating those mutable variables. This process of instantiation is (for reasons that elude me) called <a href="http://dictionary.reference.com/browse/zonk">zonking</a> in GHC's sources. The zonking routines for the various forms of Haskell constructs are responsible for most of the code in the module <a href="GhcModule(compiler/typecheck/TcHsSyn.lhs)" class="uri" title="wikilink">GhcModule(compiler/typecheck/TcHsSyn.lhs)</a>, whereas the routines that actually operate on mutable types are defined in <a href="GhcModule(compiler/typecheck/TcMType.lhs)" class="uri" title="wikilink">GhcModule(compiler/typecheck/TcMType.lhs)</a>; this includes the zonking of type variables and type terms, routines to create mutable structures and update them as well as routines that check constraints, such as that type variables in function signatures have not been instantiated during type checking. The actual type unification routine is `uTys` in the module <a href="GhcModule(compiler/typecheck/TcUnify.lhs)" class="uri" title="wikilink">GhcModule(compiler/typecheck/TcUnify.lhs)</a>.</p>
<p>All type variables that may be instantiated (those in signatures may not), but haven't been instantiated during type checking, are zonked to `()`, so that after type checking all mutable variables have been eliminated.</p>
<h3 id="type-representation">Type Representation</h3>
<p>The representation of types is fixed in the module <a href="GhcModule(compiler/types/TypeRep.lhs)" class="uri" title="wikilink">GhcModule(compiler/types/TypeRep.lhs)</a> and exported as the data type `Type`. Read the comments in the `TypeRep` module! A couple of points:</p>
<p><code>*Typesynonymapplicationsarerepresentedasa`TyConApp`witha`TyCon`thatcontainstheexpansion.Theexpansionisdoneon-demandby`Type.coreView`.Unexpandedtypesynonymsareusefulforgeneratingcomprehensibleerrormessages.</code></p>
<p><code>*The`PredTy`constructorwrapsatypeconstraintargument(dictionary,implicitparameter,orequality).Theyareexpandedon-demandby`coreView`.</code></p>
<p>As explained in <a href="GhcModule(compiler/typecheck/TcType.lhs)" class="uri" title="wikilink">GhcModule(compiler/typecheck/TcType.lhs)</a>, GHC supports rank-N types, but during type inference maintains the restriction that type variables cannot be instantiated to quantified types (i.e., the type system is predicative). However the type system of Core is fully impredicative.</p>
<h3 id="type-checking-environment">Type Checking Environment</h3>
<p>During type checking, GHC maintains a <em>type environment</em> whose type definitions are fixed in the module <a href="GhcModule(compiler/typecheck/TcRnTypes.lhs)" class="uri" title="wikilink">GhcModule(compiler/typecheck/TcRnTypes.lhs)</a> with the operations defined in <a href="GhcModule(compiler/typecheck/TcEnv.lhs)" class="uri" title="wikilink">GhcModule(compiler/typecheck/TcEnv.lhs)</a>. Among other things, the environment contains all imported and local instances as well as a list of <em>global</em> entities (imported and local types and classes together with imported identifiers) and <em>local</em> entities (locally defined identifiers). This environment is threaded through the [wiki:Commentary/Compiler/TcRnMonad type checking monad].</p>
<h3 id="expressions-1">Expressions</h3>
<p>Expressions are type checked by <a href="GhcModule(compiler/typecheck/TcExpr)" class="uri" title="wikilink">GhcModule(compiler/typecheck/TcExpr)</a>.</p>
<p>Usage occurences of identifiers are processed by the function tcId whose main purpose is to [#HandlingofDictionariesandMethodInstances instantiate overloaded identifiers]. It essentially calls `TcInst.instOverloadedFun` once for each universally quantified set of type constraints. It should be noted that overloaded identifiers are replaced by new names that are first defined in the LIE (Local Instance Environment?) and later promoted into top-level bindings.</p>
<h3 id="handling-of-dictionaries-and-method-instances">Handling of Dictionaries and Method Instances</h3>
<p>GHC implements overloading using so-called <em>dictionaries</em>. A dictionary is a tuple of functions -- one function for each method in the class of which the dictionary implements an instance. During type checking, GHC replaces each type constraint of a function with one additional argument. At runtime, the extended function gets passed a matching class dictionary by way of these additional arguments. Whenever the function needs to call a method of such a class, it simply extracts it from the dictionary.</p>
<p>This sounds simple enough; however, the actual implementation is a bit more tricky as it wants to keep track of all the instances at which overloaded functions are used in a module. This information is useful to optimise the code. The implementation is the module <a href="GhcModule(compiler/typecheck/Inst.lhs)" class="uri" title="wikilink">GhcModule(compiler/typecheck/Inst.lhs)</a>.</p>
<p>The function `instOverloadedFun` is invoked for each overloaded usage occurrence of an identifier, where overloaded means that the type of the identifier contains a non-trivial type constraint. It proceeds in two steps: (1) Allocation of a method instance (`newMethodWithGivenTy`) and (2) instantiation of functional dependencies. The former implies allocating a new unique identifier, which replaces the original (overloaded) identifier at the currently type-checked usage occurrence.</p>
<p>The new identifier (after being threaded through the LIE) eventually will be bound by a top-level binding whose rhs contains a partial application of the original overloaded identifier. This papp applies the overloaded function to the dictionaries needed for the current instance. In GHC lingo, this is called a <em>method</em>. Before becoming a top-level binding, the method is first represented as a value of type Inst.Inst, which makes it easy to fold multiple instances of the same identifier at the same types into one global definition. (And probably other things, too, which I haven't investigated yet.)</p>
<p><strong>Note:</strong> As of 13 January 2001 (wrt. to the code in the CVS HEAD), the above mechanism interferes badly with RULES pragmas defined over overloaded functions. During instantiation, a new name is created for an overloaded function partially applied to the dictionaries needed in a usage position of that function. As the rewrite rule, however, mentions the original overloaded name, it won't fire anymore -- unless later phases remove the intermediate definition again. The latest CVS version of GHC has an option '-fno-method-sharing', which avoids sharing instantiation stubs. This is usually/often/sometimes sufficient to make the rules fire again.</p>
<h2 id="connection-with-ghcs-constraint-solver">Connection with GHC's Constraint Solver</h2>
<p>The solver for the type nats is implemented as an extra stage in GHC's constrraint solver (see `TcInteract.thePipeline`).</p>
<p>The following modules contain most of the code relevant for the solver:</p>
<p><code>*`TcTypeNats`:Themainsolvermachinery</code><br />
<code>*`TcTypeNatsRules`:Therulesusedbythesolver</code><br />
<code>*`TcTYpeNatsEval`:Functionsfordirectevaluationonconstants</code></p>
<h2 id="generating-evidence">Generating Evidence</h2>
<p>The solver produces evidence (i.e., proofs) when computing new &quot;given&quot; constraints, or when solving existing &quot;wanted&quot; constraints. The evidence is constructed by applications of a set of pre-defined rules. The rules are values of type `TypeRep.CoAxiomRule`. Conceptually, rules have the form:  The rules have the usual logical meaning: the variables are universally quantified, and the assumptions imply the concluson. As a concrete example, consider the rule for left-cancellation of addtion: </p>
<p>The type `CoAxiomRule` also supports infinte literal-indexed families of simple axioms using constructor `CoAxiomTyLit`. These have the form:  In this case `conclusion` is an equation that contains no type variables but may depend on the literals in the name of the family. For example, the basic definitional axiom for addition, `TcTypeNatsRules.axAddDef`, uses this mechanism:  At present, the assumptions and conclusion of all rules are equations between types but this restriction is not important and could be lifted in the future.</p>
<p>The rules used by the solver are in module `TcTypeNatsRules`.</p>
<h2 id="the-solver">The Solver</h2>
<p>The entry point to the solver is `TcTypeNats.typeNatStage`.</p>
<p>We start by examining the constraint to see if it is obviously unsolvable (using function `impossible`), and if so we stash it in the constraint-solver's state and stop. Note that there is no assumption that `impossible` is complete, but it is important that it is sound, so if `impossible` returns `True`, then the constraint is definitely unsolvable, but if `impossible` returns `False`, then we don't know if the constraint is solvable or not.</p>
<p>The rest of the stage proceeds depending on the type of constraint, as follows.</p>
<h3 id="given-constraints">Given Constraints</h3>
<p>Given constraints correspond to adding new assumptions that may be used by the solver. We start by checking if the new constraint is trivial (using function `solve`). A constraint is considered to be trivial if it matches an already existing constraint or a rule that is known to the solver. Such given constraints are ignored because they do not contribute new information. If the new given is non-trivial, then it will be recorded to the inert set as a new fact, and we proceed to &quot;interact&quot; it with existing givens, in the hope of computing additional useful facts (function `computeNewGivenWork`).</p>
<p>IMPORTANT: We assume that &quot;given&quot; constraints are processed before &quot;wanted&quot; ones. A new given constraint may be used to solve any existing wanted, so every time we added a new given to the inert set we should move all potentially solvable &quot;wanted&quot; constraint from the inert set back to the work queue. We DON'T do this, because it is quite inefficient: there is no obvious way to compute which &quot;wanted&quot;s might be affected, so we have to restart all of them!</p>
<p>The heart of the interaction is the function `interactCt`, which performs one step of &quot;forward&quot; reasoning. The idea is to compute new constraints whose proofs are made by an application of a rule to the new given, and some existing givens. These new constraints are added as new work, to be processed further on the next iteration of GHC's constraint solver.</p>
<p>Aside: when we compute the new facts, we check to see if any are obvious contradictions. This is not strictly necessary because they would be detected on the next iteration of the solver. However, by doing the check early we get slightly better error messages because we can report the original constraint as being unsolvable (it leads to a contradiction), which tends to be easier to relate to the original program. Of course, this is not completely fool-proof---it is still possible that a contradiction is detected at a later iteration. An alternative idea---not yet implemented---would be to examine the proof of a contradiction and extract the original constraints that lead to it in the first place.</p>
<h3 id="derived-constraints">Derived Constraints</h3>
<p>``Derived`` constraints are facts that are implied by the constraints in the inert set. They do not have complete proofs because they may depend on proofs of as yet unsolved wanted constraints. GHC does not associate any proof terms with derived constraints (to keep things simple?). In the constraint solver, they are mostly used as &quot;hints&quot;. For example, consider the wanted constraint , where  is a free unification variable. These are the steps we'll take to solve the constraint:</p>
<p></p>
<p>The type-nat solver processes derived constraints in a similar fashion to given constraints (`computeNewDerivedWork`): it checks to see if they are trivially known and, if not, then it tries to generate some additional derived constraints. The main difference is that derived constraints can be interacted with all existing constraints to produce new facts, while given constraints only interact with other givens.</p>
<h3 id="wanted-constraints">Wanted Constraints</h3>
<p>The main purpose of the solver is to discharge ``wanted`` constraints (the purpose of processing given and derived constraints is to help solve existing wanted goals). When we encounter a new wanted goals we proceed as follows:</p>
<p><code>1.Trytosolvethegoal,usingafewdifferentstrategies:</code><br />
<code>1.Trytoseeifitmatchestheconclusionofaniffrule(`solveIff`).Aassumptionsofrulebecomenewwantedwork.</code><br />
<code>2.Trytoseeifitmatchesanaxiomexactly(`solve`)</code><br />
<code>3.Trytheorderingsolverfor`&lt;=`goals(`solveLeq`)</code><br />
<code>4.Trytousea(possiblysynthesized)assumption</code></p>
<p><code>2.Ifthatdidn'twork:</code><br />
<code>1.Wantedisaddedtotheinertset</code><br />
<code>2.Checktoseeifanyoftheexistingwantedsintheinertsetcanbesolvedintermsofthenewgoal(`reExamineWanteds`)</code><br />
<code>3.Generatenewderivedfacts.</code></p>
<h4 id="using-iff-rules">Using IFF Rules</h4>
<p>These rules are used to replace a wanted constraint with a collection of logically equivalent wanted constraints. If a wanted constraint matches the head of one of these rules, than it is solved using the rules, and the we generate new wanted constraints for the rule's assumptions.</p>
<p>The following are important properties of IFF rules:</p>
<p><code>*Theyneedtobesound(ofcourse!)</code><br />
<code>*Theassumptionsneedtobelogicallyequivalenttotheconclusion(i.e.,theyshouldnotresultinaharderproblemtosolvethantheoriginalgoal).</code><br />
<code>*Theassumptionsneedtobe</code><em><code>simpler</code></em><code>fromthepointofviewoftheconstraintsolver(i.e.,weshouldn'tendupwiththeoriginalgoalaftersomesteps---thiswouldleadtonon-termination).</code></p>
<p>At present, IFF rules are used to define certain operators in terms of others. For example, this is the only rule for solving constraints about subtraction: </p>
<h4 id="using-axioms">Using Axioms</h4>
<p>Basic operators are defined with an infinite family of axiom schemes. As we can't have these written as a long list (searching might never stop!), we have some custom code that checks to see if a constraint might be solvable using one of the definitional axioms (see `solveWithAxiom`, `byAxiom`).</p>
<h4 id="using-the-order-model">Using the Order Model</h4>
<p>Constraints about the ordering of type-level numbers are kept in a datastructure (`LeqFacts`) which forms a ``model'' of the information represented by the constraints (in a similar fashion to how substitutions form a model for a set of equations).</p>
<p>The purpose of the model is to eliminate redundant constraints, and to make it easy to find proofs for queries of the form `x &lt;= y`. In practise, of particular interest are questions such as `1 &lt;= x` because these appear as assumptions on a number of rules (e.g., cancellation of multiplication). In the future, this model could also be used to implement an interval analysis, which would compute intervals approximating the values of variables.</p>
<p>TODO: At present, this model is reconstructed every time it needs to be used, which is a bit inefficient. Perhaps it'd be better to use this directly as the representation of `&lt;=` constraints in the inert set.</p>
<p>The model is a directed acyclic graph, as follows:</p>
<p><code>*vertices:constantsorvariables(ofkind`Nat`)</code><br />
<code>*edges:theedgefrom`A`to`B`isaproofthat`A&lt;=B`.</code></p>
<p>So, to find a proof of `A &lt;= B`, we insert `A` and `B` in the model, and then look for a path from `A` to `B`. The proofs on the path can be composed using the rule for transitivity of `&lt;=` to form the final proof.</p>
<p>When manipulating the model, we maintain the following &quot;minimality&quot; invariant: there should be no direct edge between two vertices `A` and `B`, if there is a path that can already get us from `A` to `B. Here are some examples (with edges pointing upwards) </p>
<p>The purpose of the invariant is to eliminate redundant information. Note, however, that it does not guarantee that there is a unique way to prove a goal.</p>
<h4 id="using-extended-assumptions">Using Extended Assumptions</h4>
<p>Another way to prove a goal is to look it up in the assumptions. If the goal matched an assumption exactly, then GHC would have already solved it in one of its previous stages of the constraint solver. However, due to the commutativity and associativity of some of the operators, it is possible to have goal that could be solved by assumption, only if the assumption was &quot;massaged&quot; a bit.</p>
<p>This &quot;massaging&quot; is implemented by the function `widenAsmps`, which extends the set of assumption by performing a bit of forward reasoning using a limited set of rules. Typically, these are commutativity an associativity rules, and the `widenAsmps` function tries to complete the set of assumptions with respect to these operations. For example: </p>
<p>Note that the extended assumptions are very similar to derived constraints, except that we keep their proofs.</p>
<h4 id="re-examining-wanteds">Re-examining Wanteds</h4>
<p>If none of the strategies for solving a wanted constraint worked, then the constraint is added to the inert set. Since we'd like to keep the inert set minimal, we have to see if any of the existing wanted constraints might be solvable in terms of the new wanted (`reExamineWanteds`).</p>
<p>It is good to keep the inert set minimal for the following reasons:</p>
<p><code>*Inferredtypesarenicer,</code><br />
<code>*IthelpsGHCtosolveconstraintsby&quot;inlining&quot;(e.g.,ifwe</code><br />
<code>haveonlyasingleconstraint`x+y~z`,thenwecaneliminateit</code><br />
<code>byreplacingalloccurrencesof`z`with`x+y`,howeverwecan't</code><br />
<code>dothatifweendedupwithtwoconstraints`(x+y~z,y+x~z)).</code></p>
<p>We consider each (numeric) wanted constraint in the inert set and check if we can solve it in terms of the new wanted and all other wanteds. If so, then it is removed from the inert set, otherwise it stays there.</p>
<p>Note that we can't implement this by kicking out the existing wanted constraints and putting them back on the work queue, because this would lead to non-termination. Here is an example of how this might happen: </p>
<p>Perhaps there is a way around this but, for the moment, we just re-examine the numeric wanteds locally, without going through the constraint solver pipe-line.</p>
<p><a href="PageOutline" class="uri" title="wikilink">PageOutline</a></p>
<h1 id="the-data-type-and-its-friends-1">The data type  and its friends</h1>
<p>GHC compiles a typed programming language, and GHC's intermediate language is explicitly typed. So the data type that GHC uses to represent types is of central importance.</p>
<p>The single data type  is used to represent</p>
<p><code>*Types(possiblyofhigherkind);e.g.`[Int]`,`Maybe`</code><br />
<code>*Kinds(whichclassifytypesandcoercions);e.g.`(*-&gt;*)`,`T:=:[Int]`.See[wiki:Commentary/Compiler/Kinds]</code><br />
<code>*Sorts(whichclassifytypes);e.g.`TY`,`CO`</code></p>
<p>GHC's use of [wiki:Commentary/Compiler/FC coercions and equality constraints] is important enough to deserve its own page.</p>
<p>The module  exposes the representation because a few other modules (, , , etc) work directly on its representation. However, you should not lightly pattern-match on ; it is meant to be an abstract type. Instead, try to use functions defined by ,  etc.</p>
<h2 id="views-of-types-1">Views of types</h2>
<p>Even when considering only types (not kinds, sorts, coercions) you need to know that GHC uses a <em>single</em> data type for types. You can look at the same type in different ways:</p>
<p><code>*The&quot;typecheckerview&quot;regardsthetypeasaHaskelltype,completewithimplicitparameters,classconstraints,andthelike.Forexample:</code></p>
<p></p>
<p><code>Functionsin`TcType`takethisviewoftypes;e.g.`tcSplitSigmaTy`splitsupatypeintoitsforall'dtypevariables,itsconstraints,andtherest.</code></p>
<p><code>*The&quot;coreview&quot;regardsthetypeasaCore-languagetype,whereclassandimplicitparameterconstraintsaretreatedasfunctionarguments:</code></p>
<p></p>
<p><code>Functionsin`Type`takethisview.</code></p>
<p>The data type `Type` represents type synonym applications in un-expanded form. E.g.  Here `f`'s type doesn't look like a function type, but it really is. The function `Type.coreView :: Type -&gt; Maybe Type` takes a type and, if it's a type synonym application, it expands the synonym and returns `Just <expanded-type>`. Otherwise it returns `Nothing`.</p>
<p>Now, other functions use `coreView` to expand where necessary, thus:  Notice the first line, which uses the view, and recurses when the view 'fires'. Since `coreView` is non-recursive, GHC will inline it, and the optimiser will ultimately produce something like: </p>
<h2 id="the-representation-of-1">The representation of </h2>
<p>Here, then is the representation of types (see <a href="GhcFile(compiler/types/TypeRep.hs)" class="uri" title="wikilink">GhcFile(compiler/types/TypeRep.hs)</a> for more details): </p>
<p>Invariant: if the head of a type application is a , GHC <em>always</em> uses the  constructor, not . This invariant is maintained internally by 'smart constructors'. A similar invariant applies to ;  is never used with an arrow type.</p>
<p>Type variables are represented by the `TyVar` constructor of the [wiki:Commentary/Compiler/EntityTypes data type Var].</p>
<h2 id="overloaded-types-1">Overloaded types</h2>
<p>In Haskell we write  but in Core the `=&gt;` is represented by an ordinary `FunTy`. So f's type looks like this:  Nevertheless, we can tell when a function argument is actually a predicate (and hence should be displayed with `=&gt;`, etc), using  The various forms of predicate can be extracted thus:  These functions are defined in module `Type`.</p>
<h2 id="classifying-types-1">Classifying types</h2>
<p>GHC uses the following nomenclature for types:</p>
<p><strong><code>Unboxed</code></strong><code>::Atypeisunboxediffitsrepresentationisotherthanapointer.Unboxedtypesarealsounlifted.</code></p>
<p><strong><code>Lifted</code></strong><code>::Atypeisliftediffithasbottomasanelement.Closuresalwayshaveliftedtypes:i.e.anylet-boundidentifierinCoremusthavealiftedtype.Operationally,aliftedobjectisonethatcanbeentered.Onlyliftedtypesmaybeunifiedwithatypevariable.</code></p>
<p><strong><code>Data</code></strong><code>::Atypedeclaredwith</code><strong></strong><code>.Alsoboxedtuples.</code></p>
<p><strong><code>Algebraic</code></strong><code>::Analgebraicdatatypeisadatatypewithoneormoreconstructors,whetherdeclaredwith</code><code>or</code><code>.Analgebraictypeisonethatcanbedeconstructedwithacaseexpression.&quot;Algebraic&quot;is</code><strong><code>NOT</code></strong><code>thesameas&quot;lifted&quot;,becauseunboxed(andthusunlifted)tuplescountas&quot;algebraic&quot;.</code></p>
<p><strong><code>Primitive</code></strong><code>::atypeisprimitiveiffitisabuilt-intypethatcan'tbeexpressedinHaskell.</code><br />
<code></code><br />
<code>Currently,allprimitivetypesareunlifted,butthat'snotnecessarilythecase.(E.g.Intcouldbeprimitive.)</code></p>
<p><code>Someprimitivetypesareunboxed,suchasInt#,whereassomeareboxedbutunlifted(suchas`ByteArray#`).Theonlyprimitivetypesthatweclassifyasalgebraicaretheunboxedtuples.</code></p>
<p>Examples of type classifications:</p>
<p>|| || <strong>Primitive</strong> || <strong>Boxed</strong> || <strong>Lifted</strong> || <strong>Algebraic</strong> || || `Int#` || Yes || No || No || No || || `ByteArray#` || Yes || Yes || No || No || || `(# a, b #)` || Yes || No || No || Yes || || `( a, b )` || No || Yes || Yes || Yes || || `[a]` || No || Yes || Yes || Yes ||</p>
<h2 id="unique-1">Unique</h2>
<p>`Unique`s provide a fast comparison mechanism for more complex things. Every `RdrName`, `Name`, `Var`, `TyCon`, `TyVar`, etc. has a `Unique`. When these more complex structures are collected (in `UniqFM`s or other types of collection), their `Unique` typically provides the key by which the collection is indexed.</p>
<hr />
<h2 id="current-design">Current design</h2>
<p>A `Unique` consists of the <em>domain</em> of the thing it identifies and a unique integer value 'within' that domain. The two are packed into a single `Int#`, with the <em>domain</em> being the top 8 bits.</p>
<p>The domain is never inspected (SLPJ believes). The sole reason for its existence is to provide a number of different ranges of `Unique` values that are guaranteed not to conflict.</p>
<p>=== Lifetime</p>
<p>The lifetime of a `Unique` is a single invocation of GHC, i.e. they must not 'leak' to compiler output, the reason being that `Unique`s may be generated/assigned non-deterministically. When compiler output is non-deterministic, it becomes significantly harder to, for example, [wiki:Commentary/Compiler/RecompilationAvoidance avoid recompilation]. Uniques do not get serialised into .hi files, for example.</p>
<p>Note, that &quot;one compiler invocation&quot; is not the same as the compilation of a single `Module`. Invocations such as `ghc --make` or `ghc --interactive` give rise to longer invocation life-times.</p>
<p>This is also the reasons why `OccName`s are <em>not</em> ordered based on the `Unique`s of their underlying `FastString`s, but rather <em>lexicographically</em> (see <a href="GhcFile(compiler/basicTypes/OccName.lhs)" class="uri" title="wikilink">GhcFile(compiler/basicTypes/OccName.lhs)</a> for details). &gt; &gt; <strong>SLPJ:</strong> I am far from sure that the Ord instance for `OccName` is ever used, so this remark is probably misleading. Try deleting it and see where it is used (if at all). &gt; <strong>PKFH:</strong> At least `Name` and `RdrName` (partially) define their own `Ord` instances in terms of the instance of `OccName`. Maybe these `Ord` instances are also redundant, but for now it seems wise to keep them in. When everything has `Data` instances (after this and many other redesigns), I'm sure it will be easier to find such dependency relations.</p>
<h3 id="known-key-things">Known-key things</h3>
<p>A hundred or two library entities (types, classes, functions) are so-called &quot;known-key things&quot;. See [wiki:Commentary/Compiler/WiredIn this page]. A known-key thing has a fixed `Unique` that is fixed when the compiler is built, and thus lives across all invocations of that compiler. These known-key `Unique`s <em>are</em> written into .hi files. But that's ok because they are fully deterministic and never change.</p>
<p>&gt; <strong>PKFH</strong> That's fine then; we also know for sure these things fit in the 30 bits used in the `hi`-files. I'll comment appropriately.</p>
<h3 id="interface-files-1">Interface files</h3>
<p>Entities in a interface file (.hi file) are, for the most part, stored in a symbol table, and referred to (from elsewhere in the same interface file) by an index into that table. Here are the details from <a href="GhcFile(compiler/iface/BinIface.lhs)" class="uri" title="wikilink">GhcFile(compiler/iface/BinIface.lhs)</a>: </p>
<hr />
<h2 id="redesign-2014-1">Redesign (2014)</h2>
<p>=== TL;DR The redesign is to accomplish the following:</p>
<p><code>*Allowderivationoftypeclassinstancesfor`Unique`</code><br />
<code>*Restoreinvariantsfromtheoriginaldesign;hiderepresentationdetails</code><br />
<code>*Eliminateviolationsofinvariantsanddesign-violationsinotherplacesofthecompiler(e.g.`Unique`sshouldn'tbewrittento`hi`-files,butare).</code></p>
<p>&gt; &gt; <strong>SLPJ</strong> I don't think this is a design violation; see above. Do you have any other examples in mind? &gt; <strong>PKFH</strong> Not really of design-violations (and no other compiler-output stuff) other than the invariants mentioned above it, just yet. The key point, though, is that there are a lot of comments in `Unique` about not exporting things so that we know X, Y and Z, but then those things <em>are</em> exported, so we don't know them to be true. Case in point is the export of `mkUnique`, but also `mkUniqueGrimily`. The latter has a comment 'only for `UniqSupply`' but is also used in other places (like Template Haskell). One redesign is to put this restriction in the name, so there still is the facility offered by `mkUniqueGrimily`, but now it's called `mkUniqueOnlyForUniqSupply` (and `mkUniqueOnlyForTemplateHaskell`), the ugliness of which should help, over time, to get rid of them.</p>
<p>=== Longer</p>
<p>In an attempt to give more of GHC's innards well-behaved instances of `Typeable`, `Data`, `Foldable`, `Traversable`, etc. the implementation of `Unique`s was a bit of a sore spot. They were implemented (20+ years earlier) using custom boxing, viz.  making automatic derivation of such type class instances hard. There was already a comment asking why it wasn't simply a `newtype` around a normal (boxed) `Int`. Independently, there was some discussion on the mailinglists about the use of (signed) `Int`s in places where `Word`s would be more appropriate. Further inspection of the `Unique` implementation made clear that a lot of invariants mentioned in comments had been violated by incremental edits. This is discussed in more detail below, but these things together (the desire for automatic derivation and the restoration of some important invariants) motivated a moderate redesign.</p>
<p>=== Status Quo (pre redesign)</p>
<p>A `Unique` has a domain (`TyCon`, `DataCon`, `PrelName`, `Builtin`, etc.) that was codified by a character. The remainder of the `Unique` was an integer that should be unique for said domain. This <strong>was</strong> once guaranteed through the export list of <a href="GhcFile(compiler/basicTypes/Unique.lhs)" class="uri" title="wikilink">GhcFile(compiler/basicTypes/Unique.lhs)</a>, where direct access to the domain-character was hidden, i.e.  were not exported. This should have guaranteed that every domain was assigned its own unique character, because only in <a href="GhcFile(compiler/basicTypes/Unique.lhs)" class="uri" title="wikilink">GhcFile(compiler/basicTypes/Unique.lhs)</a> could those `Char`s be assigned. However, through  this separation of concerns leaked out to <a href="GhcFile(compiler/basicTypes/UniqSupply.lhs)" class="uri" title="wikilink">GhcFile(compiler/basicTypes/UniqSupply.lhs)</a>, because its `Int` argument is the <em>entire</em> `Unique` and not just the integer part 'under' the domain character. &gt; &gt; <strong>SLPJ</strong> OK, but to eliminate `mkUniqueGrimily` you need to examine the calls, decide how to do it better, and document the new design. &gt; <strong>PKFH</strong> See above; the solution for now is `mkUniqueOnlyForUniqSupply`. A separate patch will deal with trying to refactor/redesign `UniqSupply` if this is necessary.</p>
<p>The function `mkSplitUniqSupply` made the domain-character accessible to all the other modules, by having a wholly separate implementation of the functionality of `mkUnique`.</p>
<p>Where the intention was still to have a clean interface, the (would-be) hidden `mkUnique` is only called by functions defined in the `Unique` module with the corresponding character, e.g. </p>
<p>=== New plan</p>
<p>In the new design, the domains are explicitly encoded in a sum-type `UniqueDomain`. At the very least, this should help make the code a little more self-documenting <em>and</em> prevent accidental overlap in the choice of bits to identify the domain. Since the purpose of `Unique`s is to provide <em>fast</em> comparison for different types of things, the redesign should remain performance concious. With this in mind, keeping the `UniqueDomain` and the integer-part explicitly in the type  seems unwise, but by choosing  we win the ability to automatically derive things and should also be able to test how far optimisation has come in the past 20+ years; does default boxing with `newtype`-style wrapping have (nearly) the same performance as manual unboxing? This should follow from the tests.</p>
<p>The encoding is kept the same, i.e. the `Word` is still built up with the domain encoded in the most significant bits and the integer-part in the remaining bits. However, instead encoding the domain as a `Char` in the (internal <em>and</em> external interface), we now create an ADT (sum-type) that encodes the domain. This has two advantages. First, it prevents people from picking domain-tags ad hoc an possibly overlapping. Second, encoding in the `Word` does not rely on the assumption that the domain requires and/or fits in 8 bits. Since Haskell `Char`s are unicode, the 8-bit assumption is wrong for the old design. In other words, the above examples are changed to:</p>
<p></p>
<p>Ideal world scenario, the entire external interface would be:  and the instances for `Eq`, `Ord`, `Data`, etc. For now, though, it will also have </p>
<p>&gt; &gt; <strong>SLPJ</strong> I agree that a `newtype` around a `Word` is better than a `data` type around `Int#`. That is a small, simple change. But I think you plan to do more than this, and that &quot;more&quot; is not documented here. E.g. what is the new API to `Unique`? &gt; <strong>PKFH</strong> Added. See above.</p>
<h1 id="unpacking-primitive-fields">Unpacking primitive fields</h1>
<p>This page describes a proposal to automatically unpack (strict) primitive fields. A primitive fields is a field that when unpacked has a pointer-sized representation. Examples include `Int`, `Word`, `Float`, and `newtype`s thereof.</p>
<h2 id="goals-and-non-goals">Goals and non-goals</h2>
<p>This proposal is about changing the default behavior of GHC, not changing expressiveness. Users can still use `UNPACK` and `NOUNPACK` to explicitly control the memory representation of fields.</p>
<p>There are two goals:</p>
<p><code>1.Reducetheamountofboilerplateexperiencedprogrammershavetowrite:AsofFeb18th2012,the</code><a href="http://hackage.haskell.org/package/bytestring"><code>bytestring</code></a><code>,</code><a href="http://hackage.haskell.org/package/text"><code>text</code></a><code>,and</code><a href="http://hackage.haskell.org/package/containers"><code>containers</code></a><code>packageshad46fieldsthatmatchedthedefinitionofprimitivegivenabove.43ofthesehadanexplicit`UNPACK`pragma(andtheremaining3couldhavehadonewithoutchangingtheperformanceoftheprogram.)</code></p>
<p><code>2.ToprovidebetterdefaultsforbeginnerandintermediatelevelHaskellers.Notunpackinge.g.`Int`fieldscanhavealarge,negativeeffectonperformanceandmanybeginnerandintermediatelevelHaskellersarebittenbythis.</code></p>
<h2 id="detailed-design">Detailed design</h2>
<h2 id="benchmarks">Benchmarks</h2>
<h1 id="unused-imports-1">Unused imports</h1>
<p>GHC has a series of bugs related to the &quot;report unused imports&quot; flags, including #1148, #2267, #1074, #2436, #10117.</p>
<p>This page describes a new design.</p>
<h2 id="the-current-story">The current story</h2>
<p>Currently (GHC 6.10) we report three different things:</p>
<p><code>*warnUnusedModules:importM,wherenothingisusedfromM</code><br />
<code>*warnUnusedImports:importM(f),wherefisunused,andMdoesn'tfallunderwarnUnusedModules</code><br />
<code>*warnDuplicateImports:importM+importM(f),evenwhenfisusedcomplainaboutduplicateimportoff</code></p>
<h2 id="examples-1">Examples</h2>
<p>The hard bit is to specify what the warning should do. Consider these examples, where `Foo` exports `x` and `y`, and `FooPlus` re-exports all of `Foo`, plus `z`:  Which import is redudant, in each case?</p>
<p>Also: we might warn if you import the same module more than once, and the imports can be combined (ie they have the same 'qualified' and 'as' attributes)  Here both are used, but we might want to suggest combining them.</p>
<h2 id="specfication">Specfication</h2>
<p>We can at least agree on this:</p>
<p><code>*Ifthewarningsuggeststhatanimportcanbeomitted,andyouomitit,</code><br />
<code>theprogramshouldstillcompile.</code><br />
<code>*It'snotworthtryingtobetoosubtle.The90%caseisverysimple.</code></p>
<p>Say that an <em>import-item</em> is either an entire import-all decl (eg `import Foo`), or a particular item in an import list (eg `import Foo( ..., x, ...)`). The general idea is that for each use of an imported name, we will attribute that use to one (or possibly more) import-items. Then, any import items with no uses attributed to them are unused, and are warned about. More precisely:</p>
<p><code>1.Forevery`RdrName`intheprogramtext,findalltheimport-itemsthatbroughtitintoscope.Thelookupmechanismon`RdrNames`alreadytakesaccountofwhetherthe`RdrName`wasqualified,andwhichimportshavetherightqualificationetc,sothisstepisveryeasy.</code></p>
<p><code>2.Chooseoneofthese,the&quot;chosenimport-item&quot;,andmarkit&quot;used&quot;.</code></p>
<p><code>3.Nowbleataboutanyimport-itemsthatareunused.Foradecl</code><br />
<code>`importFoo(x,y)`,ifboththe`x`and`y`itemsareunused,it'dbebetter</code><br />
<code>tobleantabouttheentiredeclratherthantheindividualitems.</code></p>
<p>The import-item choosing step 2 implies that there is a total order on import-items. We say import-item A ``dominates`` import-item B if we chooose A over B. Here is one possible dominance relationship:</p>
<p><code>*`importFoo`dominates`importFoo(x)`.(Youcouldalsoarguethatthe</code><br />
<code>reverseshouldhold.)</code><br />
<code>*Otherwisechoosethetextuallyfirstone.</code></p>
<p>Other notes:</p>
<p><code>*Thealgorithmchoosesexactlyoneimport-iteminstep2.Itwould</code><br />
<code>alsobesoundtochoosemorethanoneiftherewasatie,butthencompletely-duplicate</code><br />
<code>importsmightnotbereported.</code></p>
<p><code>*Notethatifwehaveanimportitem`importFoo(Bar(bar))`,then</code><br />
<code>it'smarkedasusedifeither`Bar`or`bar`areused.Wecouldhaveyetfiner</code><br />
<code>resolutionandreportevenunusedsub-items.</code></p>
<p><code>*Weshouldretainthespecialcaseofnotwarningabout`importFoo()`,whichimplies&quot;instancedeclarationsonly&quot;.</code></p>
<hr />
<h2 id="implementation-1">Implementation</h2>
<p>We want to collect the set of all `RdrNames` that are mentioned in the program. We must collect <strong>`RdrNames`</strong> not `Names`:  Here both imports are required, but you can only tell that by seeing the RdrNames, not by knowing that the name 'x' is used.</p>
<p>I think that all lookups go through either, `RnEnv.lookupGreRn_maybe` or `RnEnv.lookup_sub_bndr`. So in `RnEnv.lookupGreRn_maybe`, if `(gre_prov gre)` is `(Imported _)`, and in `RnEnv.lookup_sub_bndr`, put `rdr_name` in a new  in `TcGblEnv`. All the `tcg_used_rdrnames` are in scope; if not, we report an error and do not add it to `tcg_used_rdrnames`.</p>
<p>Other notes</p>
<p><code>*Anyparticular(in-scope)used`RdrName`isboughtintoscopeby</code><br />
<code>oneormore`RdrName.ImportSpec`'s.Youcanfindthese`ImportSpecs`</code><br />
<code>intheGREreturnedbythelookup.</code></p>
<p><code>*Theunitof&quot;unusedimport&quot;reportingisoneofthese`ImportSpecs`.</code></p>
<p><code>*Supposethat'rn'isaused,imported`RdrName`,and'iss'is</code><br />
<code>the`[ImportSpecs]`thatbroughtitintoscope.Then,toafirst</code><br />
<code>approximationalltheissarecounted'used'.</code></p>
<p><code>*Wecancompare`ImportSpecs`forequalitybytheir`SrcSpans`</code></p>
<p><code>*In`TcRnDriver.tcRnImports`,saveimport_declsinanew</code><br />
<code>`tcg_rn_rdr_imports::Maybe[LImportDeclRdrName]`</code><br />
<code>in`TcGblEnv`</code></p>
<hr />
<h2 id="algorithm">Algorithm</h2>
<p>The algorithm for deciding which imports have been used is based around this datatype: </p>
<p>We convert import declarations into trees of `ImportInfo`s, e.g.  becomes (only the `SDoc` and `[RdrName]` fields are given, as that's the interesting bit)  If a node in the tree is marked as used, then so are all nodes above it. For example, given the tree a use of `&quot;D&quot;` marks both the first and third lines as used.</p>
<p>When we come to giving warnings, if a node is unused then we warn about it, and do not descend into the rest of that subtree, as the node we warn about subsumes its children. If the node is marked as used then we descend, looking to see if any of its children are unused.</p>
<p>Here are how some example imports map to trees of `ImportInfo`, assuming `Foo` exports `a`, `b`, `D(c1, c2)`. </p>
<p>These trees are built by `RnNames.mkImportInfo`. In `RnNames.warnUnusedImportDecls` we make two lists of `ImportInfo`s; one list contains all the explicit imports, e.g.  and the other contains the implicit imports, e.g. </p>
<p>Then `RnNames.markUsages` is called for each `RdrName` that was used in the program. The current implementation marks all explicit import as used unless there are no such imports, in which case it marks all implicit imports as used. A small tweak to `markUsages` would allow it to mark only the first import it finds as used.</p>
<p>As well as the `RdrName`s used in the source, we also need to mark as used the names that are exported. We first call `RnNames.expandExports` to expand `D(..)` into `D(c1, c2)`, and then call `RnNames.markExportUsages`. Normally this just marks the `RdrName`s as used in the same way that uses in the module body are handled, but it is also possible for an entire module to be &quot;used&quot;, if `module Foo` is in the export list. In this case `RnNames.markModuleUsed` does the hard work, marking every module imported with that name as used.</p>
<h1 id="updates-1">Updates</h1>
<p>Source files: <a href="GhcFile(rts/Updates.h)" class="uri" title="wikilink">GhcFile(rts/Updates.h)</a>, <a href="GhcFile(rts/Updates.cmm)" class="uri" title="wikilink">GhcFile(rts/Updates.cmm)</a></p>
<hr />
<p>CategoryStub</p>
<h1 id="the-user-manual">The user manual</h1>
<p>GHC's user manual contains documentation intended for users of GHC. They are not interested in how GHC works; they just want to use it.</p>
<p>The user manual is held in <a href="GhcFile(docs/user_guide)" class="uri" title="wikilink">GhcFile(docs/user_guide)</a>, and is written in !ReStructuredText format (`.rst` files). This allows us to typeset it as HTML pages, or as LaTeX.</p>
<p>See also the [wiki:Building/Docs notes on building the documentation].</p>
<p>See the &quot;Care and feeding of your GHC User's Guide&quot; section for conventions and a basic introduction to ReST.</p>
<h1 id="ghc-boot-library-version-history">GHC Boot Library Version History</h1>
<p>This table lists the versions of GHC against those of its boot libraries, including most notably the `base` library. This may be useful if you ever want to find out which version of the `base` package was bundled with which version of GHC or vice versa.</p>
<p>See also: LanguagePragmaHistory, which lists the language extensions added and/or removed in each GHC version.</p>
<p></p>
<p>|| ||= <strong>HEAD</strong> =||= <strong>7.10.3</strong> =||= <strong>7.10.2</strong> =||= <strong>7.10.1</strong> =||= <strong>7.8.4</strong> =||= <strong>7.8.3</strong> =||= <strong>7.8.2</strong> =||= <strong>7.8.1</strong> =||= <strong>7.6.3</strong> =||= <strong>7.6.2</strong> =||= <strong>7.6.1</strong> =||= <strong>7.4.2</strong> =||= <strong>7.4.1</strong> =||= <strong>7.2.2</strong> =||= <strong>7.2.1</strong> =||= <strong>7.0.4</strong> =||= <strong>7.0.3</strong> =||= <strong>7.0.2</strong> =||= <strong>7.0.1</strong> =|| ||=`Cabal` =|| 1.23.0.0 || 1.22.5.0 || 1.22.4.0 || 1.22.2.0 || 1.18.1.5 |||||| 1.18.1.3 |||||| 1.16.0 |||| 1.14.0 |||| 1.12.0 || 1.10.2.0 |||| 1.10.1.0 || 1.10.0.0 || ||=`Win32` =|||||||| 2.3.1.0 |||||||| 2.3.0.2 |||||| 2.3.0.0 |||| 2.2.2.0 |||| 2.2.1.0 |||||||| 2.2.0.2 || ||=`array` =|||||||| 0.5.1.0 |||||||| 0.5.0.0 |||||| 0.4.0.1 |||| 0.4.0.0 |||| 0.3.0.3 |||||||| 0.3.0.2 || ||=`base` =|| 4.9.0.0 || 4.8.2.0 || 4.8.1.0 || 4.8.0.0 || 4.7.0.2 || 4.7.0.1 |||| 4.7.0.0 |||| 4.6.0.1 || 4.6.0.0 || 4.5.1.0 || 4.5.0.0 || 4.4.1.0 || 4.4.0.0 |||||| 4.3.1.0 || 4.3.0.0 || ||=`bin-package-db` =|| <em>none</em> |||||||||||||||||||||||||||||||||||| 0.0.0.0 || ||=`binary` =|| 0.8.0.0 |||| 0.7.5.0 || 0.7.3.0 |||||||| 0.7.1.0 |||||| 0.5.1.1 |||| 0.5.1.0 |||| 0.5.0.2* |||||||| <em>none</em> || ||=`bytestring` =|| 0.10.7.0 |||||| 0.10.6.0 |||||||| 0.10.4.0 |||| 0.10.0.2 || 0.10.0.0 |||| 0.9.2.1 |||| 0.9.2.0 |||||| 0.9.1.10 || 0.9.1.8 || ||=`containers` =|| 0.5.7.1 |||||| 0.5.6.2 |||||||| 0.5.5.1 |||||| 0.5.0.0 |||| 0.4.2.1 |||| 0.4.1.0 |||||||| 0.4.0.0 || ||=`deepseq` =|| 1.4.2.0 |||||| 1.4.1.1 |||||||| 1.3.0.2 |||||| 1.3.0.1 |||| 1.3.0.0 |||||||||||| <em>none</em> || ||=`directory` =|| 1.2.5.0 |||||| 1.2.2.0 |||||||| 1.2.1.0 |||| 1.2.0.1 || 1.2.0.0 |||| 1.1.0.2 |||| 1.1.0.1 |||||||| 1.1.0.0 || ||=`extensible-exceptions` =|||||||||||||||||||||| <em>none</em> |||| 0.1.1.4 |||| 0.1.1.3 |||||||| 0.1.1.2 || ||=`ffi` =|||||||||||||||||||||||||| <em>none</em> |||||||||||| 1.0 || ||=`filepath` =|| 1.4.1.0 |||||| 1.4.0.0 |||||||| 1.3.0.2 |||||| 1.3.0.1 |||| 1.3.0.0 |||| 1.2.0.1 |||||||| 1.2.0.0 || ||=`ghc` =|| 7.11.20151220* || 7.10.3* || 7.10.2* || 7.10.1* || 7.8.4* || 7.8.3* || 7.8.2* || 7.8.1* || 7.6.3* || 7.6.2* || 7.6.1* || 7.4.2* || 7.4.1* || 7.2.2* || 7.2.1* || 7.0.4* || 7.0.3* || 7.0.2* || 7.0.1* || ||=`ghc-binary` =|||||||||||||||||||||||||||||| <em>none</em> |||||||| 0.5.0.2* || ||=`ghc-boot` =|| 0.0.0.0 |||||||||||||||||||||||||||||||||||| <em>none</em> || ||=`ghc-prim` =|| 0.5.0.0 |||||| 0.4.0.0 |||||||| 0.3.1.0 |||||| 0.3.0.0 |||||||||||||||| 0.2.0.0 || ||=`ghci` =|| 0 |||||||||||||||||||||||||||||||||||| <em>none</em> || ||=`haskeline` =|| 0.7.2.2 |||||| 0.7.2.1 |||| 0.7.1.2 |||||||||||||||||||||||||| <em>none</em> || ||=`haskell2010` =|||||||| <em>none</em> |||||||| 1.1.2.0* |||||| 1.1.1.0* |||| 1.1.0.1* |||| 1.1.0.0* |||||||| 1.0.0.0* || ||=`haskell98` =|||||||| <em>none</em> |||||||| 2.0.0.3* |||||| 2.0.0.2* |||| 2.0.0.1* |||| 2.0.0.0* |||||| 1.1.0.1 || 1.1.0.0 || ||=`hoopl` =|| 3.10.2.0 |||||| 3.10.0.2 |||||||| 3.10.0.1 |||||| 3.9.0.0 |||| 3.8.7.3 |||| 3.8.7.1 |||||||| <em>none</em> || ||=`hpc` =|||||||| 0.6.0.2 |||||||| 0.6.0.1 |||||| 0.6.0.0 |||| 0.5.1.1 |||| 0.5.1.0 |||||||| 0.5.0.6 || ||=`integer-gmp` =|||||||| 1.0.0.0 |||||||| 0.5.1.0 |||||| 0.5.0.0 |||| 0.4.0.0 |||| 0.3.0.0 |||||| 0.2.0.3 || 0.2.0.2 || ||=`old-locale` =|||||||| <em>none</em> |||||||| 1.0.0.6 |||||| 1.0.0.5 |||| 1.0.0.4 |||| 1.0.0.3 |||||||| 1.0.0.2 || ||=`old-time` =|||||||| <em>none</em> |||||||| 1.1.0.2 |||||| 1.1.0.1 |||| 1.1.0.0 |||| 1.0.0.7 |||||||| 1.0.0.6 || ||=`pretty` =|| 1.1.3.2 |||||| 1.1.2.0 |||||||| 1.1.1.1 |||||||||| 1.1.1.0 |||| 1.1.0.0 |||||||| 1.0.1.2 || ||=`process` =|| 1.4.1.0 |||||| 1.2.3.0 |||||||| 1.2.0.0 |||||| 1.1.0.2 |||| 1.1.0.1 |||| 1.1.0.0 |||||| 1.0.1.5 || 1.0.1.4 || ||=`random` =|||||||||||||||||||||||||||||| <em>none</em> |||||||| 1.0.0.3 || ||=`rts` =|||||||||||||||||||||||||||||||||||||| 1.0 || ||=`template-haskell` =|| 2.11.0.0 |||||| 2.10.0.0 |||||||| 2.9.0.0 |||||| 2.8.0.0 |||| 2.7.0.0 |||| 2.6.0.0 |||||||| 2.5.0.0 || ||=`terminfo` =|| 0.4.0.2 |||||| 0.4.0.1 |||| 0.4.0.0 |||||||||||||||||||||||||| <em>none</em> || ||=`time` =|| 1.6 |||||| 1.5.0.1 |||||||| 1.4.2 |||||| 1.4.0.1 |||| 1.4 |||| 1.2.0.5 |||||||| 1.2.0.3 || ||=`transformers` =|| 0.5.0.0 |||||| 0.4.2.0 |||||||| 0.3.0.0 |||||||||||||||||||||| <em>none</em> || ||=`unix` =|| 2.7.1.1 |||||| 2.7.1.0 |||||||| 2.7.0.1 |||| 2.6.0.1 || 2.6.0.0 || 2.5.1.1 || 2.5.1.0 |||| 2.5.0.0 |||||| 2.4.2.0 || 2.4.1.0 || ||=`xhtml` =|||||||||||| 3000.2.1 |||||||||||||||||||||||||| <em>none</em> || || ||= <strong>HEAD</strong> =||= <strong>7.10.3</strong> =||= <strong>7.10.2</strong> =||= <strong>7.10.1</strong> =||= <strong>7.8.4</strong> =||= <strong>7.8.3</strong> =||= <strong>7.8.2</strong> =||= <strong>7.8.1</strong> =||= <strong>7.6.3</strong> =||= <strong>7.6.2</strong> =||= <strong>7.6.1</strong> =||= <strong>7.4.2</strong> =||= <strong>7.4.1</strong> =||= <strong>7.2.2</strong> =||= <strong>7.2.1</strong> =||= <strong>7.0.4</strong> =||= <strong>7.0.3</strong> =||= <strong>7.0.2</strong> =||= <strong>7.0.1</strong> =||</p>
<p>Note: A `*` after the version number denotes the package being hidden by default.</p>
<p>A table covering some GHC 6.* releases can be found at <a href="https://wiki.haskell.org/Libraries_released_with_GHC" class="uri">https://wiki.haskell.org/Libraries_released_with_GHC</a></p>
<p>= Warnings and Deprecations</p>
<p>For now, see the relevant <a href="http://downloads.haskell.org/~ghc/latest/docs/html/users_guide/pragmas.html#warning-deprecated-pragma">GHC User's Guide Section</a> describing the `DEPRECATE` and `WARNING` pragmas.</p>
<p>TODO</p>
<h1 id="ghc-commentary-weak-pointers-and-finalizers">GHC Commentary: Weak Pointers and Finalizers</h1>
<hr />
<p>CategoryStub <a href="PageOutline" class="uri" title="wikilink">PageOutline</a></p>
<h1 id="work-in-progress-on-the-llvm-backend">Work in Progress on the LLVM Backend</h1>
<p>This page is meant to collect together information about people working on (or interested in working on) LLVM in GHC, and the projects they are looking at. See also the [wiki:Commentary/Compiler/NewCodeGen state of play of the whole back end]. This is more a page of ideas for improvements to the LLVM backend and less so an indication of actual work going on.</p>
<h3 id="llvm-ir-representation">LLVM IR Representation</h3>
<p>The LLVM IR is modeled in GHC using an algebraic data type to represent the first order abstract syntax of the LLVM assembly code. The LLVM representation lives in the 'Llvm' subdirectory and also contains code for pretty printing. This is the same approach taken by EHC's LLVM Back-end, and we adapted the module developed by them for this purpose.</p>
<p>The current design is overly complicated and could be faster. It uses String + show operations for printing for example when it should be using !FastString + Outputable. Before simplifying this design though it would be good to investigate using the LLVM API instead of the assembly language for interacting with LLVM. This would be done most likely by using the pre-existing Haskell LLVM API bindings found <a href="http://hackage.haskell.org/package/llvm">here</a>. This should hopefully provide a speed up in compilation speeds which is greatly needed since the LLVM back-end is ~2x slower at the moment.</p>
<h3 id="tables_next_to_code-1">TABLES_NEXT_TO_CODE</h3>
<p>We now support [wiki:Commentary/Compiler/Backends/LLVM/Issues#TABLES_NEXT_TO_CODE TNTC] using an approach of gnu as subsections. This seems to work fine but we would like still to move to a pure LLVM solution. Ideally we would implement this in LLVM by allowing a global variable to be associated with a function, so that LLVM is aware that the two will be laid out next to each other and can better optimise (e.g using this approach LLVM should be able to perform constant propagation on info-tables).</p>
<p><strong>Update (30/06/2010):</strong> The current TNTC solution doesn't work on Mac OS X. So we need to implement an LLVM based solution. We currently support OS X by post processing the assembly. Pure LLVM is a nicer way forward.</p>
<h3 id="llvm-alias-analysis-pass">LLVM Alias Analysis Pass</h3>
<p><strong>Update: This has been implemented, needs more work though</strong></p>
<p>LLVM doesn't seem to do a very good job of figuring out what can alias what in the code generated by GHC. We should write our own alias analysis pass to fix this.</p>
<h3 id="optimise-llvm-for-the-type-of-code-ghc-produces">Optimise LLVM for the type of Code GHC produces</h3>
<p>At the moment only a some fairly basic benchmarking has been done of the LLVM back-end. Enough to give an indication of how it performs on the whole (well as far as you trust benchmarks anyway) and of what it can sometimes achieve. However this is by no means exauhstive or probably even close to it and doesn't give us enough information about the areas where LLVM performs badly. The LLVM optimisation pass also at the moment just uses the standard '-O[123]' levels, which like GCC entail a whole bunch of optimisation passes. These groups are designed for C programs mostly.</p>
<p>So:</p>
<p><code>*Morebenchmarking,particularlyfindingsomebadspotsfortheLLVMback-endandgeneratingagoodpictureofthecharacteristicsoftheback-end.</code><br />
<code>*LookintotheLLVMoptimiser,e.gperhapssomemoreworkinthestyleof</code><a href="http://donsbot.wordpress.com/2010/03/01/evolving-faster-haskell-programs-now-with-llvm/"><code>Don's</code> <code>work</code></a><br />
<code>*LookatanynewoptimisationpassesthatcouldbewrittenforLLVMwhichwouldhelptoimprovethecodeitgeneratesforGHC.</code><br />
<code>*Lookatgeneralfixes/improvementtoLLVMtoimprovethecodeitgeneratesforLLVM.</code><br />
<code>*SometimesthereisabenefitfromrunningtheLLVMoptimisertwiceofthecode(e.gopt-O3|opt-O3...).WeshouldaddacommandlineflagthatallowsyoutospecifythenumberofiterationsyouwanttheLLVMoptimisertodo.</code></p>
<h3 id="update-the-back-end-to-use-the-new-cmm-data-types-new-code-generator">Update the Back-end to use the new Cmm data types / New Code Generator</h3>
<p>There is ongoing work to produce a new, nicer, more modular code generator for GHC (the slightly confusingly name code generator in GHC refers to the pipeline stage where the Core IR is compiled to the Cmm IR). The LLVM back-end could be updated to make sure it works with the new code generator and does so in an efficient manner.</p>
<h3 id="llvms-link-time-optimisations">LLVM's Link Time Optimisations</h3>
<p>One of LLVM's big marketing features is its support for link time optimisation. This does things such as in-lining across module boundaries, more aggressive dead code elimination... etc). The LLVM back-end could be updated to make use of this. Roman apparently tried to use the new 'gold' linker with GHC and it doesn't support all the needed features.</p>
<p><code>*</code><a href="http://llvm.org/releases/2.6/docs/LinkTimeOptimization.html"><code>22</code></a><br />
<code>*</code><a href="http://llvm.org/docs/GoldPlugin.html"><code>23</code></a></p>
<h3 id="llvm-cross-compiler-port">LLVM Cross Compiler / Port</h3>
<p>This is more of an experimental idea but the LLVM back-end looks like it would make a great choice for Porting LLVM. That is, instead of porting LLVM through the usual route of via-C and then fixing up the NCG, just try to do it all through the LLVM back-end. As LLVM is quite portable and supported on more platforms then GHC, it would be an interesting and valuable experiment to try to port GHC to a new platform by simply getting the LLVM back-end working on it. (The LLVM back-end works in both unregistered and registered mode, another advantage for porting compared to the C and NCG back-ends).</p>
<p>It would also be interesting to looking into improving GHC to support cross compiling and doing this through the LLVM back-end as it should be easier to fix up to support this feature than the C or NCG back-ends.</p>
<h3 id="get-rid-of-proc-point-splitting">Get rid of Proc Point Splitting</h3>
<p>When Cmm code is first generated a single Haskell function will be mostly compiled to one Cmm function. This Cmm function isn't passed to the backends though as the CPS style used in it requires that the backends be able to take the address of labels in a function since they're used as return points. The C backend can't support this. While there is a GNU C extension allowing the address of a label to be taken, the address can only be used locally (in the same function). So what proc point splitting does is cut a single Cmm function into multiple top level Cmm functions so that instead of needing to take the address of a label, we now take the address of a function.</p>
<p>It would be nice to get rid of proc point splitting. This is one of the goals for the new code generator. This will give us much bigger Cmm functions which should give more room for LLVM to optimise. There is an issue though that LLVM doesn't support taking the address of a local label either. So will need to add support to LLVM for taking label addresses or convert CPS style into something more direct if thats possible.</p>
<h3 id="dont-pass-around-dead-stg-registers">Don't Pass Around Dead STG Registers</h3>
<p><strong>Update: This has been implemented</strong></p>
<p>At the moment in the LLVM backend we always pass around the pinned STG registers as arguments for every Cmm function. A huge amount of the time though we aren't storing anything in the STG registers, they are dead really. If we can treat the correctly as dead then LLVM will have more free registers and the allocator should do a better job. We need to change the STG -&gt; Cmm code generator to attach register liveness information at function exit points (e.g calls, jumps, returns).</p>
<p>e.g This <a href="http://hackage.haskell.org/trac/ghc/ticket/4308">bug (#4308)</a> is as a result of this problem.</p>
<p><a href="PageOutline" class="uri" title="wikilink">PageOutline</a></p>
<h1 id="wired-in-and-known-key-things">Wired-in and known-key things</h1>
<p>There are three categories of entities that GHC &quot;knows about&quot;; that is, information about them is baked into GHC's source code.</p>
<p><code>*[wiki:Commentary/Compiler/WiredIn#WiredinthingsWired-inthings]---GHCknowseverythingaboutthese</code><br />
<code>*[wiki:Commentary/Compiler/WiredIn#KnownkeythingsKnown-keythings]---GHCknowsthe</code><em><code>name</code></em><code>,includingthe</code><code>,butnotthedefinition</code><br />
<code>*[wiki:Commentary/Compiler/WiredIn#OrigRdrNamethingsOrigRdrNamethings]---GHCknowswhichmoduleit'sdefinedin</code></p>
<h2 id="wired-in-things">Wired-in things</h2>
<p>A <strong>Wired-in thing</strong> is fully known to GHC. Most of these are `TyCon`s such as `Bool`. It is very convenient to simply be able to refer to `boolTyCon :: TyCon` without having to look it up in an environment.</p>
<p>All [wiki:Commentary/Compiler/TypeType#Classifyingtypes primitive types] are wired-in things, and have wired-in `Name`s. The primitive types (and their `Names`) are all defined in <a href="GhcFile(compiler/prelude/TysPrim.hs)" class="uri" title="wikilink">GhcFile(compiler/prelude/TysPrim.hs)</a>.</p>
<p>The non-primitive wired-in type constructors are defined in <a href="GhcFile(compiler/prelude/TysWiredIn.hs)" class="uri" title="wikilink">GhcFile(compiler/prelude/TysWiredIn.hs)</a>. There are a handful of wired-in `Id`s in <a href="GhcFile(compiler/basicTypes/MkId.hs)" class="uri" title="wikilink">GhcFile(compiler/basicTypes/MkId.hs)</a>. There are no wired-in classes (they are too complicated).</p>
<p>All the non-primitive wired-in things are <em>also</em> defined in GHC's libraries, because even though GHC knows about them we still need to generate code for them. For example, `Bool` is a wired-in type constructor, but it is still defined in `GHC.Base` because we need the info table etc for the data constructors. Arbitrarily bad things will happen if the wired-in definition in <a href="GhcFile(compiler/prelude/TysWiredIn.hs)" class="uri" title="wikilink">GhcFile(compiler/prelude/TysWiredIn.hs)</a> differs from that in the library module.</p>
<p>All wired-in things have a `WiredIn` `Name` (see [wiki:Commentary/Compiler/NameType Names]), which in turn contains the thing. See [wiki:Commentary/Compiler/CaseStudies/Bool a case study of Bool implementation] for more details.</p>
<h2 id="known-key-things-1">Known-key things</h2>
<p>A <strong>known-key thing</strong> has a fixed, pre-allocated `Unique` or <strong>key</strong>. They should really be called &quot;known-Name&quot; things, because the baked-in knowledge is:</p>
<p><code>*Itsdefining`Module`</code><br />
<code>*Its`OccName`</code><br />
<code>*Its`Unique`</code></p>
<p>Almost all known-key names are defined in <a href="GhcFile(compiler/prelude/PrelNames.hs)" class="uri" title="wikilink">GhcFile(compiler/prelude/PrelNames.hs)</a>; for example: .</p>
<p>The point about known-key things is that GHC knows its <em>name</em>, but not its <em>definition</em>. The definition must still be read from an interface file as usual. The known key just allows an efficient lookup in the environment.</p>
<h2 id="initialisation">Initialisation</h2>
<p>When reading an interface file, GHC might come across &quot;GHC.Base.Eq&quot;, which is the name of the `Eq` class. How does it match up this occurrence in the interface file with `eqClassName` defined in `PrelNames`? Because the global name cache maintained by the renamer is initialised with all the known-key names. This is done by the (hard-to-find) function `HscMain.newHscEnv`:  Notice that the initialisation embraces both the wired-in and (&quot;basic&quot;) known-key names.</p>
<h2 id="orig-rdrname-things">`Orig` `RdrName` things</h2>
<p>An <strong>Orig !RdrName thing</strong> has a top-level definition of a `RdrName`, using the `Orig` constructor. Here, the baked-in information is:</p>
<p><code>*Itsdefining`Module`</code><br />
<code>*Its`OccName`</code></p>
<p>Again, almost all of these are in <a href="GhcFile(compiler/prelude/PrelNames.hs)" class="uri" title="wikilink">GhcFile(compiler/prelude/PrelNames.hs)</a>. Example: .</p>
<h1 id="ghc-commentary-the-word">GHC Commentary: The Word</h1>
<p>The most important type in the runtime is , defined in <a href="GhcFile(includes/stg/Types.h)" class="uri" title="wikilink">GhcFile(includes/stg/Types.h)</a>. A word is defined to be the same size as a pointer on the current platform. All these types are interconvertible without losing information, and have the same size (as reported by ):</p>
<p><code>::</code><br />
<code>Anunsigedintegraltypeofwordsize</code></p>
<p><code>::</code><br />
<code>Asignedintegraltypeofwordsize</code></p>
<p><code>::</code><br />
<code>Pointerto</code></p>
<p>The word is the basic unit of allocation in GHC: the heap and stack are both allocated in units of a word. Throughout the runtime we often use sizes that are in units of words, so as to abstract away from the real word size of the underlying architecture.</p>
<p>The `StgWord` type is also useful for storing the <em>size</em> of a memory object, since an `StgWord` is guaranteed to at least span the range of addressable memory. It is rather like `size_t` in this respect, although we prefer to use `StgWord` in the RTS sources.</p>
<p>C-- only understands units of bytes, so we have various macros in <a href="GhcFile(includes/Cmm.h)" class="uri" title="wikilink">GhcFile(includes/Cmm.h)</a> to make manipulating things in units of words easier in  files.</p>
</body>
</html>
